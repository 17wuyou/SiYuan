{"ID":"20250914144634-v8qdr7p","Spec":"1","Type":"NodeDocument","Properties":{"id":"20250914144634-v8qdr7p","title":"01 语言模型是少样本学习者","type":"doc","updated":"20250915174549"},"Children":[{"ID":"20250914144634-378an50","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250914144634-378an50","updated":"20250915174549"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"摘要"}]},{"ID":"20250914145152-lmvdjbl","Type":"NodeParagraph","Properties":{"id":"20250914145152-lmvdjbl","updated":"20250914145210"},"Children":[{"Type":"NodeText","Data":"近期的研究表明，通过在大型文本语料库上进行预训练，然后在特定任务上进行微调，可以在许多自然语言处理（NLP）任务和基准测试中取得显著的进步。然而，这种方法虽然在架构上通常是与任务无关的，但仍然需要针对特定任务的、包含数千或数万个样本的微调数据集。相比之下，人类通常可以仅通过几个例子或简单的指令来完成一个新的语言任务——这是当前自然语言处理系统在很大程度上难以做到的。在这里，我们展示了扩大语言模型的规模可以极大地提高与任务无关的、少样本（few-shot）学习的性能，有时甚至能达到与先前最先进的微调方法相媲美的水平。具体来说，我们训练了一个名为GPT-3的自回归语言模型，它拥有1750亿个参数，比之前任何非稀疏语言模型都要大10倍，并在少样本学习的设置下测试其性能。对于所有任务，GPT-3在应用时都没有进行任何梯度更新或微调，任务和少样本的演示完全通过与模型的文本交互来指定。GPT-3在许多NLP数据集上都取得了强大的性能，包括翻译、问答和完形填空任务，以及一些需要即时推理或领域适应的任务，例如打乱单词、在句子中使用一个新词，或者进行三位数的算术运算。与此同时，我们也发现了一些数据集，在这些数据集上GPT-3的少样本学习仍然存在困难，以及一些由于在大型网络语料库上训练而面临方法论问题的数据集。最后，我们发现GPT-3可以生成新闻文章的样本，人类评估者很难区分这些文章与人类写的文章。我们讨论了这一发现以及GPT-3在更广泛的社会层面上的意义。"}]},{"ID":"20250914145214-6jhjw5d","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250914145214-6jhjw5d","updated":"20250915174549"},"Children":[{"Type":"NodeText","Data":"1. 引言"}]},{"ID":"20250914145323-59ttkug","Type":"NodeParagraph","Properties":{"id":"20250914145323-59ttkug","updated":"20250914145323"},"Children":[{"Type":"NodeText","Data":"近几年来，自然语言处理（NLP）系统出现了一个趋势，即在大型文本语料库上进行预训练，以吸收其中丰富的语言信息，然后在特定任务上进行微调以实现迁移学习。最初，单层表示是通过词向量 [MCCP+13, PSM14] 学习的，并被输入到针对特定任务的架构中。后来，具有多层表示和上下文状态的循环神经网络（RNN）被用于更强的预训练表示 [DCLT15, MBXS+17, PYLZ17]（尽管仍然适用于特定任务的架构）。最近，预训练的循环神经网络或Transformer语言模型 [VSP+17] 被直接进行微调，完全移除了对特定任务架构的需求 [RNSS18, DCLT18, HR18]。"}]},{"ID":"20250914145323-pcd4hhr","Type":"NodeParagraph","Properties":{"id":"20250914145323-pcd4hhr","updated":"20250915174549"},"Children":[{"Type":"NodeText","Data":"这一最新的范式在许多具有挑战性的NLP任务上取得了实质性的进展，例如阅读理解、问答、文本蕴含等等，并且基于新的架构和算法[RSR+19, LOG+19, YDY+19, LCG+19]，这一进展还在继续。然而，这种方法的一个主要限制是，虽然其在性能上是与任务无关的，但它仍然需要在特定任务的数据集上进行特定任务的微调，才能达到强大的性能。一个架构通常需要在一个包含数万到数十万个例子的数据集上进行微调才能正常运作。消除这一限制有几个原因。"}]},{"ID":"20250914145323-o5om1vm","Type":"NodeParagraph","Properties":{"id":"20250914145323-o5om1vm","updated":"20250914145323"},"Children":[{"Type":"NodeText","Data":"首先，从实践的角度来看，为每个新任务都需要一个庞大的标记样本数据集，这限制了语言模型的适用性。可能的标签示例范围非常广泛，从纠正语法、生成一个抽象概念的例子，到批评一个短篇故事。对于许多这样的任务，收集大量的监督训练数据是困难的，特别是当这个过程需要为每个新任务重复进行时。"}]},{"ID":"20250914145323-lg2fa4y","Type":"NodeParagraph","Properties":{"id":"20250914145323-lg2fa4y","updated":"20250914145323"},"Children":[{"Type":"NodeText","Data":"其次，随着模型表达能力的增强和训练分布的狭窄，利用虚假相关性的潜力也随之增长。这给预训练加微调的范式带来了问题，在这种范式中，模型被设计为在预训练期间吸收大量信息，但随后在非常狭窄的任务分布上进行微调。有证据表明，在这种范式下，模型的泛化能力可能并不好，模型只是过度拟合了训练分布，并且在分布外（out-of-distribution）的情况下表现不佳 [YCS+19, MPL19]。因此，微调模型在特定基准测试上的性能可能夸大了在人类通常执行的更广泛的任务上的实际性能 [GS18, NS19]。"}]},{"ID":"20250914145323-7enfqjr","Type":"NodeParagraph","Properties":{"id":"20250914145323-7enfqjr","updated":"20250914145408"},"Children":[{"Type":"NodeText","Data":"第三，人类不需要大量的监督数据集来学习大多数语言任务——一个简短的自然语言指令（例如，“请告诉我这句话是描述了快乐还是悲伤的事情”）或者最多几个任务演示的例子（例如，“这里有两个勇敢行为的例子；请给出第三个勇敢行为的例子”）通常就足以使人类能够执行一个新的语言任务，使其达到至少合理的胜任水平。与我们当前NLP技术的这种适应性相比，这种能力在实践中具有很大的优势——它允许人类无缝地混合或在许多任务和技能之间切换，例如，在进行长时间的对话时，可以临时加入一个拼写校正。要广泛地使用，我们希望我们的NLP系统也能拥有同样的流畅性和通用性。"}]},{"ID":"20250914145819-6eh8hzu","Type":"NodeParagraph","Properties":{"id":"20250914145819-6eh8hzu","updated":"20250914145918"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914145819-hpxrdiq.png"},{"Type":"NodeLinkSpace"},{"Type":"NodeLinkTitle","Data":"图 1.1：语言模型元学习 在无监督预训练期间，语言模型发展出一套广泛的技能和模式识别能力。然后，它在推理时使用这些能力来快速适应或识别期望的任务。我们使用术语“上下文学习”（in-context learning）来指代这个内循环过程，这个过程在每个序列的前向传播过程中发生。这些图中的序列并非模型在训练期间看到的，而是旨在说明模型在预训练后是如何工作的，但它们是有意被构造成类似于训练数据中嵌入的重复子任务的。"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250914145422-5n2ka23","Type":"NodeParagraph","Properties":{"id":"20250914145422-5n2ka23","updated":"20250914145422"},"Children":[{"Type":"NodeText","Data":"解决这些问题的一个潜在途径是“元学习”（meta-learning）——在语言模型的背景下，模型在训练时发展出一套广泛的技能和模式识别能力，然后在推理时利用这些能力快速适应或识别所需的任务。最近的工作 [RWC+19] 试图通过我们称之为“条件式自然语言学习”（conditioned on a natural language instruction）或几个任务演示的文本输入来做到这一点，而不是通过显式的任务规范；模型被条件化在一个自然语言指令和/或几个任务的演示上，并被期望通过预测接下来会出现什么来完成任务的其余部分。"}]},{"ID":"20250914145422-gi30lz8","Type":"NodeParagraph","Properties":{"id":"20250914145422-gi30lz8","updated":"20250914145422"},"Children":[{"Type":"NodeText","Data":"虽然这已经显示出一些初步的希望，但这种方法仍然比微调差得多——例如，[RWC+19] 在Natural Questions上的准确率只有4%，即使其在CoQA上的55 F1得分现在也比最先进水平低35个点。元学习清楚地需要大量的改进，才能成为一种可行的解决语言任务的方法。"}]},{"ID":"20250914145422-ugn68lt","Type":"NodeParagraph","Properties":{"id":"20250914145422-ugn68lt","updated":"20250914145422"},"Children":[{"Type":"NodeText","Data":"语言建模的另一个近期趋势可能提供一条更有希望的前进道路。近年来，Transformer语言模型的容量已经大幅增加，从 [RNSS18] 的1亿个参数，到 [DCLT18] 的3亿个参数，到 [RWC+19] 的80亿个参数，到 [SPP+19] 的110亿个参数，到 [RSR+19] 的170亿个参数，最后到 [TUR+20] 的170亿个参数。每一次规模的扩大都在文本合成和/或下游NLP任务上带来了改进，并且有证据表明，对数损失（log loss）与许多下游任务的改善有很强的相关性，这遵循了随规模平滑提升的趋势 [KMH+20]。由于上下文学习（in-context learning）涉及吸收在模型参数内编码的许多技能和任务，因此有理由认为，上下文学习能力也可能随着规模的扩大而显示出强大的增长。"}]},{"ID":"20250914150215-v52kw0t","Type":"NodeParagraph","Properties":{"id":"20250914150215-v52kw0t","updated":"20250914150422"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914150215-y77j6x3.png"},{"Type":"NodeLinkSpace"},{"Type":"NodeLinkTitle","Data":"图 1.2: 更大的模型在利用上下文学习方面效率显著更高 我们展示了在一个需要从单词中移除随机符号的简单任务上，上下文学习的有效性。我们展示了在有和没有自然语言任务描述（见3.9.2节）的情况下，上下文学习的效果。对于大型模型，曲线更陡峭，表明它们学习任务的能力更强。我们在各种任务中都定性地观察到了类似的行为。"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250914150449-wrkaht6","Type":"NodeBlockquote","Properties":{"id":"20250914150449-wrkaht6","updated":"20250914150533"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914150533-0gpzwct","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914150533-0gpzwct","updated":"20250914150533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 1.1：语言模型元学习 (Figure 1.1: Language model meta-learning)"}]},{"ID":"20250914150533-os67q9h","Type":"NodeParagraph","Properties":{"id":"20250914150533-os67q9h","updated":"20250914150533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容:"}]},{"ID":"20250914150533-o0bka0n","Type":"NodeList","ListData":{},"Properties":{"id":"20250914150533-o0bka0n","updated":"20250914150533"},"Children":[{"ID":"20250914150533-xy7h707","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150533-xy7h707","updated":"20250914150533"},"Children":[{"ID":"20250914150533-987ob84","Type":"NodeParagraph","Properties":{"id":"20250914150533-987ob84","updated":"20250914150533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外循环 (outer loop):"},{"Type":"NodeText","Data":" 通过无监督预训练进行学习 (Learning via SGD during unsupervised pre-training)"}]}]},{"ID":"20250914150533-ev524bi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150533-ev524bi","updated":"20250914150533"},"Children":[{"ID":"20250914150533-d86v4uv","Type":"NodeParagraph","Properties":{"id":"20250914150533-d86v4uv","updated":"20250914150533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内循环 (inner loop):"},{"Type":"NodeText","Data":" 上下文学习 (In-context Learning)"}]}]},{"ID":"20250914150533-di5ca9i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150533-di5ca9i","updated":"20250914150533"},"Children":[{"ID":"20250914150533-x4q1pr0","Type":"NodeParagraph","Properties":{"id":"20250914150533-x4q1pr0","updated":"20250914150533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"序列 #1, #2, #3 (sequence #1, #2, #3):"},{"Type":"NodeText","Data":" 展示了不同的上下文学习示例，包括算术、拼写纠正和法语翻译。"}]}]}]}]},{"ID":"20250914150450-o4t5bw6","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914150450-o4t5bw6","updated":"20250914150619"},"Children":[{"ID":"20250914150619-390xjd5","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914150619-390xjd5","updated":"20250914150619"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 1.2：更大的模型在利用上下文学习方面效率显著更高"}]},{"ID":"20250914150619-minrj3y","Type":"NodeParagraph","Properties":{"id":"20250914150619-minrj3y","updated":"20250914150620"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容:"}]},{"ID":"20250914150619-dmi6nx1","Type":"NodeList","ListData":{},"Properties":{"id":"20250914150619-dmi6nx1","updated":"20250914150620"},"Children":[{"ID":"20250914150619-92og7p6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150619-92og7p6","updated":"20250914150619"},"Children":[{"ID":"20250914150619-902ik7u","Type":"NodeParagraph","Properties":{"id":"20250914150619-902ik7u","updated":"20250914150619"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (%) (Accuracy (%))"}]}]},{"ID":"20250914150619-4ylekp7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150619-4ylekp7","updated":"20250914150619"},"Children":[{"ID":"20250914150619-oohma6d","Type":"NodeParagraph","Properties":{"id":"20250914150619-oohma6d","updated":"20250914150619"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 上下文中的示例数量 (K) (Number of Examples in Context (K))"}]}]},{"ID":"20250914150619-tp172ku","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150619-tp172ku","updated":"20250914150619"},"Children":[{"ID":"20250914150619-gr5bdml","Type":"NodeParagraph","Properties":{"id":"20250914150619-gr5bdml","updated":"20250914150619"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"}]},{"ID":"20250914150619-ts7pwuj","Type":"NodeList","ListData":{},"Properties":{"id":"20250914150619-ts7pwuj","updated":"20250914150619"},"Children":[{"ID":"20250914150619-ggvkf6y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150619-ggvkf6y","updated":"20250914150619"},"Children":[{"ID":"20250914150619-nyrd8vr","Type":"NodeParagraph","Properties":{"id":"20250914150619-nyrd8vr","updated":"20250914150619"},"Children":[{"Type":"NodeText","Data":"175B Params (1750亿参数)"}]}]},{"ID":"20250914150619-rhooonz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150619-rhooonz","updated":"20250914150619"},"Children":[{"ID":"20250914150619-ks816xo","Type":"NodeParagraph","Properties":{"id":"20250914150619-ks816xo","updated":"20250914150619"},"Children":[{"Type":"NodeText","Data":"13B Params (130亿参数)"}]}]},{"ID":"20250914150619-169jhrs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150619-169jhrs","updated":"20250914150619"},"Children":[{"ID":"20250914150619-yjdr1i4","Type":"NodeParagraph","Properties":{"id":"20250914150619-yjdr1i4","updated":"20250914150619"},"Children":[{"Type":"NodeText","Data":"1.3B Params (13亿参数)"}]}]},{"ID":"20250914150619-sbxz8sh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150619-sbxz8sh","updated":"20250914150619"},"Children":[{"ID":"20250914150619-ln91w99","Type":"NodeParagraph","Properties":{"id":"20250914150619-ln91w99","updated":"20250914150619"},"Children":[{"Type":"NodeText","Data":"Natural Language Prompt (自然语言提示)"}]}]},{"ID":"20250914150619-05ng4f7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150619-05ng4f7","updated":"20250914150619"},"Children":[{"ID":"20250914150619-f6xrlyb","Type":"NodeParagraph","Properties":{"id":"20250914150619-f6xrlyb","updated":"20250914150619"},"Children":[{"Type":"NodeText","Data":"No Prompt (无提示)"}]}]}]}]}]},{"Type":"NodeBlockquoteMarker","Data":"\u003e","Properties":{"updated":"20250914150620"}}]},{"ID":"20250914150539-61zrwq7","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914150539-61zrwq7","updated":"20250914150647"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914150647-4ftiq8m","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250914150647-4ftiq8m","updated":"20250914150647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250914150647-nrdefdo","Type":"NodeParagraph","Properties":{"id":"20250914150647-nrdefdo","updated":"20250914150647"},"Children":[{"Type":"NodeText","Data":"这篇论文节选的核心思想是，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过极大地增加语言模型的规模，可以使其在不需要针对特定任务进行微调的情况下，仅通过少量示例（Few-shot）甚至零示例（Zero-shot）就能很好地完成新任务。"},{"Type":"NodeText","Data":" 这标志着从传统的“预训练+微调”范式向一种更灵活、更接近人类学习方式的“上下文学习”（In-context Learning）范式的转变。"}]}]},{"ID":"20250914150635-xrn1j7p","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914150635-xrn1j7p","updated":"20250914150708"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914150708-c92wvvx","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914150708-c92wvvx","updated":"20250914150708"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键概念解析"}]},{"ID":"20250914150708-ly4dbra","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250914150708-ly4dbra","updated":"20250914150708"},"Children":[{"ID":"20250914150708-2dfc616","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250914150708-2dfc616","updated":"20250914150708"},"Children":[{"ID":"20250914150708-2husc1h","Type":"NodeParagraph","Properties":{"id":"20250914150708-2husc1h","updated":"20250914150708"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练 (Pre-training) 和微调 (Fine-tuning):"}]},{"ID":"20250914150708-otd02gz","Type":"NodeList","ListData":{},"Properties":{"id":"20250914150708-otd02gz","updated":"20250914150708"},"Children":[{"ID":"20250914150708-sxck3it","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150708-sxck3it","updated":"20250914150708"},"Children":[{"ID":"20250914150708-tsi2zw6","Type":"NodeParagraph","Properties":{"id":"20250914150708-tsi2zw6","updated":"20250914150708"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练："},{"Type":"NodeText","Data":" 在大规模的、无标签的文本数据上训练一个通用的语言模型，让它学习语言的普遍规律、语法、事实知识等。"}]}]},{"ID":"20250914150708-cm8fxws","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150708-cm8fxws","updated":"20250914150708"},"Children":[{"ID":"20250914150708-cm5ep4q","Type":"NodeParagraph","Properties":{"id":"20250914150708-cm5ep4q","updated":"20250914150708"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调："},{"Type":"NodeText","Data":" 将预训练好的模型在一个规模较小但有标签的、针对特定任务的数据集上继续训练，使模型的参数适应这个特定任务。这是GPT-3之前的主流方法，但缺点是需要为每个新任务收集和标注数据。"}]}]}]}]},{"ID":"20250914150708-yf8xxdz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250914150708-yf8xxdz","updated":"20250914150708"},"Children":[{"ID":"20250914150708-6v91ph6","Type":"NodeParagraph","Properties":{"id":"20250914150708-6v91ph6","updated":"20250914150708"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本学习 (Few-shot Learning):"}]},{"ID":"20250914150708-bq5q76o","Type":"NodeList","ListData":{},"Properties":{"id":"20250914150708-bq5q76o","updated":"20250914150708"},"Children":[{"ID":"20250914150708-yfzpby2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150708-yfzpby2","updated":"20250914150708"},"Children":[{"ID":"20250914150708-7hg76ni","Type":"NodeParagraph","Properties":{"id":"20250914150708-7hg76ni","updated":"20250914150708"},"Children":[{"Type":"NodeText","Data":"指的是模型在只看到极少数（通常是1到几十个）任务示例的情况下学习新任务的能力。"}]}]},{"ID":"20250914150708-wuiswe3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150708-wuiswe3","updated":"20250914150708"},"Children":[{"ID":"20250914150708-ytmpzl8","Type":"NodeParagraph","Properties":{"id":"20250914150708-ytmpzl8","updated":"20250914150708"},"Children":[{"Type":"NodeText","Data":"这篇论文中还提到了 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单样本学习 (One-shot)"},{"Type":"NodeText","Data":"，即只给一个例子，和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本学习 (Zero-shot)"},{"Type":"NodeText","Data":"，即不给任何例子，只给任务的自然语言描述。"}]}]}]}]},{"ID":"20250914150708-0kbratz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250914150708-0kbratz","updated":"20250914150708"},"Children":[{"ID":"20250914150708-p3c33ey","Type":"NodeParagraph","Properties":{"id":"20250914150708-p3c33ey","updated":"20250914150708"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (In-context Learning):"}]},{"ID":"20250914150708-2vopaz2","Type":"NodeList","ListData":{},"Properties":{"id":"20250914150708-2vopaz2","updated":"20250914150708"},"Children":[{"ID":"20250914150708-q2ihba1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150708-q2ihba1","updated":"20250914150708"},"Children":[{"ID":"20250914150708-jaupih7","Type":"NodeParagraph","Properties":{"id":"20250914150708-jaupih7","updated":"20250914150708"},"Children":[{"Type":"NodeText","Data":"这是GPT-3实现少样本学习的核心机制。 模型不是通过更新其内部参数（梯度更新）来学习新任务，而是在其接收的“上下文”（即提示或prompt）中直接包含任务的描述和几个示例。"}]}]},{"ID":"20250914150708-pk30p1b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150708-pk30p1b","updated":"20250914150708"},"Children":[{"ID":"20250914150708-w184r02","Type":"NodeParagraph","Properties":{"id":"20250914150708-w184r02","updated":"20250914150708"},"Children":[{"Type":"NodeText","Data":"模型在处理这个上下文时，会“理解”任务的模式，然后在没有看到任何示例的情况下，对新的输入给出正确的输出。这就像给一个聪明人看几个例子，他就能举一反三。"}]}]}]}]}]}]},{"ID":"20250914150635-m1qgjzs","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914150635-m1qgjzs","updated":"20250914150726"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914150726-0av011q","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914150726-0av011q","updated":"20250914150726"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"论文核心论点与贡献"}]},{"ID":"20250914150726-shpwidf","Type":"NodeList","ListData":{},"Properties":{"id":"20250914150726-shpwidf","updated":"20250914150727"},"Children":[{"ID":"20250914150726-vf4l14u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150726-vf4l14u","updated":"20250914150726"},"Children":[{"ID":"20250914150726-c6649g7","Type":"NodeParagraph","Properties":{"id":"20250914150726-c6649g7","updated":"20250914150726"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模的重要性 (Scaling Hypothesis):"},{"Type":"NodeText","Data":" 论文的核心假设是，模型的性能会随着其参数量的增加而提升，特别是在上下文学习能力上。GPT-3拥有1750亿个参数，远超之前的模型，其强大的少样本学习能力验证了这一假设。"}]}]},{"ID":"20250914150726-63p0gij","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150726-63p0gij","updated":"20250914150726"},"Children":[{"ID":"20250914150726-1hsz06b","Type":"NodeParagraph","Properties":{"id":"20250914150726-1hsz06b","updated":"20250914150726"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"范式转变："},{"Type":"NodeText","Data":" GPT-3的成功表明，我们可能不需要为每个任务都进行耗时耗力的微调。通过精心设计提示（Prompt Engineering），一个巨大的预训练模型就能胜任多种任务，这极大地提高了模型的通用性和易用性。"}]}]},{"ID":"20250914150726-46zbubn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150726-46zbubn","updated":"20250914150726"},"Children":[{"ID":"20250914150726-jemqtnl","Type":"NodeParagraph","Properties":{"id":"20250914150726-jemqtnl","updated":"20250914150726"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"元学习 (Meta-learning) 的视角:"},{"Type":"NodeText","Data":" 如图1.1所示，可以将GPT-3的学习过程看作一个两阶段的元学习。"}]},{"ID":"20250914150726-6tgohzw","Type":"NodeList","ListData":{},"Properties":{"id":"20250914150726-6tgohzw","updated":"20250914150726"},"Children":[{"ID":"20250914150726-1cctgho","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150726-1cctgho","updated":"20250914150726"},"Children":[{"ID":"20250914150726-867rgdb","Type":"NodeParagraph","Properties":{"id":"20250914150726-867rgdb","updated":"20250914150726"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外循环："},{"Type":"NodeText","Data":" 漫长的无监督预训练过程，模型在这个阶段学习如何学习。"}]}]},{"ID":"20250914150726-k6kmgsq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150726-k6kmgsq","updated":"20250914150726"},"Children":[{"ID":"20250914150726-o0e83k5","Type":"NodeParagraph","Properties":{"id":"20250914150726-o0e83k5","updated":"20250914150726"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内循环："},{"Type":"NodeText","Data":" 快速的上下文学习过程，模型在推理时利用预训练阶段学到的“学习能力”来快速适应新任务。"}]}]}]}]}]}]},{"ID":"20250914150714-8hjm9v9","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914150714-8hjm9v9","updated":"20250914150743"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914150743-b4o0znk","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914150743-b4o0znk","updated":"20250914150743"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图表解析"}]},{"ID":"20250914150743-nmpqecb","Type":"NodeList","ListData":{},"Properties":{"id":"20250914150743-nmpqecb","updated":"20250914150743"},"Children":[{"ID":"20250914150743-wu8kwvm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150743-wu8kwvm","updated":"20250914150743"},"Children":[{"ID":"20250914150743-2d6rhyj","Type":"NodeParagraph","Properties":{"id":"20250914150743-2d6rhyj","updated":"20250914150743"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 1.1："},{"Type":"NodeText","Data":" 直观地展示了“上下文学习”的概念。无论任务是数学计算、单词纠错还是语言翻译，模型都能通过在提示中给出几个“输入 -\u003e 输出”的例子来理解任务要求，并完成新的任务。这整个过程发生在模型的单次前向传播中，没有参数更新。"}]}]},{"ID":"20250914150743-8462lwn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150743-8462lwn","updated":"20250914150743"},"Children":[{"ID":"20250914150743-cjuj4dh","Type":"NodeParagraph","Properties":{"id":"20250914150743-cjuj4dh","updated":"20250914150743"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 1.2："},{"Type":"NodeText","Data":" 用数据证明了模型规模与上下文学习效率之间的正相关关系。"}]},{"ID":"20250914150743-t82r4gy","Type":"NodeList","ListData":{},"Properties":{"id":"20250914150743-t82r4gy","updated":"20250914150743"},"Children":[{"ID":"20250914150743-mtvjnfi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150743-mtvjnfi","updated":"20250914150743"},"Children":[{"ID":"20250914150743-pb0p9p2","Type":"NodeParagraph","Properties":{"id":"20250914150743-pb0p9p2","updated":"20250914150743"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型越大，学习越快："},{"Type":"NodeText","Data":" 拥有1750亿参数的模型（蓝色实线）的准确率曲线最为陡峭，意味着它能从极少数的例子中快速学习，准确率提升非常显著。"}]}]},{"ID":"20250914150743-jm68niu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150743-jm68niu","updated":"20250914150743"},"Children":[{"ID":"20250914150743-0lo5ojp","Type":"NodeParagraph","Properties":{"id":"20250914150743-0lo5ojp","updated":"20250914150743"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例越多，效果越好："},{"Type":"NodeText","Data":" 随着上下文中示例数量（K值）的增加，所有模型的准确率都在提升。"}]}]},{"ID":"20250914150743-c7q7frg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914150743-c7q7frg","updated":"20250914150743"},"Children":[{"ID":"20250914150743-2s0cw4l","Type":"NodeParagraph","Properties":{"id":"20250914150743-2s0cw4l","updated":"20250914150743"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然语言提示的作用："},{"Type":"NodeText","Data":" 带有自然语言描述的提示（实线）通常比没有提示（虚线）的效果更好，说明清晰的指令有助于模型理解任务。"}]}]}]}]}]}]},{"ID":"20250914150714-zijlbwp","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914150714-zijlbwp","updated":"20250914151109"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914150758-uokiclz","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914150758-uokiclz","updated":"20250914151109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"}]},{"ID":"20250914150758-4o3do6a","Type":"NodeParagraph","Properties":{"id":"20250914150758-4o3do6a","updated":"20250914150758"},"Children":[{"Type":"NodeText","Data":"这部分内容介绍了GPT-3的核心贡献：证明了通过大规模的模型和数据进行预训练，可以催生出强大的“上下文学习”能力，从而在许多NLP任务上摆脱对特定任务微调的依赖。 这一发现不仅推动了自然语言处理领域的技术进步，也为构建更通用、更接近人类学习方式的人工智能系统指明了方向。"}]}]},{"ID":"20250914151149-dug9ogq","Type":"NodeParagraph","Properties":{"id":"20250914151149-dug9ogq","updated":"20250914151221"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914151149-emo7d0m.png"},{"Type":"NodeLinkSpace"},{"Type":"NodeLinkTitle","Data":"图 1.3: 跨基准测试的聚合性能"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250914151253-87ybni6","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914151253-87ybni6","updated":"20250914151257"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914151257-wwh6j1z","Type":"NodeParagraph","Properties":{"id":"20250914151257-wwh6j1z","updated":"20250914151257"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容:"}]},{"ID":"20250914151257-wtc5fq0","Type":"NodeList","ListData":{},"Properties":{"id":"20250914151257-wtc5fq0","updated":"20250914151257"},"Children":[{"ID":"20250914151257-evr6anf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151257-evr6anf","updated":"20250914151257"},"Children":[{"ID":"20250914151257-ws1lsg5","Type":"NodeParagraph","Properties":{"id":"20250914151257-ws1lsg5","updated":"20250914151257"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" 跨基准测试的聚合性能 (Aggregate Performance Across Benchmarks)"}]}]},{"ID":"20250914151257-cn41kng","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151257-cn41kng","updated":"20250914151257"},"Children":[{"ID":"20250914151257-rv3bl74","Type":"NodeParagraph","Properties":{"id":"20250914151257-rv3bl74","updated":"20250914151257"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250914151257-vhimwcu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151257-vhimwcu","updated":"20250914151257"},"Children":[{"ID":"20250914151257-c5dufc7","Type":"NodeParagraph","Properties":{"id":"20250914151257-c5dufc7","updated":"20250914151257"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量（单位：十亿） (Parameters in LM (Billions))"}]}]},{"ID":"20250914151257-zxpvw47","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151257-zxpvw47","updated":"20250914151257"},"Children":[{"ID":"20250914151257-pji0v77","Type":"NodeParagraph","Properties":{"id":"20250914151257-pji0v77","updated":"20250914151257"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"}]},{"ID":"20250914151257-gi1c2mm","Type":"NodeList","ListData":{},"Properties":{"id":"20250914151257-gi1c2mm","updated":"20250914151257"},"Children":[{"ID":"20250914151257-xf5mtm2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151257-xf5mtm2","updated":"20250914151257"},"Children":[{"ID":"20250914151257-5re64ei","Type":"NodeParagraph","Properties":{"id":"20250914151257-5re64ei","updated":"20250914151257"},"Children":[{"Type":"NodeText","Data":"Few Shot (少样本)"}]}]},{"ID":"20250914151257-effacim","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151257-effacim","updated":"20250914151257"},"Children":[{"ID":"20250914151257-krt5ox5","Type":"NodeParagraph","Properties":{"id":"20250914151257-krt5ox5","updated":"20250914151257"},"Children":[{"Type":"NodeText","Data":"One Shot (单样本)"}]}]},{"ID":"20250914151257-tev2d5r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151257-tev2d5r","updated":"20250914151257"},"Children":[{"ID":"20250914151257-3unor7j","Type":"NodeParagraph","Properties":{"id":"20250914151257-3unor7j","updated":"20250914151257"},"Children":[{"Type":"NodeText","Data":"Zero Shot (零样本)"}]}]}]}]}]},{"ID":"20250914151257-xcz487t","Type":"NodeParagraph","Properties":{"id":"20250914151257-xcz487t","updated":"20250914151257"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":"\n随着模型规模的稳步提升，所有42个以准确率为度量的基准测试的聚合性能也随之提高。虽然零样本性能提升最为平缓，但少样本性能提升得更为迅速，这表明更大的模型更擅长在上下文中学习。关于在标准自然语言处理基准测试套件SuperGLUE上的更详细分析，请参见图3.8。"}]}]},{"ID":"20250914151051-p6tnvgr","Type":"NodeParagraph","Properties":{"id":"20250914151051-p6tnvgr","updated":"20250914151323"},"Children":[{"Type":"NodeText","Data":"在本文中，我们通过训练一个拥有1750亿参数的自回归语言模型来测试这个假设，并衡量其上下文学习能力。具体来说，我们在超过二十个自然语言处理数据集和一些新颖的任务上评估GPT-3，这些任务不太可能被直接包含在训练数据中。对于每项任务，我们都在三种条件下评估GPT-3：（a）“少样本学习”（few-shot learning），即我们允许在模型的上下文窗口中放入尽可能多的示例（通常是10到100个）；（b）“单样本学习”（one-shot learning），即我们只允许一个示例；以及（c）“零样本学习”（zero-shot learning），即不提供任何示例，只给出一个用自然语言描述的任务指令。GPT-3原则上也可以通过传统的微调方式进行评估，但我们把这项工作留给未来。"}]},{"ID":"20250914151051-kjust5u","Type":"NodeParagraph","Properties":{"id":"20250914151051-kjust5u","updated":"20250914151323"},"Children":[{"Type":"NodeText","Data":"图1.2说明了这些情况，并显示了模型的少样本学习，即通过自然语言任务描述和上下文中的示例来移除单词中的多余符号。模型的性能随着任务描述的加入和上下文中示例数量（K）的增加而显著提升。在这种情况下以及在我们研究的大多数任务中，模型规模和上下文中示例数量之间的总体趋势惊人地一致。我们强调，这种类型的“学习”曲线不涉及任何梯度更新或微调，仅仅是增加了作为条件的演示数量。"}]},{"ID":"20250914151051-kw6skq6","Type":"NodeParagraph","Properties":{"id":"20250914151051-kw6skq6","updated":"20250914151323"},"Children":[{"Type":"NodeText","Data":"总的来说，在大多数自然语言处理任务上，GPT-3在零样本和单样本设置下展现出了有前景的性能，在少样本设置下，其性能有时甚至能接近或超过了通过微调达到的当前最佳水平（state-of-the-art）。例如，GPT-3在CoQA数据集的单样本设置中达到了81.5 F1分，在零样本设置中达到了84.0 F1分。相比之下，经过微调的最佳模型达到了90.7 F1分。同样地，GPT-3在TriviaQA数据集的零样本设置中取得了64.3%的准确率，在单样本设置中为68.0%，在少样本设置中为71.2%，这最后一项结果与在封闭书籍设定下运行的、经过微调的当前最佳模型相当。"}]},{"ID":"20250914151051-d2yz6ek","Type":"NodeParagraph","Properties":{"id":"20250914151051-d2yz6ek","updated":"20250914151323"},"Children":[{"Type":"NodeText","Data":"GPT-3还展示了单样本和少样本的能力，这些能力旨在测试快速适应或即时推理，包括单词乱序重组、执行算术运算，以及在使用一个仅定义过一次的新词造句。我们还发现，在少样本设置下，GPT-3可以生成合成的新闻文章，人类评估者很难将其与人类写的文章区分开来。"}]},{"ID":"20250914151051-q2twpdk","Type":"NodeParagraph","Properties":{"id":"20250914151051-q2twpdk","updated":"20250914151323"},"Children":[{"Type":"NodeText","Data":"与此同时，我们也发现了一些GPT-3即便在少样本设置下仍然表现不佳的任务。这包括自然语言推理任务，如ANLI数据集，以及一些阅读理解数据集，如RACE或QuAC。通过对GPT-3的优势和劣势进行广泛的描述，我们希望能激发对语言模型中少样本学习的研究，并引起大家对需要改进之处的关注。"}]},{"ID":"20250914151051-90mr0y6","Type":"NodeParagraph","Properties":{"id":"20250914151051-90mr0y6","updated":"20250914151323"},"Children":[{"Type":"NodeText","Data":"需要注意的是，图1.3中展示的整体结果（汇总了各种任务）本身不应被视为一个有意义的常规基准测试。"}]},{"ID":"20250914151051-5v96c2l","Type":"NodeParagraph","Properties":{"id":"20250914151051-5v96c2l","updated":"20250914151323"},"Children":[{"Type":"NodeText","Data":"我们还对“数据污染”（data contamination）问题进行了系统性研究——这是一个在训练高容量模型时日益严重的问题，例如在Common Crawl这样的数据集上训练，可能会无意中包含来自测试集的内容，仅仅因为这些内容常常存在于网络上。在本文中，我们系统地开发了工具来衡量数据污染并量化其扭曲效应。虽然我们发现数据污染对GPT-3在大多数数据集上的性能影响很小，但我们确实发现了一些数据集可能因此夸大了结果，我们根据严重程度，选择不报告这些数据集上的结果，或者用星号标注出来。"}]},{"ID":"20250914151051-p9kcw6u","Type":"NodeParagraph","Properties":{"id":"20250914151051-p9kcw6u","updated":"20250914151323"},"Children":[{"Type":"NodeText","Data":"除上述所有内容外，我们还训练了一系列较小的模型（参数范围从1.25亿到130亿），以便将它们在零样本、单样本和少样本设置下的性能与GPT-3进行比较。总的来说，对于大多数任务，我们发现在所有三种设置下，性能都随着模型容量的增加而平稳提升；一个值得注意的模式是，零样本、单样本和少样本性能之间的差距通常随着模型容量的增加而扩大，这或许表明更大的模型是更熟练的“元学习者”。"}]},{"ID":"20250914151051-nk036r9","Type":"NodeParagraph","Properties":{"id":"20250914151051-nk036r9","updated":"20250914151323"},"Children":[{"Type":"NodeText","Data":"最后，鉴于GPT-3所展现出的广泛能力，我们讨论了关于偏见、公平性和更广泛的社会影响的担忧，并尝试对此进行了初步的特性分析。"}]},{"ID":"20250914151051-rvqnzpq","Type":"NodeParagraph","Properties":{"id":"20250914151051-rvqnzpq","updated":"20250914151323"},"Children":[{"Type":"NodeText","Data":"本文的其余部分组织如下。在第2节中，我们描述了训练和评估GPT-3的方法。第3节展示了在零样本、单样本和少样本设置下，模型在所有任务上的结果。第4节探讨了数据污染（训练-测试重叠）问题。第5节讨论了模型的局限性。第6节讨论了更广泛的影响。第7节回顾了相关工作，第8节进行总结。"}]},{"ID":"20250914151336-1t7t0zo","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914151336-1t7t0zo","updated":"20250914151341"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914151341-0pqevd2","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250914151341-0pqevd2","updated":"20250914151341"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250914151341-xnksozz","Type":"NodeParagraph","Properties":{"id":"20250914151341-xnksozz","updated":"20250914151342"},"Children":[{"Type":"NodeText","Data":"这部分内容承接前文，进一步阐述了GPT-3的实验设置、核心发现、研究严谨性以及未来的研究方向。"}]}]},{"ID":"20250914151336-5f7ez4e","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914151336-5f7ez4e","updated":"20250914151353"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914151353-zbpoaf7","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914151353-zbpoaf7","updated":"20250914151353"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心观点与发现"}]},{"ID":"20250914151353-gu0v7ib","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250914151353-gu0v7ib","updated":"20250914151354"},"Children":[{"ID":"20250914151353-eq0zjp6","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250914151353-eq0zjp6","updated":"20250914151353"},"Children":[{"ID":"20250914151353-vje64z5","Type":"NodeParagraph","Properties":{"id":"20250914151353-vje64z5","updated":"20250914151353"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能与模型规模、示例数量正相关："}]},{"ID":"20250914151353-ewu7b02","Type":"NodeList","ListData":{},"Properties":{"id":"20250914151353-ewu7b02","updated":"20250914151353"},"Children":[{"ID":"20250914151353-ut5yoi0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151353-ut5yoi0","updated":"20250914151353"},"Children":[{"ID":"20250914151353-ifewxsm","Type":"NodeParagraph","Properties":{"id":"20250914151353-ifewxsm","updated":"20250914151353"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 1.3"},{"Type":"NodeText","Data":" 是本节的核心图示，它清晰地展示了一个关键趋势：无论是在零样本、单样本还是少样本设置下，模型的性能（准确率）都随着参数量的增加而系统性地提高。"}]}]},{"ID":"20250914151353-gi6gevn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151353-gi6gevn","updated":"20250914151353"},"Children":[{"ID":"20250914151353-5mocbty","Type":"NodeParagraph","Properties":{"id":"20250914151353-5mocbty","updated":"20250914151353"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本学习受益最大："},{"Type":"NodeText","Data":" 图中“Few Shot”曲线的斜率最大，意味着随着模型规模的增长，少样本学习带来的性能提升最为显著。这印证了论文的核心论点："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更大的模型是更好的上下文学习者"},{"Type":"NodeText","Data":"。它们能更有效地利用给出的少量示例来理解和完成任务。"}]}]}]}]},{"ID":"20250914151353-dt7gufc","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250914151353-dt7gufc","updated":"20250914151353"},"Children":[{"ID":"20250914151353-g5xj615","Type":"NodeParagraph","Properties":{"id":"20250914151353-g5xj615","updated":"20250914151353"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在某些任务上可与微调模型媲美："}]},{"ID":"20250914151353-481cx94","Type":"NodeList","ListData":{},"Properties":{"id":"20250914151353-481cx94","updated":"20250914151353"},"Children":[{"ID":"20250914151353-4u5t06t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151353-4u5t06t","updated":"20250914151353"},"Children":[{"ID":"20250914151353-vswggzb","Type":"NodeParagraph","Properties":{"id":"20250914151353-vswggzb","updated":"20250914151353"},"Children":[{"Type":"NodeText","Data":"一个惊人的发现是，GPT-3仅通过少样本学习（无任何参数微调），在一些知名基准测试（如TriviaQA）上的表现已经可以和经过专门微调的顶尖模型相提并论。这在当时是一个重大的突破，因为它表明了抛弃“为每个任务进行微调”这一传统范式的可能性。"}]}]}]}]},{"ID":"20250914151353-mkydlw1","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250914151353-mkydlw1","updated":"20250914151353"},"Children":[{"ID":"20250914151353-7j15mbs","Type":"NodeParagraph","Properties":{"id":"20250914151353-7j15mbs","updated":"20250914151353"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强大的即时推理和生成能力："}]},{"ID":"20250914151353-rwgp47y","Type":"NodeList","ListData":{},"Properties":{"id":"20250914151353-rwgp47y","updated":"20250914151353"},"Children":[{"ID":"20250914151353-b2ebg2e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151353-b2ebg2e","updated":"20250914151353"},"Children":[{"ID":"20250914151353-932ao8s","Type":"NodeParagraph","Properties":{"id":"20250914151353-932ao8s","updated":"20250914151353"},"Children":[{"Type":"NodeText","Data":"除了在标准NLP任务上的优异表现，GPT-3还展示了处理需要即时推理的任务的能力，如算术和单词重组。"}]}]},{"ID":"20250914151353-w07xrg5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151353-w07xrg5","updated":"20250914151353"},"Children":[{"ID":"20250914151353-rrjru46","Type":"NodeParagraph","Properties":{"id":"20250914151353-rrjru46","updated":"20250914151353"},"Children":[{"Type":"NodeText","Data":"更引人注目的是，它能生成与人类手笔难以区分的新闻文章，这既展示了其强大的生成能力，也引出了重要的社会和伦理问题。"}]}]}]}]}]}]},{"ID":"20250914151336-j3c4r1b","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914151336-j3c4r1b","updated":"20250914151406"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914151406-59f5r84","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914151406-59f5r84","updated":"20250914151406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"研究的严谨性"}]},{"ID":"20250914151406-4cjxmdf","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250914151406-4cjxmdf","updated":"20250914151407"},"Children":[{"ID":"20250914151406-s0vlow8","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250914151406-s0vlow8","updated":"20250914151406"},"Children":[{"ID":"20250914151406-y7kets9","Type":"NodeParagraph","Properties":{"id":"20250914151406-y7kets9","updated":"20250914151406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据污染”问题的处理："}]},{"ID":"20250914151406-xtlcyi6","Type":"NodeList","ListData":{},"Properties":{"id":"20250914151406-xtlcyi6","updated":"20250914151406"},"Children":[{"ID":"20250914151406-y028rfh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151406-y028rfh","updated":"20250914151406"},"Children":[{"ID":"20250914151406-736jihz","Type":"NodeParagraph","Properties":{"id":"20250914151406-736jihz","updated":"20250914151406"},"Children":[{"Type":"NodeText","Data":"作者们非常严谨地考虑了“数据污染”问题，即模型的训练数据中可能包含了测试集的内容。他们开发工具来检测和量化这种污染的影响，并对受影响的结果进行了处理（不报告或加星号标注）。这大大增强了其实验结果的可信度。"}]}]}]}]},{"ID":"20250914151406-09rmjce","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250914151406-09rmjce","updated":"20250914151406"},"Children":[{"ID":"20250914151406-c5r5vyq","Type":"NodeParagraph","Properties":{"id":"20250914151406-c5r5vyq","updated":"20250914151406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统性的模型规模对比："}]},{"ID":"20250914151406-cydkgfy","Type":"NodeList","ListData":{},"Properties":{"id":"20250914151406-cydkgfy","updated":"20250914151406"},"Children":[{"ID":"20250914151406-gocc1jy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914151406-gocc1jy","updated":"20250914151406"},"Children":[{"ID":"20250914151406-yixcr4n","Type":"NodeParagraph","Properties":{"id":"20250914151406-yixcr4n","updated":"20250914151406"},"Children":[{"Type":"NodeText","Data":"研究团队不仅训练了最大的1750亿参数模型，还训练了一系列从小到大的模型。这使得他们能够系统地研究“规模”（scaling）对模型能力的影响，并得出了“模型越大，元学习能力越强”的结论。这里的“元学习能力”具体表现为，大模型能更好地利用上下文中的示例，从而使得少样本学习与零样本学习之间的性能差距更大。"}]}]}]}]}]}]},{"ID":"20250914151354-5xaj5kn","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914151354-5xaj5kn","updated":"20250914151431"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914151431-o227chz","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914151431-o227chz","updated":"20250914151431"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结与展望"}]},{"ID":"20250914151431-9pbcy6m","Type":"NodeParagraph","Properties":{"id":"20250914151431-9pbcy6m","updated":"20250914151431"},"Children":[{"Type":"NodeText","Data":"这部分内容通过具体的实验设置和聚合结果，为GPT-3的强大能力提供了坚实的证据。它不仅展示了GPT-3在多个维度上的卓越性能，还通过严谨的方法论排除了潜在的干扰因素。最后，作者明确指出了由这项技术引发的社会伦理问题（偏见、公平性等），并规划了论文后续章节的结构，为读者提供了清晰的阅读路线图。"}]},{"ID":"20250914151431-v8q1usy","Type":"NodeParagraph","Properties":{"id":"20250914151431-v8q1usy","updated":"20250914151431"},"Children":[{"Type":"NodeText","Data":"总而言之，本节的核心信息是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模的扩大确实能带来质的飞跃，使语言模型获得了强大的上下文学习能力，从而在无需微调的情况下就能高效地解决多种任务。"}]}]},{"ID":"20250914153817-6ahpwo0","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250914153817-6ahpwo0","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2. 方法 (Approach)"}]},{"ID":"20250914153817-b464hc7","Type":"NodeParagraph","Properties":{"id":"20250914153817-b464hc7","updated":"20250914153838"},"Children":[{"Type":"NodeText","Data":"我们基础的预训练方法，包括模型、数据和训练，与 [RWC+19] 中描述的过程相似，只是在模型大小、数据集大小和多样性，以及训练时长方面进行了相对直接的扩展。我们对上下文学习（in-context learning）的使用也与 [RWC+19] 类似，但在本文中，我们在评估GPT-3时，系统性地探索了不同的设置。因此，我们首先明确定义和对比我们将在评估GPT-3时使用的不同设置，或者说是在原则上可以用来评估GPT-3的设置。这些设置可以看作是一个谱系，取决于它们在多大程度上依赖于任务特定的数据（参见图2.1的说明）。具体来说，我们至少可以确定这个谱系上的四个点："}]},{"ID":"20250914153817-eutukar","Type":"NodeList","ListData":{},"Properties":{"id":"20250914153817-eutukar","updated":"20250914154140"},"Children":[{"ID":"20250914153817-j3mnt1t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914153817-j3mnt1t","updated":"20250914153817"},"Children":[{"ID":"20250914153817-xdxh71g","Type":"NodeParagraph","Properties":{"id":"20250914153817-xdxh71g","updated":"20250914153817"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调 (Fine-Tuning, FT)"},{"Type":"NodeText","Data":" 一直是近年来的主流方法，它涉及到在一个为期望任务设计的有监督数据集上更新预训练模型的权重。通常会使用成千上万个有标签的样本。微调的主要优势是在许多基准测试上都能获得强大的性能。其主要缺点是需要为每个任务准备一个新的大型数据集，这可能导致在分布外数据上的泛化能力较差 [MPL19]，并且可能利用训练数据中的虚假相关性 [GSL+18, NK19]，这可能导致与人类表现进行不公平的比较。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在我们的工作中，我们不微调GPT-3"},{"Type":"NodeText","Data":"，因为我们的重点是与任务无关的性能，但GPT-3原则上是可以被微调的，这是我们未来工作的方向。"}]}]},{"ID":"20250914153817-qhp1jhk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914153817-qhp1jhk","updated":"20250914153817"},"Children":[{"ID":"20250914153817-eef5iuv","Type":"NodeParagraph","Properties":{"id":"20250914153817-eef5iuv","updated":"20250914153817"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本 (Few-Shot, FS)"},{"Type":"NodeText","Data":" 是我们在本文中用来指代这样一种设定：在推理时，我们给模型一些任务的演示作为“条件” [RWC+19]，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不允许任何权重的更新"},{"Type":"NodeText","Data":"。如图2.1所示，一个典型的任务上下文可能包含一个期望的补全（例如，一句英文句子和它的法文翻译），然后是几个上下文和补全的例子，最后是一个上下文，模型需要提供补全。我们通常设置K的值在10到100之间，这个数量取决于多少个例子能放进模型的上下文窗口中（nctx = 2048）。少样本学习的主要优点是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大幅减少了对特定任务数据的需求"},{"Type":"NodeText","Data":"，并降低了从一个狭窄的微调数据集中学习到过于狭隘分布的可能性。其主要缺点是，到目前为止，用这种方法得到的结果远不如最先进的微调模型。此外，仍然需要少量的特定任务数据。如此处描述的语言模型的少样本学习与机器学习领域中其他上下文使用的少样本学习相关 [HYC01, VBL+16]——两者都涉及基于广泛的任务分布（在这里是隐含在预训练数据中）进行学习，然后快速适应一个新任务。"}]}]},{"ID":"20250914153817-pw4npb7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914153817-pw4npb7","updated":"20250914153817"},"Children":[{"ID":"20250914153817-255v1gc","Type":"NodeParagraph","Properties":{"id":"20250914153817-255v1gc","updated":"20250914153817"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单样本 (One-Shot, OS)"},{"Type":"NodeText","Data":" 与少样本相同，只是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只允许一个演示示例"},{"Type":"NodeText","Data":"，此外还有一个对任务的自然语言描述，如图1.1所示。区分单样本和零样本（见下文）的原因是，它与我们向人类传达任务的方式最相似。例如，当要求人类在像亚马逊土耳其机器人（Amazon Mechanical Turk）这样的人类众包服务上完成一项任务时，通常会给出一个任务的演示。相比之下，如果没有给出示例，有时很难沟通任务的内容或格式。"}]}]},{"ID":"20250914154139-2dmy1fr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154139-2dmy1fr","updated":"20250914154140"},"Children":[{"ID":"20250914154139-nfrgsps","Type":"NodeParagraph","Properties":{"id":"20250914154139-nfrgsps","updated":"20250914154140"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本 (Zero-Shot, ZS)"},{"Type":"NodeText","Data":" 与单样本设置相同，只是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不提供任何演示示例"},{"Type":"NodeText","Data":"，只给出一个对任务的自然语言指令。这种方法提供了最大的便利性，避免了虚假的相关性（它们通常只在大量数据中出现），但也是最具挑战性的设置。在某些情况下，如果没有先前的例子，人类可能都很难理解任务的格式，所以这个设置在某些情况下“不公平地困难”。例如，如果有人被要求“为200米短跑制作一张世界纪录表格”，这个要求可能是模棱两可的，即使经过澄清，要准确理解表格应该是什么样子以及应该包含什么细节也可能很困难。然而，对于至少一些设置明确的任务，比如翻译任务，人类很可能仅从文本指令中就知道如何执行任务，如图2.1所示。"}]}]}]},{"ID":"20250914153953-rbjbkpc","Type":"NodeParagraph","Properties":{"id":"20250914153953-rbjbkpc","updated":"20250914153953"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914153953-8dphm3a.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250914154107-10ik5us","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914154107-10ik5us","updated":"20250914154120"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914154120-jgz3j9x","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914154120-jgz3j9x","updated":"20250914154120"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 2.1：我们探索的三种上下文学习设置与传统的微调对比"}]},{"ID":"20250914154120-kccdnax","Type":"NodeParagraph","Properties":{"id":"20250914154120-kccdnax","updated":"20250914154120"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250914154120-ra7t3d9","Type":"NodeList","ListData":{},"Properties":{"id":"20250914154120-ra7t3d9","updated":"20250914154120"},"Children":[{"ID":"20250914154120-04ablwm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-04ablwm","updated":"20250914154120"},"Children":[{"ID":"20250914154120-du4bu5y","Type":"NodeParagraph","Properties":{"id":"20250914154120-du4bu5y","updated":"20250914154120"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我们探索的三种上下文学习设置 (The three settings we explore for in-context learning)"}]},{"ID":"20250914154120-5yrtr8h","Type":"NodeList","ListData":{},"Properties":{"id":"20250914154120-5yrtr8h","updated":"20250914154120"},"Children":[{"ID":"20250914154120-q3nen00","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-q3nen00","updated":"20250914154120"},"Children":[{"ID":"20250914154120-q933x00","Type":"NodeParagraph","Properties":{"id":"20250914154120-q933x00","updated":"20250914154120"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本 (Zero-shot)"}]},{"ID":"20250914154120-rhahhwp","Type":"NodeList","ListData":{},"Properties":{"id":"20250914154120-rhahhwp","updated":"20250914154120"},"Children":[{"ID":"20250914154120-6scbawb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-6scbawb","updated":"20250914154120"},"Children":[{"ID":"20250914154120-a03nn6z","Type":"NodeParagraph","Properties":{"id":"20250914154120-a03nn6z","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"模型仅根据自然语言指令来回答问题。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不执行任何梯度更新"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250914154120-1b86pw2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-1b86pw2","updated":"20250914154120"},"Children":[{"ID":"20250914154120-1cmxnxk","Type":"NodeParagraph","Properties":{"id":"20250914154120-1cmxnxk","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Translate English to French:"},{"Type":"NodeText","Data":"​ (任务描述)"}]}]},{"ID":"20250914154120-u6uz2aw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-u6uz2aw","updated":"20250914154120"},"Children":[{"ID":"20250914154120-8wn566q","Type":"NodeParagraph","Properties":{"id":"20250914154120-8wn566q","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"cheese =\u0026gt;"},{"Type":"NodeText","Data":"​ (提示)"}]}]}]}]},{"ID":"20250914154120-1419y36","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-1419y36","updated":"20250914154120"},"Children":[{"ID":"20250914154120-8lpq69l","Type":"NodeParagraph","Properties":{"id":"20250914154120-8lpq69l","updated":"20250914154120"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单样本 (One-shot)"}]},{"ID":"20250914154120-c183a2x","Type":"NodeList","ListData":{},"Properties":{"id":"20250914154120-c183a2x","updated":"20250914154120"},"Children":[{"ID":"20250914154120-r6iq6df","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-r6iq6df","updated":"20250914154120"},"Children":[{"ID":"20250914154120-5zpwjyl","Type":"NodeParagraph","Properties":{"id":"20250914154120-5zpwjyl","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"除了任务描述，模型还会看到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个"},{"Type":"NodeText","Data":"任务示例。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不执行任何梯度更新"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250914154120-voy92fn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-voy92fn","updated":"20250914154120"},"Children":[{"ID":"20250914154120-0w6wc5q","Type":"NodeParagraph","Properties":{"id":"20250914154120-0w6wc5q","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Translate English to French:"},{"Type":"NodeText","Data":"​ (任务描述)"}]}]},{"ID":"20250914154120-z4w6vin","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-z4w6vin","updated":"20250914154120"},"Children":[{"ID":"20250914154120-5zf05qq","Type":"NodeParagraph","Properties":{"id":"20250914154120-5zf05qq","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"sea otter =\u0026gt; loutre de mer"},{"Type":"NodeText","Data":"​ (示例)"}]}]},{"ID":"20250914154120-7eft9x9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-7eft9x9","updated":"20250914154120"},"Children":[{"ID":"20250914154120-2q14e3h","Type":"NodeParagraph","Properties":{"id":"20250914154120-2q14e3h","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"cheese =\u0026gt;"},{"Type":"NodeText","Data":"​ (提示)"}]}]}]}]},{"ID":"20250914154120-6axanv7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-6axanv7","updated":"20250914154120"},"Children":[{"ID":"20250914154120-426i7kb","Type":"NodeParagraph","Properties":{"id":"20250914154120-426i7kb","updated":"20250914154120"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本 (Few-shot)"}]},{"ID":"20250914154120-ghfw25y","Type":"NodeList","ListData":{},"Properties":{"id":"20250914154120-ghfw25y","updated":"20250914154120"},"Children":[{"ID":"20250914154120-2vbq61l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-2vbq61l","updated":"20250914154120"},"Children":[{"ID":"20250914154120-w2xxq4i","Type":"NodeParagraph","Properties":{"id":"20250914154120-w2xxq4i","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"除了任务描述，模型还会看到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"几个"},{"Type":"NodeText","Data":"任务示例。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不执行任何梯度更新"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250914154120-7l5f0d5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-7l5f0d5","updated":"20250914154120"},"Children":[{"ID":"20250914154120-750jo7k","Type":"NodeParagraph","Properties":{"id":"20250914154120-750jo7k","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Translate English to French:"},{"Type":"NodeText","Data":"​ (任务描述)"}]}]},{"ID":"20250914154120-f5vgaoz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-f5vgaoz","updated":"20250914154120"},"Children":[{"ID":"20250914154120-5mxdh1z","Type":"NodeParagraph","Properties":{"id":"20250914154120-5mxdh1z","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"sea otter =\u0026gt; loutre de mer"},{"Type":"NodeText","Data":"​ (示例)"}]}]},{"ID":"20250914154120-7z3infu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-7z3infu","updated":"20250914154120"},"Children":[{"ID":"20250914154120-h1j3h5p","Type":"NodeParagraph","Properties":{"id":"20250914154120-h1j3h5p","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"peppermint =\u0026gt; menthe poivrée"},{"Type":"NodeText","Data":"​ (示例)"}]}]},{"ID":"20250914154120-hczrcrj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-hczrcrj","updated":"20250914154120"},"Children":[{"ID":"20250914154120-3q7btv1","Type":"NodeParagraph","Properties":{"id":"20250914154120-3q7btv1","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"plush giraffe =\u0026gt; girafe peluche"},{"Type":"NodeText","Data":"​ (示例)"}]}]},{"ID":"20250914154120-uwi1w8e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-uwi1w8e","updated":"20250914154120"},"Children":[{"ID":"20250914154120-afe1dab","Type":"NodeParagraph","Properties":{"id":"20250914154120-afe1dab","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"cheese =\u0026gt;"},{"Type":"NodeText","Data":"​ (提示)"}]}]}]}]}]}]},{"ID":"20250914154120-8pjdrgg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-8pjdrgg","updated":"20250914154120"},"Children":[{"ID":"20250914154120-f8tp3kh","Type":"NodeParagraph","Properties":{"id":"20250914154120-f8tp3kh","updated":"20250914154120"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"传统的微调（GPT-3未使用） (Traditional fine-tuning (not used for GPT-3))"}]},{"ID":"20250914154120-74v49h6","Type":"NodeList","ListData":{},"Properties":{"id":"20250914154120-74v49h6","updated":"20250914154120"},"Children":[{"ID":"20250914154120-wlyrd7h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-wlyrd7h","updated":"20250914154120"},"Children":[{"ID":"20250914154120-orkwwzf","Type":"NodeParagraph","Properties":{"id":"20250914154120-orkwwzf","updated":"20250914154120"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调 (Fine-tuning)"}]},{"ID":"20250914154120-t3m0267","Type":"NodeList","ListData":{},"Properties":{"id":"20250914154120-t3m0267","updated":"20250914154120"},"Children":[{"ID":"20250914154120-zu93lcj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-zu93lcj","updated":"20250914154120"},"Children":[{"ID":"20250914154120-1aqku55","Type":"NodeParagraph","Properties":{"id":"20250914154120-1aqku55","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"模型使用一个大型的特定任务语料库，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"梯度更新"},{"Type":"NodeText","Data":"进行重复训练。"}]}]},{"ID":"20250914154120-iq0f402","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-iq0f402","updated":"20250914154120"},"Children":[{"ID":"20250914154120-zsd8qie","Type":"NodeParagraph","Properties":{"id":"20250914154120-zsd8qie","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"sea otter =\u0026gt; loutre de mer"},{"Type":"NodeText","Data":"​ (示例 #1)"}]}]},{"ID":"20250914154120-b6ydych","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-b6ydych","updated":"20250914154120"},"Children":[{"ID":"20250914154120-pincs6j","Type":"NodeParagraph","Properties":{"id":"20250914154120-pincs6j","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"strong code","TextMarkTextContent":"梯度更新"},{"Type":"NodeText","Data":"​ (gradient update)"}]}]},{"ID":"20250914154120-vrgu7to","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-vrgu7to","updated":"20250914154120"},"Children":[{"ID":"20250914154120-htqsrqh","Type":"NodeParagraph","Properties":{"id":"20250914154120-htqsrqh","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"peppermint =\u0026gt; menthe poivrée"},{"Type":"NodeText","Data":"​ (示例 #2)"}]}]},{"ID":"20250914154120-vpcpz8g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-vpcpz8g","updated":"20250914154120"},"Children":[{"ID":"20250914154120-eg3mugc","Type":"NodeParagraph","Properties":{"id":"20250914154120-eg3mugc","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"strong code","TextMarkTextContent":"梯度更新"},{"Type":"NodeText","Data":"​ (gradient update)"}]}]},{"ID":"20250914154120-04ggwwl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-04ggwwl","updated":"20250914154120"},"Children":[{"ID":"20250914154120-sgdowlr","Type":"NodeParagraph","Properties":{"id":"20250914154120-sgdowlr","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"..."}]}]},{"ID":"20250914154120-4kzlawp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-4kzlawp","updated":"20250914154120"},"Children":[{"ID":"20250914154120-9xwbvxl","Type":"NodeParagraph","Properties":{"id":"20250914154120-9xwbvxl","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"plush giraffe =\u0026gt; girafe peluche"},{"Type":"NodeText","Data":"​ (示例 #N)"}]}]},{"ID":"20250914154120-dcfjav9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-dcfjav9","updated":"20250914154120"},"Children":[{"ID":"20250914154120-vn0ly6v","Type":"NodeParagraph","Properties":{"id":"20250914154120-vn0ly6v","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"strong code","TextMarkTextContent":"梯度更新"},{"Type":"NodeText","Data":"​ (gradient update)"}]}]},{"ID":"20250914154120-n0vywj0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154120-n0vywj0","updated":"20250914154120"},"Children":[{"ID":"20250914154120-sansyh2","Type":"NodeParagraph","Properties":{"id":"20250914154120-sansyh2","updated":"20250914154120"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"cheese =\u0026gt;"},{"Type":"NodeText","Data":"​ (提示)"}]}]}]}]}]}]}]},{"ID":"20250914154120-v6xersl","Type":"NodeParagraph","Properties":{"id":"20250914154120-v6xersl","updated":"20250914154120"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明翻译:"},{"Type":"NodeText","Data":"\n图2.1展示了使用语言模型执行任务的四种方法，并对比了传统的微调。上面的面板展示了我们研究的三种设置：零样本、单样本和少样本，这些方法要求模型在测试时仅通过前向传播来执行任务。我们通常在少样本设置下为模型提供十几个演示。所有任务描述、示例和提示的确切措辞可以在附录G中找到。"}]}]},{"ID":"20250914153817-x1v9whk","Type":"NodeParagraph","Properties":{"id":"20250914153817-x1v9whk","updated":"20250914154059"},"Children":[{"Type":"NodeText","Data":"图2.1展示了将英语翻译成法语的四种方法。在本文中，我们的重点是零样本、单样本和少样本，旨在将它们作为相互竞争的替代方案进行比较，而不是将它们视为竞争对手。但我们确实对不同问题设置提供了见解，这些设置在特定基准测试和计算效率之间提供了不同的权衡。我们特别强调了少样本的结果，因为它们在大多数情况下最能接近最先进的微调模型的性能。最终，无论是单样本还是零样本，有时都与人类表现相当，并且是未来工作的重要目标。"}]},{"ID":"20250914154157-67bxvdt","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914154157-67bxvdt","updated":"20250914154204"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914154204-48co4m6","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250914154204-48co4m6","updated":"20250914154204"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250914154204-6k0zhw7","Type":"NodeParagraph","Properties":{"id":"20250914154204-6k0zhw7","updated":"20250914154204"},"Children":[{"Type":"NodeText","Data":"这部分内容是理解GPT-3论文核心贡献的关键，因为它详细定义了评估模型能力所使用的四种不同“范式”，并清晰地将本文的研究重点与传统方法区分开来。"}]}]},{"ID":"20250914154157-31x9wel","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914154157-31x9wel","updated":"20250914154219"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914154219-4f0zyfb","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914154219-4f0zyfb","updated":"20250914154219"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心概念：两种学习方式"}]},{"ID":"20250914154219-6bdhdsb","Type":"NodeParagraph","Properties":{"id":"20250914154219-6bdhdsb","updated":"20250914154220"},"Children":[{"Type":"NodeText","Data":"这部分内容对比了两种根本不同的让模型“学习”任务的方式："}]},{"ID":"20250914154219-hsgzjjv","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250914154219-hsgzjjv","updated":"20250914154220"},"Children":[{"ID":"20250914154219-gv7kbyj","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250914154219-gv7kbyj","updated":"20250914154219"},"Children":[{"ID":"20250914154219-6setxv8","Type":"NodeParagraph","Properties":{"id":"20250914154219-6setxv8","updated":"20250914154219"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过权重更新学习（Learning via Gradient Updates）"}]},{"ID":"20250914154219-7jifisw","Type":"NodeList","ListData":{},"Properties":{"id":"20250914154219-7jifisw","updated":"20250914154219"},"Children":[{"ID":"20250914154219-8f74shp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154219-8f74shp","updated":"20250914154219"},"Children":[{"ID":"20250914154219-7ga2t27","Type":"NodeParagraph","Properties":{"id":"20250914154219-7ga2t27","updated":"20250914154219"},"Children":[{"Type":"NodeText","Data":"这就是传统的 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调 (Fine-Tuning, FT)"},{"Type":"NodeText","Data":"。模型通过在成千上万个有标签的例子上进行训练，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实际地调整其内部的参数（权重）"},{"Type":"NodeText","Data":"，从而专门适应某个特定任务。"}]}]},{"ID":"20250914154219-7y40k68","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154219-7y40k68","updated":"20250914154219"},"Children":[{"ID":"20250914154219-lagxhnb","Type":"NodeParagraph","Properties":{"id":"20250914154219-lagxhnb","updated":"20250914154219"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":"：性能通常非常高。"}]}]},{"ID":"20250914154219-2gxm8qx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154219-2gxm8qx","updated":"20250914154219"},"Children":[{"ID":"20250914154219-k3n3rd4","Type":"NodeParagraph","Properties":{"id":"20250914154219-k3n3rd4","updated":"20250914154219"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"需要大量标注数据"},{"Type":"NodeText","Data":"，成本高昂，且可能导致模型过拟合，泛化能力差。"}]}]},{"ID":"20250914154219-j7l8ok4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154219-j7l8ok4","updated":"20250914154219"},"Children":[{"ID":"20250914154219-9iece8x","Type":"NodeParagraph","Properties":{"id":"20250914154219-9iece8x","updated":"20250914154219"},"Children":[{"Type":"NodeText","Data":"论文明确指出，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3的研究没有采用这种方法"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250914154219-xh6b6io","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250914154219-xh6b6io","updated":"20250914154219"},"Children":[{"ID":"20250914154219-o7x31qx","Type":"NodeParagraph","Properties":{"id":"20250914154219-o7x31qx","updated":"20250914154219"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过上下文学习（Learning via In-context Learning）"}]},{"ID":"20250914154219-jvfr127","Type":"NodeList","ListData":{},"Properties":{"id":"20250914154219-jvfr127","updated":"20250914154219"},"Children":[{"ID":"20250914154219-bh8eemt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154219-bh8eemt","updated":"20250914154219"},"Children":[{"ID":"20250914154219-43lfql5","Type":"NodeParagraph","Properties":{"id":"20250914154219-43lfql5","updated":"20250914154219"},"Children":[{"Type":"NodeText","Data":"这是本文研究的重点，包括 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本 (Few-Shot, FS)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单样本 (One-Shot, OS)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本 (Zero-Shot, ZS)"},{"Type":"NodeText","Data":" 这三种设置。"}]}]},{"ID":"20250914154219-70f08ls","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154219-70f08ls","updated":"20250914154219"},"Children":[{"ID":"20250914154219-2qcpbm8","Type":"NodeParagraph","Properties":{"id":"20250914154219-2qcpbm8","updated":"20250914154219"},"Children":[{"Type":"NodeText","Data":"在这种模式下，模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内部参数是固定不变的"},{"Type":"NodeText","Data":"，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"没有任何梯度更新"},{"Type":"NodeText","Data":"。模型完全通过理解提供给它的“上下文”（即提示，prompt）来执行任务。学习过程发生在“推理时”，而不是“训练时”。"}]}]},{"ID":"20250914154219-fr2y1wt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154219-fr2y1wt","updated":"20250914154219"},"Children":[{"ID":"20250914154219-41wv9wy","Type":"NodeParagraph","Properties":{"id":"20250914154219-41wv9wy","updated":"20250914154219"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极大地减少甚至消除了对特定任务标注数据的依赖"},{"Type":"NodeText","Data":"，更加灵活和通用。"}]}]},{"ID":"20250914154219-lv4ydtn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154219-lv4ydtn","updated":"20250914154219"},"Children":[{"ID":"20250914154219-a3jbx8d","Type":"NodeParagraph","Properties":{"id":"20250914154219-a3jbx8d","updated":"20250914154219"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":"：对模型的“理解”能力要求极高，是一种更具挑战性的设置。"}]}]}]}]}]}]},{"ID":"20250914154206-bnp0qv2","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250914154206-bnp0qv2","updated":"20250914154233"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250914154233-6avwn54","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250914154233-6avwn54","updated":"20250914154233"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三种上下文学习设置的递进关系"}]},{"ID":"20250914154233-54xxdd7","Type":"NodeParagraph","Properties":{"id":"20250914154233-54xxdd7","updated":"20250914154233"},"Children":[{"Type":"NodeText","Data":"这三种设置可以看作是提供给模型的信息量（即示例数量）的递减："}]},{"ID":"20250914154233-qklw2ud","Type":"NodeList","ListData":{},"Properties":{"id":"20250914154233-qklw2ud","updated":"20250914154233"},"Children":[{"ID":"20250914154233-vjahp5p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154233-vjahp5p","updated":"20250914154233"},"Children":[{"ID":"20250914154233-byi40z7","Type":"NodeParagraph","Properties":{"id":"20250914154233-byi40z7","updated":"20250914154233"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本 (Few-Shot)"},{"Type":"NodeText","Data":"：提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述 + 几个示例"},{"Type":"NodeText","Data":" (通常10-100个)。这是信息最丰富的上下文学习设置，因此性能通常也最好，最接近微调模型。"}]}]},{"ID":"20250914154233-r6o7b5g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154233-r6o7b5g","updated":"20250914154233"},"Children":[{"ID":"20250914154233-48ityhs","Type":"NodeParagraph","Properties":{"id":"20250914154233-48ityhs","updated":"20250914154233"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单样本 (One-Shot)"},{"Type":"NodeText","Data":"：提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述 + 仅一个示例"},{"Type":"NodeText","Data":"。这种方式非常接近人类学习新任务的方式，通常一个例子就能让人举一反三。"}]}]},{"ID":"20250914154233-r1nlpey","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250914154233-r1nlpey","updated":"20250914154233"},"Children":[{"ID":"20250914154233-9pgsun1","Type":"NodeParagraph","Properties":{"id":"20250914154233-9pgsun1","updated":"20250914154233"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本 (Zero-Shot)"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只提供任务描述，不提供任何示例"},{"Type":"NodeText","Data":"。这是对模型能力最严苛的考验，要求模型仅凭指令就能理解并执行任务。"}]}]}]}]},{"ID":"20250915110840-hqmqknz","Type":"NodeParagraph","Properties":{"id":"20250915110840-hqmqknz","updated":"20250915110908"},"Children":[{"Type":"NodeText","Data":"下文的 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.1节"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.2节"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.3节"},{"Type":"NodeText","Data":"将分别详细介绍我们的模型、训练数据和训练过程。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.4节"},{"Type":"NodeText","Data":"将讨论我们如何进行少样本、单样本和零样本评估的细节。"}]},{"ID":"20250915110840-qvg3clz","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915110840-qvg3clz","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 2.1：模型尺寸、架构和学习超参数"},{"Type":"NodeText","Data":"（批次大小以词元（token）计，学习率以万分之一计）"}]},{"ID":"20250915110840-ohyn5w3","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1,1],"Properties":{"colgroup":"|||||||","id":"20250915110840-ohyn5w3","updated":"20250915111047"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"模型名称"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"n_params (参数量)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"n_layers (层数)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"d_model (模型宽度)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"n_heads (注意力头数)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"d_head (注意力头维度)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Batch Size (批次大小)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Learning Rate (学习率)"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Small"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.25亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"12"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"768"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"12"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.5M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.0 × 10⁻⁴"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Medium"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.5亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1024"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.5M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.0 × 10⁻⁴"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Large"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.6亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1536"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.5M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.5 × 10⁻⁴"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 XL"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"13亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"128"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.0 × 10⁻⁴"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 2.7B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"27亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2560"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.6 × 10⁻⁴"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 6.7B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"67亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4096"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"128"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.2 × 10⁻⁴"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 13B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"130亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"40"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5140"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"40"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"128"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0 × 10⁻⁴"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 175B 或 “GPT-3”"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1750亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"12288"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"128"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.2M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.6 × 10⁻⁴"}]}]}]},{"ID":"20250915110840-044rnpz","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915110840-044rnpz","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.1 模型与架构 (Model and Architectures)"}]},{"ID":"20250915110840-tvsbmpw","Type":"NodeParagraph","Properties":{"id":"20250915110840-tvsbmpw","updated":"20250915111047"},"Children":[{"Type":"NodeText","Data":"我们使用了与 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-2"},{"Type":"NodeText","Data":" [RWC+19] 相同的模型和架构，包括其中描述的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"修改后的初始化、预归一化（pre-normalization）和可逆的词元化（reversible tokenization）"},{"Type":"NodeText","Data":"，但有一个例外：我们在Transformer的各层中使用了交替的稠密和局部带状稀疏的注意力模式，这与稀疏Transformer [CGRS19] 类似。为了研究模型规模对机器学习性能的影响，我们训练了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"8种不同规模的模型"},{"Type":"NodeText","Data":"，参数范围从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1.25亿到1750亿"},{"Type":"NodeText","Data":"，最后一个我们称之为 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3"},{"Type":"NodeText","Data":"。先前的工作 [KMH+20] 表明，在有足够训练数据的情况下，验证损失的缩放遵循一个与模型规模相关的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平滑幂律（smooth power law）"},{"Type":"NodeText","Data":"；训练许多不同规模的模型使我们能够检验这一假设，无论是在下游语言任务上还是验证损失上。"}]},{"ID":"20250915110840-26rqx5b","Type":"NodeParagraph","Properties":{"id":"20250915110840-26rqx5b","updated":"20250915111047"},"Children":[{"Type":"NodeText","Data":"表2.1展示了我们8个模型的尺寸和架构。这里的 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"n_params"},{"Type":"NodeText","Data":" 是可训练参数的总数，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"n_layers"},{"Type":"NodeText","Data":" 是总层数，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"d_model"},{"Type":"NodeText","Data":" 是每个瓶颈层中的单元数（我们总是让前馈层的宽度是瓶颈层宽度的四倍，即 d_ff = 4 * d_model），"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"d_head"},{"Type":"NodeText","Data":" 是每个注意力头的维度。所有模型都使用了 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"n_ctx = 2048 个词元（token）的上下文窗口"},{"Type":"NodeText","Data":"。我们在GPU之间对模型进行了分区，同时在深度和宽度维度上进行划分，以最小化节点之间的数据传输。精确的架构参数是基于计算效率和在GPU间布局模型的负载均衡来选择的。先前的工作 [KMH+20] 表明，验证损失对这些参数在合理的大范围内不敏感。"}]},{"ID":"20250915110840-gujm7po","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915110840-gujm7po","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.2 训练数据集 (Training Dataset)"}]},{"ID":"20250915110840-87e8e2g","Type":"NodeParagraph","Properties":{"id":"20250915110840-87e8e2g","updated":"20250915111118"},"Children":[{"Type":"NodeText","Data":"语言模型的数据集迅速扩展，最终达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"近万亿词"},{"Type":"NodeText","Data":"的规模 [RSR+19]，这足以在不更新的情况下训练我们最大的模型。然而，我们发现，未经过滤或轻度过滤的 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Common Crawl"},{"Type":"NodeText","Data":" 数据集的质量要比更精选的数据集低。因此，我们采取了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三个步骤来提高数据集的平均质量"},{"Type":"NodeText","Data":"：(1) 我们下载并过滤了一个基于与一系列高质量参考语料库相似度进行筛选的 Common Crawl 版本，(2) 我们在数据集内部和跨数据集层面进行了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模糊去重"},{"Type":"NodeText","Data":"，以防止冗余并保持我们的留出验证集的完整性，(3) 我们还在训练组合中加入了已知的高质量参考语料库，以增强 Common Crawl 的内容并增加其多样性。"}]},{"ID":"20250915110840-7rjh6lp","Type":"NodeParagraph","Properties":{"id":"20250915110840-7rjh6lp","updated":"20250915111118"},"Children":[{"Type":"NodeText","Data":"处理 Common Crawl 的第一步细节在附录A中有描述。对于第三步，我们加入了几个高质量的语料库，包括一个扩展版的 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WebText2"},{"Type":"NodeText","Data":" 数据集 [RWC+19]，它是通过抓取更长时间段内的链接创建的；两个基于互联网的书籍语料库（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Books1"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Books2"},{"Type":"NodeText","Data":"）；以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"英文维基百科"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915110840-efcpbwt","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915110840-efcpbwt","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 2.2：训练期间使用的总计算量 (Total Compute Used During Training)"}]},{"ID":"20250915110840-2dbaz1r","Type":"NodeParagraph","Properties":{"id":"20250915110840-2dbaz1r","updated":"20250915140503"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明翻译:"},{"Type":"NodeText","Data":"\n基于对《自然语言模型缩放法则》[KMH+20] 的分析，我们"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在远少于常规词元数量的数据上训练了远大于常规规模的模型"},{"Type":"NodeText","Data":"。因此，尽管GPT-3 3B模型比RoBERTa-Large（3.55亿参数）大了近10倍，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两个模型在预训练期间都消耗了大约50 petaflop/s-days的计算量"},{"Type":"NodeText","Data":"。计算方法的细节可以在附录D中找到。"}]},{"ID":"20250915110840-s552dod","Type":"NodeThematicBreak","Properties":{"id":"20250915110840-s552dod","updated":"20250915140503"}},{"ID":"20250915110840-bjix9be","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915110840-bjix9be","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 2.2：用于训练GPT-3的数据集"}]},{"ID":"20250915110840-vei3b17","Type":"NodeTable","TableAligns":[1,1,1,1],"Properties":{"colgroup":"|||","id":"20250915110840-vei3b17","updated":"20250915140510"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"数据集"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"数量（词元）"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"在训练组合中的权重"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"训练3000亿词元后经过的轮数（Epochs）"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Common Crawl (filtered)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4100亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"60%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.44"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WebText2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"190亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"22%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.9"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Books1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"120亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.9"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Books2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"550亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.43"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Wikipedia"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"30亿"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.4"}]}]}]},{"ID":"20250915140523-qrctak0","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915140523-qrctak0","updated":"20250915140541"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915140526-wzad04j","Type":"NodeParagraph","Properties":{"id":"20250915140526-wzad04j","updated":"20250915140541"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明翻译:"},{"Type":"NodeText","Data":"\n“在训练组合中的权重”指的是训练期间从给定数据集中抽取的样本比例，我们"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有意使其与数据集的大小不成正比"},{"Type":"NodeText","Data":"。因此，在训练3000亿个词元的过程中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高质量数据集被看到了最多3.4次，而其他数据集被看到的次数还不到一次"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915110840-06qpvqr","Type":"NodeParagraph","Properties":{"id":"20250915110840-06qpvqr","updated":"20250915140510"},"Children":[{"Type":"NodeText","Data":"在广泛的互联网数据上预训练的语言模型，尤其是那些特别大的模型，一个主要的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法论上的担忧"},{"Type":"NodeText","Data":"是模型有能力记住大量内容，这可能导致"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据污染"},{"Type":"NodeText","Data":"，特别是对于那些其测试或开发集无意中出现在预训练数据中的下游任务。为了减少这种污染，我们搜索并尝试移除了我们研究的所有基准测试的开发集和测试集与训练数据之间的任何重叠。然而，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过滤中的一个bug导致我们忽略了一些重叠"},{"Type":"NodeText","Data":"，并且"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"由于训练成本高昂，重新训练模型是不可行的"},{"Type":"NodeText","Data":"。在第4节中，我们将描述这些重叠的影响，并在未来的工作中更积极地消除数据污染。"}]},{"ID":"20250915140828-yogb8zt","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915140828-yogb8zt","updated":"20250915140837"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915140837-o3ku2au","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915140837-o3ku2au","updated":"20250915140837"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915140837-76hics8","Type":"NodeParagraph","Properties":{"id":"20250915140837-76hics8","updated":"20250915140837"},"Children":[{"Type":"NodeText","Data":"这部分详细介绍了构建GPT-3所涉及的三个核心要素："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型架构、训练数据和计算资源"},{"Type":"NodeText","Data":"，并坦诚地指出了一个方法论上的问题。"}]}]},{"ID":"20250915140941-dw81tfo","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915140941-dw81tfo","updated":"20250915141001"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915141001-f3tn91h","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915141001-f3tn91h","updated":"20250915141001"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1. 模型架构：系统性的规模扩展"}]},{"ID":"20250915141001-drsf8hl","Type":"NodeList","ListData":{},"Properties":{"id":"20250915141001-drsf8hl","updated":"20250915141001"},"Children":[{"ID":"20250915141001-p705s3m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915141001-p705s3m","updated":"20250915141001"},"Children":[{"ID":"20250915141001-7nte2ro","Type":"NodeParagraph","Properties":{"id":"20250915141001-7nte2ro","updated":"20250915141001"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想："},{"Type":"NodeText","Data":" GPT-3的架构并非全新创造，而是在成熟的 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-2"},{"Type":"NodeText","Data":" 架构基础上进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统性的、大规模的扩展"},{"Type":"NodeText","Data":"。作者们的目标是验证一个关键假设——“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缩放法则（Scaling Laws）"},{"Type":"NodeText","Data":"”，即模型的性能会随着其规模（参数量）、数据量和计算量的增加而可预测地提升。"}]}]},{"ID":"20250915141001-vkcmolp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915141001-vkcmolp","updated":"20250915141001"},"Children":[{"ID":"20250915141001-n16m7uc","Type":"NodeParagraph","Properties":{"id":"20250915141001-n16m7uc","updated":"20250915141001"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"8个不同规模的模型："},{"Type":"NodeText","Data":" 如 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表2.1"},{"Type":"NodeText","Data":" 所示，研究团队训练了从1.25亿到1750亿参数不等的8个模型。这使得他们能够清晰地绘制出性能随规模变化的曲线，为“缩放法则”提供了强有力的证据。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1750亿参数的“GPT-3”模型"},{"Type":"NodeText","Data":"是这个系列中的巅峰之作，其规模在当时是前所未有的。"}]}]},{"ID":"20250915141001-t64q0n5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915141001-t64q0n5","updated":"20250915141001"},"Children":[{"ID":"20250915141001-cvdxo0v","Type":"NodeParagraph","Properties":{"id":"20250915141001-cvdxo0v","updated":"20250915141001"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2048词元的上下文窗口："},{"Type":"NodeText","Data":" 这是模型一次能“看”到的文本长度，这个长度决定了模型处理长文本和进行上下文学习的能力上限。"}]}]}]}]},{"ID":"20250915140955-babu6m9","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915140955-babu6m9","updated":"20250915141017"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915141017-fskzhdj","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915141017-fskzhdj","updated":"20250915141017"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2. 训练数据：质量优先与精心混合"}]},{"ID":"20250915141017-pvdhrx3","Type":"NodeList","ListData":{},"Properties":{"id":"20250915141017-pvdhrx3","updated":"20250915141018"},"Children":[{"ID":"20250915141017-mqz4t28","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915141017-mqz4t28","updated":"20250915141017"},"Children":[{"ID":"20250915141017-sq46nhw","Type":"NodeParagraph","Properties":{"id":"20250915141017-sq46nhw","updated":"20250915141017"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"挑战："},{"Type":"NodeText","Data":" 训练如此巨大的模型需要海量数据，但原始的网络数据（如Common Crawl）质量参差不齐，充满噪声。"}]}]},{"ID":"20250915141017-8mcnbvx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915141017-8mcnbvx","updated":"20250915141017"},"Children":[{"ID":"20250915141017-10z0dra","Type":"NodeParagraph","Properties":{"id":"20250915141017-10z0dra","updated":"20250915141017"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解决方案："},{"Type":"NodeText","Data":" 作者采取了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“质量优先”"},{"Type":"NodeText","Data":"的策略。"}]},{"ID":"20250915141017-g2kv6rn","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915141017-g2kv6rn","updated":"20250915141017"},"Children":[{"ID":"20250915141017-6mwztnf","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915141017-6mwztnf","updated":"20250915141017"},"Children":[{"ID":"20250915141017-3ua2mgw","Type":"NodeParagraph","Properties":{"id":"20250915141017-3ua2mgw","updated":"20250915141017"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过滤："},{"Type":"NodeText","Data":" 对庞大的Common Crawl数据集进行筛选，只保留与高质量语料库相似的内容。"}]}]},{"ID":"20250915141017-w41t2nt","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915141017-w41t2nt","updated":"20250915141017"},"Children":[{"ID":"20250915141017-swzcl0s","Type":"NodeParagraph","Properties":{"id":"20250915141017-swzcl0s","updated":"20250915141017"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"去重："},{"Type":"NodeText","Data":" 进行模糊去重，避免模型在重复内容上过度训练。"}]}]},{"ID":"20250915141017-o00x1o3","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915141017-o00x1o3","updated":"20250915141017"},"Children":[{"ID":"20250915141017-ul66q9e","Type":"NodeParagraph","Properties":{"id":"20250915141017-ul66q9e","updated":"20250915141017"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合高质量数据："},{"Type":"NodeText","Data":" 将过滤后的数据与精选的高质量语料库（WebText2, Books1, Books2, Wikipedia）混合。"}]}]}]}]},{"ID":"20250915141017-rxoodjw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915141017-rxoodjw","updated":"20250915141017"},"Children":[{"ID":"20250915141017-c6xg2ed","Type":"NodeParagraph","Properties":{"id":"20250915141017-c6xg2ed","updated":"20250915141017"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键策略（见表2.2）："},{"Type":"NodeText","Data":" 他们在训练中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对高质量数据进行了过采样（over-sampling）"},{"Type":"NodeText","Data":"。例如，维基百科（Wikipedia）虽然只占数据总量的很小一部分，但在训练中被“喂”给模型3.4次（epochs）。这意味着模型会更频繁地“学习”高质量、事实性强的内容，这被认为是提升模型能力和可靠性的关键。"}]}]}]}]},{"ID":"20250915140956-bbje16f","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915140956-bbje16f","updated":"20250915141034"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915141034-rxf72g6","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915141034-rxf72g6","updated":"20250915141034"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3. 计算资源与训练策略：更大的模型，更少的数据轮次"}]},{"ID":"20250915141034-mvaoa8r","Type":"NodeList","ListData":{},"Properties":{"id":"20250915141034-mvaoa8r","updated":"20250915141034"},"Children":[{"ID":"20250915141034-mai54ow","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915141034-mai54ow","updated":"20250915141034"},"Children":[{"ID":"20250915141034-lemfmxs","Type":"NodeParagraph","Properties":{"id":"20250915141034-lemfmxs","updated":"20250915141034"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 2.2"},{"Type":"NodeText","Data":" 直观地展示了训练GPT-3模型所需的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"惊人计算量"},{"Type":"NodeText","Data":"，远超之前的BERT、RoBERTa等模型。"}]}]},{"ID":"20250915141034-inyqgbs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915141034-inyqgbs","updated":"20250915141034"},"Children":[{"ID":"20250915141034-6992dmq","Type":"NodeParagraph","Properties":{"id":"20250915141034-6992dmq","updated":"20250915141034"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"独特的训练理念："},{"Type":"NodeText","Data":" 基于“缩放法则”，作者们得出一个重要结论：在固定的计算预算下，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将资源用于扩大模型规模比将资源用于在更多数据上训练更长时间，带来的收益更大"},{"Type":"NodeText","Data":"。这就是为什么GPT-3的训练数据轮次（epochs）非常少（大部分数据只见过不到一次），但模型规模却做得非常大。这与之前很多模型（如RoBERTa）在相对较小的数据集上反复训练的策略形成了鲜明对比。"}]}]}]}]},{"ID":"20250915141019-h4w6mej","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915141019-h4w6mej","updated":"20250915141055"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915141055-g2wq0at","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250915141055-g2wq0at","updated":"20250915141055"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4. 方法论的坦诚：数据污染问题"}]},{"ID":"20250915141055-tdcx3ac","Type":"NodeList","ListData":{},"Properties":{"id":"20250915141055-tdcx3ac","updated":"20250915141055"},"Children":[{"ID":"20250915141055-nlasthr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915141055-nlasthr","updated":"20250915141055"},"Children":[{"ID":"20250915141055-2ucfo0m","Type":"NodeParagraph","Properties":{"id":"20250915141055-2ucfo0m","updated":"20250915141055"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"透明度："},{"Type":"NodeText","Data":" 作者非常坦诚地承认了研究中的一个缺陷——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据污染"},{"Type":"NodeText","Data":"。由于一个bug，他们未能完全清除训练数据中包含的测试集内容。"}]}]},{"ID":"20250915141055-oj6faxl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915141055-oj6faxl","updated":"20250915141055"},"Children":[{"ID":"20250915141055-2o8qn4b","Type":"NodeParagraph","Properties":{"id":"20250915141055-2o8qn4b","updated":"20250915141055"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重要性："},{"Type":"NodeText","Data":" 这个问题很重要，因为它可能导致模型在某些基准测试上的得分被夸大（因为它在训练时“偷看”了答案）。作者承认了这一点，并因"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高昂的训练成本"},{"Type":"NodeText","Data":"而无法重新训练模型来修正。这种科学上的诚实和透明是这篇论文的一个重要特点。"}]}]}]}]},{"ID":"20250914145604-cdp5w0m","Type":"NodeParagraph","Properties":{"id":"20250914145604-cdp5w0m","updated":"20250915141053"},"Children":[{"Type":"NodeText","Data":"\n"}]},{"ID":"20250915140615-zvct5p1","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915140615-zvct5p1","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.3 训练过程 (Training Process)"}]},{"ID":"20250915140615-y2psddl","Type":"NodeParagraph","Properties":{"id":"20250915140615-y2psddl","updated":"20250915141053"},"Children":[{"Type":"NodeText","Data":"正如 [KMH+20, MKAT18] 中所发现的，更大的模型通常可以使用更大的批次大小，但需要更小的学习率。我们在训练期间测量梯度噪声规模，并用它来指导我们对批次大小的选择 [MKAT18]。表2.1展示了我们使用的参数设置。为了在不耗尽内存的情况下训练更大的模型，我们混合使用了"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"矩阵乘法内部的模型并行"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"跨网络层的模型并行"},{"Type":"NodeText","Data":"。所有模型都在由微软提供的高带宽集群上，使用 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"V100 GPU"},{"Type":"NodeText","Data":" 进行训练。训练过程和超参数设置的细节在附录B中有描述。"}]},{"ID":"20250915140615-yd9zz5l","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915140615-yd9zz5l","updated":"20250915141053"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915140615-lqhhieu","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915140615-lqhhieu","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915140615-h9i4x3t","Type":"NodeParagraph","Properties":{"id":"20250915140615-h9i4x3t","updated":"20250915140615"},"Children":[{"Type":"NodeText","Data":"这部分简要但关键地概述了成功训练巨大模型所必需的工程技术。"}]},{"ID":"20250915140615-iesnipo","Type":"NodeList","ListData":{},"Properties":{"id":"20250915140615-iesnipo","updated":"20250915140615"},"Children":[{"ID":"20250915140615-tag4s76","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915140615-tag4s76","updated":"20250915140615"},"Children":[{"ID":"20250915140615-lvxq02p","Type":"NodeParagraph","Properties":{"id":"20250915140615-lvxq02p","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"超参数的权衡"},{"Type":"NodeText","Data":": 这里指出了一个在大模型训练中的关键原则：模型规模、批次大小和学习率之间存在相互制约的关系。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型越大，就需要越大的批次和越小的学习率"},{"Type":"NodeText","Data":"来保证训练的稳定性和收敛性。这并非凭空猜测，而是基于先前研究的经验性结论。"}]}]},{"ID":"20250915140615-xdnkiq1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915140615-xdnkiq1","updated":"20250915140615"},"Children":[{"ID":"20250915140615-xbbotpx","Type":"NodeParagraph","Properties":{"id":"20250915140615-xbbotpx","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"并行的艺术"},{"Type":"NodeText","Data":": 训练一个像GPT-3 175B这样参数量巨大的模型，是任何单个GPU都无法完成的任务。这里的核心技术是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型并行"},{"Type":"NodeText","Data":"。作者提到了两种并行策略的结合："}]},{"ID":"20250915140615-8y6v54b","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915140615-8y6v54b","updated":"20250915140615"},"Children":[{"ID":"20250915140615-c1t3rog","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915140615-c1t3rog","updated":"20250915140615"},"Children":[{"ID":"20250915140615-3w4z7ec","Type":"NodeParagraph","Properties":{"id":"20250915140615-3w4z7ec","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"张量并行 (Tensor Parallelism)"},{"Type":"NodeText","Data":": 即文中的“矩阵乘法内部的模型并行”，它将模型内部的单个大矩阵（如权重矩阵）切分到多个GPU上进行计算。"}]}]},{"ID":"20250915140615-bbyi0kf","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915140615-bbyi0kf","updated":"20250915140615"},"Children":[{"ID":"20250915140615-fyctx94","Type":"NodeParagraph","Properties":{"id":"20250915140615-fyctx94","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"流水线并行 (Pipeline Parallelism)"},{"Type":"NodeText","Data":": 即文中的“跨网络层的模型并行”，它将模型的不同层（layers）分配到不同的GPU上，形成一个流水线。\n这种复杂的并行策略是成功训练千亿级参数模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工程关键"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915140615-c2vqunw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915140615-c2vqunw","updated":"20250915140615"},"Children":[{"ID":"20250915140615-uhexmc0","Type":"NodeParagraph","Properties":{"id":"20250915140615-uhexmc0","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"计算资源"},{"Type":"NodeText","Data":": 明确指出使用了NVIDIA V100 GPU和微软提供的高性能计算集群，这不仅说明了所需的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"巨大计算成本"},{"Type":"NodeText","Data":"，也体现了这类前沿研究对顶级基础设施的依赖。"}]}]}]}]},{"ID":"20250915140615-u4lmfq6","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915140615-u4lmfq6","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.4 评估 (Evaluation)"}]},{"ID":"20250915140615-vew5yn6","Type":"NodeParagraph","Properties":{"id":"20250915140615-vew5yn6","updated":"20250915141053"},"Children":[{"Type":"NodeText","Data":"对于"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"少样本学习"},{"Type":"NodeText","Data":"，我们通过从该任务的训练集中随机抽取 "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"K"},{"Type":"NodeText","Data":" 个样本作为"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"条件"},{"Type":"NodeText","Data":"，来评估评估集中的每个样本，根据任务的不同，用1或2个换行符分隔。对于LAMBADA和Storycloze这两个任务，没有可用的监督训练集，因此我们从"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"开发集"},{"Type":"NodeText","Data":"中抽取条件示例，并在"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"测试集"},{"Type":"NodeText","Data":"上进行评估。对于Winograd（原始的，非SuperGLUE版本），只有一个数据集，所以我们直接从中抽取条件示例。"}]},{"ID":"20250915140615-9p1ccoh","Type":"NodeParagraph","Properties":{"id":"20250915140615-9p1ccoh","updated":"20250915141053"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"K"},{"Type":"NodeText","Data":" 可以是0到模型上下文窗口（所有模型的 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"n_ctx 均为2048"},{"Type":"NodeText","Data":"）允许的最大值之间的任何值，通常可以容纳"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"10到100个示例"},{"Type":"NodeText","Data":"。更大的 "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"K"},{"Type":"NodeText","Data":" 值通常更好，但并非总是如此，所以当有单独的开发集和测试集可用时，我们会用几个不同的 "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"K"},{"Type":"NodeText","Data":" 值进行实验，然后在测试集上运行表现最好的那个 "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"K"},{"Type":"NodeText","Data":" 值。对于某些任务（参见附录G），除了（或者在 "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"K"},{"Type":"NodeText","Data":"=0 的情况下，代替）演示示例外，我们还使用"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"自然语言提示"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915140615-6jy7oo5","Type":"NodeParagraph","Properties":{"id":"20250915140615-6jy7oo5","updated":"20250915141053"},"Children":[{"Type":"NodeText","Data":"对于涉及从多个选项中选择一个正确补全的"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"多项选择任务"},{"Type":"NodeText","Data":"（例如ARC, OpenBookQA, 和 RACE），我们提供 "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"K"},{"Type":"NodeText","Data":" 个“上下文+正确补全”的示例，然后提供一个只有上下文的示例，并比较语言模型对每个补全选项的"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"似然度"},{"Type":"NodeText","Data":"。对于大多数任务，我们可以比较每个词元的似然度（为了按长度归一化），然而在一个小的开发集上，我们通过对每个补全选项的"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"无条件概率"},{"Type":"NodeText","Data":"进行"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"归一化"},{"Type":"NodeText","Data":"，获得了额外的性能提升，具体计算方式为 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"P(补全|上下文) / P(补全|答案上下文)"},{"Type":"NodeText","Data":"​，其中"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"答案上下文"},{"Type":"NodeText","Data":"​是字符串 \"Answer: \" 或 \"A: \"，用于提示补全应该是一个答案，但这个答案是通用的。"}]},{"ID":"20250915140615-h2io87e","Type":"NodeParagraph","Properties":{"id":"20250915140615-h2io87e","updated":"20250915141053"},"Children":[{"Type":"NodeText","Data":"在涉及"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"二元分类"},{"Type":"NodeText","Data":"的任务中，我们给选项赋予更有语义意义的名称（例如，“True”或“False”而不是0或1），然后将其视为多项选择任务；我们有时也会像 [RSR+19] 中那样构建任务（详见附录G）。"}]},{"ID":"20250915140615-fdzba1s","Type":"NodeParagraph","Properties":{"id":"20250915140615-fdzba1s","updated":"20250915141053"},"Children":[{"Type":"NodeText","Data":"对于"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"自由形式补全"},{"Type":"NodeText","Data":"的任务，我们使用与 [RSR+19] 相同的参数进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"集束搜索（beam search）"},{"Type":"NodeText","Data":"：束宽为4，长度惩罚系数 α = 0.6。我们根据手头的任务，使用F1相似度分数、BLEU或精确匹配来为模型评分。"}]},{"ID":"20250915140615-2qb6c9t","Type":"NodeParagraph","Properties":{"id":"20250915140615-2qb6c9t","updated":"20250915141053"},"Children":[{"Type":"NodeText","Data":"最终结果在公开可用的测试集上报告，针对每种模型大小和学习设置（零样本、单样本和少样本）。如果测试集是私有的，我们的模型通常太大而无法在测试服务器上运行，所以我们在开发集上报告结果。我们确实向少数数据集（SuperGLUE, TriviaQA, PiQA）的测试服务器提交了结果，我们提交了200B模型的少样本结果，并为所有其他模型报告开发集结果。"}]},{"ID":"20250915140615-y1zcy0k","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915140615-y1zcy0k","updated":"20250915140615"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915140615-h6kfz5h","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915140615-h6kfz5h","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915140615-7b0s1z7","Type":"NodeParagraph","Properties":{"id":"20250915140615-7b0s1z7","updated":"20250915140615"},"Children":[{"Type":"NodeText","Data":"这部分详细阐述了如何科学、严谨地对GPT-3的上下文学习能力进行评估，是理解其论文中各种性能数据从何而来的关键。"}]},{"ID":"20250915140615-1ga2124","Type":"NodeList","ListData":{},"Properties":{"id":"20250915140615-1ga2124","updated":"20250915140615"},"Children":[{"ID":"20250915140615-wm8aocj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915140615-wm8aocj","updated":"20250915140615"},"Children":[{"ID":"20250915140615-bo653i3","Type":"NodeParagraph","Properties":{"id":"20250915140615-bo653i3","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"提示的构建方法 (Prompt Construction)"},{"Type":"NodeText","Data":": 这是评估上下文学习的核心。对于少样本学习，评估时给出的示例（即"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"条件"},{"Type":"NodeText","Data":"）是从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务的训练集中随机抽取"},{"Type":"NodeText","Data":"的。这保证了评估的公平性和可重复性，避免了人工精心挑选“最佳”示例来拔高分数。"}]}]},{"ID":"20250915140615-s63s6xo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915140615-s63s6xo","updated":"20250915140615"},"Children":[{"ID":"20250915140615-zrtg09q","Type":"NodeParagraph","Properties":{"id":"20250915140615-zrtg09q","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"针对不同任务类型的评估策略"},{"Type":"NodeText","Data":": GPT-3是一个通用模型，但不同的NLP任务有不同的输出格式。作者为此设计了不同的评估方案："}]},{"ID":"20250915140615-ys5hehi","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915140615-ys5hehi","updated":"20250915140615"},"Children":[{"ID":"20250915140615-dbjm2t4","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915140615-dbjm2t4","updated":"20250915140615"},"Children":[{"ID":"20250915140615-00smsdk","Type":"NodeParagraph","Properties":{"id":"20250915140615-00smsdk","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多项选择题"},{"Type":"NodeText","Data":": 不是让模型自由生成答案，而是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计算模型认为哪个给定选项的概率（似然度）最高"},{"Type":"NodeText","Data":"。这是一种非常聪明且有效的方法，可以将开放的生成问题转化为可量化的选择问题。"}]}]},{"ID":"20250915140615-5y0mrfx","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915140615-5y0mrfx","updated":"20250915140615"},"Children":[{"ID":"20250915140615-8hiaym4","Type":"NodeParagraph","Properties":{"id":"20250915140615-8hiaym4","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"二元分类"},{"Type":"NodeText","Data":": 将简单的“0/1”标签换成更有意义的词语，如“True/False”。这利用了语言模型在预训练时学到的语义知识，帮助模型更好地理解任务。"}]}]},{"ID":"20250915140615-41jpg7x","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915140615-41jpg7x","updated":"20250915140615"},"Children":[{"ID":"20250915140615-8tyrefm","Type":"NodeParagraph","Properties":{"id":"20250915140615-8tyrefm","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放式生成"},{"Type":"NodeText","Data":": 使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"集束搜索（beam search）"},{"Type":"NodeText","Data":"这一标准技术来生成高质量的文本，而不是简单地选择最可能的一个词。"}]}]}]}]},{"ID":"20250915140615-mp1r012","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915140615-mp1r012","updated":"20250915140615"},"Children":[{"ID":"20250915140615-ep6c1ws","Type":"NodeParagraph","Properties":{"id":"20250915140615-ep6c1ws","updated":"20250915140615"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"科学严谨性"},{"Type":"NodeText","Data":": 作者明确区分了在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开发集 (development set)"},{"Type":"NodeText","Data":" 和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"测试集 (test set)"},{"Type":"NodeText","Data":" 上的报告。通常，在开发集上调试超参数（比如选择最佳的K值），然后在从未见过的测试集上报告最终成绩。这种做法是机器学习研究的标准规范，确保了结果的公正性。"}]}]}]}]},{"ID":"20250915142553-clbzl44","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-clbzl44","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3. 结果 (Results)"}]},{"ID":"20250915142553-9y2uc5p","Type":"NodeParagraph","Properties":{"id":"20250915142553-9y2uc5p","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"在图3.1中，我们展示了第2节中描述的8个模型的训练曲线。对于这张图，我们还额外加入了6个参数量少至10万的超小型模型。正如在 [KMH+20] 中所观察到的，当有效利用训练计算资源时，语言模型的性能遵循一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幂律（power-law）"},{"Type":"NodeText","Data":"。在将这一趋势再扩展两个数量级后，我们只观察到与该幂律"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常轻微（如果有的话）的偏离"},{"Type":"NodeText","Data":"。有人可能会担心，这些在"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"交叉熵损失"},{"Type":"NodeText","Data":"上的改进仅仅来自于对我们训练语料库中虚假细节的建模。然而，我们将在接下来的章节中看到，交叉熵损失的改进，能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在广泛的自然语言任务上带来持续的性能提升"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915142553-2j4p9m5","Type":"NodeParagraph","Properties":{"id":"20250915142553-2j4p9m5","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"下面，我们在广泛的数据集上评估第2节中描述的8个模型（1750亿参数的GPT-3和7个更小的模型）。我们将这些数据集分为9个类别，分别代表大致相似的任务。"}]},{"ID":"20250915142553-ciclipv","Type":"NodeParagraph","Properties":{"id":"20250915142553-ciclipv","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"在 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.1节"},{"Type":"NodeText","Data":" 中，我们评估传统语言建模任务和与语言建模相似的任务，例如完形填空任务和句子/段落补全任务。在 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.2节"},{"Type":"NodeText","Data":" 中，我们评估类似于“闭卷”问答的任务：即需要利用存储在模型参数中的信息来回答常识性问题的任务。在 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.3节"},{"Type":"NodeText","Data":" 中，我们评估模型在语言之间进行翻译的能力（尤其是在单样本和少样本设置下）。在 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.4节"},{"Type":"NodeText","Data":" 中，我们评估模型在类Winograd模式任务上的性能。在 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.5节"},{"Type":"NodeText","Data":" 中，我们评估在涉及常识推理或问答的数据集上的表现。在 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.6节"},{"Type":"NodeText","Data":" 中，我们评估阅读理解任务，在 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.7节"},{"Type":"NodeText","Data":" 中，我们评估SuperGLUE基准测试套件，并在 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.8节"},{"Type":"NodeText","Data":" 中简要探讨NLI（自然语言推理）。最后，在 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.9节"},{"Type":"NodeText","Data":" 中，我们设计了一些新颖的任务，专门用于探究上下文学习能力——这些任务侧重于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"即时推理、适应性技能或开放式文本合成"},{"Type":"NodeText","Data":"。我们在少样本、单样本和零样本设置下评估所有任务。"}]},{"ID":"20250915142553-e48gihe","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-e48gihe","updated":"20250915142554"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-odlokoi","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-odlokoi","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-uaxfg8y","Type":"NodeParagraph","Properties":{"id":"20250915142553-uaxfg8y","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这部分是结果章节的引言，为后续所有实验数据提供了理论基础和内容导览。"}]},{"ID":"20250915142553-p5y5yhk","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915142553-p5y5yhk","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心理论：缩放法则 (Scaling Law)"}]},{"ID":"20250915142553-gv86e04","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-gv86e04","updated":"20250915142553"},"Children":[{"ID":"20250915142553-unato50","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-unato50","updated":"20250915142553"},"Children":[{"ID":"20250915142553-1f57skh","Type":"NodeParagraph","Properties":{"id":"20250915142553-1f57skh","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"引言的核心是再次强调"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“缩放法则”"},{"Type":"NodeText","Data":"的有效性。作者指出，即使模型规模和计算量增加了两个数量级（100倍），性能提升的趋势依然遵循可预测的幂律，没有出现瓶颈。这本身就是一个重大发现。"}]}]}]},{"ID":"20250915142553-5epryur","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915142553-5epryur","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心问题：泛化而非记忆"}]},{"ID":"20250915142553-g07oiuu","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-g07oiuu","updated":"20250915142553"},"Children":[{"ID":"20250915142553-h1zx6ob","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-h1zx6ob","updated":"20250915142553"},"Children":[{"ID":"20250915142553-cykwvr9","Type":"NodeParagraph","Properties":{"id":"20250915142553-cykwvr9","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"作者提出了一个关键的质疑：模型在训练指标（交叉熵损失）上的提升，会不会只是因为它"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"死记硬背"},{"Type":"NodeText","Data":"了训练数据，而没有真正学会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化"},{"Type":"NodeText","Data":"的能力？这部分引言的作用就是告诉读者，后续的所有实验结果都将证明，这种提升是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有意义的"},{"Type":"NodeText","Data":"，它实实在在地转化为了在各种真实NLP任务上的强大能力。"}]}]}]},{"ID":"20250915142553-lbk8dkv","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915142553-lbk8dkv","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容结构"}]},{"ID":"20250915142553-e4e93fs","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-e4e93fs","updated":"20250915142553"},"Children":[{"ID":"20250915142553-a4f89hp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-a4f89hp","updated":"20250915142553"},"Children":[{"ID":"20250915142553-svpsl2c","Type":"NodeParagraph","Properties":{"id":"20250915142553-svpsl2c","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"最后，该部分清晰地列出了后续内容的结构，像一份“实验报告”的目录，让读者可以清晰地了解将要展示的9大类任务评估，从基础的语言建模到复杂的即时推理。"}]}]}]}]},{"ID":"20250915142843-r8ci6k8","Type":"NodeParagraph","Properties":{"id":"20250915142843-r8ci6k8","updated":"20250915142843"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915142842-rve3uqy.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915142553-8cl1l41","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-8cl1l41","updated":"20250915142553"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-ppd4sxl","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915142553-ppd4sxl","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.1：性能随计算量平滑扩展"}]},{"ID":"20250915142553-n1z9ic1","Type":"NodeParagraph","Properties":{"id":"20250915142553-n1z9ic1","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915142553-prxoywk","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-prxoywk","updated":"20250915142553"},"Children":[{"ID":"20250915142553-m9e7dvx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-m9e7dvx","updated":"20250915142553"},"Children":[{"ID":"20250915142553-nzagxfu","Type":"NodeParagraph","Properties":{"id":"20250915142553-nzagxfu","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" 性能随计算量平滑扩展 (Smooth scaling of performance with compute)"}]}]},{"ID":"20250915142553-vt6lzcw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-vt6lzcw","updated":"20250915142553"},"Children":[{"ID":"20250915142553-dzkbr49","Type":"NodeParagraph","Properties":{"id":"20250915142553-dzkbr49","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 验证集损失 (Validation Loss)"}]}]},{"ID":"20250915142553-ql0lyft","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-ql0lyft","updated":"20250915142553"},"Children":[{"ID":"20250915142553-ui9ftm4","Type":"NodeParagraph","Properties":{"id":"20250915142553-ui9ftm4","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 计算量 (PetaFLOP/s-days)"}]}]},{"ID":"20250915142553-j5n3wrt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-j5n3wrt","updated":"20250915142553"},"Children":[{"ID":"20250915142553-giqyw4l","Type":"NodeParagraph","Properties":{"id":"20250915142553-giqyw4l","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"颜色条:"},{"Type":"NodeText","Data":" 参数量 (Parameters)"}]}]},{"ID":"20250915142553-kyiwe3a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-kyiwe3a","updated":"20250915142553"},"Children":[{"ID":"20250915142553-h8z8whb","Type":"NodeParagraph","Properties":{"id":"20250915142553-h8z8whb","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"虚线公式:"},{"Type":"NodeText","Data":" L = 2.57 * C⁻⁰.⁰⁴⁸"}]}]},{"ID":"20250915142553-8c5a6qd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-8c5a6qd","updated":"20250915142553"},"Children":[{"ID":"20250915142553-dzq70xn","Type":"NodeParagraph","Properties":{"id":"20250915142553-dzq70xn","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 以交叉熵验证损失衡量的性能，显示出与训练所用计算量之间存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幂律关系"},{"Type":"NodeText","Data":"。[KMH+20] 中观察到的幂律行为，在额外增加两个数量级的计算量后依然成立，仅与预测曲线有微小偏差。对于此图，我们排除了计算量和参数量之间重复的部分。"}]}]}]},{"ID":"20250915142553-y23ia86","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-y23ia86","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-wtk22ge","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-wtk22ge","updated":"20250915142553"},"Children":[{"ID":"20250915142553-9w6q7e6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-9w6q7e6","updated":"20250915142553"},"Children":[{"ID":"20250915142553-5zpk8ec","Type":"NodeParagraph","Properties":{"id":"20250915142553-5zpk8ec","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这张图是整篇论文"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最重要的理论基石"},{"Type":"NodeText","Data":"。它在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对数-对数坐标系"},{"Type":"NodeText","Data":"下展示了模型的验证损失（越低越好）与投入的计算量之间的关系。"}]}]},{"ID":"20250915142553-cg7q8an","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-cg7q8an","updated":"20250915142553"},"Children":[{"ID":"20250915142553-gx1oni2","Type":"NodeParagraph","Properties":{"id":"20250915142553-gx1oni2","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键发现"},{"Type":"NodeText","Data":"：图中的数据点几乎完美地拟合成一条"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"直线"},{"Type":"NodeText","Data":"。在对数坐标系下，直线关系就等同于现实世界中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幂律关系"},{"Type":"NodeText","Data":"。这意味着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型的性能提升是可预测的"},{"Type":"NodeText","Data":"——只要投入更多的计算资源（训练更大的模型），就能获得可预期的、更好的性能。这种平滑且没有平台期的趋势，给了研究者极大的信心去“大力出奇迹”。"}]}]}]}]},{"ID":"20250915143417-dw8a0fj","Type":"NodeTable","TableAligns":[1,1],"Properties":{"colgroup":"|","id":"20250915143417-dw8a0fj","updated":"20250915143417"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PTB"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SOTA (零样本)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"35.8ᵃ"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 零样本"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"20.5"}]}]}]},{"ID":"20250915142553-qjaecuo","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-qjaecuo","updated":"20250915143411"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-nh442is","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915142553-nh442is","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.1：在PTB语言建模数据集上的零样本结果"}]},{"ID":"20250915142553-q1ina6h","Type":"NodeParagraph","Properties":{"id":"20250915142553-q1ina6h","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915142553-ose70pn","Type":"NodeTable","TableAligns":[1,1],"Properties":{"colgroup":"|","id":"20250915142553-ose70pn","updated":"20250915142553"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PTB"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SOTA (零样本)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"35.8ᵃ"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 零样本"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"20.5"}]}]}]},{"ID":"20250915142553-nzxfyg9","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-nzxfyg9","updated":"20250915142553"},"Children":[{"ID":"20250915142553-q6i0l89","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-q6i0l89","updated":"20250915142553"},"Children":[{"ID":"20250915142553-xc10j42","Type":"NodeParagraph","Properties":{"id":"20250915142553-xc10j42","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" 许多其他常见的语言建模数据集被省略了，因为它们源自维基百科或其他包含在GPT-3训练数据中的来源。"}]}]}]},{"ID":"20250915142553-2xgk4dz","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-2xgk4dz","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-2spcbgu","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-2spcbgu","updated":"20250915142553"},"Children":[{"ID":"20250915142553-3wxnmh2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-3wxnmh2","updated":"20250915142553"},"Children":[{"ID":"20250915142553-ampzq1n","Type":"NodeParagraph","Properties":{"id":"20250915142553-ampzq1n","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这张表展示了GPT-3在经典的Penn Tree Bank (PTB)数据集上的表现。“PTB”后面的数值是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"困惑度（Perplexity, ppl）"},{"Type":"NodeText","Data":"，这个值"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"越低越好"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915142553-f33bkvp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-f33bkvp","updated":"20250915142553"},"Children":[{"ID":"20250915142553-nz8i25x","Type":"NodeParagraph","Properties":{"id":"20250915142553-nz8i25x","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键结果"},{"Type":"NodeText","Data":"：在不进行任何微调的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本"},{"Type":"NodeText","Data":"设置下，GPT-3的困惑度（20.5）远低于之前的最佳水平（35.8），这是一个非常显著的提升。它证明了GPT-3强大的基础语言建模能力。"}]}]}]}]},{"ID":"20250915142553-b0lkej1","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915142553-b0lkej1","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.1 语言建模、完形填空和补全任务 (Language Modeling, Cloze, and Completion Tasks)"}]},{"ID":"20250915142553-luz4elu","Type":"NodeParagraph","Properties":{"id":"20250915142553-luz4elu","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"在本节中，我们测试GPT-3在传统语言建模任务上的性能，以及涉及预测单个感兴趣的词、补全一个句子或段落，或从可能的补全中进行选择的任务。"}]},{"ID":"20250915142553-jhoufh0","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-jhoufh0","updated":"20250915142554"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-tyatr3t","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-tyatr3t","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-9dysami","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-9dysami","updated":"20250915142553"},"Children":[{"ID":"20250915142553-v7v1nbn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-v7v1nbn","updated":"20250915142553"},"Children":[{"ID":"20250915142553-3mzpmaa","Type":"NodeParagraph","Properties":{"id":"20250915142553-3mzpmaa","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这是一个引导性段落，说明本节将要测试的是模型最基础也是最核心的能力——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本预测和补全"},{"Type":"NodeText","Data":"。这些任务是后续更复杂任务（如问答、翻译）的基础。"}]}]}]}]},{"ID":"20250915142553-3k6cpaw","Type":"NodeParagraph","Properties":{"id":"20250915142553-3k6cpaw","updated":"20250915142554"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.1.1 宾州树库 (Penn Tree Bank, PTB)"}]},{"ID":"20250915142553-ys5s0om","Type":"NodeParagraph","Properties":{"id":"20250915142553-ys5s0om","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"我们计算了在[RWC+19]中测量的宾州树库（PTB）[MKM+94]上的零样本困惑度。我们省略了那项工作中与维基百科相关的4个任务，因为它们完全包含在我们的训练数据中。PTB也面临这个问题，因为它的数据来源是一个十亿词的语料库，该语料库包含在我们的训练集中。PTB通过其过时的现代互联网数据来源，在一定程度上避免了这个问题。PTB的困惑度达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"20.50"},{"Type":"NodeText","Data":"，比之前的最佳水平提升了15个点。请注意，由于PTB是一个传统的语言建模数据集，它没有明确的单样本或少样本评估的划分，所以我们只测量零样本。"}]},{"ID":"20250915142553-78aehwa","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-78aehwa","updated":"20250915142554"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-f5c3m5a","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-f5c3m5a","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-m17hwkq","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-m17hwkq","updated":"20250915142553"},"Children":[{"ID":"20250915142553-0n7fqek","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-0n7fqek","updated":"20250915142553"},"Children":[{"ID":"20250915142553-r1p0hcx","Type":"NodeParagraph","Properties":{"id":"20250915142553-r1p0hcx","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这段文字详细解释了 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.1"},{"Type":"NodeText","Data":" 的结果。"}]}]},{"ID":"20250915142553-aec2rer","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-aec2rer","updated":"20250915142553"},"Children":[{"ID":"20250915142553-tfoti4h","Type":"NodeParagraph","Properties":{"id":"20250915142553-tfoti4h","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"数据污染问题"},{"Type":"NodeText","Data":"：作者坦诚地指出了PTB数据集可能存在于训练数据中的问题，这体现了研究的严谨性。"}]}]},{"ID":"20250915142553-n2pjjsw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-n2pjjsw","updated":"20250915142553"},"Children":[{"ID":"20250915142553-l1w8oe9","Type":"NodeParagraph","Properties":{"id":"20250915142553-l1w8oe9","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"显著的性能提升"},{"Type":"NodeText","Data":"：再次强调了GPT-3在零样本设置下取得的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"15个点的巨大提升"},{"Type":"NodeText","Data":"，证明了其基础建模能力的强大。"}]}]}]}]},{"ID":"20250915142553-35i7kme","Type":"NodeParagraph","Properties":{"id":"20250915142553-35i7kme","updated":"20250915142554"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.1.2 LAMBADA"}]},{"ID":"20250915142553-ucr5eep","Type":"NodeParagraph","Properties":{"id":"20250915142553-ucr5eep","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"LAMBADA数据集 [PKL+16] 测试模型在文本中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长程依赖性"},{"Type":"NodeText","Data":"的建模能力——模型被要求预测句子的最后一个词，而这需要阅读和理解一段上下文。最近的研究表明，随着模型规模的持续扩大，在这个困难的基准测试上正在产生递减的回报。然而，最近两个最先进的结果之间的巨大差异表明，进一步的改进是可能的[SFP+19]。"}]},{"ID":"20250915143704-ph8fx86","Type":"NodeTable","TableAligns":[1,1,1,1,1],"Properties":{"colgroup":"||||","id":"20250915143704-ph8fx86","updated":"20250915143704"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LAMBADA (acc)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LAMBADA (ppl)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"StoryCloze (acc)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HellaSwag (acc)"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SOTA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"68.0ᵃ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.63ᵇ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"91.8"},{"Type":"NodeText","Data":"ᶜ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"85.6"},{"Type":"NodeText","Data":"ᵈ"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Zero-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"76.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"83.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78.9"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 One-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"72.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.35"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"84.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78.1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"86.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"87.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"79.3"}]}]}]},{"ID":"20250915142553-aczmu5y","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-aczmu5y","updated":"20250915142554"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-4xcd7j6","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915142553-4xcd7j6","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.2：在完形填空和补全任务上的性能"}]},{"ID":"20250915142553-yrvpakp","Type":"NodeParagraph","Properties":{"id":"20250915142553-yrvpakp","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915142553-bq8t6tq","Type":"NodeTable","TableAligns":[1,1,1,1,1],"Properties":{"colgroup":"||||","id":"20250915142553-bq8t6tq","updated":"20250915142553"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LAMBADA (acc)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LAMBADA (ppl)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"StoryCloze (acc)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HellaSwag (acc)"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SOTA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"68.0ᵃ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.63ᵃ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"91.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"85.6"},{"Type":"NodeText","Data":"ᵇ"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 零样本"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"76.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"83.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78.9"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 单样本"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"72.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.35"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"84.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78.1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 少样本"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"86.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"87.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"79.3"}]}]}]},{"ID":"20250915142553-vs04puf","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-vs04puf","updated":"20250915142553"},"Children":[{"ID":"20250915142553-yv4nlpi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-yv4nlpi","updated":"20250915142553"},"Children":[{"ID":"20250915142553-txd6yze","Type":"NodeParagraph","Properties":{"id":"20250915142553-txd6yze","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" GPT-3在LAMBADA上显著提升了SOTA，同时在两个困难的完形填空补全数据集上也取得了值得尊敬的性能。ᵃ[Tur20] ᵇ[RWC+19] ᵈ[LCH+20]。"}]}]}]},{"ID":"20250915142553-tz458zm","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-tz458zm","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-8ja7ev5","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-8ja7ev5","updated":"20250915142553"},"Children":[{"ID":"20250915142553-uo26n12","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-uo26n12","updated":"20250915142553"},"Children":[{"ID":"20250915142553-qce88d3","Type":"NodeParagraph","Properties":{"id":"20250915142553-qce88d3","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这张表展示了GPT-3在三个需要深度上下文理解的任务上的表现。"}]}]},{"ID":"20250915142553-f7sfthp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-f7sfthp","updated":"20250915142553"},"Children":[{"ID":"20250915142553-lv79xtl","Type":"NodeParagraph","Properties":{"id":"20250915142553-lv79xtl","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"LAMBADA的突破"},{"Type":"NodeText","Data":": 最引人注目的结果是在LAMBADA上。GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本"},{"Type":"NodeText","Data":"设置下的准确率（76.2%）就已经"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越了之前经过微调的SOTA模型"},{"Type":"NodeText","Data":"（68.0%）。而在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本"},{"Type":"NodeText","Data":"设置下，准确率更是达到了惊人的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"86.4%"},{"Type":"NodeText","Data":"。这强有力地证明了GPT-3处理长程依赖的能力。"}]}]},{"ID":"20250915142553-3e9ocgx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-3e9ocgx","updated":"20250915142553"},"Children":[{"ID":"20250915142553-yw9s1m2","Type":"NodeParagraph","Properties":{"id":"20250915142553-yw9s1m2","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"其他任务的强劲表现"},{"Type":"NodeText","Data":": 在StoryCloze和HellaSwag这两个常识推理任务上，虽然没有全面超越微调后的SOTA，但其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无需微调"},{"Type":"NodeText","Data":"就能取得如此接近的成绩，本身就是一项了不起的成就。"}]}]}]}]},{"ID":"20250915143650-7mot9e7","Type":"NodeParagraph","Properties":{"id":"20250915143650-7mot9e7","updated":"20250915143650"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915143650-9m3739q.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915142553-064gyac","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-064gyac","updated":"20250915142554"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-nyi6nvj","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915142553-nyi6nvj","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.2：LAMBADA数据集上的性能"}]},{"ID":"20250915142553-r5u1cqu","Type":"NodeParagraph","Properties":{"id":"20250915142553-r5u1cqu","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915142553-tgmnlxx","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-tgmnlxx","updated":"20250915142553"},"Children":[{"ID":"20250915142553-5vhbr98","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-5vhbr98","updated":"20250915142553"},"Children":[{"ID":"20250915142553-uhqj2k6","Type":"NodeParagraph","Properties":{"id":"20250915142553-uhqj2k6","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" LAMBADA"}]}]},{"ID":"20250915142553-dp52r0t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-dp52r0t","updated":"20250915142553"},"Children":[{"ID":"20250915142553-exs1rus","Type":"NodeParagraph","Properties":{"id":"20250915142553-exs1rus","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915142553-bmzg8ug","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-bmzg8ug","updated":"20250915142553"},"Children":[{"ID":"20250915142553-7ejssxc","Type":"NodeParagraph","Properties":{"id":"20250915142553-7ejssxc","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915142553-bec6v82","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-bec6v82","updated":"20250915142553"},"Children":[{"ID":"20250915142553-2f83nr1","Type":"NodeParagraph","Properties":{"id":"20250915142553-2f83nr1","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 人类 (Human), 零样本SOTA (Zero-Shot SOTA), 零样本 (Zero-Shot), 单样本 (One-Shot), 少样本 (Few-Shot (K=15))"}]}]},{"ID":"20250915142553-92evws5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-92evws5","updated":"20250915142553"},"Children":[{"ID":"20250915142553-fzj8qz4","Type":"NodeParagraph","Properties":{"id":"20250915142553-fzj8qz4","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 在LAMBADA数据集上，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型模型的少样本能力开始大幅提升准确率"},{"Type":"NodeText","Data":"。GPT-3 2.7B模型在此设置下超过了SOTA 17B模型Turing-NLG [Tur20]，而GPT-3 175B则将SOTA提升了18%。请注意，零样本和少样本使用了不同的格式，如正文所述。"}]}]}]},{"ID":"20250915142553-7ncjk1l","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-7ncjk1l","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-r0mm5a5","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-r0mm5a5","updated":"20250915142553"},"Children":[{"ID":"20250915142553-iobrvqk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-iobrvqk","updated":"20250915142553"},"Children":[{"ID":"20250915142553-dtygrae","Type":"NodeParagraph","Properties":{"id":"20250915142553-dtygrae","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这张图是展示"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“规模效应”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“上下文学习”"},{"Type":"NodeText","Data":"力量的绝佳例证。"}]}]},{"ID":"20250915142553-d6u257s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-d6u257s","updated":"20250915142553"},"Children":[{"ID":"20250915142553-oq0deqs","Type":"NodeParagraph","Properties":{"id":"20250915142553-oq0deqs","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"规模是关键"},{"Type":"NodeText","Data":"：观察所有曲线，无论是零样本、单样本还是少样本，准确率都随着模型参数量的增加而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳步提升"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915142553-qaa1ton","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-qaa1ton","updated":"20250915142553"},"Children":[{"ID":"20250915142553-diry8uk","Type":"NodeParagraph","Properties":{"id":"20250915142553-diry8uk","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"少样本学习的爆发"},{"Type":"NodeText","Data":"：最关键的是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本（Few-Shot）"},{"Type":"NodeText","Data":"的绿色曲线。在模型规模较小时，它的表现平平。但当模型规模超过一定阈值（大约13B参数）后，它的性能开始"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"急剧攀升"},{"Type":"NodeText","Data":"，远远超过了其他设置，甚至超过了人类水平的估测线。这表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只有足够大的模型，才能有效利用上下文中的示例进行学习"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915142553-hgpj4z2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-hgpj4z2","updated":"20250915142553"},"Children":[{"ID":"20250915142553-b1l5r4u","Type":"NodeParagraph","Properties":{"id":"20250915142553-b1l5r4u","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"超越SOTA"},{"Type":"NodeText","Data":"：图中标出了之前的SOTA模型的位置，可以清晰地看到，GPT-3在零样本设置下就超越了它，在少样本设置下更是大幅领先。"}]}]}]}]},{"ID":"20250915142553-4cakwpz","Type":"NodeParagraph","Properties":{"id":"20250915142553-4cakwpz","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"并且[Tur20]认为“继续将模型和数据大小扩大几个数量级不是前进的道路”。我们发现这条路仍然充满希望，并且在零样本设置下，GPT-3在LAMBADA上达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"76%"},{"Type":"NodeText","Data":"的准确率，比之前的SOTA提升了8%。"}]},{"ID":"20250915142553-b588l2m","Type":"NodeParagraph","Properties":{"id":"20250915142553-b588l2m","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"LAMBADA也展示了"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"少样本学习的灵活性"},{"Type":"NodeText","Data":"，因为它提供了一种解决该数据集经典问题的方法。一个标准的语言模型别无选择，只能将句子预测为句子的结尾，即使这在段落的更广泛语境中不合适。这个问题之前是通过使用带停止词过滤器的模型[RWC+19]（禁止“续写”词）来部分解决的。少样本设置允许我们改为将任务“框定”为一个完形填空任务——并允许语言模型推断出期望的补全类型。我们使用以下填充空白格式："}]},{"ID":"20250915142553-tok5bqb","Type":"NodeParagraph","Properties":{"id":"20250915142553-tok5bqb","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"爱丽丝和鲍勃是朋友。爱丽丝去看望她的朋友___________ → 鲍勃"},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915142553-p0iai14","Type":"NodeParagraph","Properties":{"id":"20250915142553-p0iai14","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"乔治买了一些他最喜欢的麦片，一盒___________ → 幸运符"},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915142553-tbka7zd","Type":"NodeParagraph","Properties":{"id":"20250915142553-tbka7zd","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"当以这种方式呈现示例时，GPT-3在少样本设置下达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"86.4%的准确率"},{"Type":"NodeText","Data":"，比之前的SOTA提升了18%。我们观察到少样本性能随着模型规模的增加而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强劲增长"},{"Type":"NodeText","Data":"。虽然此设置使单样本模型的性能降低了近20%，但它将零样本设置的准确率提高了10%。最后，这种填充空白方法对小模型无效，它们在这种设置下表现比零样本更差。这也许是因为小模型需要几个例子来识别模式。"}]},{"ID":"20250915142553-yvxvkl7","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-yvxvkl7","updated":"20250915142553"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-emvy58s","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-emvy58s","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-yrdh8q3","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-yrdh8q3","updated":"20250915142553"},"Children":[{"ID":"20250915142553-jnly77w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-jnly77w","updated":"20250915142553"},"Children":[{"ID":"20250915142553-kxhei6v","Type":"NodeParagraph","Properties":{"id":"20250915142553-kxhei6v","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"反驳现有观点"},{"Type":"NodeText","Data":"：作者直接引用并反驳了当时的一篇论文[Tur20]的观点，用自己压倒性的实验结果证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“继续扩大规模”这条路不仅可行，而且效果显著"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915142553-rcpaosh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-rcpaosh","updated":"20250915142553"},"Children":[{"ID":"20250915142553-fihh7iy","Type":"NodeParagraph","Properties":{"id":"20250915142553-fihh7iy","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"提示工程 (Prompt Engineering)"},{"Type":"NodeText","Data":"：这里展示了一个非常重要的概念——通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改变向模型提问的方式"},{"Type":"NodeText","Data":"（即“框定”任务），可以显著提升性能。将一个开放的句子补全任务，通过示例转化为一个类似“填空题”的任务，能更好地引导模型给出期望的答案。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习灵活性"},{"Type":"NodeText","Data":"的体现。"}]}]},{"ID":"20250915142553-w84bgix","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-w84bgix","updated":"20250915142553"},"Children":[{"ID":"20250915142553-aug5wlg","Type":"NodeParagraph","Properties":{"id":"20250915142553-aug5wlg","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"规模与上下文学习的关系"},{"Type":"NodeText","Data":"：最后一段的观察至关重要——这种“填空”的提示技巧"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只对大模型有效"},{"Type":"NodeText","Data":"。小模型反而会被这种格式搞糊涂。这再次印证了图3.2的结论："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有效的上下文学习能力是随着模型规模的扩大而涌现的"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915143834-eupx3vl","Type":"NodeTable","TableAligns":[1,1,1,1],"Properties":{"colgroup":"|||","id":"20250915143834-eupx3vl","updated":"20250915143834"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"NaturalQS"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WebQS"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"TriviaQA"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RAG (Fine-tuned, Open-Domain) [LPP⁺20]"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"44.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"45.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"68.0"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T5-11B+SSM (Fine-tuned, Closed-Book) [RRS20]"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"36.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"44.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"60.5"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T5-11B (Fine-tuned, Closed-Book)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"37.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"50.1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Zero-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64.3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 One-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"23.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"25.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"68.0"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"71.2"}]}]}]},{"ID":"20250915142553-kykk9gg","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-kykk9gg","updated":"20250915142554"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-evv3931","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915142553-evv3931","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.3：在三个开放域问答任务上的结果"}]},{"ID":"20250915142553-i7pv8jb","Type":"NodeParagraph","Properties":{"id":"20250915142553-i7pv8jb","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915142553-q802odh","Type":"NodeTable","TableAligns":[1,1,1,1],"Properties":{"colgroup":"|||","id":"20250915142553-q802odh","updated":"20250915142553"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"NaturalQS"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WebQS"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"TriviaQA"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RAG (微调, 开放域) [LPP+20]"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"44.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"45.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"68.0"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T5-11B+SSM (微调, 闭卷) [RRS20]"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"36.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"44.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"60.5"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T5-11B (微调, 闭卷)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"37.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"50.1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 零样本"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64.3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 单样本"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"23.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"25.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"68.0"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 少样本"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"71.2"}]}]}]},{"ID":"20250915142553-7lm2bi5","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-7lm2bi5","updated":"20250915142553"},"Children":[{"ID":"20250915142553-ht4t40z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-ht4t40z","updated":"20250915142553"},"Children":[{"ID":"20250915142553-yws6iex","Type":"NodeParagraph","Properties":{"id":"20250915142553-yws6iex","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" GPT-3在少样本、单样本和零样本设置下展示，与之前在闭卷和开放域设置下的SOTA结果进行比较。TriviaQA的少样本结果是在wiki分割测试服务器上评估的。"}]}]}]},{"ID":"20250915142553-k6v0fei","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-k6v0fei","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-be8upox","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-be8upox","updated":"20250915142553"},"Children":[{"ID":"20250915142553-rjqpryj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-rjqpryj","updated":"20250915142553"},"Children":[{"ID":"20250915142553-vb3rzt0","Type":"NodeParagraph","Properties":{"id":"20250915142553-vb3rzt0","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这张表比较了GPT-3与当时最先进的问答模型（RAG和T5）在三个问答数据集上的表现。"}]}]},{"ID":"20250915142553-pict1yn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-pict1yn","updated":"20250915142553"},"Children":[{"ID":"20250915142553-p9vw8mr","Type":"NodeParagraph","Properties":{"id":"20250915142553-p9vw8mr","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"闭卷 vs. 开放域"},{"Type":"NodeText","Data":": “闭卷”（Closed-Book）意味着模型只能依赖其内部参数中存储的知识来回答问题。“开放域”（Open-Domain）或“检索增强”（Retrieval-Augmented, 如RAG）模型可以在回答问题时"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检索外部文档"},{"Type":"NodeText","Data":"。GPT-3在这里是作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭卷"},{"Type":"NodeText","Data":"模型进行评估的。"}]}]},{"ID":"20250915142553-xtwn1b7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-xtwn1b7","updated":"20250915142553"},"Children":[{"ID":"20250915142553-fjxy1ps","Type":"NodeParagraph","Properties":{"id":"20250915142553-fjxy1ps","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"TriviaQA上的惊人表现"},{"Type":"NodeText","Data":"：最引人注目的结果是在TriviaQA上。GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单样本"},{"Type":"NodeText","Data":"设置下就达到了与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调过的、可以检索外部文档的SOTA模型RAG相媲美"},{"Type":"NodeText","Data":"的水平（68.0%）。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本"},{"Type":"NodeText","Data":"设置下，更是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越了所有对比模型"},{"Type":"NodeText","Data":"（71.2%）。这表明，1750亿参数的GPT-3在其内部"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"存储了海量的世界知识"},{"Type":"NodeText","Data":"，并且可以通过上下文学习有效地被调用。"}]}]},{"ID":"20250915142553-5f4h4vf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-5f4h4vf","updated":"20250915142553"},"Children":[{"ID":"20250915142553-398gds3","Type":"NodeParagraph","Properties":{"id":"20250915142553-398gds3","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"em strong","TextMarkTextContent":"局限性"},{"Type":"NodeText","Data":"：在NaturalQS和WebQS上，GPT-3的表现不如检索增强的RAG模型。这表明，对于那些需要精确、具体、可能不是特别大众化的知识的问题，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"依赖内部参数的“记忆”仍然不如直接去外部文档中查找"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915142553-gb3sshl","Type":"NodeParagraph","Properties":{"id":"20250915142553-gb3sshl","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"需要注意的一点是，一项测试集污染分析发现，LAMBADA数据集的一个显著的少数部分出现在我们的训练数据中——然而在第4节中进行的分析表明，这对性能的影响可以忽略不计。"}]},{"ID":"20250915142553-k2l0z3h","Type":"NodeParagraph","Properties":{"id":"20250915142553-k2l0z3h","updated":"20250915142554"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.1.3 HellaSwag"}]},{"ID":"20250915142553-h3wpetj","Type":"NodeParagraph","Properties":{"id":"20250915142553-h3wpetj","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"HellaSwag数据集 [ZHB+19] 涉及为故事或一组指令选择最佳结尾。这些示例是为语言模型特意挖掘出来的难题，但对人类来说却很简单（人类准确率达到95.6%）。GPT-3在单样本设置下达到了78.1%的准确率，在少样本设置下达到了79.3%，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超过了微调过的1.5B参数模型"},{"Type":"NodeText","Data":"[ZHR+19]的75.4%的准确率，但仍略低于微调过的多任务模型ALUM的85.6%的SOTA。"}]},{"ID":"20250915142553-9tdqf1q","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-9tdqf1q","updated":"20250915142554"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-oq7yy6p","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-oq7yy6p","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-op18c5h","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-op18c5h","updated":"20250915142553"},"Children":[{"ID":"20250915142553-ahaanbf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-ahaanbf","updated":"20250915142553"},"Children":[{"ID":"20250915142553-n5xcbjf","Type":"NodeParagraph","Properties":{"id":"20250915142553-n5xcbjf","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这段内容展示了GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识推理"},{"Type":"NodeText","Data":"方面的能力。HellaSwag是一个专门设计来“迷惑”语言模型的常识数据集。"}]}]},{"ID":"20250915142553-70aemnw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-70aemnw","updated":"20250915142553"},"Children":[{"ID":"20250915142553-utmrg8p","Type":"NodeParagraph","Properties":{"id":"20250915142553-utmrg8p","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键结果"},{"Type":"NodeText","Data":"：GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"没有微调"},{"Type":"NodeText","Data":"的情况下，性能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超过了比它小但经过微调的模型"},{"Type":"NodeText","Data":"。这再次证明了规模带来的上下文学习能力可以部分替代任务特定的微调。"}]}]},{"ID":"20250915142553-dmyy1ae","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-dmyy1ae","updated":"20250915142553"},"Children":[{"ID":"20250915142553-ktbv5vu","Type":"NodeParagraph","Properties":{"id":"20250915142553-ktbv5vu","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与SOTA的差距"},{"Type":"NodeText","Data":"：它仍然落后于当时最顶尖的、经过复杂多任务微调的模型。这表明，虽然上下文学习很强大，但在某些特别困难的任务上，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专门的微调仍然具有优势"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915142553-7se3yv9","Type":"NodeParagraph","Properties":{"id":"20250915142553-7se3yv9","updated":"20250915142554"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.1.4 StoryCloze"}]},{"ID":"20250915142553-mvvbnrw","Type":"NodeParagraph","Properties":{"id":"20250915142553-mvvbnrw","updated":"20250915142554"},"Children":[{"Type":"NodeText","Data":"我们接下来评估GPT-3在StoryCloze 2016数据集 [MCH+16] 上的表现，该任务涉及为五句话长的故事选择正确的结尾句子（K=70）。GPT-3在零样本设置下达到了83.2%的准确率，在少样本设置下达到了87.7%。这比使用BERT微调的SOTA [LDL19] 的91.8%低了4.1%，但比之前的零样本SOTA提升了大约10%。"}]},{"ID":"20250915142553-1nydf4c","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-1nydf4c","updated":"20250915142554"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-9o69r3y","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-9o69r3y","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915142553-0og4oh3","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-0og4oh3","updated":"20250915142553"},"Children":[{"ID":"20250915142553-1khb3dy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-1khb3dy","updated":"20250915142553"},"Children":[{"ID":"20250915142553-irbgzxx","Type":"NodeParagraph","Properties":{"id":"20250915142553-irbgzxx","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这部分继续测试模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识和故事理解能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915142553-eqqe1v2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-eqqe1v2","updated":"20250915142553"},"Children":[{"ID":"20250915142553-q353mii","Type":"NodeParagraph","Properties":{"id":"20250915142553-q353mii","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结果分析"},{"Type":"NodeText","Data":"：与HellaSwag类似，GPT-3在StoryCloze上表现强劲，尤其是在零样本设置下大幅提升了SOTA水平。然而，它依然未能超越经过微调的SOTA模型。这与前面的结果共同构成了一个模式："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3的上下文学习在很多任务上都能达到“非常好”甚至“SOTA”的水平，但在一些特定的、有大量标注数据的基准测试上，精心微调的模型仍然能达到更高的上限。"}]}]}]}]},{"ID":"20250915142553-8e0c440","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915142553-8e0c440","updated":"20250915142553"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915142553-o8rlm2v","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915142553-o8rlm2v","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250915142553-l2okfbe","Type":"NodeParagraph","Properties":{"id":"20250915142553-l2okfbe","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"这一整节“结果”的核心目的，是提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"坚实的、多方位的实验证据"},{"Type":"NodeText","Data":"来支持论文的核心论点。通过对这些图表和文字的综合分析，我们可以得出以下关键结论："}]},{"ID":"20250915142553-352m4ue","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915142553-352m4ue","updated":"20250915142553"},"Children":[{"ID":"20250915142553-41em4ja","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915142553-41em4ja","updated":"20250915142553"},"Children":[{"ID":"20250915142553-tn1lcrw","Type":"NodeParagraph","Properties":{"id":"20250915142553-tn1lcrw","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“缩放法则”是基石"},{"Type":"NodeText","Data":"：图3.1是所有结果的理论基础。它证明了通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩大模型规模和计算投入来提升模型性能是可预测且有效的"},{"Type":"NodeText","Data":"。后续所有任务的成功，都源于这个基础能力的提升。"}]}]},{"ID":"20250915142553-7qdixab","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915142553-7qdixab","updated":"20250915142553"},"Children":[{"ID":"20250915142553-zavas56","Type":"NodeParagraph","Properties":{"id":"20250915142553-zavas56","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的惊人涌现"},{"Type":"NodeText","Data":"：本节最重要的发现是，当模型规模足够大时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强大的上下文学习（In-context Learning）能力会涌现出来"},{"Type":"NodeText","Data":"。图3.2在LAMBADA上的表现是最佳例证：仅仅给出几个例子（少样本），一个巨大的模型就能在没有参数更新的情况下，超越为该任务专门微调的SOTA模型。这标志着一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"新范式的诞生"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915142553-6i99bbk","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915142553-6i99bbk","updated":"20250915142553"},"Children":[{"ID":"20250915142553-8vhq7f7","Type":"NodeParagraph","Properties":{"id":"20250915142553-8vhq7f7","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型即知识库 (Knowledge as Parameters)"},{"Type":"NodeText","Data":"：在TriviaQA问答任务（表3.3）上的成功表明，GPT-3不仅是一个语言处理器，更是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"庞大的知识库"},{"Type":"NodeText","Data":"。它将海量的世界知识隐式地存储在其1750亿个参数中，并能通过提示有效地进行查询。这挑战了传统依赖外部数据库或文档检索的问答系统。"}]}]},{"ID":"20250915142553-lxlts5m","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250915142553-lxlts5m","updated":"20250915142553"},"Children":[{"ID":"20250915142553-5yty8b9","Type":"NodeParagraph","Properties":{"id":"20250915142553-5yty8b9","updated":"20250915142553"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用性与局限性的并存"},{"Type":"NodeText","Data":"：GPT-3在横跨语言建模、完形填空、常识推理、知识问答等多种任务上都表现出色，证明了其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极强的通用性"},{"Type":"NodeText","Data":"。然而，结果也清晰地展示了其局限性："}]},{"ID":"20250915142553-6ww5iqf","Type":"NodeList","ListData":{},"Properties":{"id":"20250915142553-6ww5iqf","updated":"20250915142553"},"Children":[{"ID":"20250915142553-zzyax1y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-zzyax1y","updated":"20250915142553"},"Children":[{"ID":"20250915142553-ebfn57b","Type":"NodeParagraph","Properties":{"id":"20250915142553-ebfn57b","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"在需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确、非主流知识"},{"Type":"NodeText","Data":"的问答上，不如检索增强模型。"}]}]},{"ID":"20250915142553-tmthdkl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915142553-tmthdkl","updated":"20250915142553"},"Children":[{"ID":"20250915142553-kj87a1b","Type":"NodeParagraph","Properties":{"id":"20250915142553-kj87a1b","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"在有大量高质量标注数据的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成熟基准测试"},{"Type":"NodeText","Data":"（如StoryCloze）上，仍无法完全超越经过精心微调的SOTA模型。"}]}]}]}]}]},{"ID":"20250915142553-w48e9fs","Type":"NodeParagraph","Properties":{"id":"20250915142553-w48e9fs","updated":"20250915142553"},"Children":[{"Type":"NodeText","Data":"总结而言，第3节通过一系列详实的实验，从根本上改变了NLP领域的认知。它证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过规模化，语言模型可以从简单的“模式匹配器”转变为强大的“上下文学习者”和“知识载体”，为通向更通用人工智能的道路提供了有力的证据和方向。"}]}]},{"ID":"20250915144327-z1lyziy","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144327-z1lyziy","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.2 闭卷问答 (Closed Book Question Answering)"}]},{"ID":"20250915144327-pwj7vt9","Type":"NodeParagraph","Properties":{"id":"20250915144327-pwj7vt9","updated":"20250915144328"},"Children":[{"Type":"NodeText","Data":"在本节中，我们测量GPT-3回答关于广泛事实性知识问题的能力。由于可能存在的查询组合数量巨大，这项任务通常是通过一个信息检索系统来解决的，该系统首先找到相关文本，然后结合一个模型，在给定问题和检索到的文本的情况下生成答案。由于这种设置允许系统搜索并以文本为条件，它被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“开放书籍”（open-book）"},{"Type":"NodeText","Data":"。[RRS20] 最近证明，一个大型语言模型可以令人惊讶地很好地直接回答问题，而无需以任何辅助信息为条件。他们将这种更严格的评估假设称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“闭卷”（closed-book）"},{"Type":"NodeText","Data":"。他们的工作表明，即使是高容量模型也只能偶尔胜过随机猜测，但我们用GPT-3测试了这个假设。我们在3个数据集上评估GPT-3：[RRS20]中使用的Natural Questions [KPR+19]、WebQuestions [BCFL13]和TriviaQA [JCWZ17]，使用相同的分割方式。请注意，除了所有结果都在闭卷设置下得出之外，我们使用的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本、单样本和零样本评估，代表了比以往闭卷工作更严格的条件"},{"Type":"NodeText","Data":"：除了不允许外部内容，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对问答数据集本身的微调也是不允许的"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915144327-84ovqik","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144327-84ovqik","updated":"20250915144328"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144327-enayxbd","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144327-enayxbd","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915144327-x7x1umx","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144327-x7x1umx","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心概念：开放书籍 vs. 闭卷"}]},{"ID":"20250915144327-4qg5ecl","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144327-4qg5ecl","updated":"20250915144327"},"Children":[{"ID":"20250915144327-4y5ogzt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-4y5ogzt","updated":"20250915144327"},"Children":[{"ID":"20250915144327-pg6farl","Type":"NodeParagraph","Properties":{"id":"20250915144327-pg6farl","updated":"20250915144327"},"Children":[{"Type":"NodeText","Data":"这部分首先清晰地定义了两种问答范式："}]},{"ID":"20250915144327-boprnye","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144327-boprnye","updated":"20250915144327"},"Children":[{"ID":"20250915144327-ijq2leh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-ijq2leh","updated":"20250915144327"},"Children":[{"ID":"20250915144327-w1w8pos","Type":"NodeParagraph","Properties":{"id":"20250915144327-w1w8pos","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放书籍 (Open-Book)"},{"Type":"NodeText","Data":": 这是传统的方式，模型可以像“开卷考试”一样，先去一个知识库（如维基百科）中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"查找"},{"Type":"NodeText","Data":"相关信息，然后再根据找到的内容回答问题。"}]}]},{"ID":"20250915144327-dnpeka1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-dnpeka1","updated":"20250915144327"},"Children":[{"ID":"20250915144327-ukzy5nq","Type":"NodeParagraph","Properties":{"id":"20250915144327-ukzy5nq","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭卷 (Closed-Book)"},{"Type":"NodeText","Data":": 这是一种更具挑战性的方式，模型必须像“闭卷考试”一样，完全依赖其在训练期间"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"记在“脑子”（即模型参数）里的知识"},{"Type":"NodeText","Data":"来回答问题，不能临时查资料。"}]}]}]}]}]},{"ID":"20250915144327-dijtew2","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144327-dijtew2","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3的“终极”闭卷考试"}]},{"ID":"20250915144327-qz7ebm5","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144327-qz7ebm5","updated":"20250915144327"},"Children":[{"ID":"20250915144327-0i1h0t8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-0i1h0t8","updated":"20250915144327"},"Children":[{"ID":"20250915144327-7ylqe7b","Type":"NodeParagraph","Properties":{"id":"20250915144327-7ylqe7b","updated":"20250915144327"},"Children":[{"Type":"NodeText","Data":"作者强调，他们对GPT-3的评估是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“史上最严”"},{"Type":"NodeText","Data":"的闭卷考试。不仅不允许模型查找外部资料（这是闭卷的基本要求），甚至"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不允许针对问答任务进行任何微调"},{"Type":"NodeText","Data":"。这意味着GPT-3必须仅凭其通用的预训练知识和几个临时的例子，就能完成问答任务。"}]}]}]}]},{"ID":"20250915144327-6g3eg1g","Type":"NodeParagraph","Properties":{"id":"20250915144327-6g3eg1g","updated":"20250915144328"},"Children":[{"Type":"NodeText","Data":"GPT-3的结果显示在表3.3中。在TriviaQA上，我们在零样本设置下达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"64.3%"},{"Type":"NodeText","Data":"的准确率，在单样本设置下为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"68.0%"},{"Type":"NodeText","Data":"，在少样本设置下为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"71.2%"},{"Type":"NodeText","Data":"。零样本的结果已经比微调过的T5-11B高出14.2%，并且也比一个在预训练前加入了问答格式跨度预测的版本高出3.8%。单样本的结果提升了3.7%，并且"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"追平了"},{"Type":"NodeText","Data":"一个为开放域问答系统定制的SOTA模型，该模型不仅经过微调，还使用了一个基于15.3B参数稠密向量的检索机制，从2100万个文档中检索信息[LPP+20]。GPT-3的少样本结果在此基础上又进一步提升了3.2%。"}]},{"ID":"20250915144327-rwdzeag","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144327-rwdzeag","updated":"20250915144328"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144327-scoe8g2","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144327-scoe8g2","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915144327-ygl6alo","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144327-ygl6alo","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"TriviaQA上的惊人突破"}]},{"ID":"20250915144327-82tksma","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144327-82tksma","updated":"20250915144327"},"Children":[{"ID":"20250915144327-489upxa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-489upxa","updated":"20250915144327"},"Children":[{"ID":"20250915144327-4i6lie6","Type":"NodeParagraph","Properties":{"id":"20250915144327-4i6lie6","updated":"20250915144327"},"Children":[{"Type":"NodeText","Data":"这是本节乃至整篇论文最令人震撼的结果之一。TriviaQA是一个以事实性知识为主的问答数据集。"}]}]},{"ID":"20250915144327-2e1ss6m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-2e1ss6m","updated":"20250915144327"},"Children":[{"ID":"20250915144327-77aefko","Type":"NodeParagraph","Properties":{"id":"20250915144327-77aefko","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本超越微调"},{"Type":"NodeText","Data":": GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"什么例子都不给"},{"Type":"NodeText","Data":"的情况下（64.3%），其表现已经"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"远超"},{"Type":"NodeText","Data":"一个经过专门问答微调的、拥有110亿参数的强大模型T5-11B（50.1%）。"}]}]},{"ID":"20250915144327-n2hhxn2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-n2hhxn2","updated":"20250915144327"},"Children":[{"ID":"20250915144327-2ldsz1b","Type":"NodeParagraph","Properties":{"id":"20250915144327-2ldsz1b","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单样本媲美开放域SOTA"},{"Type":"NodeText","Data":": GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只看了一个例子"},{"Type":"NodeText","Data":"的情况下（68.0%），其表现竟然"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"追平了"},{"Type":"NodeText","Data":"当时最先进的、可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上网查资料"},{"Type":"NodeText","Data":"（开放域）的微调模型RAG（68.0%）。"}]}]},{"ID":"20250915144327-oxtnykd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-oxtnykd","updated":"20250915144327"},"Children":[{"ID":"20250915144327-6asl496","Type":"NodeParagraph","Properties":{"id":"20250915144327-6asl496","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本创造新纪录"},{"Type":"NodeText","Data":": 在看了几个例子后（71.2%），GPT-3"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"创造了新的SOTA记录"},{"Type":"NodeText","Data":"，超越了所有之前的方法。"}]}]},{"ID":"20250915144327-0y77v87","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-0y77v87","updated":"20250915144327"},"Children":[{"ID":"20250915144327-jpilfql","Type":"NodeParagraph","Properties":{"id":"20250915144327-jpilfql","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心启示"},{"Type":"NodeText","Data":": 这个结果有力地证明，一个足够大的语言模型，其内部参数可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"存储海量的、可供查询的世界知识"},{"Type":"NodeText","Data":"，其效果甚至可以媲美乃至超越那些依赖外部知识库的复杂系统。"}]}]}]}]},{"ID":"20250915144327-ok452kt","Type":"NodeParagraph","Properties":{"id":"20250915144327-ok452kt","updated":"20250915144328"},"Children":[{"Type":"NodeText","Data":"在WebQuestions（WebQs）上，GPT-3在零样本设置下达到了14.4%的准确率，在单样本设置下为25.3%，在少样本设置下为41.5%。这与微调过的T5-11B的37.4%和微调过的T5-11B+SSM的44.7%相比，后者使用了一种问答专用的预训练程序。与最先进的微调模型相比，GPT-3在少样本设置下的性能正在接近。值得注意的是，与TriviaQA相比，WebQs从零样本到少样本的性能增益要大得多（其零样本和单样本表现也较差），这或许表明WebQs问题和/或它们的答案风格对于GPT-3来说是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分布外（out-of-distribution）"},{"Type":"NodeText","Data":"的。"}]},{"ID":"20250915144454-nilbyug","Type":"NodeParagraph","Properties":{"id":"20250915144454-nilbyug","updated":"20250915144454"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915144454-f36fxgn.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915144327-44j2zqe","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144327-44j2zqe","updated":"20250915144328"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144327-yhbulhv","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144327-yhbulhv","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.3：TriviaQA上的性能"}]},{"ID":"20250915144327-qfc5xlc","Type":"NodeParagraph","Properties":{"id":"20250915144327-qfc5xlc","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915144327-8irxm6t","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144327-8irxm6t","updated":"20250915144327"},"Children":[{"ID":"20250915144327-6mnpyz9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-6mnpyz9","updated":"20250915144327"},"Children":[{"ID":"20250915144327-5eluuzo","Type":"NodeParagraph","Properties":{"id":"20250915144327-5eluuzo","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" TriviaQA"}]}]},{"ID":"20250915144327-motfd9y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-motfd9y","updated":"20250915144327"},"Children":[{"ID":"20250915144327-hvbgj5i","Type":"NodeParagraph","Properties":{"id":"20250915144327-hvbgj5i","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915144327-y0fhk58","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-y0fhk58","updated":"20250915144327"},"Children":[{"ID":"20250915144327-y94d6pq","Type":"NodeParagraph","Properties":{"id":"20250915144327-y94d6pq","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915144327-ishullh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-ishullh","updated":"20250915144327"},"Children":[{"ID":"20250915144327-76nuyah","Type":"NodeParagraph","Properties":{"id":"20250915144327-76nuyah","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 零样本 (Zero-Shot), 单样本 (One-Shot), 少样本 (Few-Shot (K=64)), 微调SOTA (Fine-tuned SOTA)"}]}]},{"ID":"20250915144327-dmvqlc8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-dmvqlc8","updated":"20250915144327"},"Children":[{"ID":"20250915144327-qe654gq","Type":"NodeParagraph","Properties":{"id":"20250915144327-qe654gq","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 在TriviaQA上，GPT-3的性能随着模型规模平滑增长，表明"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言模型随着其容量的增加会持续吸收知识"},{"Type":"NodeText","Data":"。单样本和少样本的性能比零样本有显著提升，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"追平并最终超越了"},{"Type":"NodeText","Data":"微调过的开放域SOTA模型RAG [LPP⁺20]的性能。"}]}]}]},{"ID":"20250915144327-0vsio45","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144327-0vsio45","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915144327-tekc4e2","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144327-tekc4e2","updated":"20250915144327"},"Children":[{"ID":"20250915144327-zfa6mci","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-zfa6mci","updated":"20250915144327"},"Children":[{"ID":"20250915144327-5akl0gm","Type":"NodeParagraph","Properties":{"id":"20250915144327-5akl0gm","updated":"20250915144327"},"Children":[{"Type":"NodeText","Data":"这张图是“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型越大，知道得越多"},{"Type":"NodeText","Data":"”这一观点的完美视觉呈现。"}]}]},{"ID":"20250915144327-byvj7ms","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-byvj7ms","updated":"20250915144327"},"Children":[{"ID":"20250915144327-9605qj5","Type":"NodeParagraph","Properties":{"id":"20250915144327-9605qj5","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识的缩放法则"},{"Type":"NodeText","Data":": 三条曲线都呈现出平滑的上升趋势，这意味着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型的知识量直接与其参数规模正相关"},{"Type":"NodeText","Data":"。投入更多参数，模型就能存储更多的事实知识。"}]}]},{"ID":"20250915144327-004ocno","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-004ocno","updated":"20250915144327"},"Children":[{"ID":"20250915144327-41y5mqa","Type":"NodeParagraph","Properties":{"id":"20250915144327-41y5mqa","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习解锁知识"},{"Type":"NodeText","Data":": 观察三条曲线的间距可以发现，提供一或多个示例（单样本/少样本）能系统性地提升所有规模模型的性能。这表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习是有效“解锁”或“查询”模型内部存储知识的关键"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915144327-7eumev4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-7eumev4","updated":"20250915144327"},"Children":[{"ID":"20250915144327-46qar73","Type":"NodeParagraph","Properties":{"id":"20250915144327-46qar73","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越微调的临界点"},{"Type":"NodeText","Data":": 图中清晰地标出了之前微调SOTA模型的位置。可以看到，GPT-3在达到约130亿参数时，其单样本性能就追上了SOTA，而1750亿参数的模型则实现了全面超越。"}]}]}]}]},{"ID":"20250915144327-o69be8x","Type":"NodeParagraph","Properties":{"id":"20250915144327-o69be8x","updated":"20250915144328"},"Children":[{"Type":"NodeText","Data":"尽管如此，在少样本设置下，GPT-3似乎能够适应这种分布，并恢复强大的性能。"}]},{"ID":"20250915144327-nqc9n33","Type":"NodeParagraph","Properties":{"id":"20250915144327-nqc9n33","updated":"20250915144328"},"Children":[{"Type":"NodeText","Data":"在Natural Questions（NQs）上，GPT-3在零样本设置下达到了14.6%的准确率，在单样本设置下为23.0%，在少样本设置下为29.9%，而微调过的T5 11B+SSM为36.6%。与WebQs类似，从零样本到少样本的巨大增益可能表明存在分布偏移，并且也可能解释了与TriviaQA和WebQs相比，其竞争力较差的原因。特别地，NQs中的问题倾向于需要更细粒度的知识，这些知识可能在维基百科上有，但可能考验了GPT-3的容量和宽泛的预训练分布的极限。"}]},{"ID":"20250915144327-kc9pj0y","Type":"NodeParagraph","Properties":{"id":"20250915144327-kc9pj0y","updated":"20250915144328"},"Children":[{"Type":"NodeText","Data":"总的来说，在三个数据集中，有一个（TriviaQA）GPT-3的单样本性能就追平了开放域微调SOTA。在另外两个数据集上，尽管没有使用微调，它也接近了闭卷SOTA的性能。在所有3个数据集上，我们发现性能都随着模型规模非常平滑地扩展（图3.3和附录H图H.7），这可能反映了这样一个理念，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型容量直接转化为模型参数中吸收的更多“知识”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915144327-394ag1e","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144327-394ag1e","updated":"20250915144328"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144327-d4d0zfs","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144327-d4d0zfs","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915144327-q7y3wgg","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144327-q7y3wgg","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WebQS和NQs上的表现分析"}]},{"ID":"20250915144327-69ql7jp","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144327-69ql7jp","updated":"20250915144327"},"Children":[{"ID":"20250915144327-wjirril","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-wjirril","updated":"20250915144327"},"Children":[{"ID":"20250915144327-kqtnc0w","Type":"NodeParagraph","Properties":{"id":"20250915144327-kqtnc0w","updated":"20250915144327"},"Children":[{"Type":"NodeText","Data":"与在TriviaQA上的辉煌战绩不同，GPT-3在WebQS和NQs上表现稍逊，未能超越微调过的SOTA。"}]}]},{"ID":"20250915144327-bm3v34d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-bm3v34d","updated":"20250915144327"},"Children":[{"ID":"20250915144327-41q01l2","Type":"NodeParagraph","Properties":{"id":"20250915144327-41q01l2","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分布外问题 (Out-of-Distribution)"},{"Type":"NodeText","Data":": 作者推测，这可能是因为这两个数据集的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题或答案的格式"},{"Type":"NodeText","Data":"与GPT-3在预训练时见过的海量文本"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"风格不太一样"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915144327-noc5sit","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-noc5sit","updated":"20250915144327"},"Children":[{"ID":"20250915144327-3ldz3co","Type":"NodeParagraph","Properties":{"id":"20250915144327-3ldz3co","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的适应能力"},{"Type":"NodeText","Data":": 一个关键的观察是，在这两个数据集上，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从零样本到少样本的性能提升幅度特别大"},{"Type":"NodeText","Data":"。这暗示了：模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可能知道答案"},{"Type":"NodeText","Data":"，但一开始不知道该以何种格式输出。通过少量的示例，它"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"迅速学会了任务的要求"},{"Type":"NodeText","Data":"，从而大幅提升了性能。这完美地展示了上下文学习的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"快速适应能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915144327-3sn5a1a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144327-3sn5a1a","updated":"20250915144327"},"Children":[{"ID":"20250915144327-g69f4qq","Type":"NodeParagraph","Properties":{"id":"20250915144327-g69f4qq","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识粒度"},{"Type":"NodeText","Data":": 对于NQs，作者还提出了另一种可能性，即它需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更精细、更冷门"},{"Type":"NodeText","Data":"的知识，这可能超出了GPT-3通过预训练所能有效存储的范围。"}]}]}]}]},{"ID":"20250915144327-aw6leub","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144327-aw6leub","updated":"20250915144328"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144327-551h0jv","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144327-551h0jv","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250915144327-a73sggb","Type":"NodeParagraph","Properties":{"id":"20250915144327-a73sggb","updated":"20250915144327"},"Children":[{"Type":"NodeText","Data":"本节（3.2）是GPT-3论文中最具影响力的部分之一，它系统地论证了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超大语言模型可以作为一种新型的知识库"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915144327-jruueiw","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915144327-jruueiw","updated":"20250915144327"},"Children":[{"ID":"20250915144327-1bcoqwd","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915144327-1bcoqwd","updated":"20250915144327"},"Children":[{"ID":"20250915144327-nnjma4n","Type":"NodeParagraph","Properties":{"id":"20250915144327-nnjma4n","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"范式转变的证明"},{"Type":"NodeText","Data":": 通过在TriviaQA上以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“闭卷+无微调”"},{"Type":"NodeText","Data":"的极简方式"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"战胜"},{"Type":"NodeText","Data":"了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“开卷+微调”"},{"Type":"NodeText","Data":"的复杂系统，GPT-3证明了将事实知识直接编码到模型参数中的可行性和巨大潜力。这为后续所有大型语言模型的发展奠定了“将模型作为知识库”的基础理念。"}]}]},{"ID":"20250915144327-ykh5ugz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915144327-ykh5ugz","updated":"20250915144327"},"Children":[{"ID":"20250915144327-ixls5nw","Type":"NodeParagraph","Properties":{"id":"20250915144327-ixls5nw","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识遵循缩放法则"},{"Type":"NodeText","Data":": 图3.3直观地展示了模型的知识储备与其规模成正比。这为“大力出奇迹”提供了理论依据："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只要模型做得足够大，它就能自然地从预训练数据中吸收并存储海量的世界知识"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915144327-ci4vk6s","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915144327-ci4vk6s","updated":"20250915144327"},"Children":[{"ID":"20250915144327-3gmy3o2","Type":"NodeParagraph","Properties":{"id":"20250915144327-3gmy3o2","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习是知识的“API”"},{"Type":"NodeText","Data":": 如果说模型参数是存储知识的“硬盘”，那么"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（尤其是少样本学习）就是查询这个硬盘的“应用程序接口（API）”"},{"Type":"NodeText","Data":"。对于模型不熟悉的查询格式（如WebQS和NQs），几个查询示例就能教会模型如何正确地检索和格式化其内部知识，从而发挥出强大的性能。"}]}]},{"ID":"20250915144327-fekrqba","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250915144327-fekrqba","updated":"20250915144327"},"Children":[{"ID":"20250915144327-h63s7bf","Type":"NodeParagraph","Properties":{"id":"20250915144327-h63s7bf","updated":"20250915144327"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"坦诚面对局限"},{"Type":"NodeText","Data":": 论文也并未夸大其词，而是坦诚地展示了在某些数据集（WebQS, NQs）上与SOTA的差距，并对可能的原因（分布偏移、知识粒度）进行了合理的分析。这体现了研究的严谨性，并为后续研究指明了方向，例如如何让模型更好地处理长尾、细粒度的知识。"}]}]}]},{"ID":"20250915144327-h4zq4fu","Type":"NodeParagraph","Properties":{"id":"20250915144327-h4zq4fu","updated":"20250915144327"},"Children":[{"Type":"NodeText","Data":"综上所述，这一节通过坚实的证据和深入的分析，描绘了一幅激动人心的图景：一个预训练好的、巨大的语言模型，本身就是一个无需外部依赖、可通过自然语言灵活查询的通用知识库。"}]}]},{"ID":"20250915144810-ooeuzo0","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144810-ooeuzo0","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.3 翻译 (Translation)"}]},{"ID":"20250915144810-cl6ybcb","Type":"NodeParagraph","Properties":{"id":"20250915144810-cl6ybcb","updated":"20250915144811"},"Children":[{"Type":"NodeText","Data":"对于GPT-2，曾使用一个过滤器对一个多语言文档集合进行处理，以生成一个仅包含英语的数据集，以解决质量问题。即使经过这种过滤，GPT-2也展现出了一些多语言能力，并且在法英互译时表现不俗，尽管其训练数据中仅剩下10MB的法语文本。由于我们将模型容量从GPT-2到GPT-3"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提升了超过两个数量级"},{"Type":"NodeText","Data":"，我们也扩展了训练数据的范围以包含更多其他语言的代表，尽管这仍然是一个有待进一步改进的领域。如2.2节所讨论的，我们的大部分数据来源于经过质量过滤的原始Common Crawl。尽管GPT-3的训练数据"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主要仍是英语（按词数计占93%）"},{"Type":"NodeText","Data":"，但它也包含了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7%的其他语言文本"},{"Type":"NodeText","Data":"。这些语言在补充材料中有记录。为了更好地理解翻译能力，我们也扩展了我们的分析，加入了另外两种常被研究的语言：德语和罗马尼亚语。"}]},{"ID":"20250915144810-ipdcyne","Type":"NodeParagraph","Properties":{"id":"20250915144810-ipdcyne","updated":"20250915144811"},"Children":[{"Type":"NodeText","Data":"现有的"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"无监督机器翻译"},{"Type":"NodeText","Data":"方法通常将在一对单语数据集上的预训练与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"回译（back-translation）"},{"Type":"NodeText","Data":"[SHB15]相结合，以一种受控的方式在这两种语言之间架起桥梁。相比之下，GPT-3从一个以自然方式混合了多种语言的训练数据中学习，在词、句子和文档层面上将它们结合起来。GPT-3也只使用一个单一的训练目标，这个目标并未针对任何特定任务进行定制或设计。然而，我们的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单样本/少样本设置与先前纯粹的无监督工作并不严格可比"},{"Type":"NodeText","Data":"，因为它们使用了少量的成对示例（1或64个）。这相当于多达一两页的上下文内训练数据。"}]},{"ID":"20250915144810-5j5j4po","Type":"NodeParagraph","Properties":{"id":"20250915144810-5j5j4po","updated":"20250915145713"},"Children":[{"Type":"NodeText","Data":"结果显示在表3.4中。只接收任务的自然语言描述的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本GPT-3，其表现仍然不如近期的无监督NMT结果"},{"Type":"NodeText","Data":"。然而，仅仅提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个"},{"Type":"NodeText","Data":"示例演示结果显示在表3.4中。只接收任务的自然语言描述的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本GPT-3，其表现仍然不如近期的无监督NMT结果"},{"Type":"NodeText","Data":"。然而，仅仅提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个"},{"Type":"NodeText","Data":"示例演示每个翻译任务的性能都提升了超过7个BLEU分，并接近了之前工作的性能。GPT-3在完整的少样本设置下进一步将性能提升了4个BLEU分，从而在与之前的无监督NMT工作相似的平均性能上取得了最好的结果。对于所研究的三种输入语言，GPT-3在翻译成英语时显著优于之前的无监督NMT工作，但在翻译到其他方向时表现不佳。En→Ro（英语到罗马尼亚语）的表现值得注意，比之前的无监督NMT工作差了超过10个BLEU分。这可能是由于重复使用了在几乎完全是英语的训练数据集上开发的字节对编码（BPE）词汇表。对于Fr→En和De→En，少样本GPT-3的表现超过了我们文献中最好的监督结果，但我们怀疑这些是不具竞争力的基准；我们不认为这些结果代表了真正的SOTA水平。对于Ro→En，少样本GPT-3的表现比SOTA的总体水平低0.5 BLEU，而SOTA是通过在608K个标记示例上进行无监督预训练、有监督微调和回译实现的[LHCG19b]。"}]},{"ID":"20250915144810-c28ha64","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144810-c28ha64","updated":"20250915144811"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144810-e4477bj","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144810-e4477bj","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915144810-mftg507","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144810-mftg507","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练背景与方法对比"}]},{"ID":"20250915144810-i80vbjo","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-i80vbjo","updated":"20250915144810"},"Children":[{"ID":"20250915144810-4t26ib6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-4t26ib6","updated":"20250915144810"},"Children":[{"ID":"20250915144810-bst9o1z","Type":"NodeParagraph","Properties":{"id":"20250915144810-bst9o1z","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“无心插柳”的多语言能力"},{"Type":"NodeText","Data":": 作者首先指出，即使是主要用英语数据训练的GPT-2也意外地展现出翻译能力。基于此，GPT-3的训练数据被有意地加入了更多非英语内容（尽管仍占少数，仅7%）。"}]}]},{"ID":"20250915144810-5n5mu2v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-5n5mu2v","updated":"20250915144810"},"Children":[{"ID":"20250915144810-cpd2iul","Type":"NodeParagraph","Properties":{"id":"20250915144810-cpd2iul","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习方式的根本不同"},{"Type":"NodeText","Data":": 这里将GPT-3的学习方式与传统的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无监督机器翻译（Unsupervised NMT）"},{"Type":"NodeText","Data":"进行了关键对比。"}]},{"ID":"20250915144810-b03xm4f","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-b03xm4f","updated":"20250915144810"},"Children":[{"ID":"20250915144810-qqiosie","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-qqiosie","updated":"20250915144810"},"Children":[{"ID":"20250915144810-dmjgo1m","Type":"NodeParagraph","Properties":{"id":"20250915144810-dmjgo1m","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"传统UMT"},{"Type":"NodeText","Data":": 采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"回译"},{"Type":"NodeText","Data":"等复杂技术，专门针对两种语言（如英-法）进行训练，目标明确。"}]}]},{"ID":"20250915144810-2kqumuc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-2kqumuc","updated":"20250915144810"},"Children":[{"ID":"20250915144810-26szx9b","Type":"NodeParagraph","Properties":{"id":"20250915144810-26szx9b","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3"},{"Type":"NodeText","Data":": 在一个混杂了多种语言的“大染缸”里，用一个通用的“预测下一个词”的目标进行学习，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并未专门为翻译任务进行任何优化"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915144810-xohuh0x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-xohuh0x","updated":"20250915144810"},"Children":[{"ID":"20250915144810-83d4mol","Type":"NodeParagraph","Properties":{"id":"20250915144810-83d4mol","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"公平性声明"},{"Type":"NodeText","Data":": 作者坦诚地指出，他们的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本"},{"Type":"NodeText","Data":"设置因为使用了一两个成对的翻译示例，所以不能被严格视为“无监督”，这是一种严谨的科学态度。"}]}]}]}]},{"ID":"20250915145013-jhpru3f","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1],"Properties":{"colgroup":"||||||","id":"20250915145013-jhpru3f","updated":"20250915145013"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"En→Fr"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fr→En"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"En→De"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"De→En"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"En→Ro"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Ro→En"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SOTA (有监督)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"45.6"},{"Type":"NodeText","Data":"ᵃ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"35.0ᵇ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"41.2"},{"Type":"NodeText","Data":"ᶜ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"40.2ᵈ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"38.5"},{"Type":"NodeText","Data":"ᵉ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"39.9"},{"Type":"NodeText","Data":"ᵉ"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"XLM [LC19]"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"33.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"33.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"26.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"33.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"31.8"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MASS [STQ⁺19]"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"37.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"28.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"35.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"35.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"33.1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"mBART [LGQ⁺20]"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"37.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"35.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"30.5"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Zero-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"25.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"21.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"27.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"19.9"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 One-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"28.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"33.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"26.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"30.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"20.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"38.6"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"39.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"40.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"21.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"39.5"}]}]}]},{"ID":"20250915144810-v16wetm","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144810-v16wetm","updated":"20250915144811"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144810-g0lrdv3","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144810-g0lrdv3","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.4：少样本GPT-3在翻译任务上的表现"}]},{"ID":"20250915144810-4sohukw","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-4sohukw","updated":"20250915144810"},"Children":[{"ID":"20250915144810-e38f64p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-e38f64p","updated":"20250915144810"},"Children":[{"ID":"20250915144810-c6gjark","Type":"NodeParagraph","Properties":{"id":"20250915144810-c6gjark","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本GPT-3在将法语翻译成英语时，以5个BLEU分的优势超越了之前的无监督NMT SOTA"},{"Type":"NodeText","Data":"。我们报告在WMT'14 Fr↔En、WMT'16 De↔En和WMT'16 Ro↔En数据集上的BLEU分数，使用与XLM词元化相同的多语言bleu.perl进行测量。为了与之前的无监督NMT工作更紧密地比较，结果在附录H中报告。SacreBLEU [Pos18] 结果在附录H中报告。带星号的结果表示有监督SOTA，具有相对置信度。"}]}]}]},{"ID":"20250915144810-vvzhjhb","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144810-vvzhjhb","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915144810-fjy7as3","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-fjy7as3","updated":"20250915144810"},"Children":[{"ID":"20250915144810-nhpjr0l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-nhpjr0l","updated":"20250915144810"},"Children":[{"ID":"20250915144810-xtzxltx","Type":"NodeParagraph","Properties":{"id":"20250915144810-xtzxltx","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"这张表是本节的核心数据，BLEU分数是衡量翻译质量的标准，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分数越高越好"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915144810-i29jffy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-i29jffy","updated":"20250915144810"},"Children":[{"ID":"20250915144810-fhbiqb9","Type":"NodeParagraph","Properties":{"id":"20250915144810-fhbiqb9","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越无监督SOTA"},{"Type":"NodeText","Data":": 最亮眼的结果是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Fr→En"},{"Type":"NodeText","Data":"（法语到英语）的翻译。GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本"},{"Type":"NodeText","Data":"设置下达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"39.2"},{"Type":"NodeText","Data":"的BLEU分，显著"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越了所有专门为无监督翻译设计的模型"},{"Type":"NodeText","Data":"（如MASS的34.9）。De→En和Ro→En也取得了类似SOTA级别的表现。"}]}]},{"ID":"20250915144810-549bq7u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-549bq7u","updated":"20250915144810"},"Children":[{"ID":"20250915144810-p671s2i","Type":"NodeParagraph","Properties":{"id":"20250915144810-p671s2i","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“翻译到英语”的优势"},{"Type":"NodeText","Data":": 一个非常明显的模式是，在所有三个语言对中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将外语翻译成英语"},{"Type":"NodeText","Data":"（Fr→En, De→En, Ro→En）的表现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"远好于"},{"Type":"NodeText","Data":"将英语翻译成外语。这很可能是因为训练数据中英语占绝对主导（93%），模型对生成流畅的英语更有把握。"}]}]},{"ID":"20250915144810-8ouc8in","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-8ouc8in","updated":"20250915144810"},"Children":[{"ID":"20250915144810-28sf8x3","Type":"NodeParagraph","Properties":{"id":"20250915144810-28sf8x3","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与有监督SOTA的差距"},{"Type":"NodeText","Data":": 尽管表现出色，但与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有监督（Supervised）"},{"Type":"NodeText","Data":"的SOTA模型相比，GPT-3仍有巨大差距。有监督模型使用了大量的平行语料（成对的翻译句子）进行训练，其性能上限自然更高。"}]}]}]}]},{"ID":"20250915145138-5iixqes","Type":"NodeParagraph","Properties":{"id":"20250915145138-5iixqes","updated":"20250915145138"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915145138-z6ayqum.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915144810-cmi2tp8","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144810-cmi2tp8","updated":"20250915144811"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144810-emvr40b","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144810-emvr40b","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.4：翻译性能"}]},{"ID":"20250915144810-10biln6","Type":"NodeParagraph","Properties":{"id":"20250915144810-10biln6","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915144810-rrqwa10","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-rrqwa10","updated":"20250915144810"},"Children":[{"ID":"20250915144810-cyzjjri","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-cyzjjri","updated":"20250915144810"},"Children":[{"ID":"20250915144810-sxlcvxl","Type":"NodeParagraph","Properties":{"id":"20250915144810-sxlcvxl","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" 翻译 (多语言-BLEU) (Translation (Multi-BLEU))"}]}]},{"ID":"20250915144810-v7qneaj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-v7qneaj","updated":"20250915144810"},"Children":[{"ID":"20250915144810-uwgofn9","Type":"NodeParagraph","Properties":{"id":"20250915144810-uwgofn9","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" BLEU"}]}]},{"ID":"20250915144810-2aits0b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-2aits0b","updated":"20250915144810"},"Children":[{"ID":"20250915144810-crhxr97","Type":"NodeParagraph","Properties":{"id":"20250915144810-crhxr97","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915144810-y37xh5r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-y37xh5r","updated":"20250915144810"},"Children":[{"ID":"20250915144810-pet1f1k","Type":"NodeParagraph","Properties":{"id":"20250915144810-pet1f1k","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"}]},{"ID":"20250915144810-ak9ramu","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-ak9ramu","updated":"20250915144810"},"Children":[{"ID":"20250915144810-duu7z6z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-duu7z6z","updated":"20250915144810"},"Children":[{"ID":"20250915144810-rst6788","Type":"NodeParagraph","Properties":{"id":"20250915144810-rst6788","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"法语 → 英语 (French → English)"}]}]},{"ID":"20250915144810-4ma2f0i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-4ma2f0i","updated":"20250915144810"},"Children":[{"ID":"20250915144810-h3hgwbr","Type":"NodeParagraph","Properties":{"id":"20250915144810-h3hgwbr","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"英语 → 法语 (English → French)"}]}]},{"ID":"20250915144810-vomadla","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-vomadla","updated":"20250915144810"},"Children":[{"ID":"20250915144810-4niz6lz","Type":"NodeParagraph","Properties":{"id":"20250915144810-4niz6lz","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"德语 → 英语 (German → English)"}]}]},{"ID":"20250915144810-bd4m08h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-bd4m08h","updated":"20250915144810"},"Children":[{"ID":"20250915144810-0p3emz0","Type":"NodeParagraph","Properties":{"id":"20250915144810-0p3emz0","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"英语 → 德语 (English → German)"}]}]},{"ID":"20250915144810-mg0cn6n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-mg0cn6n","updated":"20250915144810"},"Children":[{"ID":"20250915144810-zgpxkbk","Type":"NodeParagraph","Properties":{"id":"20250915144810-zgpxkbk","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"罗马尼亚语 → 英语 (Romanian → English)"}]}]},{"ID":"20250915144810-fpgop0p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-fpgop0p","updated":"20250915144810"},"Children":[{"ID":"20250915144810-nrg3rkv","Type":"NodeParagraph","Properties":{"id":"20250915144810-nrg3rkv","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"英语 → 罗马尼亚语 (English → Romanian)"}]}]}]}]},{"ID":"20250915144810-r06jsfh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-r06jsfh","updated":"20250915144810"},"Children":[{"ID":"20250915144810-ueor9if","Type":"NodeParagraph","Properties":{"id":"20250915144810-ueor9if","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本翻译性能随着模型容量的增加而持续改善"},{"Type":"NodeText","Data":"。在所有6个语言对的数据集上都观察到了随模型规模的持续改进趋势，以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将外语翻译成英语比从英语翻译成外语更强的趋势"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250915144810-83lhtg3","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144810-83lhtg3","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915144810-70dok6c","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-70dok6c","updated":"20250915144810"},"Children":[{"ID":"20250915144810-7sk98x6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-7sk98x6","updated":"20250915144810"},"Children":[{"ID":"20250915144810-xsep7ol","Type":"NodeParagraph","Properties":{"id":"20250915144810-xsep7ol","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"这张图生动地展示了翻译能力的“缩放法则”。"}]}]},{"ID":"20250915144810-zo7ii4n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-zo7ii4n","updated":"20250915144810"},"Children":[{"ID":"20250915144810-ps81yny","Type":"NodeParagraph","Properties":{"id":"20250915144810-ps81yny","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模效应"},{"Type":"NodeText","Data":": 所有的曲线都随着模型参数量的增加而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平滑且持续地向上攀升"},{"Type":"NodeText","Data":"，这再次证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型越大，翻译能力越强"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915144810-amyh94x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-amyh94x","updated":"20250915144810"},"Children":[{"ID":"20250915144810-ayp3jun","Type":"NodeParagraph","Properties":{"id":"20250915144810-ayp3jun","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"翻译不对称性"},{"Type":"NodeText","Data":": 图中清晰地显示出三条"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实线（翻译到英语）"},{"Type":"NodeText","Data":"系统性地高于三条"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"虚线（从英语翻译）"},{"Type":"NodeText","Data":"。这直观地证实了在表3.4中观察到的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"翻译不对称现象"},{"Type":"NodeText","Data":"，并表明这种现象在所有模型规模上都存在。"}]}]},{"ID":"20250915144810-nmx5mr5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-nmx5mr5","updated":"20250915144810"},"Children":[{"ID":"20250915144810-revsa2u","Type":"NodeParagraph","Properties":{"id":"20250915144810-revsa2u","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"罗马尼亚语的特殊性"},{"Type":"NodeText","Data":": 英语到罗马尼亚语（红色虚线）的性能最低，这可能与训练数据中罗马尼亚语的占比较低有关。"}]}]}]}]},{"ID":"20250915145045-woq51t4","Type":"NodeTable","TableAligns":[1,1,1],"Properties":{"colgroup":"||","id":"20250915145045-woq51t4","updated":"20250915145045"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Winograd"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Winogrande (XL)"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned SOTA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"90.1"},{"Type":"NodeText","Data":"ᵃ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"84.6"},{"Type":"NodeText","Data":"ᵇ"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Zero-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"88.3ᵃ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70.2"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 One-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"89.7ᵃ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"73.2"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"88.6ᵃ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"77.7"}]}]}]},{"ID":"20250915144810-co0uo00","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144810-co0uo00","updated":"20250915144810"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144810-3p7obtw","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144810-3p7obtw","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.5：在WSC273版本的Winograd模式和Winogrande数据集上的结果"}]},{"ID":"20250915144810-v0hbzx9","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-v0hbzx9","updated":"20250915144810"},"Children":[{"ID":"20250915144810-t071vk7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-t071vk7","updated":"20250915144810"},"Children":[{"ID":"20250915144810-o297fbp","Type":"NodeParagraph","Properties":{"id":"20250915144810-o297fbp","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" 关于Winograd测试集的潜在污染细节见第4节。ᵃ[SBBC19] ᵇ[LYN⁺20]。"}]}]}]},{"ID":"20250915144810-qcbq17q","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144810-qcbq17q","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915144810-0hvkokk","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-0hvkokk","updated":"20250915144810"},"Children":[{"ID":"20250915144810-va4l3oj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-va4l3oj","updated":"20250915144810"},"Children":[{"ID":"20250915144810-ankoa2l","Type":"NodeParagraph","Properties":{"id":"20250915144810-ankoa2l","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"这张表衡量的是模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识推理"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代词消歧"},{"Type":"NodeText","Data":"能力。Winograd模式任务需要模型理解句子中代词（如 a man, a woman）的正确指代。"}]}]},{"ID":"20250915144810-t1jolbh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-t1jolbh","updated":"20250915144810"},"Children":[{"ID":"20250915144810-1vq1zth","Type":"NodeParagraph","Properties":{"id":"20250915144810-1vq1zth","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"接近人类水平"},{"Type":"NodeText","Data":": 在经典的Winograd数据集上，GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本"},{"Type":"NodeText","Data":"设置下就达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"88.3%"},{"Type":"NodeText","Data":"的准确率，非常接近经过微调的SOTA模型（90.1%）和人类水平。"}]}]},{"ID":"20250915144810-kiuckim","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-kiuckim","updated":"20250915144810"},"Children":[{"ID":"20250915144810-s9kisqs","Type":"NodeParagraph","Properties":{"id":"20250915144810-s9kisqs","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在更大数据集上的表现"},{"Type":"NodeText","Data":": Winogrande是一个规模更大、难度更高的版本。在这个任务上，GPT-3虽然未能达到SOTA水平，但其少样本性能（77.7%）也相当可观，显示了强大的常识推理潜力。"}]}]}]}]},{"ID":"20250915144810-oixdbxw","Type":"NodeParagraph","Properties":{"id":"20250915144810-oixdbxw","updated":"20250915144811"},"Children":[{"Type":"NodeText","Data":"每个翻译任务的性能都提升了超过7个BLEU分，并接近了之前工作的性能。GPT-3在完整的少样本设置下进一步将性能提升了4个BLEU分，从而在与之前的无监督NMT工作相似的平均性能上取得了最好的结果。对于所研究的三种输入语言，GPT-3在翻译成英语时显著优于之前的无监督NMT工作，但在翻译到其他方向时表现不佳。En→Ro（英语到罗马尼亚语）的表现值得注意，比之前的无监督NMT工作差了超过10个BLEU分。这可能是由于重复使用了在几乎完全是英语的训练数据集上开发的字节对编码（BPE）词汇表。对于Fr→En和De→En，少样本GPT-3的表现超过了我们文献中最好的监督结果，但我们怀疑这些是不具竞争力的基准；我们不认为这些结果代表了真正的SOTA水平。对于Ro→En，少样本GPT-3的表现比SOTA的总体水平低0.5 BLEU，而SOTA是通过在608K个标记示例上进行无监督预训练、有监督微调和回译实现的[LHCG19b]。"}]},{"ID":"20250915144810-awnsjb4","Type":"NodeParagraph","Properties":{"id":"20250915144810-awnsjb4","updated":"20250915144811"},"Children":[{"Type":"NodeText","Data":"最后，在所有语言对和所有三种设置（零样本、单样本和少样本）中，都存在着随模型容量改善的平滑趋势。这显示在图3.4的少样本结果中，所有设置的缩放情况显示在附录H中。"}]},{"ID":"20250915145211-mi9x6v1","Type":"NodeParagraph","Properties":{"id":"20250915145211-mi9x6v1","updated":"20250915145211"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915145211-4yn6ufr.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915144810-zml5o7x","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144810-zml5o7x","updated":"20250915144811"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144810-gggqmxv","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915144810-gggqmxv","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.5：Winogrande数据集上的性能"}]},{"ID":"20250915144810-b4xim44","Type":"NodeParagraph","Properties":{"id":"20250915144810-b4xim44","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915144810-fia0ooy","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-fia0ooy","updated":"20250915144810"},"Children":[{"ID":"20250915144810-nak8paw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-nak8paw","updated":"20250915144810"},"Children":[{"ID":"20250915144810-bdwiils","Type":"NodeParagraph","Properties":{"id":"20250915144810-bdwiils","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" Winogrande"}]}]},{"ID":"20250915144810-vo0vqsl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-vo0vqsl","updated":"20250915144810"},"Children":[{"ID":"20250915144810-wbkxu7x","Type":"NodeParagraph","Properties":{"id":"20250915144810-wbkxu7x","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915144810-2on7mja","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-2on7mja","updated":"20250915144810"},"Children":[{"ID":"20250915144810-0l2ehb8","Type":"NodeParagraph","Properties":{"id":"20250915144810-0l2ehb8","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915144810-w5hd5io","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-w5hd5io","updated":"20250915144810"},"Children":[{"ID":"20250915144810-dzwkob2","Type":"NodeParagraph","Properties":{"id":"20250915144810-dzwkob2","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 人类 (Human), 微调RoBERTa-Large (Fine-tuned RoBERTa-Large), 微调BERT-Large (Fine-tuned BERT-Large), 零样本 (Zero-Shot), 单样本 (One-Shot), 少样本 (Few-Shot (K=50)), 随机猜测 (Random Guessing)"}]}]},{"ID":"20250915144810-0omp7f2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-0omp7f2","updated":"20250915144810"},"Children":[{"ID":"20250915144810-5vb529n","Type":"NodeParagraph","Properties":{"id":"20250915144810-5vb529n","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本、单样本和少样本性能随着模型容量的扩展而平滑"},{"Type":"NodeText","Data":"。随着模型规模的增加，少样本学习的收益也相对增加，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本GPT-3 175B与微调过的RoBERTa-large具有竞争力"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250915144810-jdyfii1","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144810-jdyfii1","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915144810-3blbgow","Type":"NodeList","ListData":{},"Properties":{"id":"20250915144810-3blbgow","updated":"20250915144810"},"Children":[{"ID":"20250915144810-1i1wwsf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-1i1wwsf","updated":"20250915144810"},"Children":[{"ID":"20250915144810-yok04do","Type":"NodeParagraph","Properties":{"id":"20250915144810-yok04do","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"这张图是常识推理能力随规模变化的直观展示。"}]}]},{"ID":"20250915144810-82e000v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-82e000v","updated":"20250915144810"},"Children":[{"ID":"20250915144810-j7qsz0w","Type":"NodeParagraph","Properties":{"id":"20250915144810-j7qsz0w","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰的缩放效应"},{"Type":"NodeText","Data":": 所有GPT-3的曲线（蓝、绿、橙）都稳步上升，远离随机猜测线，再次验证了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型越大，常识推理能力越强"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915144810-mawqajw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-mawqajw","updated":"20250915144810"},"Children":[{"ID":"20250915144810-p63y1qz","Type":"NodeParagraph","Properties":{"id":"20250915144810-p63y1qz","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本学习的价值"},{"Type":"NodeText","Data":": 橙色的少样本曲线随着模型规模的增大，与零样本和单样本曲线的差距逐渐拉大，说明"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大模型能更有效地从示例中学习推理模式"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915144810-dl1l5na","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915144810-dl1l5na","updated":"20250915144810"},"Children":[{"ID":"20250915144810-oupp7x0","Type":"NodeParagraph","Properties":{"id":"20250915144810-oupp7x0","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与微调模型的比较"},{"Type":"NodeText","Data":": 最关键的一点是，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"175B的少样本GPT-3（橙色曲线最右端）的性能已经非常接近甚至追上了专门为该任务微调过的RoBERTa-Large模型"},{"Type":"NodeText","Data":"。这再次表明，巨大的规模和上下文学习可以在一定程度上替代任务特定的微调。"}]}]}]}]},{"ID":"20250915144810-7r0ql5o","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915144810-7r0ql5o","updated":"20250915144810"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915144810-k43pvae","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915144810-k43pvae","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250915144810-t8z940y","Type":"NodeParagraph","Properties":{"id":"20250915144810-t8z940y","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"本次分析涵盖了翻译和常识推理两大核心NLP领域，揭示了GPT-3在这两方面能力的共性和特性。"}]},{"ID":"20250915144810-9ly5isn","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915144810-9ly5isn","updated":"20250915144810"},"Children":[{"ID":"20250915144810-ne7mwgy","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915144810-ne7mwgy","updated":"20250915144810"},"Children":[{"ID":"20250915144810-rk3n2k1","Type":"NodeParagraph","Properties":{"id":"20250915144810-rk3n2k1","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用能力的涌现"},{"Type":"NodeText","Data":": GPT-3在没有经过任何专门翻译或常识推理训练的情况下，仅通过大规模的通用预训练，就获得了在这两个领域的强大能力。这证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超大规模模型可以“举一反三”，从语言模式中学习到翻译和推理等高级认知能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915144810-kdt45cp","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915144810-kdt45cp","updated":"20250915144810"},"Children":[{"ID":"20250915144810-gwhvhaj","Type":"NodeParagraph","Properties":{"id":"20250915144810-gwhvhaj","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“缩放法则”的普适性"},{"Type":"NodeText","Data":": 无论是翻译任务（图3.4）还是常识推理任务（图3.5），性能都与模型规模呈现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰、平滑的正相关关系"},{"Type":"NodeText","Data":"。这表明“缩放法则”不仅仅适用于基础的语言建模，也同样适用于各种复杂的下游任务。"}]}]},{"ID":"20250915144810-csvb7yz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915144810-csvb7yz","updated":"20250915144810"},"Children":[{"ID":"20250915144810-5pgo52r","Type":"NodeParagraph","Properties":{"id":"20250915144810-5pgo52r","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的强大威力"},{"Type":"NodeText","Data":": 在这两个任务中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本学习都显著优于零样本和单样本"},{"Type":"NodeText","Data":"，尤其是在最大规模的模型上。这表明，通过提供少量示例来“情境化”任务，可以极大地释放大模型的潜能。在Winogrande任务上，少样本GPT-3甚至可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"媲美微调过的SOTA模型"},{"Type":"NodeText","Data":"，这展示了一种替代传统微调范式的新可能性。"}]}]},{"ID":"20250915144810-luedk8b","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250915144810-luedk8b","updated":"20250915144810"},"Children":[{"ID":"20250915144810-99g2091","Type":"NodeParagraph","Properties":{"id":"20250915144810-99g2091","updated":"20250915144810"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据偏见的影响"},{"Type":"NodeText","Data":": 翻译任务的结果（表3.4和图3.4）清晰地暴露了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练数据分布不均的后果"},{"Type":"NodeText","Data":"。由于训练数据中英语占绝对主导，模型在“翻译到英语”这个方向上的表现远超其他方向。这为后续多语言模型的发展提供了重要启示："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高质量、多语种的均衡数据至关重要"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250915144810-cf0m0l6","Type":"NodeParagraph","Properties":{"id":"20250915144810-cf0m0l6","updated":"20250915144810"},"Children":[{"Type":"NodeText","Data":"总结来说，这一部分通过翻译和常识推理两个截然不同的任务，从正反两方面印证了GPT-3的核心理念。一方面，它展示了通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模化"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习"},{"Type":"NodeText","Data":"实现的惊人通用能力；另一方面，它也坦诚地揭示了由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据偏差"},{"Type":"NodeText","Data":"带来的能力不对称性，为模型的进一步发展指明了方向。"}]}]},{"ID":"20250915155901-99kqg51","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915155901-99kqg51","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.4 类Winograd风格任务 (Winograd-Style Tasks)"}]},{"ID":"20250915155901-hijv5y0","Type":"NodeParagraph","Properties":{"id":"20250915155901-hijv5y0","updated":"20250915155901"},"Children":[{"Type":"NodeText","Data":"Winograd模式挑战 [LDM12] 是自然语言处理中的一个经典任务，它涉及到确定一个代词指代哪个词，当这个代词在语法上是模糊的，但对人类来说在语义上是明确的。最近，经过微调的语言模型在原始的Winograd数据集上已经取得了接近人类的性能，但更困难的版本，例如通过对抗性挖掘构建的Winogrande数据集 [SBBC19]，其性能仍然显著落后于人类。我们测试了GPT-3在Winograd和Winogrande这两个数据集上的表现，结果同样显示在零样本、单样本和少样本设置中。"}]},{"ID":"20250915155901-xyzg0kx","Type":"NodeTable","TableAligns":[1,1,1,1,1],"Properties":{"colgroup":"||||","id":"20250915155901-xyzg0kx","updated":"20250915155901"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PIQA"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ARC (Easy)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ARC (Challenge)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"OpenBookQA"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned SOTA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"79.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"92.0"},{"Type":"NodeText","Data":"[KKS⁺20]"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"78.5"},{"Type":"NodeText","Data":"[KKS⁺20]"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"87.2"},{"Type":"NodeText","Data":"[KKS⁺20]"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Zero-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"80.5"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"*"}]}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"68.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"51.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"57.6"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 One-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"80.5"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"*"}]}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"71.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"53.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58.8"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"82.8"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"*"}]}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"51.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"65.4"}]}]}]},{"ID":"20250915155901-ytxktys","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915155901-ytxktys","updated":"20250915155901"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915155901-cvups7y","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915155901-cvups7y","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.6：在三个常识推理任务上的结果：PIQA、ARC和OpenBookQA"}]},{"ID":"20250915155901-tv1etsv","Type":"NodeList","ListData":{},"Properties":{"id":"20250915155901-tv1etsv","updated":"20250915155901"},"Children":[{"ID":"20250915155900-2tcwaut","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155900-2tcwaut","updated":"20250915155900"},"Children":[{"ID":"20250915155901-9n96py1","Type":"NodeParagraph","Properties":{"id":"20250915155901-9n96py1","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" GPT-3的少样本PIQA结果在测试服务器上评估。关于PIQA测试集潜在污染的细节见第4节。"}]}]}]},{"ID":"20250915155901-h64cl0z","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915155901-h64cl0z","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915155901-mi8odw9","Type":"NodeList","ListData":{},"Properties":{"id":"20250915155901-mi8odw9","updated":"20250915155901"},"Children":[{"ID":"20250915155900-x1dtjhz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155900-x1dtjhz","updated":"20250915155900"},"Children":[{"ID":"20250915155901-55h36kd","Type":"NodeParagraph","Properties":{"id":"20250915155901-55h36kd","updated":"20250915155901"},"Children":[{"Type":"NodeText","Data":"这张表展示了GPT-3在三个不同类型的常识推理问答任务上的表现。"}]}]},{"ID":"20250915155900-wo42k12","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155900-wo42k12","updated":"20250915155900"},"Children":[{"ID":"20250915155901-3713u0x","Type":"NodeParagraph","Properties":{"id":"20250915155901-3713u0x","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"物理常识的霸主 (PIQA)"},{"Type":"NodeText","Data":": PIQA (Physical Interaction QA) 测试关于物理世界如何运作的常识。在这项任务上，GPT-3表现极其出色，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本设置下（80.5%）就已经超越了之前经过微调的SOTA模型（79.4%）"},{"Type":"NodeText","Data":"，并在少样本设置下进一步提升至82.8%，创造了新的纪录。这表明GPT-3从海量文本中学到了丰富的关于物理世界的直观知识。"}]}]},{"ID":"20250915155900-yjnkuzt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155900-yjnkuzt","updated":"20250915155900"},"Children":[{"ID":"20250915155901-0xszb6a","Type":"NodeParagraph","Properties":{"id":"20250915155901-0xszb6a","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学推理的挑战 (ARC)"},{"Type":"NodeText","Data":": ARC (AI2 Reasoning Challenge) 是一个更困难的、需要科学知识的推理任务。在这里，GPT-3的表现远不如微调过的SOTA。尤其是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ARC Challenge子集"},{"Type":"NodeText","Data":"上，其准确率仅在51%左右，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"几乎不比随机猜测好多少"},{"Type":"NodeText","Data":"。这揭示了GPT-3在需要更深层次、更结构化推理的领域存在明显短板。"}]}]},{"ID":"20250915155900-4pte3lr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155900-4pte3lr","updated":"20250915155900"},"Children":[{"ID":"20250915155901-z1d0mjl","Type":"NodeParagraph","Properties":{"id":"20250915155901-z1d0mjl","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识问答 (OpenBookQA)"},{"Type":"NodeText","Data":": 在这个任务上，GPT-3的表现介于两者之间。它没有达到SOTA水平，但其少样本性能（65.4%）也展示了不错的常识理解能力。"}]}]}]}]},{"ID":"20250915160012-342bv3t","Type":"NodeParagraph","Properties":{"id":"20250915160012-342bv3t","updated":"20250915160012"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915160012-av8jyi6.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915155901-s3pk988","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915155901-s3pk988","updated":"20250915155901"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915155901-hbwzwri","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915155901-hbwzwri","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.6：PhysicalQA (PIQA) 上的结果"}]},{"ID":"20250915155901-0nz7fw8","Type":"NodeParagraph","Properties":{"id":"20250915155901-0nz7fw8","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915155901-0mjmfma","Type":"NodeList","ListData":{},"Properties":{"id":"20250915155901-0mjmfma","updated":"20250915155901"},"Children":[{"ID":"20250915155900-emflxcj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155900-emflxcj","updated":"20250915155900"},"Children":[{"ID":"20250915155901-6043kzo","Type":"NodeParagraph","Properties":{"id":"20250915155901-6043kzo","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" PhysicalQA"}]}]},{"ID":"20250915155900-yh2r9rn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155900-yh2r9rn","updated":"20250915155900"},"Children":[{"ID":"20250915155901-e1qljqj","Type":"NodeParagraph","Properties":{"id":"20250915155901-e1qljqj","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915155900-wwrjk8j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155900-wwrjk8j","updated":"20250915155900"},"Children":[{"ID":"20250915155901-iw0w9tu","Type":"NodeParagraph","Properties":{"id":"20250915155901-iw0w9tu","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915155900-c7kisal","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155900-c7kisal","updated":"20250915155900"},"Children":[{"ID":"20250915155901-l2eyygi","Type":"NodeParagraph","Properties":{"id":"20250915155901-l2eyygi","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 人类 (Human), 微调SOTA (Fine-tuned SOTA), 零样本 (Zero-Shot), 单样本 (One-Shot), 少样本 (Few-Shot (K=50)), 随机猜测 (Random Guessing)"}]}]},{"ID":"20250915155900-5nfdxo5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155900-5nfdxo5","updated":"20250915155900"},"Children":[{"ID":"20250915155901-bn1jifx","Type":"NodeParagraph","Properties":{"id":"20250915155901-bn1jifx","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" GPT-3在零样本、单样本和少样本设置下的PIQA结果。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大规模的模型在所有三种条件下都取得了超过该任务上已记录的最佳分数的成绩"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250915155901-qb26yxz","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915155901-qb26yxz","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915155901-vmwk3kc","Type":"NodeList","ListData":{},"Properties":{"id":"20250915155901-vmwk3kc","updated":"20250915155901"},"Children":[{"ID":"20250915155901-97ru621","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155901-97ru621","updated":"20250915155901"},"Children":[{"ID":"20250915155901-k0skdih","Type":"NodeParagraph","Properties":{"id":"20250915155901-k0skdih","updated":"20250915155901"},"Children":[{"Type":"NodeText","Data":"这张图是表3.6中PIQA结果的可视化呈现，清晰地展示了“缩放法则”在物理常识推理上的威力。"}]}]},{"ID":"20250915155901-6olk2zs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155901-6olk2zs","updated":"20250915155901"},"Children":[{"ID":"20250915155901-lg6vg7m","Type":"NodeParagraph","Properties":{"id":"20250915155901-lg6vg7m","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越SOTA的临界点"},{"Type":"NodeText","Data":": 图中虚线代表了之前的微调SOTA水平。可以看到，GPT-3模型在规模达到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大约6.7B参数"},{"Type":"NodeText","Data":"时，其少样本性能就已经开始"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越SOTA"},{"Type":"NodeText","Data":"。而175B参数的模型则在所有设置下都稳稳地超过了SOTA。"}]}]},{"ID":"20250915155901-b8y01fz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155901-b8y01fz","updated":"20250915155901"},"Children":[{"ID":"20250915155901-qyupsef","Type":"NodeParagraph","Properties":{"id":"20250915155901-qyupsef","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模效应的又一力证"},{"Type":"NodeText","Data":": 三条曲线都随着模型规模的增长而平滑上升，再次证明"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型越大，其物理常识就越丰富和可靠"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915155901-znof0sc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155901-znof0sc","updated":"20250915155901"},"Children":[{"ID":"20250915155901-fx9hmqj","Type":"NodeParagraph","Properties":{"id":"20250915155901-fx9hmqj","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"接近人类水平"},{"Type":"NodeText","Data":": 175B模型的少样本性能（82.8%）虽然仍与人类（约90%）有差距，但已经达到了一个非常高的水平，显示出强大的潜力。"}]}]}]}]},{"ID":"20250915155901-xx6ul2m","Type":"NodeParagraph","Properties":{"id":"20250915155901-xx6ul2m","updated":"20250915155901"},"Children":[{"Type":"NodeText","Data":"我们在273个Winograd模式的原始数据集上测试了GPT-3，使用了[RWC+19]中描述的相同的“部分评估”方法。请注意，此设置与SuperGLUE基准测试中的WSC任务不同，后者被归类为二元分类，并且需要从实体中提取答案以转换为本节中描述的格式。在Winograd上，GPT-3在零样本、单样本和少样本设置下分别达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"88.3%、89.7%和88.6%"},{"Type":"NodeText","Data":"的准确率，没有显示出明显的上下文学习增益，但在所有情况下都取得了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅比SOTA和人类估计性能低几个百分点"},{"Type":"NodeText","Data":"的强劲结果。我们注意到，污染分析在训练数据中发现了一些Winograd模式，但这些似乎对结果影响很小（见第4节）。"}]},{"ID":"20250915155901-304azj5","Type":"NodeParagraph","Properties":{"id":"20250915155901-304azj5","updated":"20250915155901"},"Children":[{"Type":"NodeText","Data":"在更困难的Winogrande数据集上，我们确实发现在上下文学习中存在增益。GPT-3在零样本设置下达到了70.2%的准确率，在单样本设置下为73.2%，在少样本设置下为77.7%。作为比较，一个经过微调的RoBERTa模型达到了79%的准确率，一个拥有30亿参数高容量模型的SOTA [SBBC19]为84.6%，而人类在该任务上的表现根据[SBBC19]的报告为94.0%。"}]},{"ID":"20250915155901-ior9ukt","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915155901-ior9ukt","updated":"20250915155901"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915155901-xy4cavp","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915155901-xy4cavp","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915155901-gsl20rn","Type":"NodeParagraph","Properties":{"id":"20250915155901-gsl20rn","updated":"20250915155901"},"Children":[{"Type":"NodeText","Data":"这段文字详细分析了GPT-3在两个Winograd风格任务上的表现，揭示了其在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识推理和歧义消解"},{"Type":"NodeText","Data":"方面的能力。"}]},{"ID":"20250915155901-6aw023q","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915155901-6aw023q","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"经典Winograd任务：已接近解决"}]},{"ID":"20250915155901-07t0t1a","Type":"NodeList","ListData":{},"Properties":{"id":"20250915155901-07t0t1a","updated":"20250915155901"},"Children":[{"ID":"20250915155901-bwfp5un","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155901-bwfp5un","updated":"20250915155901"},"Children":[{"ID":"20250915155901-x20jjm0","Type":"NodeParagraph","Properties":{"id":"20250915155901-x20jjm0","updated":"20250915155901"},"Children":[{"Type":"NodeText","Data":"在最初的、经典的Winograd数据集上，GPT-3的表现非常出色。"}]}]},{"ID":"20250915155901-76plmb0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155901-76plmb0","updated":"20250915155901"},"Children":[{"ID":"20250915155901-qwn04lj","Type":"NodeParagraph","Properties":{"id":"20250915155901-qwn04lj","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本即达顶尖水平"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"即使不给任何示例（88.3%），GPT-3的性能也已经非常接近人类和经过微调的SOTA模型（约90%）"},{"Type":"NodeText","Data":"。这表明，大规模预训练已经让模型内化了解决这类经典歧义问题所需的大部分常识。"}]}]},{"ID":"20250915155901-km9slg8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155901-km9slg8","updated":"20250915155901"},"Children":[{"ID":"20250915155901-285lfey","Type":"NodeParagraph","Properties":{"id":"20250915155901-285lfey","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习收益不大"},{"Type":"NodeText","Data":": 在这个相对“简单”的任务上，提供一或多个示例并没有带来显著提升。这暗示该任务可能已经达到了GPT-3（或当前架构）通过上下文学习所能提升的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能上限"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250915155901-hhvu90f","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915155901-hhvu90f","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Winogrande任务：挑战与潜力并存"}]},{"ID":"20250915155901-v65r1w2","Type":"NodeList","ListData":{},"Properties":{"id":"20250915155901-v65r1w2","updated":"20250915155901"},"Children":[{"ID":"20250915155901-85r4ivv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155901-85r4ivv","updated":"20250915155901"},"Children":[{"ID":"20250915155901-q3pjdmr","Type":"NodeParagraph","Properties":{"id":"20250915155901-q3pjdmr","updated":"20250915155901"},"Children":[{"Type":"NodeText","Data":"Winogrande是专为挑战现有模型而设计的、更困难的版本。"}]}]},{"ID":"20250915155901-jlf6d96","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155901-jlf6d96","updated":"20250915155901"},"Children":[{"ID":"20250915155901-vy9g0ma","Type":"NodeParagraph","Properties":{"id":"20250915155901-vy9g0ma","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习效果显著"},{"Type":"NodeText","Data":": 与经典Winograd不同，在Winogrande上，从零样本（70.2%）到少样本（77.7%），性能有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"明显的、持续的提升"},{"Type":"NodeText","Data":"。这说明对于更复杂的推理任务，通过示例进行“情境化”学习是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常有效的"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915155901-pfd2fpc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915155901-pfd2fpc","updated":"20250915155901"},"Children":[{"ID":"20250915155901-smu42pb","Type":"NodeParagraph","Properties":{"id":"20250915155901-smu42pb","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与SOTA和人类的差距"},{"Type":"NodeText","Data":": 尽管表现不俗，但GPT-3的少样本性能（77.7%）仍与微调过的SOTA（84.6%）和人类（94.0%）存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"明显差距"},{"Type":"NodeText","Data":"。这表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更深层次、更鲁棒的常识推理仍然是当前大模型面临的一大挑战"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915155901-yntjt8v","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915155901-yntjt8v","updated":"20250915155901"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915155901-neth3v5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915155901-neth3v5","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250915155901-ajtsu42","Type":"NodeParagraph","Properties":{"id":"20250915155901-ajtsu42","updated":"20250915155901"},"Children":[{"Type":"NodeText","Data":"本次分析聚焦于GPT-3的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识推理"},{"Type":"NodeText","Data":"能力，通过一系列精心设计的任务，我们得到了一个全面而又细致的画像。"}]},{"ID":"20250915155901-mblgx1t","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915155901-mblgx1t","updated":"20250915155901"},"Children":[{"ID":"20250915155901-pn86cb5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915155901-pn86cb5","updated":"20250915155901"},"Children":[{"ID":"20250915155901-yfrwcrf","Type":"NodeParagraph","Properties":{"id":"20250915155901-yfrwcrf","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识推理能力的不均衡性"},{"Type":"NodeText","Data":": 这是本节最重要的发现。GPT-3并非在所有类型的常识上都表现得同样出色。它在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"物理常识（PIQA）"},{"Type":"NodeText","Data":"上展现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超强的、超越SOTA的能力"},{"Type":"NodeText","Data":"，但在需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学知识和复杂推理（ARC Challenge）"},{"Type":"NodeText","Data":"的任务上则"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表现平平"},{"Type":"NodeText","Data":"。这表明，模型从通用文本中学到的“常识”更偏向于日常、直观的物理世界互动，而对于更抽象、结构化的科学知识体系则掌握不足。"}]}]},{"ID":"20250915155901-uws6qld","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915155901-uws6qld","updated":"20250915155901"},"Children":[{"ID":"20250915155901-qoszeub","Type":"NodeParagraph","Properties":{"id":"20250915155901-qoszeub","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“缩放法则”在常识领域的延续"},{"Type":"NodeText","Data":": 无论是哪种常识任务，图3.6都清晰地表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能与模型规模严格正相关"},{"Type":"NodeText","Data":"。更大的模型拥有更可靠的常识。这为通过继续扩大模型规模来提升通用人工智能的“常识感”提供了希望。"}]}]},{"ID":"20250915155901-qqw8q3x","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915155901-qqw8q3x","updated":"20250915155901"},"Children":[{"ID":"20250915155901-hoy061i","Type":"NodeParagraph","Properties":{"id":"20250915155901-hoy061i","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习是解锁复杂推理的关键"},{"Type":"NodeText","Data":": 对于更困难的推理任务（如Winogrande），"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本学习的价值凸显出来"},{"Type":"NodeText","Data":"。当任务对模型来说不再是“小菜一碟”时，提供几个示例就成了引导模型进行正确推理的关键步骤。这再次印证了上下文学习作为一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"快速任务适应"},{"Type":"NodeText","Data":"机制的强大作用。"}]}]},{"ID":"20250915155901-ng0l0v2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250915155901-ng0l0v2","updated":"20250915155901"},"Children":[{"ID":"20250915155901-u5gvcc6","Type":"NodeParagraph","Properties":{"id":"20250915155901-u5gvcc6","updated":"20250915155901"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"接近但尚未完全解决常识问题"},{"Type":"NodeText","Data":": 尽管在某些任务上取得了SOTA，但GPT-3在更具挑战性的数据集（如Winogrande, ARC Challenge）上与人类和顶尖微调模型仍有差距。这说明，虽然大规模预训练是通往通用常识推理的有效路径，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"这条路尚未走到终点"},{"Type":"NodeText","Data":"，更鲁棒、更深层次的推理机制仍有待探索。"}]}]}]},{"ID":"20250915155901-b5s5k79","Type":"NodeParagraph","Properties":{"id":"20250915155901-b5s5k79","updated":"20250915155901"},"Children":[{"Type":"NodeText","Data":"总结而言，本节通过对GPT-3常识推理能力的深入剖析，一方面展示了大规模模型在该领域取得的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"巨大进步和惊人潜力"},{"Type":"NodeText","Data":"，另一方面也"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精准地定位了其能力边界和未来需要攻克的难点"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915160754-4nmpiu0","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160754-4nmpiu0","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.5 常识推理 (Common Sense Reasoning)"}]},{"ID":"20250915160754-jvn9w1u","Type":"NodeParagraph","Properties":{"id":"20250915160754-jvn9w1u","updated":"20250915160755"},"Children":[{"Type":"NodeText","Data":"接下来我们考察三个试图捕捉"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"物理或科学推理"},{"Type":"NodeText","Data":"的数据集，这与句子补全、阅读理解或宽泛的知识问答有所区别。第一个是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PhysicalQA (PIQA)"},{"Type":"NodeText","Data":" [BZB⁺19]，它询问关于物理世界如何运作的常识性问题，旨在探测对世界的一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“具身理解”（grounded understanding）"},{"Type":"NodeText","Data":"。GPT-3在零样本设置下达到了81.0%的准确率，在单样本设置下为80.5%，在少样本设置下为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"82.8%"},{"Type":"NodeText","Data":"（最后一个是在PIQA的测试服务器上测量的）。这与之前微调模型的79.4%的SOTA准确率相比表现优异。"}]},{"ID":"20250915160754-xsskldy","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1],"Properties":{"colgroup":"||||||","id":"20250915160754-xsskldy","updated":"20250915160755"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CoQA"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"DROP"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"QuAC"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SQuADv2"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RACE-h"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RACE-m"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned SOTA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"90.7"},{"Type":"NodeText","Data":"ᵃ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"89.1"},{"Type":"NodeText","Data":"ᵇ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"74.4"},{"Type":"NodeText","Data":"ᶜ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"93.0"},{"Type":"NodeText","Data":"ᵈ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"90.0"},{"Type":"NodeText","Data":"ᵉ"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"93.1"},{"Type":"NodeText","Data":"ᵉ"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Zero-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"81.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"23.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"59.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"45.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58.4"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 One-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"84.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"43.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"65.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"45.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"57.4"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"85.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"36.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"44.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"69.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"46.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58.1"}]}]}]},{"ID":"20250915160754-kfz3y2j","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915160754-kfz3y2j","updated":"20250915160755"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915160754-m0ogssl","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160754-m0ogssl","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.7：在阅读理解任务上的结果"}]},{"ID":"20250915160754-55lg4pa","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160754-55lg4pa","updated":"20250915160754"},"Children":[{"ID":"20250915160754-jcxgz18","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-jcxgz18","updated":"20250915160754"},"Children":[{"ID":"20250915160754-3x13r3q","Type":"NodeParagraph","Properties":{"id":"20250915160754-3x13r3q","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" CoQA、DROP、QuAC和SQuADv2的分数是F1分数，RACE的分数是准确率。ᵃ[JZC⁺19] ᵇ[JN20] ᶜ[AI19] ᵈ[QIA20] ᵉ[SPP⁺19]"}]}]}]},{"ID":"20250915160754-m9nr6tq","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915160754-m9nr6tq","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915160754-evkf877","Type":"NodeParagraph","Properties":{"id":"20250915160754-evkf877","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重要提示："},{"Type":"NodeText","Data":" 这个表格（表3.7）实际上属于论文的下一节（3.6 阅读理解），与当前正在讨论的常识推理（3.5节）的文本内容"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并不对应"},{"Type":"NodeText","Data":"。我们将分别对其进行解析。"}]},{"ID":"20250915160754-jhf93em","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160754-jhf93em","updated":"20250915160754"},"Children":[{"ID":"20250915160754-uhmq9zy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-uhmq9zy","updated":"20250915160754"},"Children":[{"ID":"20250915160754-6ud3og2","Type":"NodeParagraph","Properties":{"id":"20250915160754-6ud3og2","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"这张表展示了GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"六个主流阅读理解数据集"},{"Type":"NodeText","Data":"上的表现。"}]}]},{"ID":"20250915160754-ucpn9hx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-ucpn9hx","updated":"20250915160754"},"Children":[{"ID":"20250915160754-bsn97s9","Type":"NodeParagraph","Properties":{"id":"20250915160754-bsn97s9","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心发现：与SOTA的巨大差距"},{"Type":"NodeText","Data":"：最直观的结论是，在所有这些任务上，GPT-3（即使是少样本设置）的表现都"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"远逊于"},{"Type":"NodeText","Data":"经过专门微调的SOTA模型。"}]}]},{"ID":"20250915160754-lomsemu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-lomsemu","updated":"20250915160754"},"Children":[{"ID":"20250915160754-tzr27or","Type":"NodeParagraph","Properties":{"id":"20250915160754-tzr27or","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务难度与性能差距"},{"Type":"NodeText","Data":"："}]},{"ID":"20250915160754-14enu6z","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160754-14enu6z","updated":"20250915160754"},"Children":[{"ID":"20250915160754-nmxpolm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-nmxpolm","updated":"20250915160754"},"Children":[{"ID":"20250915160754-y8vmpr1","Type":"NodeParagraph","Properties":{"id":"20250915160754-y8vmpr1","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"在对话式问答（CoQA）上，GPT-3表现尚可（85.0 vs 90.7），差距相对较小。"}]}]},{"ID":"20250915160754-m396umn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-m396umn","updated":"20250915160754"},"Children":[{"ID":"20250915160754-xac0kij","Type":"NodeParagraph","Properties":{"id":"20250915160754-xac0kij","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"在需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数字推理"},{"Type":"NodeText","Data":"的DROP数据集上，GPT-3"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表现极差"},{"Type":"NodeText","Data":"（36.5 vs 89.1），暴露出其在处理需要精确计算和推理的文本上的巨大短板。"}]}]},{"ID":"20250915160754-ne2gcuy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-ne2gcuy","updated":"20250915160754"},"Children":[{"ID":"20250915160754-ftvy8b6","Type":"NodeParagraph","Properties":{"id":"20250915160754-ftvy8b6","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"在其他任务如SQuADv2和RACE（基于学生考试设计的困难数据集）上，差距同样非常显著。"}]}]}]}]},{"ID":"20250915160754-e3vqy91","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-e3vqy91","updated":"20250915160754"},"Children":[{"ID":"20250915160754-6r7jgkg","Type":"NodeParagraph","Properties":{"id":"20250915160754-6r7jgkg","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结论"},{"Type":"NodeText","Data":"：这个表格有力地说明，对于拥有大规模、高质量训练数据的复杂任务（如阅读理解），"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"传统的微调范式在性能上仍然拥有压倒性的优势"},{"Type":"NodeText","Data":"。上下文学习虽然灵活，但在这些“硬核”基准测试上还无法与专门训练的模型相匹敌。"}]}]}]}]},{"ID":"20250915160754-hf4n2a8","Type":"NodeParagraph","Properties":{"id":"20250915160754-hf4n2a8","updated":"20250915160755"},"Children":[{"Type":"NodeText","Data":"fine-tuned ROBERTA. PIQA与模型规模的缩放关系相对较浅，并且仍然比人类表现低10%以上，但GPT-3的少样本甚至零样本结果都"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越了当前的SOTA"},{"Type":"NodeText","Data":"。我们的分析标记出PIQA存在潜在的数据污染问题（尽管测试标签是隐藏的），因此我们保守地用星号标记这个结果。详情请参见第4节。"}]},{"ID":"20250915160754-0i1d7cd","Type":"NodeParagraph","Properties":{"id":"20250915160754-0i1d7cd","updated":"20250915160755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ARC"},{"Type":"NodeText","Data":" [CCE⁺18]是一个多项选择题数据集，问题来自3到9年级的科学考试。数据集的“Challenge”版本经过筛选，排除了那些仅通过简单统计或信息检索方法就能正确回答的问题。GPT-3在零样本设置下达到了51.4%的准确率，在单样本设置下为53.2%，在少样本设置下为51.5%。这与来自UnifiedQA [KKS⁺20]的微调RoBERTa基线（55.9%）的性能相近。在“Easy”版本的数据集上（问题可以由上述任一基线方法正确回答），GPT-3达到了71.2%（单样本）和70.1%的准确率，略微超过了来自[KKS⁺20]的微调RoBERTa基线。然而，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"这两个结果仍然远差于UnifiedQA取得的总体SOTA"},{"Type":"NodeText","Data":"，后者在Challenge集上超过了GPT-3的少样本结果27%，在Easy集上超过了22%。"}]},{"ID":"20250915160754-30kcasj","Type":"NodeParagraph","Properties":{"id":"20250915160754-30kcasj","updated":"20250915160755"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"OpenBookQA"},{"Type":"NodeText","Data":" [MCKS18]上，GPT-3从零样本到少样本设置的性能提升了68.8%，但仍然比总体SOTA低了20多个点。GPT-3的少样本性能与排行榜上的一个微调过的BERT Large基线相似。"}]},{"ID":"20250915160754-sq4u2e5","Type":"NodeParagraph","Properties":{"id":"20250915160754-sq4u2e5","updated":"20250915160755"},"Children":[{"Type":"NodeText","Data":"总的来说，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"使用GPT-3的上下文学习在常识推理任务上取得了混合的结果"},{"Type":"NodeText","Data":"，在PIQA和ARC的单样本和少样本设置中只观察到微小且不一致的增益，但在OpenBookQA上观察到了一致的改进。GPT-3在所有评估设置中都在新的PIQA数据集上创造了SOTA。"}]},{"ID":"20250915160754-8qc30gi","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915160754-8qc30gi","updated":"20250915160755"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915160754-oj79zjd","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915160754-oj79zjd","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915160754-vkhfajq","Type":"NodeParagraph","Properties":{"id":"20250915160754-vkhfajq","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"这段文字详细分析了GPT-3在三个不同类型的常识推理任务上的表现，揭示了其能力的“长板”和“短板”。"}]},{"ID":"20250915160754-yxbkw89","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160754-yxbkw89","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心发现：表现参差不齐"}]},{"ID":"20250915160754-v2hz3ci","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160754-v2hz3ci","updated":"20250915160754"},"Children":[{"ID":"20250915160754-61ml5rq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-61ml5rq","updated":"20250915160754"},"Children":[{"ID":"20250915160754-f31zdiq","Type":"NodeParagraph","Properties":{"id":"20250915160754-f31zdiq","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"与之前任务相对一致的趋势不同，GPT-3在常识推理领域的表现是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“混合的”或“参差不齐的”"},{"Type":"NodeText","Data":"，这本身就是一个重要发现。"}]}]}]},{"ID":"20250915160754-si86n6r","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160754-si86n6r","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"各项任务表现剖析"}]},{"ID":"20250915160754-aufs338","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915160754-aufs338","updated":"20250915160754"},"Children":[{"ID":"20250915160754-i8a8gg8","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915160754-i8a8gg8","updated":"20250915160754"},"Children":[{"ID":"20250915160754-0dpanxz","Type":"NodeParagraph","Properties":{"id":"20250915160754-0dpanxz","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"物理常识 (PIQA) - 强项"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915160754-m7h9g0o","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160754-m7h9g0o","updated":"20250915160754"},"Children":[{"ID":"20250915160754-b4s0chz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-b4s0chz","updated":"20250915160754"},"Children":[{"ID":"20250915160754-aujlkao","Type":"NodeParagraph","Properties":{"id":"20250915160754-aujlkao","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"GPT-3在此任务上表现极为出色，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本即超越SOTA"},{"Type":"NodeText","Data":"。这表明模型从海量文本中内化了大量关于日常物理世界如何运作的直观知识。"}]}]},{"ID":"20250915160754-hvt58yi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-hvt58yi","updated":"20250915160754"},"Children":[{"ID":"20250915160754-2c1kpv3","Type":"NodeParagraph","Properties":{"id":"20250915160754-2c1kpv3","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"作者严谨地指出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据污染的可能性"},{"Type":"NodeText","Data":"，为这个亮眼的结果增加了一份审慎。"}]}]}]}]},{"ID":"20250915160754-dowuiif","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915160754-dowuiif","updated":"20250915160754"},"Children":[{"ID":"20250915160754-l5x3mzt","Type":"NodeParagraph","Properties":{"id":"20250915160754-l5x3mzt","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学推理 (ARC) - 弱项"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915160754-oano9tv","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160754-oano9tv","updated":"20250915160754"},"Children":[{"ID":"20250915160754-lify8zi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-lify8zi","updated":"20250915160754"},"Children":[{"ID":"20250915160754-7e3py87","Type":"NodeParagraph","Properties":{"id":"20250915160754-7e3py87","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"这是GPT-3的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"明显短板"},{"Type":"NodeText","Data":"。尤其是在更困难的“Challenge”集上，其性能几乎与随机猜测无异，并且"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"远低于"},{"Type":"NodeText","Data":"经过微调的SOTA模型。"}]}]},{"ID":"20250915160754-ve69mpm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-ve69mpm","updated":"20250915160754"},"Children":[{"ID":"20250915160754-1g71f86","Type":"NodeParagraph","Properties":{"id":"20250915160754-1g71f86","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"这揭示了GPT-3的推理能力是有限的。它可能擅长基于语言模式的直觉式联想，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不擅长需要结构化知识和多步逻辑的科学推理"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915160754-4rv27z9","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915160754-4rv27z9","updated":"20250915160754"},"Children":[{"ID":"20250915160754-vpk2n1h","Type":"NodeParagraph","Properties":{"id":"20250915160754-vpk2n1h","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放式书籍问答 (OpenBookQA) - 中等表现"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915160754-i0q553d","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160754-i0q553d","updated":"20250915160754"},"Children":[{"ID":"20250915160754-atmbr2l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-atmbr2l","updated":"20250915160754"},"Children":[{"ID":"20250915160754-om24x2j","Type":"NodeParagraph","Properties":{"id":"20250915160754-om24x2j","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"GPT-3的表现介于前两者之间，性能虽然远不及SOTA，但随着示例的增加有稳定提升。"}]}]}]}]}]},{"ID":"20250915160754-d9aqb49","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160754-d9aqb49","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的局限性"}]},{"ID":"20250915160754-pll8izn","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160754-pll8izn","updated":"20250915160754"},"Children":[{"ID":"20250915160754-41capxm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-41capxm","updated":"20250915160754"},"Children":[{"ID":"20250915160754-r5eaaci","Type":"NodeParagraph","Properties":{"id":"20250915160754-r5eaaci","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"一个有趣的观察是，在PIQA和ARC上，从零样本到少样本的性能提升"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常小甚至没有"},{"Type":"NodeText","Data":"。这可能意味着对于这类问题，模型要么“凭直觉”就知道，要么就不知道，几个例子并不能教会它底层的推理逻辑。这与之前很多任务中少样本学习能带来巨大提升的现象形成了对比。"}]}]}]}]},{"ID":"20250915160754-xtmnabi","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915160754-xtmnabi","updated":"20250915160755"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915160754-zer2p09","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915160754-zer2p09","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250915160754-6z1euns","Type":"NodeParagraph","Properties":{"id":"20250915160754-6z1euns","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"本节（3.5 常识推理）与意外插入的阅读理解表格（表3.7）共同为我们描绘了一幅关于GPT-3能力边界的清晰图景。"}]},{"ID":"20250915160754-8rpktup","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915160754-8rpktup","updated":"20250915160754"},"Children":[{"ID":"20250915160754-9qwl8x5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915160754-9qwl8x5","updated":"20250915160754"},"Children":[{"ID":"20250915160754-sxm3dju","Type":"NodeParagraph","Properties":{"id":"20250915160754-sxm3dju","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识能力的“画像”"},{"Type":"NodeText","Data":": 第3.5节的文本内容深入剖析了GPT-3的常识能力。它并非一个单一的能力，而是有着明显“偏科”的画像。它"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精通基于语言经验的日常物理常识（PIQA）"},{"Type":"NodeText","Data":"，但在需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严谨、抽象的科学逻辑推理（ARC）"},{"Type":"NodeText","Data":"时则显得力不从心。这表明模型的“理解”更多是基于统计模式的直觉，而非符号化的逻辑推理。"}]}]},{"ID":"20250915160754-abd57tf","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915160754-abd57tf","updated":"20250915160754"},"Children":[{"ID":"20250915160754-k19t0s3","Type":"NodeParagraph","Properties":{"id":"20250915160754-k19t0s3","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"阅读理解的“现实检验”"},{"Type":"NodeText","Data":": 表3.7则提供了一个重要的“现实检验”。它告诉我们，尽管上下文学习在很多任务上表现惊艳，但在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"阅读理解"},{"Type":"NodeText","Data":"这一传统NLP的核心领域，特别是那些需要深度篇章理解和精确推理（如DROP）的任务上，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与专门为此任务进行微调的SOTA模型相比，GPT-3还存在巨大差距"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915160754-4w22y3v","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915160754-4w22y3v","updated":"20250915160754"},"Children":[{"ID":"20250915160754-lsq2llv","Type":"NodeParagraph","Properties":{"id":"20250915160754-lsq2llv","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 vs. 微调的权衡"},{"Type":"NodeText","Data":": 综合来看，这两部分内容共同揭示了两种范式间的权衡。"}]},{"ID":"20250915160754-jch0cxn","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160754-jch0cxn","updated":"20250915160754"},"Children":[{"ID":"20250915160754-49nh7wh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-49nh7wh","updated":"20250915160754"},"Children":[{"ID":"20250915160754-b9g0als","Type":"NodeParagraph","Properties":{"id":"20250915160754-b9g0als","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习"},{"Type":"NodeText","Data":"的优势在于其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极高的灵活性和通用性"},{"Type":"NodeText","Data":"，无需为新任务准备大量数据就能取得不错的、甚至在某些任务（如PIQA）上是顶尖的性能。"}]}]},{"ID":"20250915160754-xiia08r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160754-xiia08r","updated":"20250915160754"},"Children":[{"ID":"20250915160754-bpml9nh","Type":"NodeParagraph","Properties":{"id":"20250915160754-bpml9nh","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调"},{"Type":"NodeText","Data":"的优势在于其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在特定任务上的性能上限更高"},{"Type":"NodeText","Data":"。当拥有大量高质量的标注数据时，微调能让模型“专心致志”地攻克一个难题，达到上下文学习难以企及的精度。"}]}]}]}]},{"ID":"20250915160754-9x29b32","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250915160754-9x29b32","updated":"20250915160754"},"Children":[{"ID":"20250915160754-emjozwm","Type":"NodeParagraph","Properties":{"id":"20250915160754-emjozwm","updated":"20250915160754"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"识别模型的“舒适区”"},{"Type":"NodeText","Data":": GPT-3的表现很大程度上取决于任务是否与其庞大的预训练数据所蕴含的模式相契合。PIQA的问题风格可能更接近于网络上的日常描述，而ARC的科学问题和DROP的数字推理则可能相对稀疏，导致模型表现不佳。"}]}]}]},{"ID":"20250915160754-j5d7050","Type":"NodeParagraph","Properties":{"id":"20250915160754-j5d7050","updated":"20250915160754"},"Children":[{"Type":"NodeText","Data":"总结而言，这一部分的分析至关重要，因为它不再仅仅是展示GPT-3有多强大，而是开始"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统性地探索其能力的边界"},{"Type":"NodeText","Data":"。它告诉我们，GPT-3不是万能的，其强大的通用能力背后，是不同类型任务上表现的显著差异，以及在某些成熟领域与传统微调方法之间仍然存在的性能鸿沟。"}]}]},{"ID":"20250915160843-myupelp","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160843-myupelp","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.6 阅读理解 (Reading Comprehension)"}]},{"ID":"20250915160843-fxibsag","Type":"NodeParagraph","Properties":{"id":"20250915160843-fxibsag","updated":"20250915160844"},"Children":[{"Type":"NodeText","Data":"接下来我们评估GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"阅读理解"},{"Type":"NodeText","Data":"任务上的表现。我们使用了一个包含5个数据集的套件，涵盖了摘要式、多项选择以及基于上下文的答案抽取等形式，既有对话式也有单轮问答的设置。我们观察到GPT-3在这些数据集上的表现存在巨大差异，这表明其能力会随着不同的答案格式而变化。总的来说，我们观察到GPT-3的性能与每个数据集上使用上下文表示的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"早期基线和初步结果相当"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915160843-rf2yvy3","Type":"NodeParagraph","Properties":{"id":"20250915160843-rf2yvy3","updated":"20250915160844"},"Children":[{"Type":"NodeText","Data":"GPT-3表现最好的地方（与人类基线相差不到3个点）是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoQA"},{"Type":"NodeText","Data":" [RCM19]上，这是一个自由形式的对话式数据集。而表现最差的地方（比ELMo基线低13个F1点）是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"QuAC"},{"Type":"NodeText","Data":" [CHI⁺18]上，这是一个需要对对话行为和师生互动进行建模的数据集。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DROP"},{"Type":"NodeText","Data":" [DWD⁺19]上，一个需要离散推理和在阅读理解背景下进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数字运算"},{"Type":"NodeText","Data":"的数据集，GPT-3在少样本设置下超过了原始论文中的微调BERT基线，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仍然远低于人类表现和最先进的"},{"Type":"NodeText","Data":"、增强了神经网络与符号系统的模型[RLL⁺19]。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SQuAD 2.0"},{"Type":"NodeText","Data":" [RJL18]上，GPT-3展现了其少样本学习能力，与零样本设置相比，F1分数提升了近10个点（达到69.8）。这使其能够略微超过原始论文中最好的微调结果[LXL⁺17]。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RACE"},{"Type":"NodeText","Data":" [LXL⁺17]上，一个由初高中英语考试组成的多项选择数据集，GPT-3的表现相对较弱，仅与最早利用上下文表示的工作相当，并且"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仍然落后SOTA 45%"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915160843-lofm01x","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915160843-lofm01x","updated":"20250915160844"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915160843-02y3cji","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915160843-02y3cji","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915160843-07tzyif","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160843-07tzyif","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心发现：表现参差不齐，远逊于SOTA"}]},{"ID":"20250915160843-rnhwzz0","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-rnhwzz0","updated":"20250915160843"},"Children":[{"ID":"20250915160843-vl6ettr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-vl6ettr","updated":"20250915160843"},"Children":[{"ID":"20250915160843-j2e9ajk","Type":"NodeParagraph","Properties":{"id":"20250915160843-j2e9ajk","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"这是对前一节意外插入的阅读理解表格（表3.7）的详细文字说明。核心结论是，GPT-3在阅读理解领域的表现是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“混合的”"},{"Type":"NodeText","Data":"，并且总体上"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"远不如"},{"Type":"NodeText","Data":"经过专门微调的SOTA模型。"}]}]}]},{"ID":"20250915160843-qbzehdd","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160843-qbzehdd","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体任务表现剖析"}]},{"ID":"20250915160843-07dtx0k","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-07dtx0k","updated":"20250915160843"},"Children":[{"ID":"20250915160843-of8lcdh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-of8lcdh","updated":"20250915160843"},"Children":[{"ID":"20250915160843-n8vtb6m","Type":"NodeParagraph","Properties":{"id":"20250915160843-n8vtb6m","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强项 (CoQA)"},{"Type":"NodeText","Data":": 在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话式"},{"Type":"NodeText","Data":"、形式更自由的CoQA上，GPT-3表现出色，非常接近人类水平。这表明它擅长处理更自然、更具互动性的语言格式。"}]}]},{"ID":"20250915160843-oqzgz3e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-oqzgz3e","updated":"20250915160843"},"Children":[{"ID":"20250915160843-q77kp6q","Type":"NodeParagraph","Properties":{"id":"20250915160843-q77kp6q","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"绝对弱项 (DROP)"},{"Type":"NodeText","Data":": 在需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学和逻辑推理"},{"Type":"NodeText","Data":"的DROP数据集上，GPT-3惨败。这再次暴露了模型在符号操作和精确推理方面的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本性短板"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915160843-rdb918b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-rdb918b","updated":"20250915160843"},"Children":[{"ID":"20250915160843-u84o4i7","Type":"NodeParagraph","Properties":{"id":"20250915160843-u84o4i7","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的体现 (SQuAD 2.0)"},{"Type":"NodeText","Data":": 在SQuAD 2.0上，从零样本到少样本有近10个点的F1提升，这清晰地展示了上下文学习在适应特定任务格式上的作用。"}]}]},{"ID":"20250915160843-rfw7qnw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-rfw7qnw","updated":"20250915160843"},"Children":[{"ID":"20250915160843-ugw0uh4","Type":"NodeParagraph","Properties":{"id":"20250915160843-ugw0uh4","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总体结论"},{"Type":"NodeText","Data":": 这一节清晰地界定了GPT-3的能力边界。虽然它是一个强大的语言模型，但在传统、复杂的阅读理解基准测试上，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"其通用能力还无法替代专门的、经过微调的训练"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915160843-jleo86t","Type":"NodeParagraph","Properties":{"id":"20250915160843-jleo86t","updated":"20250915160844"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914160455-ksc5p1v.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915160843-xi9ujy3","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915160843-xi9ujy3","updated":"20250915160844"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915160843-d8s3mqs","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160843-d8s3mqs","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.7：CoQA阅读理解任务上的结果"}]},{"ID":"20250915160843-ksm7ozg","Type":"NodeParagraph","Properties":{"id":"20250915160843-ksm7ozg","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915160843-20kz4vy","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-20kz4vy","updated":"20250915160843"},"Children":[{"ID":"20250915160843-7lmcx3z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-7lmcx3z","updated":"20250915160843"},"Children":[{"ID":"20250915160843-2zwhb32","Type":"NodeParagraph","Properties":{"id":"20250915160843-2zwhb32","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" CoQA"}]}]},{"ID":"20250915160843-tew6f3i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-tew6f3i","updated":"20250915160843"},"Children":[{"ID":"20250915160843-kdcel2y","Type":"NodeParagraph","Properties":{"id":"20250915160843-kdcel2y","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915160843-m6r9j4i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-m6r9j4i","updated":"20250915160843"},"Children":[{"ID":"20250915160843-vrlwe5g","Type":"NodeParagraph","Properties":{"id":"20250915160843-vrlwe5g","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915160843-zk8hc4k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-zk8hc4k","updated":"20250915160843"},"Children":[{"ID":"20250915160843-pbbyutt","Type":"NodeParagraph","Properties":{"id":"20250915160843-pbbyutt","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 零样本 (Zero-Shot), 单样本 (One-Shot), 少样本 (Few-Shot (K=5)), 微调SOTA (Fine-tuned SOTA), 人类 (Human)"}]}]},{"ID":"20250915160843-liwepbd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-liwepbd","updated":"20250915160843"},"Children":[{"ID":"20250915160843-gvcyct5","Type":"NodeParagraph","Properties":{"id":"20250915160843-gvcyct5","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" GPT-3 175B在少样本设置下取得了85 F1的成绩，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅比人类实测表现和最先进的微调模型低几个百分点"},{"Type":"NodeText","Data":"。零样本和单样本的表现也只落后几个点，其中少样本的增益对于更大的模型来说是最大的。"}]}]}]},{"ID":"20250915160843-173lzya","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915160843-173lzya","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915160843-wcoiaj5","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-wcoiaj5","updated":"20250915160843"},"Children":[{"ID":"20250915160843-viiqtb9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-viiqtb9","updated":"20250915160843"},"Children":[{"ID":"20250915160843-7bl1gs9","Type":"NodeParagraph","Properties":{"id":"20250915160843-7bl1gs9","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"这张图是GPT-3在阅读理解任务中的“高光时刻”。"}]}]},{"ID":"20250915160843-zcu0hw2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-zcu0hw2","updated":"20250915160843"},"Children":[{"ID":"20250915160843-adzsj8a","Type":"NodeParagraph","Properties":{"id":"20250915160843-adzsj8a","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强大的对话理解能力"},{"Type":"NodeText","Data":": 该图直观地展示了GPT-3在CoQA上的强大性能。最大规模的模型（175B）在少样本设置下已经"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常接近"},{"Type":"NodeText","Data":"人类和微调SOTA的水平，这在所有阅读理解任务中是独一无二的。"}]}]},{"ID":"20250915160843-x6fcdo8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-x6fcdo8","updated":"20250915160843"},"Children":[{"ID":"20250915160843-m59ecz5","Type":"NodeParagraph","Properties":{"id":"20250915160843-m59ecz5","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缩放法则的延续"},{"Type":"NodeText","Data":": 所有三条曲线都随着模型规模的扩大而平滑上升，再次证明"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型越大，其对话式阅读理解能力越强"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915160843-fyku2ic","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160843-fyku2ic","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.7 SuperGLUE"}]},{"ID":"20250915160843-k8oibup","Type":"NodeParagraph","Properties":{"id":"20250915160843-k8oibup","updated":"20250915160844"},"Children":[{"Type":"NodeText","Data":"为了更好地在NLP任务上获得聚合结果，并与BERT和RoBERTa等流行模型进行更系统的比较，我们还在一个标准化的数据集集合上评估了GPT-3，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SuperGLUE"},{"Type":"NodeText","Data":"基准测试 [WPN⁺19] [CLC⁺19] [DMST19] [RBG11] [KCR⁺18] [ZLL⁺18] [DGM06] [BHDD⁺06] [GMDD07] [BDD⁺09] [PCC18] [PHR⁺18]。GPT-3在SuperGLUE数据集上的测试集表现在表3.8中展示。在少样本设置中，我们为所有任务使用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"32个"},{"Type":"NodeText","Data":"从训练集中随机抽样的示例，除了WSC。"}]},{"ID":"20250915160843-2wfcqek","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1],"Properties":{"colgroup":"||||||","id":"20250915160843-2wfcqek","updated":"20250915160844"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SuperGLUE 平均"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BoolQ 准确率"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CB 准确率"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CB F1"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"COPA 准确率"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RTE 准确率"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned SOTA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"89.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"91.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"96.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"93.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"94.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"92.5"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned BERT-Large"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"69.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"77.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"83.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"75.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"71.7"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"71.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"76.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"75.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"52.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"92.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"69.0"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WiC 准确率"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WSC 准确率"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MultiRC 准确率"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MultiRC F1a"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ReCoRD 准确率"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ReCoRD F1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned SOTA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"76.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"93.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"88.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"92.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"93.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned BERT-Large"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"69.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"71.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"72.0"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"49.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"80.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"50.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"90.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"91.1"}]}]}]},{"ID":"20250915160843-8i9d32p","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915160843-8i9d32p","updated":"20250915160844"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915160843-imc5p0o","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160843-imc5p0o","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.8：GPT-3在SuperGLUE上与微调基线和SOTA的性能比较"}]},{"ID":"20250915160843-iux64xr","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-iux64xr","updated":"20250915160843"},"Children":[{"ID":"20250915160843-4ptvnca","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-4ptvnca","updated":"20250915160843"},"Children":[{"ID":"20250915160843-1f5y09h","Type":"NodeParagraph","Properties":{"id":"20250915160843-1f5y09h","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" 所有结果都在测试集上报告。GPT-3少样本被给予每个任务的上下文中总共32个示例，并且不执行梯度更新。"}]}]}]},{"ID":"20250915160843-ux6zw3s","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915160843-ux6zw3s","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915160843-1gmku48","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-1gmku48","updated":"20250915160843"},"Children":[{"ID":"20250915160843-w2sjv20","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-w2sjv20","updated":"20250915160843"},"Children":[{"ID":"20250915160843-79rzkqw","Type":"NodeParagraph","Properties":{"id":"20250915160843-79rzkqw","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"这张表是GPT-3在综合性语言理解基准SuperGLUE上的“成绩单”。"}]}]},{"ID":"20250915160843-gkodmkb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-gkodmkb","updated":"20250915160843"},"Children":[{"ID":"20250915160843-rkjjii9","Type":"NodeParagraph","Properties":{"id":"20250915160843-rkjjii9","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总体表现：超越BERT-Large"},{"Type":"NodeText","Data":": 最重要的结论是，GPT-3的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本平均分（71.8）"},{"Type":"NodeText","Data":" 超越了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"经过专门微调的BERT-Large（69.0）"},{"Type":"NodeText","Data":"。这是一个里程碑式的结果，表明一个巨大的通用模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅凭上下文学习"},{"Type":"NodeText","Data":"，其综合语言能力就能超过一个为每个子任务都精细微调过的强大模型。"}]}]},{"ID":"20250915160843-9wy7499","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-9wy7499","updated":"20250915160843"},"Children":[{"ID":"20250915160843-xw9qu7m","Type":"NodeParagraph","Properties":{"id":"20250915160843-xw9qu7m","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体任务的亮点"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915160843-eciriwu","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-eciriwu","updated":"20250915160843"},"Children":[{"ID":"20250915160843-tzcxkip","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-tzcxkip","updated":"20250915160843"},"Children":[{"ID":"20250915160843-d7jw612","Type":"NodeParagraph","Properties":{"id":"20250915160843-d7jw612","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"COPA"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ReCoRD"},{"Type":"NodeText","Data":": 在这两项任务上，GPT-3的表现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极其接近甚至超过"},{"Type":"NodeText","Data":"了微调SOTA，展现了强大的因果推理和阅读理解能力。"}]}]},{"ID":"20250915160843-mpk6eiy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-mpk6eiy","updated":"20250915160843"},"Children":[{"ID":"20250915160843-2fjw0cu","Type":"NodeParagraph","Properties":{"id":"20250915160843-2fjw0cu","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MultiRC"},{"Type":"NodeText","Data":": F1分数（78.4）显著高于BERT-Large（70.0），表现不俗。"}]}]}]}]},{"ID":"20250915160843-jy23bc6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-jy23bc6","updated":"20250915160843"},"Children":[{"ID":"20250915160843-hmjan7q","Type":"NodeParagraph","Properties":{"id":"20250915160843-hmjan7q","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体任务的弱点"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915160843-pbk6qb9","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-pbk6qb9","updated":"20250915160843"},"Children":[{"ID":"20250915160843-ep060cw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-ep060cw","updated":"20250915160843"},"Children":[{"ID":"20250915160843-5ntrt49","Type":"NodeParagraph","Properties":{"id":"20250915160843-5ntrt49","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WSC"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WiC"},{"Type":"NodeText","Data":": 在这两项需要精确理解词义和指代关系的任务上，GPT-3表现不佳，尤其是WiC（49.4），几乎是随机猜测的水平。"}]}]},{"ID":"20250915160843-b748t7m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-b748t7m","updated":"20250915160843"},"Children":[{"ID":"20250915160843-y8zvgiv","Type":"NodeParagraph","Properties":{"id":"20250915160843-y8zvgiv","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CB"},{"Type":"NodeText","Data":": F1分数（52.0）远低于准确率（75.6），表明模型在处理不平衡类别时存在问题。"}]}]}]}]}]}]},{"ID":"20250915161024-mgojknh","Type":"NodeParagraph","Properties":{"id":"20250915161024-mgojknh","updated":"20250915161024"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915161024-ivrqfd1.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915160843-say89g2","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915160843-say89g2","updated":"20250915160844"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915160843-qtln5qf","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160843-qtln5qf","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.8：SuperGLUE上的性能以及上下文学习的效果"}]},{"ID":"20250915160843-xcfxjbm","Type":"NodeParagraph","Properties":{"id":"20250915160843-xcfxjbm","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915160843-4tg9ym0","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-4tg9ym0","updated":"20250915160843"},"Children":[{"ID":"20250915160843-xssl495","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-xssl495","updated":"20250915160843"},"Children":[{"ID":"20250915160843-ph4qb86","Type":"NodeParagraph","Properties":{"id":"20250915160843-ph4qb86","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"左图标题:"},{"Type":"NodeText","Data":" SuperGLUE 性能 (SuperGLUE Performance)"}]}]},{"ID":"20250915160843-1cga6r0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-1cga6r0","updated":"20250915160843"},"Children":[{"ID":"20250915160843-sh8rw0w","Type":"NodeParagraph","Properties":{"id":"20250915160843-sh8rw0w","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"右图标题:"},{"Type":"NodeText","Data":" SuperGLUE 上的上下文学习 (In-Context Learning on SuperGLUE)"}]}]},{"ID":"20250915160843-gprmxgp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-gprmxgp","updated":"20250915160843"},"Children":[{"ID":"20250915160843-chdcsw3","Type":"NodeParagraph","Properties":{"id":"20250915160843-chdcsw3","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" SuperGLUE 分数"}]}]},{"ID":"20250915160843-8ckglim","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-8ckglim","updated":"20250915160843"},"Children":[{"ID":"20250915160843-eceypz3","Type":"NodeParagraph","Properties":{"id":"20250915160843-eceypz3","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"左图横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Billions)"}]}]},{"ID":"20250915160843-06xkz3b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-06xkz3b","updated":"20250915160843"},"Children":[{"ID":"20250915160843-qdefjl2","Type":"NodeParagraph","Properties":{"id":"20250915160843-qdefjl2","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"右图横坐标:"},{"Type":"NodeText","Data":" 上下文中的示例数量 (K)"}]}]},{"ID":"20250915160843-ldoud6d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-ldoud6d","updated":"20250915160843"},"Children":[{"ID":"20250915160843-atx0o6l","Type":"NodeParagraph","Properties":{"id":"20250915160843-atx0o6l","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 与之前图表类似，包含零/单/少样本、SOTA、人类、BERT等基线。"}]}]},{"ID":"20250915160843-jckdo3p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-jckdo3p","updated":"20250915160843"},"Children":[{"ID":"20250915160843-24mex91","Type":"NodeParagraph","Properties":{"id":"20250915160843-24mex91","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"K=32"},{"Type":"NodeText","Data":"意味着我们每个任务展示32个示例，在8个任务中总共256个示例。我们报告GPT-3在开发集上的值，因此它们与表3.8中的测试集结果不完全可比。BERT-Large多任务基线是在MultiNLI（392k示例）和SWAG（113k示例）上首先微调的，而BERT++是在总共630k微调示例的数据集上进一步微调的。我们发现，在每个上下文有8个示例的情况下，BERT-Large和BERT++之间的性能差异，大致相当于GPT-3在每个上下文有1个示例和8个示例之间的差异。"}]}]}]},{"ID":"20250915160843-1rye5bc","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915160843-1rye5bc","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915160843-63ykarc","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-63ykarc","updated":"20250915160843"},"Children":[{"ID":"20250915160843-9qcldfn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-9qcldfn","updated":"20250915160843"},"Children":[{"ID":"20250915160843-7h4m50i","Type":"NodeParagraph","Properties":{"id":"20250915160843-7h4m50i","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"这两张图从两个维度深入剖析了GPT-3在SuperGLUE上的表现。"}]}]},{"ID":"20250915160843-6hj1kz6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-6hj1kz6","updated":"20250915160843"},"Children":[{"ID":"20250915160843-phsvg9d","Type":"NodeParagraph","Properties":{"id":"20250915160843-phsvg9d","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"左图 (性能 vs. 规模)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915160843-rdsueto","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-rdsueto","updated":"20250915160843"},"Children":[{"ID":"20250915160843-qlvaay2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-qlvaay2","updated":"20250915160843"},"Children":[{"ID":"20250915160843-yuzbv9l","Type":"NodeParagraph","Properties":{"id":"20250915160843-yuzbv9l","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"再次验证了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“缩放法则”"},{"Type":"NodeText","Data":"。少样本性能（橙色曲线）随着模型规模的增加而稳定提升，并且与零/单样本的差距逐渐拉大。"}]}]},{"ID":"20250915160843-xzfz3tj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-xzfz3tj","updated":"20250915160843"},"Children":[{"ID":"20250915160843-ce0wbwg","Type":"NodeParagraph","Properties":{"id":"20250915160843-ce0wbwg","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"清晰地显示，175B的GPT-3在少样本设置下"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越了微调BERT-Large"},{"Type":"NodeText","Data":"，但与微调SOTA（BERT++）和人类水平仍有明显差距。"}]}]}]}]},{"ID":"20250915160843-kjltq8e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-kjltq8e","updated":"20250915160843"},"Children":[{"ID":"20250915160843-8a3d287","Type":"NodeParagraph","Properties":{"id":"20250915160843-8a3d287","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"右图 (性能 vs. 示例数)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915160843-vklzorh","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-vklzorh","updated":"20250915160843"},"Children":[{"ID":"20250915160843-3vqfbff","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-3vqfbff","updated":"20250915160843"},"Children":[{"ID":"20250915160843-utknxsz","Type":"NodeParagraph","Properties":{"id":"20250915160843-utknxsz","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"这是理解"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习效率"},{"Type":"NodeText","Data":"的关键。性能曲线在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最初几个示例（0到8个）时急剧上升"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915160843-3y4epfw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-3y4epfw","updated":"20250915160843"},"Children":[{"ID":"20250915160843-ou1zku1","Type":"NodeParagraph","Properties":{"id":"20250915160843-ou1zku1","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"收益递减"},{"Type":"NodeText","Data":": 当示例数量超过8个后，性能曲线变得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常平坦"},{"Type":"NodeText","Data":"，增加更多示例（从8到32）带来的提升微乎其微。"}]}]},{"ID":"20250915160843-73w7fgo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-73w7fgo","updated":"20250915160843"},"Children":[{"ID":"20250915160843-qttyxew","Type":"NodeParagraph","Properties":{"id":"20250915160843-qttyxew","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心启示"},{"Type":"NodeText","Data":": 这表明上下文学习的“甜点”在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“少”而非“多”"},{"Type":"NodeText","Data":"。模型只需要很少的几个例子就能抓住任务的模式，过多的例子并不能带来显著的额外收益。"}]}]}]}]}]}]},{"ID":"20250915160843-st2vlbx","Type":"NodeParagraph","Properties":{"id":"20250915160843-st2vlbx","updated":"20250915160844"},"Children":[{"Type":"NodeText","Data":"我们观察到GPT-3的性能存在巨大差异。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"COPA"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ReCoRD"},{"Type":"NodeText","Data":"上，GPT-3取得了接近SOTA的表现，仅次于一个经过微调的110亿参数模型（T5），在排行榜上名列第二。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WSC"},{"Type":"NodeText","Data":"上，性能仍然很强，在少样本设置下达到了80.1%（注意GPT-3使用了一个不同于第3.4节中原始Winograd数据集的格式），这与一个微调过的BERT-Large的表现大致相当。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BoolQ"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MultiRC"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RTE"},{"Type":"NodeText","Data":"上，我们在少样本设置下看到了75.6%的良好性能迹象。"}]},{"ID":"20250915160843-utd49v9","Type":"NodeParagraph","Properties":{"id":"20250915160843-utd49v9","updated":"20250915160844"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WiC"},{"Type":"NodeText","Data":"是一个值得注意的弱点，少样本性能仅有49.4%（随机猜测水平）。我们尝试了多种不同的措辞和格式（例如，一个词在两个句子中使用是否意思相同），但都未能取得强劲的性能。这暗示了一种现象，这在下一节（讨论ANLI基准）中会变得更加明显——GPT-3在涉及比较两个句子或片段的任务中似乎很弱，例如一个词在一个句子中使用是否意味着另一个句子中的某个词。这也可能解释了RTE的相对较低的分数，以及WiC也遵循这种格式。尽管有这些弱点，GPT-3仍然在八个任务中的四个任务上超过了微调的BERT-Large，并且在两个任务上接近SOTA，仅次于一个110亿参数的模型。"}]},{"ID":"20250915160843-24i5htc","Type":"NodeParagraph","Properties":{"id":"20250915160843-24i5htc","updated":"20250915160844"},"Children":[{"Type":"NodeText","Data":"最后，我们注意到，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本SuperGLUE分数随着模型规模和上下文示例数量的增加而稳定提高"},{"Type":"NodeText","Data":"，显示出从上下文学习中获得的明显收益（图3.8）。我们每个任务最多使用32个示例，因为更多的示例不一定能放进我们的上下文中。在扫描不同的"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"K"},{"Type":"NodeText","Data":"值时，我们发现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3只需要每个任务不到8个示例就能在SuperGLUE总分上超过一个微调过的BERT-Large"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915160843-skd5e9x","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915160843-skd5e9x","updated":"20250915160844"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915160843-zdvnajm","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915160843-zdvnajm","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915160843-hig674k","Type":"NodeParagraph","Properties":{"id":"20250915160843-hig674k","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"这段文字是对SuperGLUE结果的深入解读，指出了具体的优劣势和关键发现。"}]},{"ID":"20250915160843-7zefm12","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160843-7zefm12","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优势领域"}]},{"ID":"20250915160843-dtxm92x","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-dtxm92x","updated":"20250915160843"},"Children":[{"ID":"20250915160843-8buj60a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-8buj60a","updated":"20250915160843"},"Children":[{"ID":"20250915160843-nl1855z","Type":"NodeParagraph","Properties":{"id":"20250915160843-nl1855z","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"COPA（因果推理）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ReCoRD（阅读理解）"},{"Type":"NodeText","Data":"上，GPT-3表现极为出色，证明了其在这些复杂推理任务上的强大潜力。"}]}]}]},{"ID":"20250915160843-x92vldq","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160843-x92vldq","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"明确的弱点：句子对比较"}]},{"ID":"20250915160843-2u9ywwp","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-2u9ywwp","updated":"20250915160843"},"Children":[{"ID":"20250915160843-d57ghzs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-d57ghzs","updated":"20250915160843"},"Children":[{"ID":"20250915160843-wky3br1","Type":"NodeParagraph","Properties":{"id":"20250915160843-wky3br1","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"作者精准地定位了GPT-3的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心弱点"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"判断两个句子之间关系的任务"},{"Type":"NodeText","Data":"。这在WiC（判断词在两个句子中意思是否相同）上表现得淋漓尽致，成绩接近随机猜测。这也解释了RTE（文本蕴含）表现不佳的原因。这表明，模型可能擅长“续写”或基于单个上下文进行推理，但在需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐和比较"},{"Type":"NodeText","Data":"两个独立文本片段的语义时存在困难。"}]}]}]},{"ID":"20250915160843-v3yed6r","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915160843-v3yed6r","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"里程碑式的结论"}]},{"ID":"20250915160843-yew7m4x","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-yew7m4x","updated":"20250915160843"},"Children":[{"ID":"20250915160843-zzrqjxq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-zzrqjxq","updated":"20250915160843"},"Children":[{"ID":"20250915160843-wfly6bz","Type":"NodeParagraph","Properties":{"id":"20250915160843-wfly6bz","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"本节最重要的结论是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅需提供8个上下文示例"},{"Type":"NodeText","Data":"，175B的GPT-3在SuperGLUE这个综合基准上的表现就能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越一个经过630k个示例精细微调的BERT-Large模型"},{"Type":"NodeText","Data":"。这极大地凸显了上下文学习在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据效率"},{"Type":"NodeText","Data":"上的巨大优势，是支持大模型+少样本学习范式的强有力证据。"}]}]}]}]},{"ID":"20250915160843-hshogy7","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915160843-hshogy7","updated":"20250915160844"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915160843-ixmbfha","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915160843-ixmbfha","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250915160843-i4m4n1f","Type":"NodeParagraph","Properties":{"id":"20250915160843-i4m4n1f","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"本次分析的3.6（阅读理解）和3.7（SuperGLUE）两节，从不同侧面共同构建了对GPT-3上下文学习能力全面而深刻的理解，特别是将其与传统的微调范式进行了对比。"}]},{"ID":"20250915160843-8mizncy","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915160843-8mizncy","updated":"20250915160843"},"Children":[{"ID":"20250915160843-453idah","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915160843-453idah","updated":"20250915160843"},"Children":[{"ID":"20250915160843-pm9zh5k","Type":"NodeParagraph","Properties":{"id":"20250915160843-pm9zh5k","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“专才” vs. “通才”的对决"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915160843-zjyx2a5","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-zjyx2a5","updated":"20250915160843"},"Children":[{"ID":"20250915160843-9832jgx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-9832jgx","updated":"20250915160843"},"Children":[{"ID":"20250915160843-gxu1jcl","Type":"NodeParagraph","Properties":{"id":"20250915160843-gxu1jcl","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"阅读理解（3.6节）"},{"Type":"NodeText","Data":"的测试更像是一场“专科考试”。在这些有大量训练数据、需要深度领域内推理的任务上，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"经过微调的“专才”模型（如SOTA）依然占据绝对优势"},{"Type":"NodeText","Data":"。GPT-3作为“通才”，表现出了明显的差距，尤其是在需要其不擅长的技能（如数学）时。"}]}]},{"ID":"20250915160843-7xppopx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-7xppopx","updated":"20250915160843"},"Children":[{"ID":"20250915160843-kgm185h","Type":"NodeParagraph","Properties":{"id":"20250915160843-kgm185h","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SuperGLUE（3.7节）"},{"Type":"NodeText","Data":"则更像是一场“高考”，考察的是综合语言能力。在这场考试中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3这个“通才”凭借其广博的知识和强大的上下文学习能力，成功击败了为每门“科目”都单独“补习”（微调）过的“偏科生”BERT-Large"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915160843-2yucct8","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915160843-2yucct8","updated":"20250915160843"},"Children":[{"ID":"20250915160843-axi6uy0","Type":"NodeParagraph","Properties":{"id":"20250915160843-axi6uy0","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的效率与机制"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915160843-vszd0ny","Type":"NodeList","ListData":{},"Properties":{"id":"20250915160843-vszd0ny","updated":"20250915160843"},"Children":[{"ID":"20250915160843-s2pqy59","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915160843-s2pqy59","updated":"20250915160843"},"Children":[{"ID":"20250915160843-zfirdaf","Type":"NodeParagraph","Properties":{"id":"20250915160843-zfirdaf","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"图3.8右侧的图表是本部分最有价值的洞见之一。它揭示了上下文学习并非“多多益善”，而是存在一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“甜点区”"},{"Type":"NodeText","Data":"。模型在看到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最初的几个示例时学习效率最高"},{"Type":"NodeText","Data":"，之后便迅速进入平台期。这为如何高效地使用大模型（即Prompt Engineering）提供了关键指导："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精炼、有效的少数示例远胜于冗长、大量的示例"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915160843-li9pjcp","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915160843-li9pjcp","updated":"20250915160843"},"Children":[{"ID":"20250915160843-w5sm2bz","Type":"NodeParagraph","Properties":{"id":"20250915160843-w5sm2bz","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精准定位能力边界"},{"Type":"NodeText","Data":": 通过对SuperGLUE子任务的细致分析，论文精准地识别出GPT-3的一个核心短板——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对句子对进行比较和关系判断的能力较弱（如WiC, RTE）"},{"Type":"NodeText","Data":"。这与它在单上下文任务（如补全、因果推理）上的强大表现形成鲜明对比，为后续的模型架构和预训练任务设计指明了改进方向。"}]}]},{"ID":"20250915160843-do8793y","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250915160843-do8793y","updated":"20250915160843"},"Children":[{"ID":"20250915160843-suzs4gn","Type":"NodeParagraph","Properties":{"id":"20250915160843-suzs4gn","updated":"20250915160843"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"范式转变的里程碑"},{"Type":"NodeText","Data":": “"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"8个例子超越微调BERT-Large"},{"Type":"NodeText","Data":"”是本部分乃至整篇论文中最具冲击力的结论之一。它用数据雄辩地证明，当模型规模达到一定程度，一种全新的、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据效率极高"},{"Type":"NodeText","Data":"的范式（上下文学习）是可行的，并且其综合能力可以超越曾经的霸主（BERT系列）。"}]}]}]},{"ID":"20250915160843-bv3z4n6","Type":"NodeParagraph","Properties":{"id":"20250915160843-bv3z4n6","updated":"20250915160843"},"Children":[{"Type":"NodeText","Data":"总结而言，这两节内容从一个“GPT-3不擅长什么”（复杂的阅读理解）和一个“GPT-3擅长什么”（通用的语言能力基准）的角度，深刻地阐述了上下文学习的优势、局限和内在机制，为大语言模型时代的到来提供了坚实的实验基础和理论洞见。"}]}]},{"ID":"20250915162447-i8p280r","Type":"NodeParagraph","Properties":{"id":"20250915162447-i8p280r","updated":"20250915162447"},"Children":[{"Type":"NodeText","Data":"好的，我们来对这部分关于GPT-3在自然语言推理（NLI）任务上的表现进行详细的翻译和解析。"}]},{"ID":"20250915162447-fmmxd11","Type":"NodeThematicBreak","Properties":{"id":"20250915162447-fmmxd11","updated":"20250915162447"}},{"ID":"20250915162447-pwuehmy","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915162447-pwuehmy","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.8 自然语言推理 (NLI)"}]},{"ID":"20250915162447-geewihk","Type":"NodeParagraph","Properties":{"id":"20250915162447-geewihk","updated":"20250915162448"},"Children":[{"Type":"NodeText","Data":"自然语言推理（NLI）[Fyo00] 关注的是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理解两个句子之间关系"},{"Type":"NodeText","Data":"的能力。在实践中，这项任务通常被构建为一个两类或三类的分类问题，模型需要对第二个句子是否在逻辑上由第一个句子引出（蕴含）、与第一个句子相矛盾（矛盾），或者可能是真实的（中性）进行分类。"}]},{"ID":"20250915162626-mhr9rb4","Type":"NodeParagraph","Properties":{"id":"20250915162626-mhr9rb4","updated":"20250915162626"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915162626-izj49dv.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915162447-1jd01w1","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915162447-1jd01w1","updated":"20250915162448"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915162447-06ej93i","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915162447-06ej93i","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.9：GPT-3在ANLI第3轮上的性能"}]},{"ID":"20250915162447-b8e7ydi","Type":"NodeParagraph","Properties":{"id":"20250915162447-b8e7ydi","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915162447-isi4v6i","Type":"NodeList","ListData":{},"Properties":{"id":"20250915162447-isi4v6i","updated":"20250915162447"},"Children":[{"ID":"20250915162447-1lszme0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-1lszme0","updated":"20250915162447"},"Children":[{"ID":"20250915162447-yan4vwa","Type":"NodeParagraph","Properties":{"id":"20250915162447-yan4vwa","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" ANLI 第3轮 (ANLI Round3)"}]}]},{"ID":"20250915162447-8heek9q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-8heek9q","updated":"20250915162447"},"Children":[{"ID":"20250915162447-6s4d15u","Type":"NodeParagraph","Properties":{"id":"20250915162447-6s4d15u","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915162447-dwpnguw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-dwpnguw","updated":"20250915162447"},"Children":[{"ID":"20250915162447-3y4qwvz","Type":"NodeParagraph","Properties":{"id":"20250915162447-3y4qwvz","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915162447-hj33v29","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-hj33v29","updated":"20250915162447"},"Children":[{"ID":"20250915162447-dp3xnoo","Type":"NodeParagraph","Properties":{"id":"20250915162447-dp3xnoo","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 零样本 (Zero-Shot), 单样本 (One-Shot), 少样本 (Few-Shot (K=50)), 随机猜测 (Random Guessing), 微调BERT-Large (Fine-tuned BERT-Large), 微调RoBERTa-Large (Fine-tuned RoBERTa-Large), 微调SOTA (Fine-tuned SOTA)"}]}]},{"ID":"20250915162447-yxytmor","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-yxytmor","updated":"20250915162447"},"Children":[{"ID":"20250915162447-vvp6bdv","Type":"NodeParagraph","Properties":{"id":"20250915162447-vvp6bdv","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 结果是在开发集上得出的，该开发集只有1500个样本，因此"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方差很高"},{"Type":"NodeText","Data":"（我们估计标准差为1.2%）。我们发现，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"较小的模型表现徘徊在随机猜测水平附近"},{"Type":"NodeText","Data":"，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本GPT-3 175B则将从随机猜测到SOTA的差距缩小了近一半"},{"Type":"NodeText","Data":"。ANLI第1轮和第2轮的结果显示在附录中。"}]}]}]},{"ID":"20250915162447-754to55","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915162447-754to55","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915162447-yozklbl","Type":"NodeList","ListData":{},"Properties":{"id":"20250915162447-yozklbl","updated":"20250915162447"},"Children":[{"ID":"20250915162447-r29uqez","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-r29uqez","updated":"20250915162447"},"Children":[{"ID":"20250915162447-7pg6k4w","Type":"NodeParagraph","Properties":{"id":"20250915162447-7pg6k4w","updated":"20250915162447"},"Children":[{"Type":"NodeText","Data":"这张图是本节的核心，它展示了GPT-3在一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极具挑战性"},{"Type":"NodeText","Data":"的NLI数据集上的表现。"}]}]},{"ID":"20250915162447-28fzhu5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-28fzhu5","updated":"20250915162447"},"Children":[{"ID":"20250915162447-b0z1mjb","Type":"NodeParagraph","Properties":{"id":"20250915162447-b0z1mjb","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“涌现”能力的绝佳例证"},{"Type":"NodeText","Data":": 图中最引人注目的现象是橙色的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本曲线"},{"Type":"NodeText","Data":"。在模型规模小于130亿参数时，它的表现与随机猜测无异，甚至还不如零样本和单样本。然而，当模型规模达到1750亿时，其性能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"突然急剧飙升"},{"Type":"NodeText","Data":"，远远甩开了其他设置，并显著超越了随机猜测水平。这是一种典型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“涌现”（Emergence）"},{"Type":"NodeText","Data":"现象——即某种能力在模型规模达到某个临界点后才突然出现。"}]}]},{"ID":"20250915162447-ybu7kg6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-ybu7kg6","updated":"20250915162447"},"Children":[{"ID":"20250915162447-a920my9","Type":"NodeParagraph","Properties":{"id":"20250915162447-a920my9","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"NLI的极端困难性"},{"Type":"NodeText","Data":": 即使是175B的GPT-3，其准确率（约41%）也远低于经过微调的模型（BERT-Large约44%，SOTA约48%）。这表明，ANLI这个通过对抗性方式构建的数据集，对于当前的语言模型来说是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极大的挑战"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915162447-n4bglur","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-n4bglur","updated":"20250915162447"},"Children":[{"ID":"20250915162447-3b7nw1g","Type":"NodeParagraph","Properties":{"id":"20250915162447-3b7nw1g","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模是解锁能力的前提"},{"Type":"NodeText","Data":": 较小模型在此任务上的无力表现，与最大模型的突然崛起形成了鲜明对比，这强有力地证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对于某些复杂的推理任务，巨大的模型规模是取得有意义进展的必要前提"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915162447-0mzz5bj","Type":"NodeParagraph","Properties":{"id":"20250915162447-0mzz5bj","updated":"20250915162448"},"Children":[{"Type":"NodeText","Data":"SuperGLUE包含一个NLI数据集RTE，它评估任务的二元版本。在RTE上，只有最大版本的GPT-3在任何评估设置下都表现出比随机猜测（56%）有说服力的更好，但在少样本设置下，GPT-3的表现与单任务微调的BERT Large相似。我们还评估了最近引入的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性自然语言推理（ANLI）"},{"Type":"NodeText","Data":"数据集[NWD⁺19]。ANLI是一个困难的数据集，它引入了一系列通过对抗性方式挖掘的、分为三轮（R1, R2, 和R3）的自然语言推理问题。与RTE类似，我们所有小于GPT-3的模型在ANLI上都表现出几乎随机猜测的水平，即使在少样本设置下（约33%），而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3本身在第3轮上显示出生命的迹象"},{"Type":"NodeText","Data":"。ANLI R3的结果在图3.9中高亮显示，所有轮次的完整结果可以在附录H中找到。这些在RTE和ANLI上的结果表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"NLI对于语言模型来说仍然是一个非常困难的任务，而它们才刚刚开始显示出进步的迹象"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915162447-62zdyya","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915162447-62zdyya","updated":"20250915162448"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915162447-idqm7ch","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915162447-idqm7ch","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915162447-n5l610p","Type":"NodeParagraph","Properties":{"id":"20250915162447-n5l610p","updated":"20250915162447"},"Children":[{"Type":"NodeText","Data":"这段文字是对NLI任务评估的总结，它精准地指出了这是GPT-3乃至当时所有语言模型的一大“软肋”。"}]},{"ID":"20250915162447-8hrrkqh","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915162447-8hrrkqh","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心发现：NLI是模型的“阿喀琉斯之踵”"}]},{"ID":"20250915162447-js3rdfi","Type":"NodeList","ListData":{},"Properties":{"id":"20250915162447-js3rdfi","updated":"20250915162447"},"Children":[{"ID":"20250915162447-g5hmz2r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-g5hmz2r","updated":"20250915162447"},"Children":[{"ID":"20250915162447-smjx7op","Type":"NodeParagraph","Properties":{"id":"20250915162447-smjx7op","updated":"20250915162447"},"Children":[{"Type":"NodeText","Data":"在上一节SuperGLUE的分析中，我们就已经看到GPT-3在RTE（一个NLI任务）上表现不佳。本节通过引入更困难的ANLI数据集，进一步证实了这一点。"}]}]},{"ID":"20250915162447-q64mt3a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-q64mt3a","updated":"20250915162447"},"Children":[{"ID":"20250915162447-605rrx6","Type":"NodeParagraph","Properties":{"id":"20250915162447-605rrx6","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“句子对比较”的弱点再现"},{"Type":"NodeText","Data":": NLI任务的核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理解两个句子之间的逻辑关系"},{"Type":"NodeText","Data":"。这与之前在WiC任务上观察到的“句子对比较”弱点一脉相承。GPT-3似乎不擅长这种需要精确对齐和推理两个独立文本片段语义的任务。"}]}]}]},{"ID":"20250915162447-m8zl7sb","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915162447-m8zl7sb","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模带来的希望"}]},{"ID":"20250915162447-97t43mq","Type":"NodeList","ListData":{},"Properties":{"id":"20250915162447-97t43mq","updated":"20250915162447"},"Children":[{"ID":"20250915162447-7ppijb4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-7ppijb4","updated":"20250915162447"},"Children":[{"ID":"20250915162447-a1jntv4","Type":"NodeParagraph","Properties":{"id":"20250915162447-a1jntv4","updated":"20250915162447"},"Children":[{"Type":"NodeText","Data":"尽管总体表现不佳，但本节也带来了一丝曙光。"}]}]},{"ID":"20250915162447-r9kobdd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-r9kobdd","updated":"20250915162447"},"Children":[{"ID":"20250915162447-gkw229f","Type":"NodeParagraph","Properties":{"id":"20250915162447-gkw229f","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“生命的迹象”"},{"Type":"NodeText","Data":": 作者用了一个非常形象的词——“signs of life”。对于小模型来说，NLI是“不可能完成的任务”，它们的表现和瞎猜没区别。但175B的GPT-3，尤其是在少样本设置下，终于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"突破了随机猜测的瓶颈"},{"Type":"NodeText","Data":"，取得了一定的、有意义的进展。"}]}]},{"ID":"20250915162447-r5hh1ix","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915162447-r5hh1ix","updated":"20250915162447"},"Children":[{"ID":"20250915162447-b443f2h","Type":"NodeParagraph","Properties":{"id":"20250915162447-b443f2h","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"进步的开端"},{"Type":"NodeText","Data":": 结论是审慎而现实的——NLI对语言模型来说"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极其困难"},{"Type":"NodeText","Data":"，而GPT-3的表现在这个难题面前只是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“刚刚开始显示出进步的迹象”"},{"Type":"NodeText","Data":"。它并未解决NLI，但它证明了通过继续扩大规模，未来或许有可能攻克这个难题。"}]}]}]}]},{"ID":"20250915162447-0xppk60","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915162447-0xppk60","updated":"20250915162448"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915162447-g57ot0q","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915162447-g57ot0q","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250915162447-klxtdxh","Type":"NodeParagraph","Properties":{"id":"20250915162447-klxtdxh","updated":"20250915162447"},"Children":[{"Type":"NodeText","Data":"本节（3.8 NLI）虽然简短，但意义重大，因为它"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精准地探测并揭示了GPT-3能力的一个核心边界"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915162447-ztrppon","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915162447-ztrppon","updated":"20250915162447"},"Children":[{"ID":"20250915162447-tlcvtsa","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915162447-tlcvtsa","updated":"20250915162447"},"Children":[{"ID":"20250915162447-kcazd3k","Type":"NodeParagraph","Properties":{"id":"20250915162447-kcazd3k","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"识别核心短板"},{"Type":"NodeText","Data":": 与之前展示模型强大能力的章节不同，本节的核心作用是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“找茬”"},{"Type":"NodeText","Data":"。通过在极具挑战性的NLI任务（特别是ANLI）上的测试，论文清晰地证明了GPT-3在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"处理句子间复杂逻辑关系"},{"Type":"NodeText","Data":"方面的严重不足。这为我们理解大语言模型的“智能”提供了一个重要的反例——它并非在所有语言任务上都无所不能。"}]}]},{"ID":"20250915162447-czvwlx7","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915162447-czvwlx7","updated":"20250915162447"},"Children":[{"ID":"20250915162447-xdc53mh","Type":"NodeParagraph","Properties":{"id":"20250915162447-xdc53mh","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“涌现”能力的最佳范例"},{"Type":"NodeText","Data":": ANLI上的性能曲线（图3.9）是展示"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“能力涌现”"},{"Type":"NodeText","Data":"现象的教科书级案例。在模型规模达到某个巨大的临界点之前，NLI能力几乎为零；而一旦越过这个临界点，该能力便"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“从无到有”"},{"Type":"NodeText","Data":"地突然出现。这不仅支持了“缩放法则”，更揭示了其背后可能存在的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质变"},{"Type":"NodeText","Data":"过程，即量的积累最终导致了能力的根本性飞跃。"}]}]},{"ID":"20250915162447-g8h19jq","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915162447-g8h19jq","updated":"20250915162447"},"Children":[{"ID":"20250915162447-3g4eknv","Type":"NodeParagraph","Properties":{"id":"20250915162447-3g4eknv","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对“理解”的深刻反思"},{"Type":"NodeText","Data":": NLI任务直接拷问了模型是否真正“理解”语言。GPT-3在此任务上的挣扎，促使我们反思其“理解”的本质。它可能更多是基于海量数据训练出的、一种对语言模式和上下文的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"直觉式掌握"},{"Type":"NodeText","Data":"，而非人类所拥有的、基于符号和逻辑的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统性推理能力"},{"Type":"NodeText","Data":"。NLI恰恰是这种系统性推理能力的“试金石”。"}]}]},{"ID":"20250915162447-7uvezkn","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250915162447-7uvezkn","updated":"20250915162447"},"Children":[{"ID":"20250915162447-ugxayr3","Type":"NodeParagraph","Properties":{"id":"20250915162447-ugxayr3","updated":"20250915162447"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为未来研究指明方向"},{"Type":"NodeText","Data":": 通过坦诚地展示这一弱点，论文为后续的研究指明了清晰的方向。如何让大语言模型更好地处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"句子对关系"},{"Type":"NodeText","Data":"、掌握"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逻辑推理"},{"Type":"NodeText","Data":"，成为了GPT-3之后NLP领域的一个核心研究课题，并直接催生了后续如指令微调（Instruction Tuning）等技术的发展，这些技术在一定程度上改善了模型在这方面的能力。"}]}]}]},{"ID":"20250915162447-2r66536","Type":"NodeParagraph","Properties":{"id":"20250915162447-2r66536","updated":"20250915162447"},"Children":[{"Type":"NodeText","Data":"总结而言，本节通过聚焦于NLI这个“硬骨头”，不仅为GPT-3的能力版图画出了清晰的边界，更通过“能力涌现”的惊人现象，深刻地揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模"},{"Type":"NodeText","Data":"在解锁复杂认知能力中的关键作用，并为整个领域提出了一个亟待解决的核心挑战。"}]}]},{"ID":"20250915163745-id2w3e8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-id2w3e8","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.9 综合性与定性任务 (Synthetic and Qualitative Tasks)"}]},{"ID":"20250915163745-n9juqwh","Type":"NodeParagraph","Properties":{"id":"20250915163745-n9juqwh","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"一种探测GPT-3在少样本（或零样本、单样本）设置下能力范围的方法是，给它一些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"要求即时进行简单计算推理、识别训练中不大可能出现过的新颖模式，或者快速适应一个不寻常任务"},{"Type":"NodeText","Data":"的任务。我们设计了几项任务来测试这类能力。首先，我们测试GPT-3执行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算术"},{"Type":"NodeText","Data":"的能力。其次，我们创建了几个涉及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重排或打乱单词中字母"},{"Type":"NodeText","Data":"的任务，这些任务不大可能在训练中被精确地见过。第三，我们测试GPT-3"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以少样本方式解决SAT风格的类比问题"},{"Type":"NodeText","Data":"的能力。最后，我们测试GPT-3在几个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定性任务"},{"Type":"NodeText","Data":"上的表现，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在新句子中使用新词、纠正英语语法，以及生成新闻文章"},{"Type":"NodeText","Data":"。我们将发布这些综合性数据集，希望能激发对语言模型测试时行为的进一步研究。"}]},{"ID":"20250915163745-dsp5k2e","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-dsp5k2e","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-f7cvbct","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-f7cvbct","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-j1qq9jv","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-j1qq9jv","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"测试的意图：超越死记硬背"}]},{"ID":"20250915163745-eeo7wgf","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-eeo7wgf","updated":"20250915163745"},"Children":[{"ID":"20250915163745-83n2zey","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-83n2zey","updated":"20250915163745"},"Children":[{"ID":"20250915163745-5eeehuc","Type":"NodeParagraph","Properties":{"id":"20250915163745-5eeehuc","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"本节的目的是设计一些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型在训练时绝对不可能“见过”"},{"Type":"NodeText","Data":"的任务，以此来检验它是否具备了真正的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理、模式识别和快速适应"},{"Type":"NodeText","Data":"能力，而不仅仅是记忆和模仿。这些任务是衡量模型是否向通用智能迈进的“试金石”。"}]}]}]}]},{"ID":"20250915163745-7oc82nm","Type":"NodeParagraph","Properties":{"id":"20250915163745-7oc82nm","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.1 算术 (Arithmetic)"}]},{"ID":"20250915163745-okrehi0","Type":"NodeParagraph","Properties":{"id":"20250915163745-okrehi0","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了测试GPT-3在没有特定任务训练的情况下执行简单算术运算的能力，我们开发了一个包含10个测试的小型测试集，这些测试涉及用自然语言向GPT-3提出一个简单的算术问题："}]},{"ID":"20250915163745-pbtp5pv","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-pbtp5pv","updated":"20250915163748"},"Children":[{"ID":"20250915163745-f2ohf7o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-f2ohf7o","updated":"20250915163745"},"Children":[{"ID":"20250915163745-6yauzus","Type":"NodeParagraph","Properties":{"id":"20250915163745-6yauzus","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两位数加法 (2D+)"},{"Type":"NodeText","Data":" – 模型被要求将两个从[0, 100)均匀采样的整数相加，问题以提问形式给出，例如：“问：48加76是多少？答：124。”"}]}]},{"ID":"20250915163745-3r6xah6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-3r6xah6","updated":"20250915163745"},"Children":[{"ID":"20250915163745-3qfw0kv","Type":"NodeParagraph","Properties":{"id":"20250915163745-3qfw0kv","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两位数减法 (2D−)"},{"Type":"NodeText","Data":" – 模型被要求将两个从[0, 100)均匀采样的整数相减；答案可能是负数。例如：“问：34减53是多少？答：-19。”"}]}]},{"ID":"20250915163745-f6z7q78","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-f6z7q78","updated":"20250915163745"},"Children":[{"ID":"20250915163745-bb3mgnp","Type":"NodeParagraph","Properties":{"id":"20250915163745-bb3mgnp","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三位数加法 (3D+)"},{"Type":"NodeText","Data":" – 与两位数加法相同，只是数字是从[0, 1000)均匀采样的。"}]}]}]},{"ID":"20250915164103-clmj4b7","Type":"NodeParagraph","Properties":{"id":"20250915164103-clmj4b7","updated":"20250915164222"},"Children":[{"Type":"NodeText","Data":"​​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915164219-8j6hluv.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163745-p53a9ib","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-p53a9ib","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-faibwuh","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-faibwuh","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.10：算术任务（少样本）上的性能"}]},{"ID":"20250915163745-fp8ekjx","Type":"NodeParagraph","Properties":{"id":"20250915163745-fp8ekjx","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163745-txil0dr","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-txil0dr","updated":"20250915163745"},"Children":[{"ID":"20250915163745-h32nbf8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-h32nbf8","updated":"20250915163745"},"Children":[{"ID":"20250915163745-aw0zxbg","Type":"NodeParagraph","Properties":{"id":"20250915163745-aw0zxbg","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" 算术 (少样本) (Arithmetic (few-shot))"}]}]},{"ID":"20250915163745-2lyupp7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-2lyupp7","updated":"20250915163745"},"Children":[{"ID":"20250915163745-i7mb44w","Type":"NodeParagraph","Properties":{"id":"20250915163745-i7mb44w","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915163745-8uqhehd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-8uqhehd","updated":"20250915163745"},"Children":[{"ID":"20250915163745-t5j48ic","Type":"NodeParagraph","Properties":{"id":"20250915163745-t5j48ic","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915163745-jur0gbc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-jur0gbc","updated":"20250915163745"},"Children":[{"ID":"20250915163745-ahctpjd","Type":"NodeParagraph","Properties":{"id":"20250915163745-ahctpjd","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"}]},{"ID":"20250915163745-uax4okp","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-uax4okp","updated":"20250915163745"},"Children":[{"ID":"20250915163745-ad83chc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-ad83chc","updated":"20250915163745"},"Children":[{"ID":"20250915163745-nvse0ho","Type":"NodeParagraph","Properties":{"id":"20250915163745-nvse0ho","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"两位数加法 (Two Digit Addition)"}]}]},{"ID":"20250915163745-08xmz0b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-08xmz0b","updated":"20250915163745"},"Children":[{"ID":"20250915163745-owhnwdt","Type":"NodeParagraph","Properties":{"id":"20250915163745-owhnwdt","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"两位数减法 (Two Digit Subtraction)"}]}]},{"ID":"20250915163745-w021tvn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-w021tvn","updated":"20250915163745"},"Children":[{"ID":"20250915163745-6z6hy92","Type":"NodeParagraph","Properties":{"id":"20250915163745-6z6hy92","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"三位数加法 (Three Digit Addition)"}]}]},{"ID":"20250915163745-sczy7bx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-sczy7bx","updated":"20250915163745"},"Children":[{"ID":"20250915163745-usarudz","Type":"NodeParagraph","Properties":{"id":"20250915163745-usarudz","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"... (以此类推，最高到五位数加减法、两位数乘法、单位数三项运算)"}]}]}]}]},{"ID":"20250915163745-mq6air4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-mq6air4","updated":"20250915163745"},"Children":[{"ID":"20250915163745-slk45mk","Type":"NodeParagraph","Properties":{"id":"20250915163745-slk45mk","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 结果显示了在少样本设置下，不同规模模型在10个算术任务上的表现。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大的两个模型（GPT-3 13B和GPT-3 175B）之间存在一个显著的性能跳跃"},{"Type":"NodeText","Data":"，后者能够可靠地完成两位数算术，基本准确地完成三位数算术，并且在相当一部分时间里能正确回答四位数算术、两位数乘法和复合运算。零样本和单样本的结果见附录。"}]}]}]},{"ID":"20250915163745-3gniu9a","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-3gniu9a","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-goafje7","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-goafje7","updated":"20250915163745"},"Children":[{"ID":"20250915163745-7btaeku","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-7btaeku","updated":"20250915163745"},"Children":[{"ID":"20250915163745-6uyfwsa","Type":"NodeParagraph","Properties":{"id":"20250915163745-6uyfwsa","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"这张图是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“能力涌现”"},{"Type":"NodeText","Data":"现象的又一个惊人例证。"}]}]},{"ID":"20250915163745-y9fijcv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-y9fijcv","updated":"20250915163745"},"Children":[{"ID":"20250915163745-qt60cpp","Type":"NodeParagraph","Properties":{"id":"20250915163745-qt60cpp","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算术能力的突然爆发"},{"Type":"NodeText","Data":": 观察图中所有曲线，在模型规模达到13B之前，所有算术任务的准确率都"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常低，接近于0"},{"Type":"NodeText","Data":"。然而，当模型规模从13B跃升到175B时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能发生了爆炸式增长"},{"Type":"NodeText","Data":"。175B的模型在两位数加减法上几乎达到了100%的准确率，在三位数加减法上也表现优异。"}]}]},{"ID":"20250915163745-owdx6k2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-owdx6k2","updated":"20250915163745"},"Children":[{"ID":"20250915163745-w1hkp45","Type":"NodeParagraph","Properties":{"id":"20250915163745-w1hkp45","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力的边界"},{"Type":"NodeText","Data":": 尽管表现惊人，但模型的算术能力是有限的。随着数字位数的增加（四位数、五位数），准确率"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"急剧下降"},{"Type":"NodeText","Data":"。两位数乘法也只达到了约30%的准确率。这表明，模型可能不是在进行真正的数学计算，而是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用其庞大的参数规模和语言模式来“模拟”或“近似”计算过程"},{"Type":"NodeText","Data":"，这种方法在问题复杂度超过一定限度后就会失效。"}]}]}]}]},{"ID":"20250915163745-fgpf4mm","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-fgpf4mm","updated":"20250915163748"},"Children":[{"ID":"20250915163745-rwl891y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-rwl891y","updated":"20250915163745"},"Children":[{"ID":"20250915163745-ifmu70z","Type":"NodeParagraph","Properties":{"id":"20250915163745-ifmu70z","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三位数减法 (3D−)"},{"Type":"NodeText","Data":" – 与两位数减法相同，只是数字是从[0, 1000)均匀采样的。"}]}]},{"ID":"20250915163745-vlunpf6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-vlunpf6","updated":"20250915163745"},"Children":[{"ID":"20250915163745-sp3vqd8","Type":"NodeParagraph","Properties":{"id":"20250915163745-sp3vqd8","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四位数加法 (4D+)"},{"Type":"NodeText","Data":" – 与三位数加法相同，只是数字是从[0, 10000)均匀采样的。"}]}]},{"ID":"20250915163745-vei25ho","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-vei25ho","updated":"20250915163745"},"Children":[{"ID":"20250915163745-20nx83j","Type":"NodeParagraph","Properties":{"id":"20250915163745-20nx83j","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四位数减法 (4D−)"},{"Type":"NodeText","Data":" – 与三位数减法相同，只是数字是从[0, 10000)均匀采样的。"}]}]},{"ID":"20250915163745-5e5we75","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-5e5we75","updated":"20250915163745"},"Children":[{"ID":"20250915163745-s9dcb2n","Type":"NodeParagraph","Properties":{"id":"20250915163745-s9dcb2n","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"五位数加法 (5D+)"},{"Type":"NodeText","Data":" – 与三位数加法相同，只是数字是从[0, 100000)均匀采样的。"}]}]},{"ID":"20250915163745-i2qla7e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-i2qla7e","updated":"20250915163745"},"Children":[{"ID":"20250915163745-f3d6t7d","Type":"NodeParagraph","Properties":{"id":"20250915163745-f3d6t7d","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"五位数减法 (5D−)"},{"Type":"NodeText","Data":" – 与三位数减法相同，只是数字是从[0, 100000)均匀采样的。"}]}]},{"ID":"20250915163745-gim99ee","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-gim99ee","updated":"20250915163745"},"Children":[{"ID":"20250915163745-y433hlh","Type":"NodeParagraph","Properties":{"id":"20250915163745-y433hlh","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两位数乘法 (2Dx)"},{"Type":"NodeText","Data":" – 模型被要求将两个从[0, 100)均匀采样的整数相乘，例如：“问：24乘以42是多少？答：1008。”"}]}]},{"ID":"20250915163745-mbfoo58","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-mbfoo58","updated":"20250915163745"},"Children":[{"ID":"20250915163745-o08qj34","Type":"NodeParagraph","Properties":{"id":"20250915163745-o08qj34","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单位数复合运算 (1DC)"},{"Type":"NodeText","Data":" – 模型被要求对一个复合运算求值。问题是从最后两位数选择的三个单位数，以及从{+,−,∗}中选择的操作。例如：“问：6+(4*8)是多少？答：38。”"}]}]}]},{"ID":"20250915163745-5uzivop","Type":"NodeParagraph","Properties":{"id":"20250915163745-5uzivop","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"在所有10个任务中，模型必须生成完全正确的答案。对于每个任务，我们生成2000个随机实例的数据集，并对所有这些实例进行模型评估。"}]},{"ID":"20250915163745-qzse5wv","Type":"NodeParagraph","Properties":{"id":"20250915163745-qzse5wv","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"我们首先评估少样本设置下的GPT-3，结果显示在图3.10中。除了加减法，GPT-3在位数增加时表现出很强的熟练度，在两位数加法上达到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"100%"},{"Type":"NodeText","Data":"的准确率，在三位数减法上达到80.2%，在三位数加法上达到94.2%。随着位数增加，性能下降，但GPT-3在四位数运算中仍能达到25-56%的准确率，在五位数运算中达到9-10%的准确率，这表明它至少有能力将运算推广到更大的数字。GPT-3在两位数乘法上也取得了29.2%的准确率，这是一项计算上特别密集的运算。最后，GPT-3在单一数字组合运算中达到了21.3%的准确率（例如，9"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"*"}]},{"Type":"NodeText","Data":"(7+5)），表明它在超越单纯记忆之外具有一定的稳健性。"}]},{"ID":"20250915163745-qh0a487","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1,1,1,1,1],"Properties":{"colgroup":"||||||||||","id":"20250915163745-qh0a487","updated":"20250915163748"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2D+"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2D-"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3D+"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3D-"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4D+"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4D-"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5D+"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5D-"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2Dx"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1DC"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Zero-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"76.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"19.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"9.8"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 One-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"99.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"86.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"65.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"27.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"100.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"98.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"80.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"94.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"25.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"26.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"9.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"9.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"29.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"21.3"}]}]}]},{"ID":"20250915163745-07kc5ji","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-07kc5ji","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-eyp6yjb","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-eyp6yjb","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.9：GPT-3 175B在基础算术任务上的性能"}]},{"ID":"20250915163745-i0uedz2","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-i0uedz2","updated":"20250915163745"},"Children":[{"ID":"20250915163745-5y7gqqc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-5y7gqqc","updated":"20250915163745"},"Children":[{"ID":"20250915163745-zb3g0km","Type":"NodeParagraph","Properties":{"id":"20250915163745-zb3g0km","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" 2,3,4,5是加法或减法的位数。2Dx是两位数乘法。1DC是单位数复合运算。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结果从零样本到单样本再到少样本稳步变得更强"},{"Type":"NodeText","Data":"，但即使是零样本也显示出显著的算术能力。"}]}]}]},{"ID":"20250915163745-i8gv8g5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-i8gv8g5","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-l93rctn","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-l93rctn","updated":"20250915163745"},"Children":[{"ID":"20250915163745-1fip7vz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-1fip7vz","updated":"20250915163745"},"Children":[{"ID":"20250915163745-dq5e3l8","Type":"NodeParagraph","Properties":{"id":"20250915163745-dq5e3l8","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"这张表详细列出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大模型（175B）"},{"Type":"NodeText","Data":"在不同设置下的算术成绩。"}]}]},{"ID":"20250915163745-85gru0g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-85gru0g","updated":"20250915163745"},"Children":[{"ID":"20250915163745-5h09btc","Type":"NodeParagraph","Properties":{"id":"20250915163745-5h09btc","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的巨大作用"},{"Type":"NodeText","Data":": 观察每一列，从零样本到单样本再到少样本，准确率都有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"显著的、持续的提升"},{"Type":"NodeText","Data":"。这表明，虽然模型可能内在地具备一定的计算潜力，但通过提供示例（尤其是少样本），可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极大地帮助模型“激活”和“校准”这种能力"},{"Type":"NodeText","Data":"，让它明白任务的要求并给出正确格式的答案。"}]}]},{"ID":"20250915163745-r5vy4zw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-r5vy4zw","updated":"20250915163745"},"Children":[{"ID":"20250915163745-f8sql2m","Type":"NodeParagraph","Properties":{"id":"20250915163745-f8sql2m","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本能力的惊喜"},{"Type":"NodeText","Data":": 即使不给任何例子，175B模型在两位数加减法上也取得了相当高的准确率。这表明，算术能力在某种程度上已经"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内化"},{"Type":"NodeText","Data":"为模型的一种基础能力。"}]}]}]}]},{"ID":"20250915163745-t18rpnh","Type":"NodeParagraph","Properties":{"id":"20250915163745-t18rpnh","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"如图3.10所示，小模型在所有这些任务上都表现很差——即使是130亿参数模型（比175B的完整GPT-3小一个量级）也只能解决两位数加减法任务不到一半的时间，而其他运算的准确率不到10%。"}]},{"ID":"20250915163745-4e1tv1o","Type":"NodeParagraph","Properties":{"id":"20250915163745-4e1tv1o","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"尽管如此，单样本和零样本的性能相对于少样本性能有所下降，这表明适应任务（或至少是任务的非常精确的格式）对于正确执行这些计算是重要的。然而，单样本性能仍然相当强劲，甚至完整GPT-3的零样本性能也显著地胜过所有更小的模型。表3.9中显示了所有三个设置的结果，附录H中显示了所有三个设置的模型容量扩展情况。"}]},{"ID":"20250915163745-4oowcis","Type":"NodeParagraph","Properties":{"id":"20250915163745-4oowcis","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了检查模型是否仅仅是记忆了训练数据中特定的算术问题，我们搜索了3位数的加减法问题。在2000个两位数加法问题中，我们只找到了17个（0.8%）形式为“\u003c数字1\u003e + \u003c数字2\u003e =”或“\u003c数字1\u003e plus \u003c数字2\u003e”的匹配项。在2000个减法问题中，我们只找到了2个匹配项（0.1%），表明只有一小部分正确答案可以被记忆。另外，对错误答案的检查表明，模型经常犯诸如不进位之类的错误，这表明它确实在尝试执行相关的计算，而不仅仅是记忆一个表格。"}]},{"ID":"20250915163745-sq64q46","Type":"NodeParagraph","Properties":{"id":"20250915163745-sq64q46","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"总的来说，GPT-3在少样本、单样本甚至零样本设置下，都显示出在相当程度上能够熟练地、近似地执行复杂算术的能力。"}]},{"ID":"20250915163745-gcc5322","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-gcc5322","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-c567cxm","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-c567cxm","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-padxyto","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-padxyto","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对算术能力的深入分析"}]},{"ID":"20250915163745-gwmjf0w","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-gwmjf0w","updated":"20250915163745"},"Children":[{"ID":"20250915163745-zpewela","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-zpewela","updated":"20250915163745"},"Children":[{"ID":"20250915163745-56vaiml","Type":"NodeParagraph","Properties":{"id":"20250915163745-56vaiml","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排除记忆"},{"Type":"NodeText","Data":": 作者通过搜索训练数据，有力地证明了模型的算术能力"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并非来自死记硬背"},{"Type":"NodeText","Data":"。测试中的绝大多数算术题在训练集中都不存在。"}]}]},{"ID":"20250915163745-kbeui8e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-kbeui8e","updated":"20250915163745"},"Children":[{"ID":"20250915163745-jjyd20u","Type":"NodeParagraph","Properties":{"id":"20250915163745-jjyd20u","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“类人”的错误"},{"Type":"NodeText","Data":": 一个非常有趣的发现是，模型犯的错误类型（如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不进位"},{"Type":"NodeText","Data":"）与人类初学者非常相似。这进一步表明，模型是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"尝试学习和执行一个计算过程"},{"Type":"NodeText","Data":"，而不是简单地从一个巨大的查找表中检索答案。"}]}]},{"ID":"20250915163745-pzye83h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-pzye83h","updated":"20250915163745"},"Children":[{"ID":"20250915163745-ktc9dnr","Type":"NodeParagraph","Properties":{"id":"20250915163745-ktc9dnr","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结论"},{"Type":"NodeText","Data":": 尽管不完美，但GPT-3确实展现出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前所未有的、在语言模型中涌现出的计算能力"},{"Type":"NodeText","Data":"。这是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"近似的、基于模式匹配的计算"},{"Type":"NodeText","Data":"，是其通用智能的一部分。"}]}]}]}]},{"ID":"20250915163745-gf11seo","Type":"NodeParagraph","Properties":{"id":"20250915163745-gf11seo","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.2 单词乱序与操作 (Word Scrambling and Manipulation Tasks)"}]},{"ID":"20250915163745-eij6yeh","Type":"NodeParagraph","Properties":{"id":"20250915163745-eij6yeh","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了测试GPT-3从少量示例中学习简单符号操作任务的能力，我们设计了5个“字符操作”任务。每个任务都涉及通过添加、删除或置换字符的方式对一个单词进行扭曲，并要求模型恢复原始单词。这5个任务是："}]},{"ID":"20250915163745-7zom362","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-7zom362","updated":"20250915163748"},"Children":[{"ID":"20250915163745-3q5qkcr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-3q5qkcr","updated":"20250915163745"},"Children":[{"ID":"20250915163745-9zygmti","Type":"NodeParagraph","Properties":{"id":"20250915163745-9zygmti","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单词内字母循环移位 (CL)"},{"Type":"NodeText","Data":" – 给定一个单词，其字母被循环移位，并用“~=”符号表示，模型应生成原始单词。例如，它可能会看到“lyinevitab”并应输出“inevitably”。"}]}]},{"ID":"20250915163745-zy0o9az","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-zy0o9az","updated":"20250915163745"},"Children":[{"ID":"20250915163745-54runm4","Type":"NodeParagraph","Properties":{"id":"20250915163745-54runm4","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"首尾字母乱序 (A1)"},{"Type":"NodeText","Data":" – 给定一个单词，除了第一个和最后一个字母外，所有字母都被随机打乱，模型必须输出原始单词。例如：“critooprun” → “corruption”。"}]}]},{"ID":"20250915163745-vt1i39m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-vt1i39m","updated":"20250915163745"},"Children":[{"ID":"20250915163745-qca7mqj","Type":"NodeParagraph","Properties":{"id":"20250915163745-qca7mqj","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"首尾两个字母乱序 (A2)"},{"Type":"NodeText","Data":" – 给定一个单词，除了前两个和后两个字母外，所有字母都被随机打乱，模型必须输出原始单词。例如：“opoepnnt” → “opponent”。"}]}]},{"ID":"20250915163745-pup5sk9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-pup5sk9","updated":"20250915163745"},"Children":[{"ID":"20250915163745-hw1mlwn","Type":"NodeParagraph","Properties":{"id":"20250915163745-hw1mlwn","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单词内随机插入 (RI)"},{"Type":"NodeText","Data":" – 在单词的随机位置插入一个随机的标点符号或空格，模型必须输出原始单词。例如：“s.u'c/c'e.s s i/o/n” → “succession”。"}]}]},{"ID":"20250915163745-f9yw6tt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-f9yw6tt","updated":"20250915163745"},"Children":[{"ID":"20250915163745-ytyj0o9","Type":"NodeParagraph","Properties":{"id":"20250915163745-ytyj0o9","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单词倒序 (RW)"},{"Type":"NodeText","Data":" – 给定一个倒序的单词，模型必须输出原始单词。例如：“stcejbo” → “objects”。"}]}]}]},{"ID":"20250915163745-nxtz7p3","Type":"NodeTable","TableAligns":[1,1,1,1,1,1],"Properties":{"colgroup":"|||||","id":"20250915163745-nxtz7p3","updated":"20250915163748"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CL"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"A1"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"A2"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RI"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RW"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Zero-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.66"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.28"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.91"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.26"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.09"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 One-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"21.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.62"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"25.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"45.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.48"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"37.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"15.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"39.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"67.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"0.44"}]}]}]},{"ID":"20250915163745-wpda6c5","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-wpda6c5","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-xr2wofu","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-xr2wofu","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.10：GPT-3 175B在各种单词乱序和操作任务上的零、单、少样本性能"}]},{"ID":"20250915163745-6jitdfd","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-6jitdfd","updated":"20250915163745"},"Children":[{"ID":"20250915163745-jpfcgx0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-jpfcgx0","updated":"20250915163745"},"Children":[{"ID":"20250915163745-wmrkvin","Type":"NodeParagraph","Properties":{"id":"20250915163745-wmrkvin","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" CL是“单词内字母循环移位”。A1是除首尾字母外的乱序。A2是除首尾两个字母外的乱序。RI是“单词内随机插入”。RW是“单词倒序”。"}]}]}]},{"ID":"20250915163745-d81oyhx","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-d81oyhx","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-tl9unc0","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-tl9unc0","updated":"20250915163745"},"Children":[{"ID":"20250915163745-ykahjr6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-ykahjr6","updated":"20250915163745"},"Children":[{"ID":"20250915163745-4cao231","Type":"NodeParagraph","Properties":{"id":"20250915163745-4cao231","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"这张表展示了175B模型在各种符号操作任务上的表现。"}]}]},{"ID":"20250915163745-r6zzwo6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-r6zzwo6","updated":"20250915163745"},"Children":[{"ID":"20250915163745-u456b6n","Type":"NodeParagraph","Properties":{"id":"20250915163745-u456b6n","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的重要性"},{"Type":"NodeText","Data":": 在所有任务中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本的表现都远超单样本和零样本"},{"Type":"NodeText","Data":"。这表明，对于这些模型从未见过的、完全新颖的抽象规则，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过示例进行学习是至关重要的"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915163745-ijgnpyi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-ijgnpyi","updated":"20250915163745"},"Children":[{"ID":"20250915163745-l9kk7xt","Type":"NodeParagraph","Properties":{"id":"20250915163745-l9kk7xt","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务难度的差异"},{"Type":"NodeText","Data":": 模型在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RI（移除插入的干扰项）"},{"Type":"NodeText","Data":"任务上表现最好，少样本准确率达到67.2%。这可能因为它更接近于模型在预训练中见过的“去噪”任务。而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RW（单词倒序）"},{"Type":"NodeText","Data":"则表现最差，准确率极低，表明完全颠倒序列对模型来说是一个巨大的挑战。"}]}]},{"ID":"20250915163745-7kop7mn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-7kop7mn","updated":"20250915163745"},"Children":[{"ID":"20250915163745-evvg3ai","Type":"NodeParagraph","Properties":{"id":"20250915163745-evvg3ai","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本的无力"},{"Type":"NodeText","Data":": 在大多数任务上，零样本的表现都非常糟糕，这符合预期。因为没有例子，模型根本不知道这些奇怪的符号（如“~=”）和乱序的字母代表什么规则。"}]}]}]}]},{"ID":"20250915163745-m5ktz8f","Type":"NodeParagraph","Properties":{"id":"20250915163745-m5ktz8f","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"对于每个任务，我们生成了10,000个示例，选择的单词是根据[Nor09]测量的，长度在4到15个字符之间的前10,000个最常见的单词。少样本结果显示在图3.11中。任务性能随着模型规模平稳增长，完整的GPT-3模型在随机插入任务上达到了66.9%的准确率。"}]},{"ID":"20250915164323-j3dy5wh","Type":"NodeParagraph","Properties":{"id":"20250915164323-j3dy5wh","updated":"20250915164323"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915164323-r231gwn.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163745-p9equzx","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-p9equzx","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-n7kwet6","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-n7kwet6","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.11：单词乱序任务（少样本）上的性能"}]},{"ID":"20250915163745-auag7ul","Type":"NodeParagraph","Properties":{"id":"20250915163745-auag7ul","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163745-at0tzc5","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-at0tzc5","updated":"20250915163745"},"Children":[{"ID":"20250915163745-j9w4me1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-j9w4me1","updated":"20250915163745"},"Children":[{"ID":"20250915163745-t1w7nrl","Type":"NodeParagraph","Properties":{"id":"20250915163745-t1w7nrl","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" 单词乱序 (少样本) (Wordscramble (few-shot))"}]}]},{"ID":"20250915163745-815qyy5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-815qyy5","updated":"20250915163745"},"Children":[{"ID":"20250915163745-83hba2j","Type":"NodeParagraph","Properties":{"id":"20250915163745-83hba2j","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915163745-z3oaewr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-z3oaewr","updated":"20250915163745"},"Children":[{"ID":"20250915163745-wprfnnq","Type":"NodeParagraph","Properties":{"id":"20250915163745-wprfnnq","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915163745-y7tflmt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-y7tflmt","updated":"20250915163745"},"Children":[{"ID":"20250915163745-neadail","Type":"NodeParagraph","Properties":{"id":"20250915163745-neadail","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 循环移位 (cycle letters), 中间1个字母乱序 (mid word 1 anagrams), 中间2个字母乱序 (mid word 2 anagrams), 随机插入 (random insertion), 单词倒序 (reversed words)"}]}]},{"ID":"20250915163745-u2y90du","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-u2y90du","updated":"20250915163745"},"Children":[{"ID":"20250915163745-ozpdeyi","Type":"NodeParagraph","Properties":{"id":"20250915163745-ozpdeyi","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 五个单词乱序任务在不同规模模型上的少样本性能。尽管模型规模和参数量不成比例，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能随着模型规模的增加而平滑改善"},{"Type":"NodeText","Data":"。175B模型在接受任务时，所有任务都显示出向上的改进趋势。所有任务的"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"K"},{"Type":"NodeText","Data":"=100。附录中显示了单样本和零样本的缩放情况。"}]}]}]},{"ID":"20250915163745-6ngqod2","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-6ngqod2","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-9btdhk8","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-9btdhk8","updated":"20250915163745"},"Children":[{"ID":"20250915163745-hx0yqn3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-hx0yqn3","updated":"20250915163745"},"Children":[{"ID":"20250915163745-zr7loeq","Type":"NodeParagraph","Properties":{"id":"20250915163745-zr7loeq","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"这张图将表3.10中的少样本结果按模型规模进行了可视化。"}]}]},{"ID":"20250915163745-idlta6s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-idlta6s","updated":"20250915163745"},"Children":[{"ID":"20250915163745-spw7u72","Type":"NodeParagraph","Properties":{"id":"20250915163745-spw7u72","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰的缩放效应"},{"Type":"NodeText","Data":": 所有任务的性能都随着模型规模的增加而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳步提升"},{"Type":"NodeText","Data":"。这表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更大的模型更擅长理解和执行抽象的符号操作规则"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915163745-853is8r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-853is8r","updated":"20250915163745"},"Children":[{"ID":"20250915163745-bd37jap","Type":"NodeParagraph","Properties":{"id":"20250915163745-bd37jap","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务难度与学习曲线"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915163745-a8twbn8","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-a8twbn8","updated":"20250915163745"},"Children":[{"ID":"20250915163745-649xtps","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-649xtps","updated":"20250915163745"},"Children":[{"ID":"20250915163745-b71tm1x","Type":"NodeParagraph","Properties":{"id":"20250915163745-b71tm1x","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"最陡峭的曲线是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RI（随机插入，绿色）"},{"Type":"NodeText","Data":"，表明模型随着规模增长，学习这个任务的速度最快。"}]}]},{"ID":"20250915163745-282kcvc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-282kcvc","updated":"20250915163745"},"Children":[{"ID":"20250915163745-tkd2j6b","Type":"NodeParagraph","Properties":{"id":"20250915163745-tkd2j6b","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"最平坦的曲线是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RW（单词倒序，紫色）"},{"Type":"NodeText","Data":"，几乎贴近于0，说明即使是最大的模型也"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"几乎没有学会"},{"Type":"NodeText","Data":"这个任务。"}]}]},{"ID":"20250915163745-r6v1q1u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-r6v1q1u","updated":"20250915163745"},"Children":[{"ID":"20250915163745-9vful97","Type":"NodeParagraph","Properties":{"id":"20250915163745-9vful97","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"其他任务介于两者之间，展示了不同程度的学习能力。"}]}]}]}]}]}]},{"ID":"20250915163745-vzsrwxb","Type":"NodeParagraph","Properties":{"id":"20250915163745-vzsrwxb","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"随机插入任务为38.6%，循环移位为40.2%，较简单的乱序任务为15.1%（其中只有第一个和最后一个字母是固定的）。在更难的乱序任务中，没有一个模型能复原单词。"}]},{"ID":"20250915163745-3tpawe3","Type":"NodeParagraph","Properties":{"id":"20250915163745-3tpawe3","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"在单样本设置下，性能明显较弱（下降一半或更多），而在零样本设置下，模型几乎无法执行任何这些任务（表3.10）。这表明模型似乎确实是在测试时学习这些任务，因为这些任务及其人工性质使得它们不太可能出现在预训练数据中（尽管我们无法确定地证实这一点）。"}]},{"ID":"20250915163745-d4cnav0","Type":"NodeParagraph","Properties":{"id":"20250915163745-d4cnav0","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"我们可以通过绘制“上下文学习曲线”来进一步量化性能，这些曲线显示任务性能是上下文示例数量的函数。我们在符号插入任务的图1.2中展示了学习曲线，需要几个例子才能让更大的模型有效地利用上下文信息，包括示例和自然语言任务描述。"}]},{"ID":"20250915163745-m18qpdt","Type":"NodeParagraph","Properties":{"id":"20250915163745-m18qpdt","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"最后，值得注意的是，解决这些任务需要字符级的操作，而我们的BPE编码在每个词元上只操作一小部分单词（平均约0.7个词元），因此需要模型不仅仅是操作BPE词元，还要深入其子结构，将单词分开再重新组合。此外，与SAT类比不同，乱序词任务不是确定性的，需要模型执行某种形式的搜索来找到与部分词元匹配和计算相对应的正确乱序。因此，这些技能涉及到相当程度的非平凡模式匹配和计算。"}]},{"ID":"20250915163745-vy52qms","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-vy52qms","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-twqhqrj","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-twqhqrj","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-k6wdgp8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-k6wdgp8","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对符号操作能力的深入分析"}]},{"ID":"20250915163745-hyo7uiw","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-hyo7uiw","updated":"20250915163745"},"Children":[{"ID":"20250915163745-93xl59v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-93xl59v","updated":"20250915163745"},"Children":[{"ID":"20250915163745-brg3729","Type":"NodeParagraph","Properties":{"id":"20250915163745-brg3729","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"真正的即时学习"},{"Type":"NodeText","Data":": 模型在这些任务上的表现，特别是零样本的无力与少样本的相对成功，有力地证明了它是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"测试时实时学习这些新规则"},{"Type":"NodeText","Data":"，而不是依赖预训练的记忆。"}]}]},{"ID":"20250915163745-c260wla","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-c260wla","updated":"20250915163745"},"Children":[{"ID":"20250915163745-sx2pec4","Type":"NodeParagraph","Properties":{"id":"20250915163745-sx2pec4","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越BPE词元的限制"},{"Type":"NodeText","Data":": 作者指出了一个非常关键的技术细节。GPT-3的输入单元是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BPE词元（token）"},{"Type":"NodeText","Data":"，而不是单个字符。要完成这些任务，模型必须学会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“看穿”词元，深入到字符层面进行操作"},{"Type":"NodeText","Data":"，然后再将结果组合成新的词元。这是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常复杂的、跨层级的操作能力"},{"Type":"NodeText","Data":"，其涌现本身就是一项了不起的成就。"}]}]},{"ID":"20250915163745-qfrmj5w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-qfrmj5w","updated":"20250915163745"},"Children":[{"ID":"20250915163745-x8mzuxm","Type":"NodeParagraph","Properties":{"id":"20250915163745-x8mzuxm","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非确定性搜索"},{"Type":"NodeText","Data":": 乱序重组任务不像算术题那样有唯一的计算路径。模型需要进行某种形式的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“搜索”"},{"Type":"NodeText","Data":"，找到最可能的原始单词。这表明模型具备了一定的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"启发式搜索和组合推理"},{"Type":"NodeText","Data":"能力。"}]}]}]}]},{"ID":"20250915163745-gtd6n8z","Type":"NodeParagraph","Properties":{"id":"20250915163745-gtd6n8z","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.3 SAT类比 (SAT Analogies)"}]},{"ID":"20250915163745-qur0vo2","Type":"NodeParagraph","Properties":{"id":"20250915163745-qur0vo2","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了测试GPT-3在另一项与典型分布有些不寻常的任务上的表现，我们收集了374个SAT类比问题的集合，这些问题构成了SAT大学入学考试的一部分，直到2005年[TLBS03]。类比是多项选择题，要求学生识别一对词语之间的关系，并从五个选项中找到与原始词对关系相同的一对。例如，“Audacious is to boldness as…”（大胆之于无畏，犹如…）的答案是“sanctimonious is to hypocrisy”（伪善之于虚伪）。学生被期望选择五个词对中与原始词对具有相同关系的词对。在这个任务上，GPT-3在少样本设置下达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"65.2%"},{"Type":"NodeText","Data":"的准确率，在单样本设置下为59.1%，在零样本设置下为53.7%，而普通大学申请者的平均分约为57% [TLBS03]（随机猜测为20%）。如图3.12所示，结果随着模型规模的改善而提高，拥有1750亿参数的完整模型比130亿参数模型提高了超过10%。"}]},{"ID":"20250915164410-wqhqzya","Type":"NodeParagraph","Properties":{"id":"20250915164410-wqhqzya","updated":"20250915164410"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915164410-sjr2ec9.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163745-irvsosz","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-irvsosz","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-12djxqt","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-12djxqt","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.12：SAT类比任务上的性能"}]},{"ID":"20250915163745-1f0g6ru","Type":"NodeParagraph","Properties":{"id":"20250915163745-1f0g6ru","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163745-guudz6z","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-guudz6z","updated":"20250915163745"},"Children":[{"ID":"20250915163745-la0ocav","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-la0ocav","updated":"20250915163745"},"Children":[{"ID":"20250915163745-7g8nste","Type":"NodeParagraph","Properties":{"id":"20250915163745-7g8nste","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" SAT 类比 (SAT Analogies)"}]}]},{"ID":"20250915163745-w2hajyq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-w2hajyq","updated":"20250915163745"},"Children":[{"ID":"20250915163745-w71cd1l","Type":"NodeParagraph","Properties":{"id":"20250915163745-w71cd1l","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915163745-0pjrqoa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-0pjrqoa","updated":"20250915163745"},"Children":[{"ID":"20250915163745-wiy2841","Type":"NodeParagraph","Properties":{"id":"20250915163745-wiy2841","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915163745-rrg5suk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-rrg5suk","updated":"20250915163745"},"Children":[{"ID":"20250915163745-8cfzol7","Type":"NodeParagraph","Properties":{"id":"20250915163745-8cfzol7","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 零样本 (Zero-Shot), 单样本 (One-Shot), 少样本 (Few-Shot (K=20)), 随机猜测 (Random Guessing)"}]}]},{"ID":"20250915163745-gqx3u5c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-gqx3u5c","updated":"20250915163745"},"Children":[{"ID":"20250915163745-6j3uxh0","Type":"NodeParagraph","Properties":{"id":"20250915163745-6j3uxh0","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 不同规模模型在SAT类比任务上的零、单、少样本性能。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大模型在少样本设置下达到了65%的准确率"},{"Type":"NodeText","Data":"，并且也展示了在较小模型中不存在的显著的上下文学习增益。"}]}]}]},{"ID":"20250915163745-knxrvos","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-knxrvos","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-8qama8q","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-8qama8q","updated":"20250915163745"},"Children":[{"ID":"20250915163745-fkh2igd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-fkh2igd","updated":"20250915163745"},"Children":[{"ID":"20250915163745-zpil3nb","Type":"NodeParagraph","Properties":{"id":"20250915163745-zpil3nb","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越人类平均水平"},{"Type":"NodeText","Data":": 这是本节的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标志性成果"},{"Type":"NodeText","Data":"。在少样本设置下，GPT-3的准确率（65.2%）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超过了当年参加SAT考试的大学申请者的平均水平（57%）"},{"Type":"NodeText","Data":"。这表明模型已经能够理解和推理词语之间复杂的抽象关系（如“部分与整体”、“原因与结果”、“程度深浅”等）。"}]}]},{"ID":"20250915163745-9fqeixq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-9fqeixq","updated":"20250915163745"},"Children":[{"ID":"20250915163745-rncyczq","Type":"NodeParagraph","Properties":{"id":"20250915163745-rncyczq","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的重要性"},{"Type":"NodeText","Data":": 观察图中的曲线间距，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习带来的提升非常显著"},{"Type":"NodeText","Data":"。尤其是在模型规模变大后，少样本（橙色）与零样本（蓝色）的差距明显拉开，再次证明大模型能更有效地利用示例来理解抽象任务。"}]}]}]}]},{"ID":"20250915163745-251e0e4","Type":"NodeParagraph","Properties":{"id":"20250915163745-251e0e4","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.4 新闻文章生成 (News Article Generation)"}]},{"ID":"20250915163745-yw6ny3q","Type":"NodeParagraph","Properties":{"id":"20250915163745-yw6ny3q","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"以前的通用语言模型已经测试过它们生成“新闻文章”的能力，其条件是给定一个人类写的、似乎来自新闻文章的合理的第一句话[RWC⁺19]。相对于[RWC⁺19]，用于训练GPT-3的数据集中，新闻文章的权重小得多，所以试图用原始、无条件样本生成新闻文章的效果较差——例如，GPT-3经常将建议的新闻文章的第一句话解释为推文，然后发布合成的回复或后续推文。为了解决这个问题，我们利用GPT-3的少样本学习能力，通过提供三个之前的示例新闻文章，然后是所需文章的标题和副标题，来提示模型。"}]},{"ID":"20250915163745-4vd3fnp","Type":"NodeParagraph","Properties":{"id":"20250915163745-4vd3fnp","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了衡量GPT-3生成的新闻文章的质量（我们认为这与一般情况下样本的条件生成质量相关），我们决定衡量"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类区分GPT-3生成的文章和人类写的文章的能力"},{"Type":"NodeText","Data":"。类似的工作已经由Kreps等人[KMB20]和Zellers等人[ZHR⁺19]进行过。生成式语言模型被训练来匹配人类生成的文本分布，因此它们生成的人类难以区分的样本，可能是模型质量的一个重要衡量标准。"}]},{"ID":"20250915163745-r7kgxi3","Type":"NodeParagraph","Properties":{"id":"20250915163745-r7kgxi3","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了研究人类辨别能力有多好，我们从网站"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"http://newser.com","TextMarkTextContent":"newser.com"},{"Type":"NodeText","Data":"上任意选择了25个文章标题和副标题（平均长度：215词）。我们生成了这些标题和副标题的补全，所有模型从125M到175B（GPT-3）的参数（平均长度：200词）。对于每个模型，我们向大约80名美国参与者展示了一个测试，其中包括这些真实标题和副标题的10个补全，其中一半由人类撰写，一半由模型生成。参与者被问及他们认为每篇文章是“很可能由人类写的”、“可能由人类写的”、“可能由机器写的”，还是“很可能由机器写的”。"}]},{"ID":"20250915163745-2hko99n","Type":"NodeParagraph","Properties":{"id":"20250915163745-2hko99n","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"我们选择的文章没有在模型的训练集中出现，避免了樱桃采摘。所有模型都使用相同的上下文和相同的文章标题和副标题，并且输出是使用相同的提示生成的，以确保所有模型之间的条件输出具有可比性。我们还进行了一个实验，控制了参与者的努力程度和注意力，结果表明我们收集到的判断是有意图的，而不是随机的模型生成的响应。我们通过生成一个“控制模型”来进行这项实验，该模型是一个160M参数的模型，没有上下文，输出随机性增加。"}]},{"ID":"20250915163745-ltmsk55","Type":"NodeTable","TableAligns":[1,1,1,1,1],"Properties":{"colgroup":"||||","id":"20250915163745-ltmsk55","updated":"20250915163748"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"模型"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"平均准确率"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"95%置信区间 (低, 高)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"与控制组比较的t值 (p值)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"“我不知道”的分配比例"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"控制组 (故意差的模型)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"86%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"83%-90%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.6%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Small"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"76%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"72%-80%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.9 (2e-4)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.9%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Medium"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"61%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58%-65%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.3 (7e-21)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.0%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Large"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"68%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64%-72%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.3 (3e-11)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5.7%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 XL"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"62%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"59%-65%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.7 (1e-19)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.5%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 6.7B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"60%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"56%-63%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.4 (5e-19)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.1%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 13B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"55%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"52%-58%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"15.3 (1e-32)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.2%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 175B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"52%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"49%-54%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"16.9 (1e-34)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.8%"}]}]}]},{"ID":"20250915163745-mmeq8bz","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-mmeq8bz","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-7hdzy5d","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-7hdzy5d","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.11：人类在识别是否为模型生成的短篇（~200词）新闻文章时的准确率"}]},{"ID":"20250915163745-0navdtn","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-0navdtn","updated":"20250915163745"},"Children":[{"ID":"20250915163745-wet2k1z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-wet2k1z","updated":"20250915163745"},"Children":[{"ID":"20250915163745-antlelo","Type":"NodeParagraph","Properties":{"id":"20250915163745-antlelo","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" 我们通过正确分配与非中性分配的比率来衡量人类准确率（从86%的控制组到52%的GPT-3 175B）。该表比较了不同模型之间的平均准确率，并显示了比较平均准确率与控制模型差异的双样本T检验结果。"}]}]}]},{"ID":"20250915163745-sh9fqhg","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-sh9fqhg","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-hu1lf3m","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-hu1lf3m","updated":"20250915163745"},"Children":[{"ID":"20250915163745-0f5km3r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-0f5km3r","updated":"20250915163745"},"Children":[{"ID":"20250915163745-92vgefs","Type":"NodeParagraph","Properties":{"id":"20250915163745-92vgefs","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"这张表的结果是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命性且令人警醒的"},{"Type":"NodeText","Data":"。它衡量的是人类分辨机器生成文本的能力，准确率"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"越低"},{"Type":"NodeText","Data":"，说明模型生成的文本"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量越高、越逼真"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915163745-66f8ouc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-66f8ouc","updated":"20250915163745"},"Children":[{"ID":"20250915163745-fo6581m","Type":"NodeParagraph","Properties":{"id":"20250915163745-fo6581m","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"接近图灵测试"},{"Type":"NodeText","Data":": 对于175B模型生成的短新闻，人类的辨别准确率只有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"52%"},{"Type":"NodeText","Data":"。考虑到随机猜测的准确率是50%，这意味着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类几乎无法区分GPT-3生成的文本和真实的新闻"},{"Type":"NodeText","Data":"。这在某种意义上已经非常接近通过“图灵测试”了。"}]}]},{"ID":"20250915163745-7zpkb0n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-7zpkb0n","updated":"20250915163745"},"Children":[{"ID":"20250915163745-f05w2db","Type":"NodeParagraph","Properties":{"id":"20250915163745-f05w2db","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰的规模效应"},{"Type":"NodeText","Data":": 从小模型到大模型，人类的辨别准确率"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续下降"},{"Type":"NodeText","Data":"（从76%降至52%），这表明模型越大，其生成的文本就越连贯、越真实、越难以识破。"}]}]}]}]},{"ID":"20250915163745-yybu1tu","Type":"NodeParagraph","Properties":{"id":"20250915163745-yybu1tu","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"平均人类准确率（每个参与者的正确分配与非中性分配的比率）在检测故意差的模型生成的文章时约为86%，其中50%是随机机会。相比之下，由175B参数模型生成的文章，人类的检测准确率仅为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"勉强高于随机机会的52%"},{"Type":"NodeText","Data":"（见表3.11）。人类检测模型生成文本的能力似乎随着模型规模的增加而接近随机机会，并且人类检测GPT-3的能力似乎比他们检测早期模型的机会要低得多。还有证据表明，参与者在每次输出上花费的时间与模型大小和文本连贯性成反比（见附录E）。"}]},{"ID":"20250915163745-ym91ltu","Type":"NodeParagraph","Properties":{"id":"20250915163745-ym91ltu","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"合成文章的例子见图3.14和3.15。大部分文本——正如评估者难以区分人类撰写的文章所表明的那样——在评估者看来是连贯的。事实不准确可以作为一篇文章是由模型生成的指标，因为模型无法访问文章标题、作者或撰写时间之外的文章元数据。其他指标包括重复、不合逻辑的句子和不寻常的短语，尽管这些通常足够微妙以至于不会被注意到。"}]},{"ID":"20250915163745-6lb7s2w","Type":"NodeParagraph","Properties":{"id":"20250915163745-6lb7s2w","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"与Ippolito等人的相关工作表明，自动检测器可能比人类在检测模型生成的文本方面有更高的成功率。GROVER [ZHR, 19]和GLTR [GSR19]等检测器的自动化可能是未来研究的一个有前途的领域。"}]},{"ID":"20250915163745-l7kpszy","Type":"NodeParagraph","Properties":{"id":"20250915163745-l7kpszy","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"Ippolito等人还指出，随着人类观察更多的词元，他们检测模型生成文本的准确率会提高。为了初步研究优秀的人类评估者在检测更长文章方面的表现，我们选择了12篇由GPT-3 175B生成的路透社新闻文章，平均长度为498词（是我们最初实验的298个词生成的补全）。在上述方法之后，我们进行了两项实验，每项实验都有大约80名美国参与者，比较人类检测GPT-3和控制模型生成文章的能力。"}]},{"ID":"20250915163745-mhxyf9g","Type":"NodeParagraph","Properties":{"id":"20250915163745-mhxyf9g","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"我们发现，人类检测由控制模型生成的较长文章的平均准确率约为88%，而由GPT-3 175B生成的文章的平均准确率仍然仅为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"勉强高于随机机会的52%"},{"Type":"NodeText","Data":"（见表3.12）。这表明，对于大约500词长的文章，GPT-3仍然能够产生人类发现难以与人类撰写的新闻文章区分开的补全。"}]},{"ID":"20250915163745-urzwppu","Type":"NodeParagraph","Properties":{"id":"20250915163745-urzwppu","updated":"20250915164423"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915164103-tnxdort.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163745-050ttxc","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-050ttxc","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-mkqkhbr","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-mkqkhbr","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.13：人类检测模型生成新闻文章的能力"}]},{"ID":"20250915163745-a6njfop","Type":"NodeParagraph","Properties":{"id":"20250915163745-a6njfop","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163745-uhkkj0c","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-uhkkj0c","updated":"20250915163745"},"Children":[{"ID":"20250915163745-0jukz6n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-0jukz6n","updated":"20250915163745"},"Children":[{"ID":"20250915163745-ax4k7a0","Type":"NodeParagraph","Properties":{"id":"20250915163745-ax4k7a0","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" 人类检测模型生成新闻文章的能力 (Human ability to detect model generated news articles)"}]}]},{"ID":"20250915163745-1xmwkm5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-1xmwkm5","updated":"20250915163745"},"Children":[{"ID":"20250915163745-i5opxf2","Type":"NodeParagraph","Properties":{"id":"20250915163745-i5opxf2","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (%) (Accuracy (%))"}]}]},{"ID":"20250915163745-f5kmps3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-f5kmps3","updated":"20250915163745"},"Children":[{"ID":"20250915163745-8vo6aec","Type":"NodeParagraph","Properties":{"id":"20250915163745-8vo6aec","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 参数数量 (对数刻度) (Number of parameters (log scale))"}]}]},{"ID":"20250915163745-ewhaju4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-ewhaju4","updated":"20250915163745"},"Children":[{"ID":"20250915163745-5p7u6ly","Type":"NodeParagraph","Properties":{"id":"20250915163745-5p7u6ly","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 随着模型规模的增加，人们识别新闻文章是否由模型生成的能力（通过正确分配与非中性分配的比率衡量）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"下降"},{"Type":"NodeText","Data":"。对故意差的控制模型输出的准确率用顶部的虚线表示，随机机会（50%）用底部的虚线表示。最佳拟合是一条幂律，带有95%的置信区间。"}]}]}]},{"ID":"20250915163745-gks89se","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-gks89se","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-ax564wb","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-ax564wb","updated":"20250915163745"},"Children":[{"ID":"20250915163745-j5f3qy2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-j5f3qy2","updated":"20250915163745"},"Children":[{"ID":"20250915163745-4twhyxu","Type":"NodeParagraph","Properties":{"id":"20250915163745-4twhyxu","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"这张图是表3.11数据的可视化，并加入了拟合曲线。"}]}]},{"ID":"20250915163745-xdju5lq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-xdju5lq","updated":"20250915163745"},"Children":[{"ID":"20250915163745-l22ob7t","Type":"NodeParagraph","Properties":{"id":"20250915163745-l22ob7t","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰的负相关趋势"},{"Type":"NodeText","Data":": 图中的数据点和拟合曲线清晰地显示出一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强烈的负相关"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型参数量越大，人类的识别准确率就越低"},{"Type":"NodeText","Data":"。这条向下的曲线直观地展示了模型生成文本质量的飞跃。"}]}]},{"ID":"20250915163745-jtkmbfl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-jtkmbfl","updated":"20250915163745"},"Children":[{"ID":"20250915163745-q2g72o5","Type":"NodeParagraph","Properties":{"id":"20250915163745-q2g72o5","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逼近随机猜测"},{"Type":"NodeText","Data":": 曲线的终点（175B模型）已经非常接近50%的随机猜测线，这再次强调了其生成文本的逼真程度。"}]}]}]}]},{"ID":"20250915163745-ddsh11b","Type":"NodeTable","TableAligns":[1,1,1,1,1],"Properties":{"colgroup":"||||","id":"20250915163745-ddsh11b","updated":"20250915163748"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"平均准确率"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"95%置信区间 (低, 高)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"与控制组比较的t值 (p值)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"“我不知道”的分配比例"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"控制组"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"88%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"84%-91%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.7%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 175B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"52%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"48%-57%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"12.7 (3.2e-23)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"10.6%"}]}]}]},{"ID":"20250915163745-zort1ju","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-zort1ju","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-9l2g18l","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-9l2g18l","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.12：人们识别是否为模型生成的"},{"Type":"NodeTextMark","TextMarkType":"u","TextMarkTextContent":"**较长**"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"（~500词）文章的能力"}]},{"ID":"20250915163745-amkihyb","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-amkihyb","updated":"20250915163745"},"Children":[{"ID":"20250915163745-mp4klbc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-mp4klbc","updated":"20250915163745"},"Children":[{"ID":"20250915163745-heq2vjc","Type":"NodeParagraph","Properties":{"id":"20250915163745-heq2vjc","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" 该表显示了人们识别是否为模型生成的文章的结果（通过正确分配与非中-性分配的比率衡量）。结果与控制模型和GPT-3 175B进行了比较，并显示了比较平均准确率与控制模型差异的双样本T检验结果。"}]}]}]},{"ID":"20250915163745-3sau96g","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-3sau96g","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-ogbm4sv","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-ogbm4sv","updated":"20250915163745"},"Children":[{"ID":"20250915163745-wf2qxgc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-wf2qxgc","updated":"20250915163745"},"Children":[{"ID":"20250915163745-uum07ip","Type":"NodeParagraph","Properties":{"id":"20250915163745-uum07ip","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"这张表的结果进一步加强了之前的结论。即使将文章长度增加到500词，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类的辨别准确率依然只有52%"},{"Type":"NodeText","Data":"。这表明GPT-3不仅能写出连贯的段落，还能维持"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长达数百词的篇章一致性"},{"Type":"NodeText","Data":"，这是之前模型难以企及的。"}]}]}]}]},{"ID":"20250915164513-62pba8x","Type":"NodeParagraph","Properties":{"id":"20250915164513-62pba8x","updated":"20250915164513"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915164513-3innfer.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163745-s3on6p7","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-s3on6p7","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-mzzsw65","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-mzzsw65","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.14：GPT-3生成的、人类最难辨别的新闻文章示例"}]},{"ID":"20250915163745-c648kur","Type":"NodeParagraph","Properties":{"id":"20250915163745-c648kur","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163745-uvrga4n","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-uvrga4n","updated":"20250915163745"},"Children":[{"ID":"20250915163745-lk84n7m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-lk84n7m","updated":"20250915163745"},"Children":[{"ID":"20250915163745-n5r4mfi","Type":"NodeParagraph","Properties":{"id":"20250915163745-n5r4mfi","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标题:"},{"Type":"NodeText","Data":" 联合卫理公会同意历史性分裂 (United Methodists Agree to Historic Split)"}]}]},{"ID":"20250915163745-t5kukrd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-t5kukrd","updated":"20250915163745"},"Children":[{"ID":"20250915163745-796ybf9","Type":"NodeParagraph","Properties":{"id":"20250915163745-796ybf9","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"副标题:"},{"Type":"NodeText","Data":" 那些反对同性婚姻的人将组建自己的教派 (Those who oppose gay marriage will form their own denomination)"}]}]},{"ID":"20250915163745-umog6g4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-umog6g4","updated":"20250915163745"},"Children":[{"ID":"20250915163745-91ao2w5","Type":"NodeParagraph","Properties":{"id":"20250915163745-91ao2w5","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文章:"},{"Type":"NodeText","Data":" (文章内容细节略，描述了联合卫理公会因对LGBTQ问题的分歧而决定分裂的事件。)"}]}]},{"ID":"20250915163745-fgcwlpe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-fgcwlpe","updated":"20250915163745"},"Children":[{"ID":"20250915163745-xelq4gf","Type":"NodeParagraph","Properties":{"id":"20250915163745-xelq4gf","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 人类最难从人类撰写的文章中区分出来的GPT-3生成的文章（准确率：12%）。"}]}]}]},{"ID":"20250915163745-gjaj7eu","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-gjaj7eu","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-z7tw774","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-z7tw774","updated":"20250915163745"},"Children":[{"ID":"20250915163745-jid5yqq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-jid5yqq","updated":"20250915163745"},"Children":[{"ID":"20250915163745-tbk1zvr","Type":"NodeParagraph","Properties":{"id":"20250915163745-tbk1zvr","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"这个示例文本展示了GPT-3生成高质量新闻的能力。文本"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构清晰、语言流畅、事实陈述（尽管可能是编造的）合乎逻辑"},{"Type":"NodeText","Data":"，并且紧扣标题和副标题。人类的辨别准确率只有12%，几乎完全被欺骗。"}]}]}]}]},{"ID":"20250915164614-gp0giwk","Type":"NodeParagraph","Properties":{"id":"20250915164614-gp0giwk","updated":"20250915164614"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915164614-s5knpsd.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163745-s0j2gt9","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-s0j2gt9","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-5ocl6k9","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-5ocl6k9","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.15：GPT-3生成的、人类最容易辨别的新闻文章示例"}]},{"ID":"20250915163745-d6xhgjp","Type":"NodeParagraph","Properties":{"id":"20250915163745-d6xhgjp","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163745-p96bh9h","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-p96bh9h","updated":"20250915163745"},"Children":[{"ID":"20250915163745-y0yxcst","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-y0yxcst","updated":"20250915163745"},"Children":[{"ID":"20250915163745-fbbc2ak","Type":"NodeParagraph","Properties":{"id":"20250915163745-fbbc2ak","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标题:"},{"Type":"NodeText","Data":" 斯塔尔的税收承诺引来梅根·凯利的嘲讽 (Star’s Tax Promise Draws Megyn Kelly’s Sarcasm)"}]}]},{"ID":"20250915163745-0gi9asl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-0gi9asl","updated":"20250915163745"},"Children":[{"ID":"20250915163745-jmnxv6c","Type":"NodeParagraph","Properties":{"id":"20250915163745-jmnxv6c","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"副标题:"},{"Type":"NodeText","Data":" 华金·菲尼克斯承诺为每个奖项穿同一件燕尾服 (Joaquin Phoenix pledged to wear the same tuxedo for each awards event)"}]}]},{"ID":"20250915163745-9os3hck","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-9os3hck","updated":"20250915163745"},"Children":[{"ID":"20250915163745-2ksobvm","Type":"NodeParagraph","Properties":{"id":"20250915163745-2ksobvm","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文章:"},{"Type":"NodeText","Data":" (文章内容细节略，描述了演员华金·菲尼克斯的环保承诺以及主持人梅根·凯利在脱口秀上的反应。)"}]}]},{"ID":"20250915163745-19gq50z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-19gq50z","updated":"20250915163745"},"Children":[{"ID":"20250915163745-dz4kmhw","Type":"NodeParagraph","Properties":{"id":"20250915163745-dz4kmhw","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 人类最容易从人类撰写的文章中区分出来的GPT-3生成的新闻文章（准确率：61%）。"}]}]}]},{"ID":"20250915163745-tdzn3l1","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-tdzn3l1","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-661d5a3","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-661d5a3","updated":"20250915163745"},"Children":[{"ID":"20250915163745-1vn7t51","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-1vn7t51","updated":"20250915163745"},"Children":[{"ID":"20250915163745-fck6npz","Type":"NodeParagraph","Properties":{"id":"20250915163745-fck6npz","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"这个示例虽然仍然连贯，但可能在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"细节、逻辑或风格上存在一些瑕疵"},{"Type":"NodeText","Data":"，使得超过60%的人能够识别出其机器生成的痕迹。这表明模型的生成能力并非完美无瑕。"}]}]}]}]},{"ID":"20250915163745-bzvlpmg","Type":"NodeParagraph","Properties":{"id":"20250915163745-bzvlpmg","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.5 学习和使用新词 (Learning and Using Novel Words)"}]},{"ID":"20250915163745-k3r3tmf","Type":"NodeParagraph","Properties":{"id":"20250915163745-k3r3tmf","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"一项在发展语言学中研究的任务是[CB78]，即人类作者学习和使用新词的能力，例如，在句子中看到一个词一次后，能够使用它，或者相反地，仅通过一次使用就能推断出一个词的含义。我们定性地测试了GPT-3执行前一项任务的能力。具体来说，我们给GPT-3一个不存在的词的定义，比如“Gigramuru”，然后要求它在一个句子中使用它。我们为5个不同的示例（一个单独的）提供了五个之前的示例..."}]},{"ID":"20250915164643-rhs0hxk","Type":"NodeParagraph","Properties":{"id":"20250915164643-rhs0hxk","updated":"20250915164643"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915164643-1lpezyz.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163745-ica8ekp","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-ica8ekp","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-hzwlrje","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163745-hzwlrje","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.16：GPT-3在少样本任务“使用新词造句”中的补全示例"}]},{"ID":"20250915163745-5ef2h3u","Type":"NodeParagraph","Properties":{"id":"20250915163745-5ef2h3u","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163745-nsimasp","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-nsimasp","updated":"20250915163745"},"Children":[{"ID":"20250915163745-zgejjpe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-zgejjpe","updated":"20250915163745"},"Children":[{"ID":"20250915163745-usv19p9","Type":"NodeParagraph","Properties":{"id":"20250915163745-usv19p9","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例1 (whatpu):"}]},{"ID":"20250915163745-17lsrqn","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-17lsrqn","updated":"20250915163745"},"Children":[{"ID":"20250915163745-3j6zomj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-3j6zomj","updated":"20250915163745"},"Children":[{"ID":"20250915163745-tv5c0g6","Type":"NodeParagraph","Properties":{"id":"20250915163745-tv5c0g6","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “whatpu”是一种生活在坦桑尼亚的毛茸茸的小动物。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我们去非洲旅行，看到了这些非常可爱的whatpus。"}]}]}]}]},{"ID":"20250915163745-abpnyr8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-abpnyr8","updated":"20250915163745"},"Children":[{"ID":"20250915163745-18w0hlb","Type":"NodeParagraph","Properties":{"id":"20250915163745-18w0hlb","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例2 (farduddle):"}]},{"ID":"20250915163745-1yfykhy","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-1yfykhy","updated":"20250915163745"},"Children":[{"ID":"20250915163745-llg84z0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-llg84z0","updated":"20250915163745"},"Children":[{"ID":"20250915163745-25tut8e","Type":"NodeParagraph","Properties":{"id":"20250915163745-25tut8e","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “farduddle”的意思是跳起来让人发笑。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有一天，当我和我的小妹妹玩的时候，她真的很兴奋，开始做这些疯狂的farduddles。"}]}]}]}]},{"ID":"20250915163745-tsgsk7m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-tsgsk7m","updated":"20250915163745"},"Children":[{"ID":"20250915163745-gyftvvj","Type":"NodeParagraph","Properties":{"id":"20250915163745-gyftvvj","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例3 (yalubalu):"}]},{"ID":"20250915163745-j2kaeh7","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-j2kaeh7","updated":"20250915163745"},"Children":[{"ID":"20250915163745-ask67fn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-ask67fn","updated":"20250915163745"},"Children":[{"ID":"20250915163745-wtzdy76","Type":"NodeParagraph","Properties":{"id":"20250915163745-wtzdy76","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “yalubalu”是一种看起来像个大南瓜的水果。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我去了特立尼达旅行，我尝试了这种在花园里种植的叫做yalubalu的水果。它很美味。"}]}]}]}]},{"ID":"20250915163745-ehz9q9y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-ehz9q9y","updated":"20250915163745"},"Children":[{"ID":"20250915163745-m4rvc01","Type":"NodeParagraph","Properties":{"id":"20250915163745-m4rvc01","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例4 (Burringo):"}]},{"ID":"20250915163745-px06u5m","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-px06u5m","updated":"20250915163745"},"Children":[{"ID":"20250915163745-bq6if8b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-bq6if8b","updated":"20250915163745"},"Children":[{"ID":"20250915163745-sj4n0z7","Type":"NodeParagraph","Properties":{"id":"20250915163745-sj4n0z7","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “Burringo”是一种加速非常快的汽车。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在我们的车库里，我们有一辆我父亲每天开去上班的Burringo。"}]}]}]}]},{"ID":"20250915163745-1rus6m0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-1rus6m0","updated":"20250915163745"},"Children":[{"ID":"20250915163745-jmltc11","Type":"NodeParagraph","Properties":{"id":"20250915163745-jmltc11","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例5 (Gigamuru):"}]},{"ID":"20250915163745-qatt3od","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-qatt3od","updated":"20250915163745"},"Children":[{"ID":"20250915163745-d0664ga","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-d0664ga","updated":"20250915163745"},"Children":[{"ID":"20250915163745-fddi63v","Type":"NodeParagraph","Properties":{"id":"20250915163745-fddi63v","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “Gigamuru”是一种日本乐器。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我有一个我叔叔作为礼物送给我的Gigamuru。我喜欢在家里弹奏它。"}]}]}]}]},{"ID":"20250915163745-8i0w4w2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-8i0w4w2","updated":"20250915163745"},"Children":[{"ID":"20250915163745-5fzxi77","Type":"NodeParagraph","Properties":{"id":"20250915163745-5fzxi77","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例6 (screeg):"}]},{"ID":"20250915163745-g8rkjdt","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-g8rkjdt","updated":"20250915163745"},"Children":[{"ID":"20250915163745-4sjppu4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-4sjppu4","updated":"20250915163745"},"Children":[{"ID":"20250915163745-65x7hnh","Type":"NodeParagraph","Properties":{"id":"20250915163745-65x7hnh","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “screeg”的意思是在空中挥舞一把剑。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我们练习了几个小时的尖叫，然后我们出去吃了冰淇淋。"}]}]}]}]},{"ID":"20250915163745-grwlq94","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-grwlq94","updated":"20250915163745"},"Children":[{"ID":"20250915163745-92tvkj4","Type":"NodeParagraph","Properties":{"id":"20250915163745-92tvkj4","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" GPT-3在一个少样本任务中的补全，即在一个句子中使用一个新词。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加粗"},{"Type":"NodeText","Data":"的补全是GPT-3的，纯文本是人类的提示。在第一个示例中，提示和补全都是由人类提供的；这之后作为后续示例的条件，其中GPT-3接收额外的提示并提供这里显示的补全。具体任务是提供GPT-3其他没有条件限制的补全。"}]}]}]},{"ID":"20250915163745-ltbdanj","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-ltbdanj","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-psa9z8l","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-psa9z8l","updated":"20250915163745"},"Children":[{"ID":"20250915163745-dxhayex","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-dxhayex","updated":"20250915163745"},"Children":[{"ID":"20250915163745-wp8dk0m","Type":"NodeParagraph","Properties":{"id":"20250915163745-wp8dk0m","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"这张图展示了GPT-3"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"惊人的快速学习和泛化能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915163745-xrnj099","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-xrnj099","updated":"20250915163745"},"Children":[{"ID":"20250915163745-mawkjk3","Type":"NodeParagraph","Properties":{"id":"20250915163745-mawkjk3","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一步到位的学习 (One-shot Learning)"},{"Type":"NodeText","Data":": 模型只需要看到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个"},{"Type":"NodeText","Data":"“定义+例句”的模式，就能立刻理解任务要求，并为后续给出的新词和定义生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语法正确、语义恰当"},{"Type":"NodeText","Data":"的句子。"}]}]},{"ID":"20250915163745-6gzbsa7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-6gzbsa7","updated":"20250915163745"},"Children":[{"ID":"20250915163745-chh8ahx","Type":"NodeParagraph","Properties":{"id":"20250915163745-chh8ahx","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越模仿"},{"Type":"NodeText","Data":": 模型生成的句子不仅仅是对示例的简单模仿。例如，它能正确地将名词“whatpu”变为复数“whatpus”，将动词“screeg”变为过去式“screeged”（尽管生成的句子有点奇怪）。这表明它"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将新词整合进了其已有的语法和语义框架中"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915163745-pvni3xi","Type":"NodeParagraph","Properties":{"id":"20250915163745-pvni3xi","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"不存在的词被定义并用在一个句子中，所以任务是在之前的示例中看到一个不存在的词的定义和用法后，在少样本中执行。图3.16显示了6个示例，其中前几个示例是人类生成的，第一个答案是人类生成的作为条件，而所有后续答案都是由GPT-3生成的，没有重新尝试或挑选任何提示。在所有情况下，生成的句子似乎都是对单词的正确或至少是合理的使用。在最后一个示例中，模型生成了动词“screeg”（即“screeged”）的合理变化形式，尽管最终的句子有点奇怪（“screeged at each other”），尽管在它能描述一场玩具剑斗的意义上是合理的。总的来说，GPT-3似乎至少能初步胜任在一个句子中使用新词的任务。"}]},{"ID":"20250915163745-mnw6v9t","Type":"NodeParagraph","Properties":{"id":"20250915163745-mnw6v9t","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.6 语法改错 (Correcting English Grammar)"}]},{"ID":"20250915163745-4ts2tb6","Type":"NodeParagraph","Properties":{"id":"20250915163745-4ts2tb6","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"另一项可以很好地用少样本学习来设置的任务是纠正英语语法。我们通过给出“Poor English input: \u003c句子\u003e\\n Good English output: \u003c句子\u003e”形式的提示来测试GPT-3。我们给了GPT-3一个人类生成的示例，然后要求它纠正5个更多的示例（没有任何遗漏或重复）。结果显示在图3.17中。"}]},{"ID":"20250915163745-evrgogd","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-evrgogd","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-p2co35k","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-p2co35k","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163745-aeq63at","Type":"NodeParagraph","Properties":{"id":"20250915163745-aeq63at","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本节缺少图3.17"},{"Type":"NodeText","Data":"，但根据文本描述，我们可以推断出其核心内容。"}]},{"ID":"20250915163745-mycwqmu","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-mycwqmu","updated":"20250915163745"},"Children":[{"ID":"20250915163745-vvxt46y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-vvxt46y","updated":"20250915163745"},"Children":[{"ID":"20250915163745-gq2zp1w","Type":"NodeParagraph","Properties":{"id":"20250915163745-gq2zp1w","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强大的零/少样本语法能力"},{"Type":"NodeText","Data":": 类似于使用新词，语法改错也是一个极佳的上下文学习应用场景。通过提供一个“错误 -\u003e 正确”的示例，模型就能理解任务模式，并对新的错误句子进行修改。这利用了模型在预训练阶段学到的海量关于正确语法的知识。这项能力是当前所有大语言模型应用（如写作助手、翻译润色）的基础。"}]}]}]}]},{"ID":"20250915163745-7rdjfmw","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915163745-7rdjfmw","updated":"20250915163746"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163745-twkwths","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163745-twkwths","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250915163745-9c9cgd0","Type":"NodeParagraph","Properties":{"id":"20250915163745-9c9cgd0","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"本节（3.9）是GPT-3论文中最具启发性和前瞻性的部分，它通过一系列专门设计的、非传统的任务，系统地探测了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越传统NLP基准的、更接近通用智能的能力"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915163745-e9429kq","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915163745-e9429kq","updated":"20250915163745"},"Children":[{"ID":"20250915163745-aqyjzi9","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915163745-aqyjzi9","updated":"20250915163745"},"Children":[{"ID":"20250915163745-yo1hwn2","Type":"NodeParagraph","Properties":{"id":"20250915163745-yo1hwn2","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“涌现”能力的集中展示"},{"Type":"NodeText","Data":": 本节是“能力涌现”现象的集中体现。无论是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算术能力（图3.10）"},{"Type":"NodeText","Data":"还是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符号操作能力（图3.11）"},{"Type":"NodeText","Data":"，都在模型规模跨越某个巨大门槛后，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从无到有地突然出现"},{"Type":"NodeText","Data":"。这强有力地证明了，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"量的积累（模型规模）可以带来质的飞跃（新能力的诞生）"},{"Type":"NodeText","Data":"，这是缩放法则背后最深刻的含义。"}]}]},{"ID":"20250915163745-r75jlgw","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915163745-r75jlgw","updated":"20250915163745"},"Children":[{"ID":"20250915163745-y2rcctd","Type":"NodeParagraph","Properties":{"id":"20250915163745-y2rcctd","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越语言的抽象推理"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915163745-428ige4","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-428ige4","updated":"20250915163745"},"Children":[{"ID":"20250915163745-l3em7ht","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-l3em7ht","updated":"20250915163745"},"Children":[{"ID":"20250915163745-f3pyzp9","Type":"NodeParagraph","Properties":{"id":"20250915163745-f3pyzp9","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算术"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单词乱序"},{"Type":"NodeText","Data":"任务证明了模型具备了一定程度的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符号操作和过程模拟能力"},{"Type":"NodeText","Data":"，它不再仅仅是处理自然语言，而是可以学习和执行抽象的规则。"}]}]},{"ID":"20250915163745-9tryxrf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-9tryxrf","updated":"20250915163745"},"Children":[{"ID":"20250915163745-876xjb1","Type":"NodeParagraph","Properties":{"id":"20250915163745-876xjb1","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAT类比"},{"Type":"NodeText","Data":"任务的成功（图3.12），则证明了模型能够理解和推理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词语之间高度抽象的语义关系"},{"Type":"NodeText","Data":"，其表现甚至超过了人类平均水平，这是其强大认知能力的重要标志。"}]}]}]}]},{"ID":"20250915163745-b7y7o0t","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915163745-b7y7o0t","updated":"20250915163745"},"Children":[{"ID":"20250915163745-y9tr5sm","Type":"NodeParagraph","Properties":{"id":"20250915163745-y9tr5sm","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以假乱真的创造力"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915163745-jxfw5xl","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163745-jxfw5xl","updated":"20250915163745"},"Children":[{"ID":"20250915163745-jepbz1f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-jepbz1f","updated":"20250915163745"},"Children":[{"ID":"20250915163745-yh3gv3x","Type":"NodeParagraph","Properties":{"id":"20250915163745-yh3gv3x","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"新闻生成"},{"Type":"NodeText","Data":"任务（表3.11/3.12, 图3.13）的结果是本节乃至整篇论文"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最具社会影响力的发现"},{"Type":"NodeText","Data":"。GPT-3生成的文本能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在统计上与人类创作无法区分"},{"Type":"NodeText","Data":"，这不仅是技术上的巨大成功，也敲响了关于信息真实性、内容创作和人工智能伦理的警钟。"}]}]},{"ID":"20250915163745-1ca6w7s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163745-1ca6w7s","updated":"20250915163745"},"Children":[{"ID":"20250915163745-imjwg6b","Type":"NodeParagraph","Properties":{"id":"20250915163745-imjwg6b","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"使用新词造句"},{"Type":"NodeText","Data":"（图3.16）则展示了模型惊人的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"快速学习和创造性泛化"},{"Type":"NodeText","Data":"能力。它不是死板地模仿，而是能将新概念无缝地融入其庞大的语言知识体系中，并进行创造性的应用。"}]}]}]}]},{"ID":"20250915163745-v5v7ur3","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250915163745-v5v7ur3","updated":"20250915163745"},"Children":[{"ID":"20250915163745-bw2oye0","Type":"NodeParagraph","Properties":{"id":"20250915163745-bw2oye0","updated":"20250915163745"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用能力的统一框架"},{"Type":"NodeText","Data":": 本节的所有任务，尽管五花八门，但都被置于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"同一个上下文学习框架"},{"Type":"NodeText","Data":"下解决。模型无需任何架构改动或微调，仅通过改变提示中的几个示例，就能在算术、符号操作、抽象推理和内容创作等截然不同的任务间自由切换。这完美地诠释了论文的核心思想——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个足够大的语言模型，本身就是一个通用的、可通过上下文指令进行编程的“处理器”"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250915163745-368saba","Type":"NodeParagraph","Properties":{"id":"20250915163745-368saba","updated":"20250915163745"},"Children":[{"Type":"NodeText","Data":"总结而言，第3.9节通过一系列巧妙的实验设计，将我们对语言模型的认知从一个“特定任务的解决者”提升到了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通用问题求解器”"},{"Type":"NodeText","Data":"的层面。它所揭示的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力、抽象推理能力和创造能力"},{"Type":"NodeText","Data":"，是GPT-3对人工智能领域最根本、最深远的贡献，并直接开启了我们今天所处的大语言模型时代。直接开启了我们今天所处的大语言模型时代。"}]},{"ID":"20250915163746-fdhliih","Type":"NodeParagraph","Properties":{"id":"20250915163746-fdhliih","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"好的，我们来对这部分关于GPT-3在综合性、定性任务上的表现进行详细的翻译和解析。这是论文结果部分的最后一节，也是最能体现模型通用智能和创造力的一节。"}]},{"ID":"20250915163746-n576kof","Type":"NodeThematicBreak","Properties":{"id":"20250915163746-n576kof","updated":"20250915163746"}},{"ID":"20250915163746-o7183pu","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-o7183pu","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.9 综合性与定性任务 (Synthetic and Qualitative Tasks)"}]},{"ID":"20250915163746-0vh29rc","Type":"NodeParagraph","Properties":{"id":"20250915163746-0vh29rc","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"一种探测GPT-3在少样本（或零样本、单样本）设置下能力范围的方法是，给它一些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"要求即时进行简单计算推理、识别训练中不大可能出现过的新颖模式，或者快速适应一个不寻常任务"},{"Type":"NodeText","Data":"的任务。我们设计了几项任务来测试这类能力。首先，我们测试GPT-3执行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算术"},{"Type":"NodeText","Data":"的能力。其次，我们创建了几个涉及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重排或打乱单词中字母"},{"Type":"NodeText","Data":"的任务，这些任务不大可能在训练中被精确地见过。第三，我们测试GPT-3"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以少样本方式解决SAT风格的类比问题"},{"Type":"NodeText","Data":"的能力。最后，我们测试GPT-3在几个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定性任务"},{"Type":"NodeText","Data":"上的表现，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在新句子中使用新词、纠正英语语法，以及生成新闻文章"},{"Type":"NodeText","Data":"。我们将发布这些综合性数据集，希望能激发对语言模型测试时行为的进一步研究。"}]},{"ID":"20250915163746-vf0b1us","Type":"NodeBlockquote","Properties":{"id":"20250915163746-vf0b1us","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-n4s5ey0","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-n4s5ey0","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-l772hy7","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-l772hy7","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"测试的意图：超越死记硬背"}]},{"ID":"20250915163746-es910ao","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-es910ao","updated":"20250915163746"},"Children":[{"ID":"20250915163746-9vsytom","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-9vsytom","updated":"20250915163746"},"Children":[{"ID":"20250915163746-ixzpxji","Type":"NodeParagraph","Properties":{"id":"20250915163746-ixzpxji","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"本节的目的是设计一些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型在训练时绝对不可能“见过”"},{"Type":"NodeText","Data":"的任务，以此来检验它是否具备了真正的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理、模式识别和快速适应"},{"Type":"NodeText","Data":"能力，而不仅仅是记忆和模仿。这些任务是衡量模型是否向通用智能迈进的“试金石”。"}]}]}]}]},{"ID":"20250915163746-liynejn","Type":"NodeParagraph","Properties":{"id":"20250915163746-liynejn","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.1 算术 (Arithmetic)"}]},{"ID":"20250915163746-s694eli","Type":"NodeParagraph","Properties":{"id":"20250915163746-s694eli","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了测试GPT-3在没有特定任务训练的情况下执行简单算术运算的能力，我们开发了一个包含10个测试的小型测试集，这些测试涉及用自然语言向GPT-3提出一个简单的算术问题："}]},{"ID":"20250915163746-7wm2pt8","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-7wm2pt8","updated":"20250915163748"},"Children":[{"ID":"20250915163746-62e3lic","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-62e3lic","updated":"20250915163746"},"Children":[{"ID":"20250915163746-kga5ync","Type":"NodeParagraph","Properties":{"id":"20250915163746-kga5ync","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两位数加法 (2D+)"},{"Type":"NodeText","Data":" – 模型被要求将两个从[0, 100)均匀采样的整数相加，问题以提问形式给出，例如：“问：48加76是多少？答：124。”"}]}]},{"ID":"20250915163746-gecfchh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-gecfchh","updated":"20250915163746"},"Children":[{"ID":"20250915163746-eybgct6","Type":"NodeParagraph","Properties":{"id":"20250915163746-eybgct6","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两位数减法 (2D−)"},{"Type":"NodeText","Data":" – 模型被要求将两个从[0, 100)均匀采样的整数相减；答案可能是负数。例如：“问：34减53是多少？答：-19。”"}]}]},{"ID":"20250915163746-679gjr7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-679gjr7","updated":"20250915163746"},"Children":[{"ID":"20250915163746-suj5q2v","Type":"NodeParagraph","Properties":{"id":"20250915163746-suj5q2v","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三位数加法 (3D+)"},{"Type":"NodeText","Data":" – 与两位数加法相同，只是数字是从[0, 1000)均匀采样的。"}]}]}]},{"ID":"20250915163746-2aknrir","Type":"NodeParagraph","Properties":{"id":"20250915163746-2aknrir","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914161324-5d55z1o.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163746-91bfx54","Type":"NodeBlockquote","Properties":{"id":"20250915163746-91bfx54","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-jsas8ew","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-jsas8ew","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.10：算术任务（少样本）上的性能"}]},{"ID":"20250915163746-wj1ls5l","Type":"NodeParagraph","Properties":{"id":"20250915163746-wj1ls5l","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163746-vq96wv6","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-vq96wv6","updated":"20250915163746"},"Children":[{"ID":"20250915163746-z70uh8m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-z70uh8m","updated":"20250915163746"},"Children":[{"ID":"20250915163746-nk55md9","Type":"NodeParagraph","Properties":{"id":"20250915163746-nk55md9","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" 算术 (少样本) (Arithmetic (few-shot))"}]}]},{"ID":"20250915163746-tw9ndei","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-tw9ndei","updated":"20250915163746"},"Children":[{"ID":"20250915163746-n4uib26","Type":"NodeParagraph","Properties":{"id":"20250915163746-n4uib26","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915163746-448pri2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-448pri2","updated":"20250915163746"},"Children":[{"ID":"20250915163746-8nh0vz7","Type":"NodeParagraph","Properties":{"id":"20250915163746-8nh0vz7","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915163746-8mjtagp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-8mjtagp","updated":"20250915163746"},"Children":[{"ID":"20250915163746-6n3fty9","Type":"NodeParagraph","Properties":{"id":"20250915163746-6n3fty9","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"}]},{"ID":"20250915163746-hm770pn","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-hm770pn","updated":"20250915163746"},"Children":[{"ID":"20250915163746-9e4sff3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-9e4sff3","updated":"20250915163746"},"Children":[{"ID":"20250915163746-6947vzc","Type":"NodeParagraph","Properties":{"id":"20250915163746-6947vzc","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"两位数加法 (Two Digit Addition)"}]}]},{"ID":"20250915163746-hxo946r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-hxo946r","updated":"20250915163746"},"Children":[{"ID":"20250915163746-7x913ie","Type":"NodeParagraph","Properties":{"id":"20250915163746-7x913ie","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"两位数减法 (Two Digit Subtraction)"}]}]},{"ID":"20250915163746-3g5byb9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-3g5byb9","updated":"20250915163746"},"Children":[{"ID":"20250915163746-7szts43","Type":"NodeParagraph","Properties":{"id":"20250915163746-7szts43","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"三位数加法 (Three Digit Addition)"}]}]},{"ID":"20250915163746-ase966g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ase966g","updated":"20250915163746"},"Children":[{"ID":"20250915163746-81ypbdn","Type":"NodeParagraph","Properties":{"id":"20250915163746-81ypbdn","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"... (以此类推，最高到五位数加减法、两位数乘法、单位数三项运算)"}]}]}]}]},{"ID":"20250915163746-ppv5f03","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ppv5f03","updated":"20250915163746"},"Children":[{"ID":"20250915163746-kcbwbbx","Type":"NodeParagraph","Properties":{"id":"20250915163746-kcbwbbx","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 结果显示了在少样本设置下，不同规模模型在10个算术任务上的表现。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大的两个模型（GPT-3 13B和GPT-3 175B）之间存在一个显著的性能跳跃"},{"Type":"NodeText","Data":"，后者能够可靠地完成两位数算术，基本准确地完成三位数算术，并且在相当一部分时间里能正确回答四位数算术、两位数乘法和复合运算。零样本和单样本的结果见附录。"}]}]}]},{"ID":"20250915163746-zc7pszp","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-zc7pszp","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-d2jiqsr","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-d2jiqsr","updated":"20250915163746"},"Children":[{"ID":"20250915163746-x4qtgvi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-x4qtgvi","updated":"20250915163746"},"Children":[{"ID":"20250915163746-smfmd9a","Type":"NodeParagraph","Properties":{"id":"20250915163746-smfmd9a","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"这张图是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“能力涌现”"},{"Type":"NodeText","Data":"现象的又一个惊人例证。"}]}]},{"ID":"20250915163746-5j5nu14","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-5j5nu14","updated":"20250915163746"},"Children":[{"ID":"20250915163746-2hfkik7","Type":"NodeParagraph","Properties":{"id":"20250915163746-2hfkik7","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算术能力的突然爆发"},{"Type":"NodeText","Data":": 观察图中所有曲线，在模型规模达到13B之前，所有算术任务的准确率都"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常低，接近于0"},{"Type":"NodeText","Data":"。然而，当模型规模从13B跃升到175B时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能发生了爆炸式增长"},{"Type":"NodeText","Data":"。175B的模型在两位数加减法上几乎达到了100%的准确率，在三位数加减法上也表现优异。"}]}]},{"ID":"20250915163746-ex5ty0u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ex5ty0u","updated":"20250915163746"},"Children":[{"ID":"20250915163746-j7j0n69","Type":"NodeParagraph","Properties":{"id":"20250915163746-j7j0n69","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力的边界"},{"Type":"NodeText","Data":": 尽管表现惊人，但模型的算术能力是有限的。随着数字位数的增加（四位数、五位数），准确率"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"急剧下降"},{"Type":"NodeText","Data":"。两位数乘法也只达到了约30%的准确率。这表明，模型可能不是在进行真正的数学计算，而是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用其庞大的参数规模和语言模式来“模拟”或“近似”计算过程"},{"Type":"NodeText","Data":"，这种方法在问题复杂度超过一定限度后就会失效。"}]}]}]}]},{"ID":"20250915163746-0ahovkx","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-0ahovkx","updated":"20250915163748"},"Children":[{"ID":"20250915163746-f9i90xm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-f9i90xm","updated":"20250915163746"},"Children":[{"ID":"20250915163746-7ytuodz","Type":"NodeParagraph","Properties":{"id":"20250915163746-7ytuodz","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三位数减法 (3D−)"},{"Type":"NodeText","Data":" – 与两位数减法相同，只是数字是从[0, 1000)均匀采样的。"}]}]},{"ID":"20250915163746-ccq769j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ccq769j","updated":"20250915163746"},"Children":[{"ID":"20250915163746-as8of8y","Type":"NodeParagraph","Properties":{"id":"20250915163746-as8of8y","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四位数加法 (4D+)"},{"Type":"NodeText","Data":" – 与三位数加法相同，只是数字是从[0, 10000)均匀采样的。"}]}]},{"ID":"20250915163746-v6zgpy8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-v6zgpy8","updated":"20250915163746"},"Children":[{"ID":"20250915163746-wbt9zov","Type":"NodeParagraph","Properties":{"id":"20250915163746-wbt9zov","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四位数减法 (4D−)"},{"Type":"NodeText","Data":" – 与三位数减法相同，只是数字是从[0, 10000)均匀采样的。"}]}]},{"ID":"20250915163746-zhf9oks","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-zhf9oks","updated":"20250915163746"},"Children":[{"ID":"20250915163746-0u2113y","Type":"NodeParagraph","Properties":{"id":"20250915163746-0u2113y","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"五位数加法 (5D+)"},{"Type":"NodeText","Data":" – 与三位数加法相同，只是数字是从[0, 100000)均匀采样的。"}]}]},{"ID":"20250915163746-p10htu3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-p10htu3","updated":"20250915163746"},"Children":[{"ID":"20250915163746-t6ifzqd","Type":"NodeParagraph","Properties":{"id":"20250915163746-t6ifzqd","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"五位数减法 (5D−)"},{"Type":"NodeText","Data":" – 与三位数减法相同，只是数字是从[0, 100000)均匀采样的。"}]}]},{"ID":"20250915163746-k9ky3re","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-k9ky3re","updated":"20250915163746"},"Children":[{"ID":"20250915163746-2dh70zt","Type":"NodeParagraph","Properties":{"id":"20250915163746-2dh70zt","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两位数乘法 (2Dx)"},{"Type":"NodeText","Data":" – 模型被要求将两个从[0, 100)均匀采样的整数相乘，例如：“问：24乘以42是多少？答：1008。”"}]}]},{"ID":"20250915163746-aydwkql","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-aydwkql","updated":"20250915163746"},"Children":[{"ID":"20250915163746-k6aquwa","Type":"NodeParagraph","Properties":{"id":"20250915163746-k6aquwa","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单位数复合运算 (1DC)"},{"Type":"NodeText","Data":" – 模型被要求对一个复合运算求值。问题是从最后两位数选择的三个单位数，以及从{+,−,∗}中选择的操作。例如：“问：6+(4*8)是多少？答：38。”"}]}]}]},{"ID":"20250915163746-hwgnbzo","Type":"NodeParagraph","Properties":{"id":"20250915163746-hwgnbzo","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"在所有10个任务中，模型必须生成完全正确的答案。对于每个任务，我们生成2000个随机实例的数据集，并对所有这些实例进行模型评估。"}]},{"ID":"20250915163746-bvpenyn","Type":"NodeParagraph","Properties":{"id":"20250915163746-bvpenyn","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"我们首先评估少样本设置下的GPT-3，结果显示在图3.10中。除了加减法，GPT-3在位数增加时表现出很强的熟练度，在两位数加法上达到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"100%"},{"Type":"NodeText","Data":"的准确率，在三位数减法上达到80.2%，在三位数加法上达到94.2%。随着位数增加，性能下降，但GPT-3在四位数运算中仍能达到25-56%的准确率，在五位数运算中达到9-10%的准确率，这表明它至少有能力将运算推广到更大的数字。GPT-3在两位数乘法上也取得了29.2%的准确率，这是一项计算上特别密集的运算。最后，GPT-3在单一数字组合运算中达到了21.3%的准确率（例如，9"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"*"}]},{"Type":"NodeText","Data":"(7+5)），表明它在超越单纯记忆之外具有一定的稳健性。"}]},{"ID":"20250915163746-hsh70op","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1,1,1,1,1],"Properties":{"colgroup":"||||||||||","id":"20250915163746-hsh70op","updated":"20250915163748"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2D+"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2D-"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3D+"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3D-"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4D+"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4D-"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5D+"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5D-"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2Dx"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1DC"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Zero-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"76.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"19.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"9.8"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 One-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"99.6"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"86.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"65.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"27.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"100.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"98.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"80.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"94.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"25.5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"26.8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"9.3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"9.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"29.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"21.3"}]}]}]},{"ID":"20250915163746-iesczpl","Type":"NodeBlockquote","Properties":{"id":"20250915163746-iesczpl","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-2n1gu3n","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-2n1gu3n","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.9：GPT-3 175B在基础算术任务上的性能"}]},{"ID":"20250915163746-ki5n75k","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-ki5n75k","updated":"20250915163746"},"Children":[{"ID":"20250915163746-mzv8i5b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-mzv8i5b","updated":"20250915163746"},"Children":[{"ID":"20250915163746-y9w1ugl","Type":"NodeParagraph","Properties":{"id":"20250915163746-y9w1ugl","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" 2,3,4,5是加法或减法的位数。2Dx是两位数乘法。1DC是单位数复合运算。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结果从零样本到单样本再到少样本稳步变得更强"},{"Type":"NodeText","Data":"，但即使是零样本也显示出显著的算术能力。"}]}]}]},{"ID":"20250915163746-qi4pn9g","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-qi4pn9g","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-iwa15y9","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-iwa15y9","updated":"20250915163746"},"Children":[{"ID":"20250915163746-xoln13w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-xoln13w","updated":"20250915163746"},"Children":[{"ID":"20250915163746-pq555xg","Type":"NodeParagraph","Properties":{"id":"20250915163746-pq555xg","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"这张表详细列出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大模型（175B）"},{"Type":"NodeText","Data":"在不同设置下的算术成绩。"}]}]},{"ID":"20250915163746-syu4j7m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-syu4j7m","updated":"20250915163746"},"Children":[{"ID":"20250915163746-wties1d","Type":"NodeParagraph","Properties":{"id":"20250915163746-wties1d","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的巨大作用"},{"Type":"NodeText","Data":": 观察每一列，从零样本到单样本再到少样本，准确率都有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"显著的、持续的提升"},{"Type":"NodeText","Data":"。这表明，虽然模型可能内在地具备一定的计算潜力，但通过提供示例（尤其是少样本），可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极大地帮助模型“激活”和“校准”这种能力"},{"Type":"NodeText","Data":"，让它明白任务的要求并给出正确格式的答案。"}]}]},{"ID":"20250915163746-3wk4j59","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-3wk4j59","updated":"20250915163746"},"Children":[{"ID":"20250915163746-kqnqv4g","Type":"NodeParagraph","Properties":{"id":"20250915163746-kqnqv4g","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本能力的惊喜"},{"Type":"NodeText","Data":": 即使不给任何例子，175B模型在两位数加减法上也取得了相当高的准确率。这表明，算术能力在某种程度上已经"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内化"},{"Type":"NodeText","Data":"为模型的一种基础能力。"}]}]}]}]},{"ID":"20250915163746-7h5bhtn","Type":"NodeParagraph","Properties":{"id":"20250915163746-7h5bhtn","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"如图3.10所示，小模型在所有这些任务上都表现很差——即使是130亿参数模型（比175B的完整GPT-3小一个量级）也只能解决两位数加减法任务不到一半的时间，而其他运算的准确率不到10%。"}]},{"ID":"20250915163746-qcixuso","Type":"NodeParagraph","Properties":{"id":"20250915163746-qcixuso","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"尽管如此，单样本和零样本的性能相对于少样本性能有所下降，这表明适应任务（或至少是任务的非常精确的格式）对于正确执行这些计算是重要的。然而，单样本性能仍然相当强劲，甚至完整GPT-3的零样本性能也显著地胜过所有更小的模型。表3.9中显示了所有三个设置的结果，附录H中显示了所有三个设置的模型容量扩展情况。"}]},{"ID":"20250915163746-0wsjixl","Type":"NodeParagraph","Properties":{"id":"20250915163746-0wsjixl","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了检查模型是否仅仅是记忆了训练数据中特定的算术问题，我们搜索了3位数的加减法问题。在2000个两位数加法问题中，我们只找到了17个（0.8%）形式为“\u003c数字1\u003e + \u003c数字2\u003e =”或“\u003c数字1\u003e plus \u003c数字2\u003e”的匹配项。在2000个减法问题中，我们只找到了2个匹配项（0.1%），表明只有一小部分正确答案可以被记忆。另外，对错误答案的检查表明，模型经常犯诸如不进位之类的错误，这表明它确实在尝试执行相关的计算，而不仅仅是记忆一个表格。"}]},{"ID":"20250915163746-2truptl","Type":"NodeParagraph","Properties":{"id":"20250915163746-2truptl","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"总的来说，GPT-3在少样本、单样本甚至零样本设置下，都显示出在相当程度上能够熟练地、近似地执行复杂算术的能力。"}]},{"ID":"20250915163746-avu7b9i","Type":"NodeBlockquote","Properties":{"id":"20250915163746-avu7b9i","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-8z1y4j7","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-8z1y4j7","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-q70bl3p","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-q70bl3p","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对算术能力的深入分析"}]},{"ID":"20250915163746-gpvlghr","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-gpvlghr","updated":"20250915163746"},"Children":[{"ID":"20250915163746-v5kypjn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-v5kypjn","updated":"20250915163746"},"Children":[{"ID":"20250915163746-xi0urie","Type":"NodeParagraph","Properties":{"id":"20250915163746-xi0urie","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排除记忆"},{"Type":"NodeText","Data":": 作者通过搜索训练数据，有力地证明了模型的算术能力"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并非来自死记硬背"},{"Type":"NodeText","Data":"。测试中的绝大多数算术题在训练集中都不存在。"}]}]},{"ID":"20250915163746-6z2uo6y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-6z2uo6y","updated":"20250915163746"},"Children":[{"ID":"20250915163746-m97jsxe","Type":"NodeParagraph","Properties":{"id":"20250915163746-m97jsxe","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“类人”的错误"},{"Type":"NodeText","Data":": 一个非常有趣的发现是，模型犯的错误类型（如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不进位"},{"Type":"NodeText","Data":"）与人类初学者非常相似。这进一步表明，模型是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"尝试学习和执行一个计算过程"},{"Type":"NodeText","Data":"，而不是简单地从一个巨大的查找表中检索答案。"}]}]},{"ID":"20250915163746-9zmpp2u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-9zmpp2u","updated":"20250915163746"},"Children":[{"ID":"20250915163746-7et11jk","Type":"NodeParagraph","Properties":{"id":"20250915163746-7et11jk","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结论"},{"Type":"NodeText","Data":": 尽管不完美，但GPT-3确实展现出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前所未有的、在语言模型中涌现出的计算能力"},{"Type":"NodeText","Data":"。这是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"近似的、基于模式匹配的计算"},{"Type":"NodeText","Data":"，是其通用智能的一部分。"}]}]}]}]},{"ID":"20250915163746-r95864s","Type":"NodeParagraph","Properties":{"id":"20250915163746-r95864s","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.2 单词乱序与操作 (Word Scrambling and Manipulation Tasks)"}]},{"ID":"20250915163746-ordlns7","Type":"NodeParagraph","Properties":{"id":"20250915163746-ordlns7","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了测试GPT-3从少量示例中学习简单符号操作任务的能力，我们设计了5个“字符操作”任务。每个任务都涉及通过添加、删除或置换字符的方式对一个单词进行扭曲，并要求模型恢复原始单词。这5个任务是："}]},{"ID":"20250915163746-b0anj5f","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-b0anj5f","updated":"20250915163748"},"Children":[{"ID":"20250915163746-wjs3rm6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-wjs3rm6","updated":"20250915163746"},"Children":[{"ID":"20250915163746-twg6h0v","Type":"NodeParagraph","Properties":{"id":"20250915163746-twg6h0v","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单词内字母循环移位 (CL)"},{"Type":"NodeText","Data":" – 给定一个单词，其字母被循环移位，并用“~=”符号表示，模型应生成原始单词。例如，它可能会看到“lyinevitab”并应输出“inevitably”。"}]}]},{"ID":"20250915163746-ekeds54","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ekeds54","updated":"20250915163746"},"Children":[{"ID":"20250915163746-5bhht0a","Type":"NodeParagraph","Properties":{"id":"20250915163746-5bhht0a","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"首尾字母乱序 (A1)"},{"Type":"NodeText","Data":" – 给定一个单词，除了第一个和最后一个字母外，所有字母都被随机打乱，模型必须输出原始单词。例如：“critooprun” → “corruption”。"}]}]},{"ID":"20250915163746-ew76aan","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ew76aan","updated":"20250915163746"},"Children":[{"ID":"20250915163746-dcja2jc","Type":"NodeParagraph","Properties":{"id":"20250915163746-dcja2jc","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"首尾两个字母乱序 (A2)"},{"Type":"NodeText","Data":" – 给定一个单词，除了前两个和后两个字母外，所有字母都被随机打乱，模型必须输出原始单词。例如：“opoepnnt” → “opponent”。"}]}]},{"ID":"20250915163746-ly1m11w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ly1m11w","updated":"20250915163746"},"Children":[{"ID":"20250915163746-v7g5az1","Type":"NodeParagraph","Properties":{"id":"20250915163746-v7g5az1","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单词内随机插入 (RI)"},{"Type":"NodeText","Data":" – 在单词的随机位置插入一个随机的标点符号或空格，模型必须输出原始单词。例如：“s.u'c/c'e.s s i/o/n” → “succession”。"}]}]},{"ID":"20250915163746-xp9hjsz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-xp9hjsz","updated":"20250915163746"},"Children":[{"ID":"20250915163746-i3vbcwm","Type":"NodeParagraph","Properties":{"id":"20250915163746-i3vbcwm","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单词倒序 (RW)"},{"Type":"NodeText","Data":" – 给定一个倒序的单词，模型必须输出原始单词。例如：“stcejbo” → “objects”。"}]}]}]},{"ID":"20250915163746-dpyvucn","Type":"NodeTable","TableAligns":[1,1,1,1,1,1],"Properties":{"colgroup":"|||||","id":"20250915163746-dpyvucn","updated":"20250915163748"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"设置"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CL"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"A1"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"A2"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RI"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RW"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Zero-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.66"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.28"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.91"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.26"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.09"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 One-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"21.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.62"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"25.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"45.4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.48"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Few-Shot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"37.9"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"15.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"39.7"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"67.2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"0.44"}]}]}]},{"ID":"20250915163746-v0c5eii","Type":"NodeBlockquote","Properties":{"id":"20250915163746-v0c5eii","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-fajmosy","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-fajmosy","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.10：GPT-3 175B在各种单词乱序和操作任务上的零、单、少样本性能"}]},{"ID":"20250915163746-70bvzvr","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-70bvzvr","updated":"20250915163746"},"Children":[{"ID":"20250915163746-rjoqqbs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-rjoqqbs","updated":"20250915163746"},"Children":[{"ID":"20250915163746-p2y370y","Type":"NodeParagraph","Properties":{"id":"20250915163746-p2y370y","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" CL是“单词内字母循环移位”。A1是除首尾字母外的乱序。A2是除首尾两个字母外的乱序。RI是“单词内随机插入”。RW是“单词倒序”。"}]}]}]},{"ID":"20250915163746-kxeptzw","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-kxeptzw","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-n6anfl5","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-n6anfl5","updated":"20250915163746"},"Children":[{"ID":"20250915163746-6iyhtxt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-6iyhtxt","updated":"20250915163746"},"Children":[{"ID":"20250915163746-1ft0a5v","Type":"NodeParagraph","Properties":{"id":"20250915163746-1ft0a5v","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"这张表展示了175B模型在各种符号操作任务上的表现。"}]}]},{"ID":"20250915163746-yfodt4y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-yfodt4y","updated":"20250915163746"},"Children":[{"ID":"20250915163746-j2v8say","Type":"NodeParagraph","Properties":{"id":"20250915163746-j2v8say","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的重要性"},{"Type":"NodeText","Data":": 在所有任务中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本的表现都远超单样本和零样本"},{"Type":"NodeText","Data":"。这表明，对于这些模型从未见过的、完全新颖的抽象规则，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过示例进行学习是至关重要的"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915163746-woj847y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-woj847y","updated":"20250915163746"},"Children":[{"ID":"20250915163746-vx4h4ph","Type":"NodeParagraph","Properties":{"id":"20250915163746-vx4h4ph","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务难度的差异"},{"Type":"NodeText","Data":": 模型在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RI（移除插入的干扰项）"},{"Type":"NodeText","Data":"任务上表现最好，少样本准确率达到67.2%。这可能因为它更接近于模型在预训练中见过的“去噪”任务。而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RW（单词倒序）"},{"Type":"NodeText","Data":"则表现最差，准确率极低，表明完全颠倒序列对模型来说是一个巨大的挑战。"}]}]},{"ID":"20250915163746-w1gavfa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-w1gavfa","updated":"20250915163746"},"Children":[{"ID":"20250915163746-edgoy4x","Type":"NodeParagraph","Properties":{"id":"20250915163746-edgoy4x","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本的无力"},{"Type":"NodeText","Data":": 在大多数任务上，零样本的表现都非常糟糕，这符合预期。因为没有例子，模型根本不知道这些奇怪的符号（如“~=”）和乱序的字母代表什么规则。"}]}]}]}]},{"ID":"20250915163746-wygonnk","Type":"NodeParagraph","Properties":{"id":"20250915163746-wygonnk","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"对于每个任务，我们生成了10,000个示例，选择的单词是根据[Nor09]测量的，长度在4到15个字符之间的前10,000个最常见的单词。少样本结果显示在图3.11中。任务性能随着模型规模平稳增长，完整的GPT-3模型在随机插入任务上达到了66.9%的准确率。"}]},{"ID":"20250915163746-cbvkx8r","Type":"NodeParagraph","Properties":{"id":"20250915163746-cbvkx8r","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914161404-b9t6u7g.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163746-89dbvyw","Type":"NodeBlockquote","Properties":{"id":"20250915163746-89dbvyw","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-c57vgui","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-c57vgui","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.11：单词乱序任务（少样本）上的性能"}]},{"ID":"20250915163746-ihe4ozi","Type":"NodeParagraph","Properties":{"id":"20250915163746-ihe4ozi","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163746-55qzozv","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-55qzozv","updated":"20250915163746"},"Children":[{"ID":"20250915163746-s65qaao","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-s65qaao","updated":"20250915163746"},"Children":[{"ID":"20250915163746-w7xqoqa","Type":"NodeParagraph","Properties":{"id":"20250915163746-w7xqoqa","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" 单词乱序 (少样本) (Wordscramble (few-shot))"}]}]},{"ID":"20250915163746-fycdx4m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-fycdx4m","updated":"20250915163746"},"Children":[{"ID":"20250915163746-vp22ydq","Type":"NodeParagraph","Properties":{"id":"20250915163746-vp22ydq","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915163746-b7v19gg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-b7v19gg","updated":"20250915163746"},"Children":[{"ID":"20250915163746-yiuet9e","Type":"NodeParagraph","Properties":{"id":"20250915163746-yiuet9e","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915163746-jv80dhm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-jv80dhm","updated":"20250915163746"},"Children":[{"ID":"20250915163746-78vbvhq","Type":"NodeParagraph","Properties":{"id":"20250915163746-78vbvhq","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 循环移位 (cycle letters), 中间1个字母乱序 (mid word 1 anagrams), 中间2个字母乱序 (mid word 2 anagrams), 随机插入 (random insertion), 单词倒序 (reversed words)"}]}]},{"ID":"20250915163746-71tm0zl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-71tm0zl","updated":"20250915163746"},"Children":[{"ID":"20250915163746-v75mikw","Type":"NodeParagraph","Properties":{"id":"20250915163746-v75mikw","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 五个单词乱序任务在不同规模模型上的少样本性能。尽管模型规模和参数量不成比例，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能随着模型规模的增加而平滑改善"},{"Type":"NodeText","Data":"。175B模型在接受任务时，所有任务都显示出向上的改进趋势。所有任务的"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"K"},{"Type":"NodeText","Data":"=100。附录中显示了单样本和零样本的缩放情况。"}]}]}]},{"ID":"20250915163746-opc9bfy","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-opc9bfy","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-hovmer8","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-hovmer8","updated":"20250915163746"},"Children":[{"ID":"20250915163746-4wrflay","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-4wrflay","updated":"20250915163746"},"Children":[{"ID":"20250915163746-noa7q05","Type":"NodeParagraph","Properties":{"id":"20250915163746-noa7q05","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"这张图将表3.10中的少样本结果按模型规模进行了可视化。"}]}]},{"ID":"20250915163746-nni3bnm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-nni3bnm","updated":"20250915163746"},"Children":[{"ID":"20250915163746-ou6c64b","Type":"NodeParagraph","Properties":{"id":"20250915163746-ou6c64b","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰的缩放效应"},{"Type":"NodeText","Data":": 所有任务的性能都随着模型规模的增加而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳步提升"},{"Type":"NodeText","Data":"。这表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更大的模型更擅长理解和执行抽象的符号操作规则"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915163746-bvv2cca","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-bvv2cca","updated":"20250915163746"},"Children":[{"ID":"20250915163746-8tjuhl9","Type":"NodeParagraph","Properties":{"id":"20250915163746-8tjuhl9","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务难度与学习曲线"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915163746-qlsuips","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-qlsuips","updated":"20250915163746"},"Children":[{"ID":"20250915163746-1h8h6rx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-1h8h6rx","updated":"20250915163746"},"Children":[{"ID":"20250915163746-nwy3pym","Type":"NodeParagraph","Properties":{"id":"20250915163746-nwy3pym","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"最陡峭的曲线是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RI（随机插入，绿色）"},{"Type":"NodeText","Data":"，表明模型随着规模增长，学习这个任务的速度最快。"}]}]},{"ID":"20250915163746-0pykip5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-0pykip5","updated":"20250915163746"},"Children":[{"ID":"20250915163746-4ebfmnx","Type":"NodeParagraph","Properties":{"id":"20250915163746-4ebfmnx","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"最平坦的曲线是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RW（单词倒序，紫色）"},{"Type":"NodeText","Data":"，几乎贴近于0，说明即使是最大的模型也"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"几乎没有学会"},{"Type":"NodeText","Data":"这个任务。"}]}]},{"ID":"20250915163746-akrkehz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-akrkehz","updated":"20250915163746"},"Children":[{"ID":"20250915163746-nxrlola","Type":"NodeParagraph","Properties":{"id":"20250915163746-nxrlola","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"其他任务介于两者之间，展示了不同程度的学习能力。"}]}]}]}]}]}]},{"ID":"20250915163746-z0okxp8","Type":"NodeParagraph","Properties":{"id":"20250915163746-z0okxp8","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"随机插入任务为38.6%，循环移位为40.2%，较简单的乱序任务为15.1%（其中只有第一个和最后一个字母是固定的）。在更难的乱序任务中，没有一个模型能复原单词。"}]},{"ID":"20250915163746-o3gnk6i","Type":"NodeParagraph","Properties":{"id":"20250915163746-o3gnk6i","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"在单样本设置下，性能明显较弱（下降一半或更多），而在零样本设置下，模型几乎无法执行任何这些任务（表3.10）。这表明模型似乎确实是在测试时学习这些任务，因为这些任务及其人工性质使得它们不太可能出现在预训练数据中（尽管我们无法确定地证实这一点）。"}]},{"ID":"20250915163746-7w3rija","Type":"NodeParagraph","Properties":{"id":"20250915163746-7w3rija","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"我们可以通过绘制“上下文学习曲线”来进一步量化性能，这些曲线显示任务性能是上下文示例数量的函数。我们在符号插入任务的图1.2中展示了学习曲线，需要几个例子才能让更大的模型有效地利用上下文信息，包括示例和自然语言任务描述。"}]},{"ID":"20250915163746-d4yfuep","Type":"NodeParagraph","Properties":{"id":"20250915163746-d4yfuep","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"最后，值得注意的是，解决这些任务需要字符级的操作，而我们的BPE编码在每个词元上只操作一小部分单词（平均约0.7个词元），因此需要模型不仅仅是操作BPE词元，还要深入其子结构，将单词分开再重新组合。此外，与SAT类比不同，乱序词任务不是确定性的，需要模型执行某种形式的搜索来找到与部分词元匹配和计算相对应的正确乱序。因此，这些技能涉及到相当程度的非平凡模式匹配和计算。"}]},{"ID":"20250915163746-dij67wo","Type":"NodeBlockquote","Properties":{"id":"20250915163746-dij67wo","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-7h2fhr4","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-7h2fhr4","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-t5n04c1","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-t5n04c1","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对符号操作能力的深入分析"}]},{"ID":"20250915163746-t1w0f9p","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-t1w0f9p","updated":"20250915163746"},"Children":[{"ID":"20250915163746-ucj2s71","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ucj2s71","updated":"20250915163746"},"Children":[{"ID":"20250915163746-sgs4epm","Type":"NodeParagraph","Properties":{"id":"20250915163746-sgs4epm","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"真正的即时学习"},{"Type":"NodeText","Data":": 模型在这些任务上的表现，特别是零样本的无力与少样本的相对成功，有力地证明了它是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"测试时实时学习这些新规则"},{"Type":"NodeText","Data":"，而不是依赖预训练的记忆。"}]}]},{"ID":"20250915163746-ev0c0se","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ev0c0se","updated":"20250915163746"},"Children":[{"ID":"20250915163746-k0agnxq","Type":"NodeParagraph","Properties":{"id":"20250915163746-k0agnxq","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越BPE词元的限制"},{"Type":"NodeText","Data":": 作者指出了一个非常关键的技术细节。GPT-3的输入单元是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BPE词元（token）"},{"Type":"NodeText","Data":"，而不是单个字符。要完成这些任务，模型必须学会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“看穿”词元，深入到字符层面进行操作"},{"Type":"NodeText","Data":"，然后再将结果组合成新的词元。这是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常复杂的、跨层级的操作能力"},{"Type":"NodeText","Data":"，其涌现本身就是一项了不起的成就。"}]}]},{"ID":"20250915163746-9wt01hc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-9wt01hc","updated":"20250915163746"},"Children":[{"ID":"20250915163746-3qlqi21","Type":"NodeParagraph","Properties":{"id":"20250915163746-3qlqi21","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非确定性搜索"},{"Type":"NodeText","Data":": 乱序重组任务不像算术题那样有唯一的计算路径。模型需要进行某种形式的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“搜索”"},{"Type":"NodeText","Data":"，找到最可能的原始单词。这表明模型具备了一定的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"启发式搜索和组合推理"},{"Type":"NodeText","Data":"能力。"}]}]}]}]},{"ID":"20250915163746-8msxmla","Type":"NodeParagraph","Properties":{"id":"20250915163746-8msxmla","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.3 SAT类比 (SAT Analogies)"}]},{"ID":"20250915163746-2xwt336","Type":"NodeParagraph","Properties":{"id":"20250915163746-2xwt336","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了测试GPT-3在另一项与典型分布有些不寻常的任务上的表现，我们收集了374个SAT类比问题的集合，这些问题构成了SAT大学入学考试的一部分，直到2005年[TLBS03]。类比是多项选择题，要求学生识别一对词语之间的关系，并从五个选项中找到与原始词对关系相同的一对。例如，“Audacious is to boldness as…”（大胆之于无畏，犹如…）的答案是“sanctimonious is to hypocrisy”（伪善之于虚伪）。学生被期望选择五个词对中与原始词对具有相同关系的词对。在这个任务上，GPT-3在少样本设置下达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"65.2%"},{"Type":"NodeText","Data":"的准确率，在单样本设置下为59.1%，在零样本设置下为53.7%，而普通大学申请者的平均分约为57% [TLBS03]（随机猜测为20%）。如图3.12所示，结果随着模型规模的改善而提高，拥有1750亿参数的完整模型比130亿参数模型提高了超过10%。"}]},{"ID":"20250915163746-tmu8by8","Type":"NodeParagraph","Properties":{"id":"20250915163746-tmu8by8","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914161426-l5r6x89.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163746-9yungdt","Type":"NodeBlockquote","Properties":{"id":"20250915163746-9yungdt","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-np2qnfs","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-np2qnfs","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.12：SAT类比任务上的性能"}]},{"ID":"20250915163746-88p4sgz","Type":"NodeParagraph","Properties":{"id":"20250915163746-88p4sgz","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163746-2s68s2l","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-2s68s2l","updated":"20250915163746"},"Children":[{"ID":"20250915163746-yzw28ru","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-yzw28ru","updated":"20250915163746"},"Children":[{"ID":"20250915163746-yeb7nkv","Type":"NodeParagraph","Properties":{"id":"20250915163746-yeb7nkv","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" SAT 类比 (SAT Analogies)"}]}]},{"ID":"20250915163746-xdinasl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-xdinasl","updated":"20250915163746"},"Children":[{"ID":"20250915163746-bc13ram","Type":"NodeParagraph","Properties":{"id":"20250915163746-bc13ram","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (Accuracy)"}]}]},{"ID":"20250915163746-tbglybz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-tbglybz","updated":"20250915163746"},"Children":[{"ID":"20250915163746-vakejyb","Type":"NodeParagraph","Properties":{"id":"20250915163746-vakejyb","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 语言模型参数量 (Parameters in LM (Billions))"}]}]},{"ID":"20250915163746-aapmhb8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-aapmhb8","updated":"20250915163746"},"Children":[{"ID":"20250915163746-h1450is","Type":"NodeParagraph","Properties":{"id":"20250915163746-h1450is","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图例:"},{"Type":"NodeText","Data":" 零样本 (Zero-Shot), 单样本 (One-Shot), 少样本 (Few-Shot (K=20)), 随机猜测 (Random Guessing)"}]}]},{"ID":"20250915163746-lrp0img","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-lrp0img","updated":"20250915163746"},"Children":[{"ID":"20250915163746-kqcbj31","Type":"NodeParagraph","Properties":{"id":"20250915163746-kqcbj31","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 不同规模模型在SAT类比任务上的零、单、少样本性能。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大模型在少样本设置下达到了65%的准确率"},{"Type":"NodeText","Data":"，并且也展示了在较小模型中不存在的显著的上下文学习增益。"}]}]}]},{"ID":"20250915163746-quk9nau","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-quk9nau","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-mlalony","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-mlalony","updated":"20250915163746"},"Children":[{"ID":"20250915163746-wg14x95","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-wg14x95","updated":"20250915163746"},"Children":[{"ID":"20250915163746-ilegisw","Type":"NodeParagraph","Properties":{"id":"20250915163746-ilegisw","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越人类平均水平"},{"Type":"NodeText","Data":": 这是本节的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标志性成果"},{"Type":"NodeText","Data":"。在少样本设置下，GPT-3的准确率（65.2%）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超过了当年参加SAT考试的大学申请者的平均水平（57%）"},{"Type":"NodeText","Data":"。这表明模型已经能够理解和推理词语之间复杂的抽象关系（如“部分与整体”、“原因与结果”、“程度深浅”等）。"}]}]},{"ID":"20250915163746-xhulb4s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-xhulb4s","updated":"20250915163746"},"Children":[{"ID":"20250915163746-a9grsl8","Type":"NodeParagraph","Properties":{"id":"20250915163746-a9grsl8","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的重要性"},{"Type":"NodeText","Data":": 观察图中的曲线间距，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习带来的提升非常显著"},{"Type":"NodeText","Data":"。尤其是在模型规模变大后，少样本（橙色）与零样本（蓝色）的差距明显拉开，再次证明大模型能更有效地利用示例来理解抽象任务。"}]}]}]}]},{"ID":"20250915163746-mw09oxz","Type":"NodeParagraph","Properties":{"id":"20250915163746-mw09oxz","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.4 新闻文章生成 (News Article Generation)"}]},{"ID":"20250915163746-5b17n94","Type":"NodeParagraph","Properties":{"id":"20250915163746-5b17n94","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"以前的通用语言模型已经测试过它们生成“新闻文章”的能力，其条件是给定一个人类写的、似乎来自新闻文章的合理的第一句话[RWC⁺19]。相对于[RWC⁺19]，用于训练GPT-3的数据集中，新闻文章的权重小得多，所以试图用原始、无条件样本生成新闻文章的效果较差——例如，GPT-3经常将建议的新闻文章的第一句话解释为推文，然后发布合成的回复或后续推文。为了解决这个问题，我们利用GPT-3的少样本学习能力，通过提供三个之前的示例新闻文章，然后是所需文章的标题和副标题，来提示模型。"}]},{"ID":"20250915163746-2t5fwvk","Type":"NodeParagraph","Properties":{"id":"20250915163746-2t5fwvk","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了衡量GPT-3生成的新闻文章的质量（我们认为这与一般情况下样本的条件生成质量相关），我们决定衡量"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类区分GPT-3生成的文章和人类写的文章的能力"},{"Type":"NodeText","Data":"。类似的工作已经由Kreps等人[KMB20]和Zellers等人[ZHR⁺19]进行过。生成式语言模型被训练来匹配人类生成的文本分布，因此它们生成的人类难以区分的样本，可能是模型质量的一个重要衡量标准。"}]},{"ID":"20250915163746-z3q52jx","Type":"NodeParagraph","Properties":{"id":"20250915163746-z3q52jx","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"为了研究人类辨别能力有多好，我们从网站"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"http://newser.com","TextMarkTextContent":"newser.com"},{"Type":"NodeText","Data":"上任意选择了25个文章标题和副标题（平均长度：215词）。我们生成了这些标题和副标题的补全，所有模型从125M到175B（GPT-3）的参数（平均长度：200词）。对于每个模型，我们向大约80名美国参与者展示了一个测试，其中包括这些真实标题和副标题的10个补全，其中一半由人类撰写，一半由模型生成。参与者被问及他们认为每篇文章是“很可能由人类写的”、“可能由人类写的”、“可能由机器写的”，还是“很可能由机器写的”。"}]},{"ID":"20250915163746-4vgs5ng","Type":"NodeParagraph","Properties":{"id":"20250915163746-4vgs5ng","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"我们选择的文章没有在模型的训练集中出现，避免了樱桃采摘。所有模型都使用相同的上下文和相同的文章标题和副标题，并且输出是使用相同的提示生成的，以确保所有模型之间的条件输出具有可比性。我们还进行了一个实验，控制了参与者的努力程度和注意力，结果表明我们收集到的判断是有意图的，而不是随机的模型生成的响应。我们通过生成一个“控制模型”来进行这项实验，该模型是一个160M参数的模型，没有上下文，输出随机性增加。"}]},{"ID":"20250915163746-xj3mdp8","Type":"NodeTable","TableAligns":[1,1,1,1,1],"Properties":{"colgroup":"||||","id":"20250915163746-xj3mdp8","updated":"20250915163748"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"模型"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"平均准确率"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"95%置信区间 (低, 高)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"与控制组比较的t值 (p值)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"“我不知道”的分配比例"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"控制组 (故意差的模型)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"86%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"83%-90%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.6%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Small"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"76%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"72%-80%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.9 (2e-4)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.9%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Medium"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"61%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58%-65%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.3 (7e-21)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.0%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 Large"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"68%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64%-72%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.3 (3e-11)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5.7%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 XL"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"62%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"59%-65%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.7 (1e-19)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.5%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 6.7B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"60%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"56%-63%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.4 (5e-19)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.1%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 13B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"55%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"52%-58%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"15.3 (1e-32)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.2%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 175B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"52%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"49%-54%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"16.9 (1e-34)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.8%"}]}]}]},{"ID":"20250915163746-52igm08","Type":"NodeBlockquote","Properties":{"id":"20250915163746-52igm08","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-4puynot","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-4puynot","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.11：人类在识别是否为模型生成的短篇（~200词）新闻文章时的准确率"}]},{"ID":"20250915163746-fpqm108","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-fpqm108","updated":"20250915163746"},"Children":[{"ID":"20250915163746-waycjll","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-waycjll","updated":"20250915163746"},"Children":[{"ID":"20250915163746-gskxbwt","Type":"NodeParagraph","Properties":{"id":"20250915163746-gskxbwt","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" 我们通过正确分配与非中性分配的比率来衡量人类准确率（从86%的控制组到52%的GPT-3 175B）。该表比较了不同模型之间的平均准确率，并显示了比较平均准确率与控制模型差异的双样本T检验结果。"}]}]}]},{"ID":"20250915163746-zfjeg3f","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-zfjeg3f","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-w0b42bd","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-w0b42bd","updated":"20250915163746"},"Children":[{"ID":"20250915163746-4sfauqc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-4sfauqc","updated":"20250915163746"},"Children":[{"ID":"20250915163746-xqc79ys","Type":"NodeParagraph","Properties":{"id":"20250915163746-xqc79ys","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"这张表的结果是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命性且令人警醒的"},{"Type":"NodeText","Data":"。它衡量的是人类分辨机器生成文本的能力，准确率"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"越低"},{"Type":"NodeText","Data":"，说明模型生成的文本"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量越高、越逼真"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915163746-fagu4io","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-fagu4io","updated":"20250915163746"},"Children":[{"ID":"20250915163746-54b7wn3","Type":"NodeParagraph","Properties":{"id":"20250915163746-54b7wn3","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"接近图灵测试"},{"Type":"NodeText","Data":": 对于175B模型生成的短新闻，人类的辨别准确率只有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"52%"},{"Type":"NodeText","Data":"。考虑到随机猜测的准确率是50%，这意味着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类几乎无法区分GPT-3生成的文本和真实的新闻"},{"Type":"NodeText","Data":"。这在某种意义上已经非常接近通过“图灵测试”了。"}]}]},{"ID":"20250915163746-vsn098q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-vsn098q","updated":"20250915163746"},"Children":[{"ID":"20250915163746-ra577xz","Type":"NodeParagraph","Properties":{"id":"20250915163746-ra577xz","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰的规模效应"},{"Type":"NodeText","Data":": 从小模型到大模型，人类的辨别准确率"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续下降"},{"Type":"NodeText","Data":"（从76%降至52%），这表明模型越大，其生成的文本就越连贯、越真实、越难以识破。"}]}]}]}]},{"ID":"20250915163746-ltsorb2","Type":"NodeParagraph","Properties":{"id":"20250915163746-ltsorb2","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"平均人类准确率（每个参与者的正确分配与非中性分配的比率）在检测故意差的模型生成的文章时约为86%，其中50%是随机机会。相比之下，由175B参数模型生成的文章，人类的检测准确率仅为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"勉强高于随机机会的52%"},{"Type":"NodeText","Data":"（见表3.11）。人类检测模型生成文本的能力似乎随着模型规模的增加而接近随机机会，并且人类检测GPT-3的能力似乎比他们检测早期模型的机会要低得多。还有证据表明，参与者在每次输出上花费的时间与模型大小和文本连贯性成反比（见附录E）。"}]},{"ID":"20250915163746-jjvfmj3","Type":"NodeParagraph","Properties":{"id":"20250915163746-jjvfmj3","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"合成文章的例子见图3.14和3.15。大部分文本——正如评估者难以区分人类撰写的文章所表明的那样——在评估者看来是连贯的。事实不准确可以作为一篇文章是由模型生成的指标，因为模型无法访问文章标题、作者或撰写时间之外的文章元数据。其他指标包括重复、不合逻辑的句子和不寻常的短语，尽管这些通常足够微妙以至于不会被注意到。"}]},{"ID":"20250915163746-99p2yud","Type":"NodeParagraph","Properties":{"id":"20250915163746-99p2yud","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"与Ippolito等人的相关工作表明，自动检测器可能比人类在检测模型生成的文本方面有更高的成功率。GROVER [ZHR, 19]和GLTR [GSR19]等检测器的自动化可能是未来研究的一个有前途的领域。"}]},{"ID":"20250915163746-05lpo5g","Type":"NodeParagraph","Properties":{"id":"20250915163746-05lpo5g","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"Ippolito等人还指出，随着人类观察更多的词元，他们检测模型生成文本的准确率会提高。为了初步研究优秀的人类评估者在检测更长文章方面的表现，我们选择了12篇由GPT-3 175B生成的路透社新闻文章，平均长度为498词（是我们最初实验的298个词生成的补全）。在上述方法之后，我们进行了两项实验，每项实验都有大约80名美国参与者，比较人类检测GPT-3和控制模型生成文章的能力。"}]},{"ID":"20250915163746-rrf4jnu","Type":"NodeParagraph","Properties":{"id":"20250915163746-rrf4jnu","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"我们发现，人类检测由控制模型生成的较长文章的平均准确率约为88%，而由GPT-3 175B生成的文章的平均准确率仍然仅为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"勉强高于随机机会的52%"},{"Type":"NodeText","Data":"（见表3.12）。这表明，对于大约500词长的文章，GPT-3仍然能够产生人类发现难以与人类撰写的新闻文章区分开的补全。"}]},{"ID":"20250915163746-bnkd57l","Type":"NodeParagraph","Properties":{"id":"20250915163746-bnkd57l","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914161452-3t3x757.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163746-wenb6c7","Type":"NodeBlockquote","Properties":{"id":"20250915163746-wenb6c7","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-nheog48","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-nheog48","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.13：人类检测模型生成新闻文章的能力"}]},{"ID":"20250915163746-pg29r4w","Type":"NodeParagraph","Properties":{"id":"20250915163746-pg29r4w","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163746-pukz5zo","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-pukz5zo","updated":"20250915163746"},"Children":[{"ID":"20250915163746-j8u43ie","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-j8u43ie","updated":"20250915163746"},"Children":[{"ID":"20250915163746-htuyc1q","Type":"NodeParagraph","Properties":{"id":"20250915163746-htuyc1q","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图标题:"},{"Type":"NodeText","Data":" 人类检测模型生成新闻文章的能力 (Human ability to detect model generated news articles)"}]}]},{"ID":"20250915163746-e8gaa53","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-e8gaa53","updated":"20250915163746"},"Children":[{"ID":"20250915163746-ifmdjfq","Type":"NodeParagraph","Properties":{"id":"20250915163746-ifmdjfq","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纵坐标:"},{"Type":"NodeText","Data":" 准确率 (%) (Accuracy (%))"}]}]},{"ID":"20250915163746-f5ylqij","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-f5ylqij","updated":"20250915163746"},"Children":[{"ID":"20250915163746-91iwf4m","Type":"NodeParagraph","Properties":{"id":"20250915163746-91iwf4m","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横坐标:"},{"Type":"NodeText","Data":" 参数数量 (对数刻度) (Number of parameters (log scale))"}]}]},{"ID":"20250915163746-ug6ujzs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ug6ujzs","updated":"20250915163746"},"Children":[{"ID":"20250915163746-uar6l0e","Type":"NodeParagraph","Properties":{"id":"20250915163746-uar6l0e","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 随着模型规模的增加，人们识别新闻文章是否由模型生成的能力（通过正确分配与非中性分配的比率衡量）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"下降"},{"Type":"NodeText","Data":"。对故意差的控制模型输出的准确率用顶部的虚线表示，随机机会（50%）用底部的虚线表示。最佳拟合是一条幂律，带有95%的置信区间。"}]}]}]},{"ID":"20250915163746-7dralos","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-7dralos","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-g9ggcqw","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-g9ggcqw","updated":"20250915163746"},"Children":[{"ID":"20250915163746-zsegtl9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-zsegtl9","updated":"20250915163746"},"Children":[{"ID":"20250915163746-kpwmw7s","Type":"NodeParagraph","Properties":{"id":"20250915163746-kpwmw7s","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"这张图是表3.11数据的可视化，并加入了拟合曲线。"}]}]},{"ID":"20250915163746-p6dkbl7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-p6dkbl7","updated":"20250915163746"},"Children":[{"ID":"20250915163746-cwp01t3","Type":"NodeParagraph","Properties":{"id":"20250915163746-cwp01t3","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰的负相关趋势"},{"Type":"NodeText","Data":": 图中的数据点和拟合曲线清晰地显示出一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强烈的负相关"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型参数量越大，人类的识别准确率就越低"},{"Type":"NodeText","Data":"。这条向下的曲线直观地展示了模型生成文本质量的飞跃。"}]}]},{"ID":"20250915163746-ezt91u3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ezt91u3","updated":"20250915163746"},"Children":[{"ID":"20250915163746-5u2b48v","Type":"NodeParagraph","Properties":{"id":"20250915163746-5u2b48v","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逼近随机猜测"},{"Type":"NodeText","Data":": 曲线的终点（175B模型）已经非常接近50%的随机猜测线，这再次强调了其生成文本的逼真程度。"}]}]}]}]},{"ID":"20250915163746-p6wh6gy","Type":"NodeTable","TableAligns":[1,1,1,1,1],"Properties":{"colgroup":"||||","id":"20250915163746-p6wh6gy","updated":"20250915163748"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"平均准确率"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"95%置信区间 (低, 高)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"与控制组比较的t值 (p值)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"“我不知道”的分配比例"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"控制组"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"88%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"84%-91%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.7%"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT-3 175B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"52%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"48%-57%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"12.7 (3.2e-23)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"10.6%"}]}]}]},{"ID":"20250915163746-6oqkjhz","Type":"NodeBlockquote","Properties":{"id":"20250915163746-6oqkjhz","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-6srxqcq","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-6srxqcq","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3.12：人们识别是否为模型生成的"},{"Type":"NodeTextMark","TextMarkType":"u","TextMarkTextContent":"**较长**"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"（~500词）文章的能力"}]},{"ID":"20250915163746-4zxxnt0","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-4zxxnt0","updated":"20250915163746"},"Children":[{"ID":"20250915163746-vrgwh6q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-vrgwh6q","updated":"20250915163746"},"Children":[{"ID":"20250915163746-lgrmz5c","Type":"NodeParagraph","Properties":{"id":"20250915163746-lgrmz5c","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格说明:"},{"Type":"NodeText","Data":" 该表显示了人们识别是否为模型生成的文章的结果（通过正确分配与非中-性分配的比率衡量）。结果与控制模型和GPT-3 175B进行了比较，并显示了比较平均准确率与控制模型差异的双样本T检验结果。"}]}]}]},{"ID":"20250915163746-tap3c0n","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-tap3c0n","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-r6elxc6","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-r6elxc6","updated":"20250915163746"},"Children":[{"ID":"20250915163746-occvrw8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-occvrw8","updated":"20250915163746"},"Children":[{"ID":"20250915163746-n4tde9j","Type":"NodeParagraph","Properties":{"id":"20250915163746-n4tde9j","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"这张表的结果进一步加强了之前的结论。即使将文章长度增加到500词，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类的辨别准确率依然只有52%"},{"Type":"NodeText","Data":"。这表明GPT-3不仅能写出连贯的段落，还能维持"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长达数百词的篇章一致性"},{"Type":"NodeText","Data":"，这是之前模型难以企及的。"}]}]}]}]},{"ID":"20250915163746-35suol8","Type":"NodeParagraph","Properties":{"id":"20250915163746-35suol8","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914161512-t0w45l6.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163746-hhmtuv3","Type":"NodeBlockquote","Properties":{"id":"20250915163746-hhmtuv3","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-1ehcll3","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-1ehcll3","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.14：GPT-3生成的、人类最难辨别的新闻文章示例"}]},{"ID":"20250915163746-1rwm726","Type":"NodeParagraph","Properties":{"id":"20250915163746-1rwm726","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163746-8l9eo9o","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-8l9eo9o","updated":"20250915163746"},"Children":[{"ID":"20250915163746-91rqt50","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-91rqt50","updated":"20250915163746"},"Children":[{"ID":"20250915163746-7yfpi5x","Type":"NodeParagraph","Properties":{"id":"20250915163746-7yfpi5x","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标题:"},{"Type":"NodeText","Data":" 联合卫理公会同意历史性分裂 (United Methodists Agree to Historic Split)"}]}]},{"ID":"20250915163746-lrk2oim","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-lrk2oim","updated":"20250915163746"},"Children":[{"ID":"20250915163746-1d3cw9s","Type":"NodeParagraph","Properties":{"id":"20250915163746-1d3cw9s","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"副标题:"},{"Type":"NodeText","Data":" 那些反对同性婚姻的人将组建自己的教派 (Those who oppose gay marriage will form their own denomination)"}]}]},{"ID":"20250915163746-ekd89ib","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ekd89ib","updated":"20250915163746"},"Children":[{"ID":"20250915163746-1x51x4d","Type":"NodeParagraph","Properties":{"id":"20250915163746-1x51x4d","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文章:"},{"Type":"NodeText","Data":" (文章内容细节略，描述了联合卫理公会因对LGBTQ问题的分歧而决定分裂的事件。)"}]}]},{"ID":"20250915163746-tbs9wcy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-tbs9wcy","updated":"20250915163746"},"Children":[{"ID":"20250915163746-7t0e468","Type":"NodeParagraph","Properties":{"id":"20250915163746-7t0e468","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 人类最难从人类撰写的文章中区分出来的GPT-3生成的文章（准确率：12%）。"}]}]}]},{"ID":"20250915163746-gqecx6m","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-gqecx6m","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-7gf4agy","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-7gf4agy","updated":"20250915163746"},"Children":[{"ID":"20250915163746-vis9n5d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-vis9n5d","updated":"20250915163746"},"Children":[{"ID":"20250915163746-8n2d2s0","Type":"NodeParagraph","Properties":{"id":"20250915163746-8n2d2s0","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"这个示例文本展示了GPT-3生成高质量新闻的能力。文本"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构清晰、语言流畅、事实陈述（尽管可能是编造的）合乎逻辑"},{"Type":"NodeText","Data":"，并且紧扣标题和副标题。人类的辨别准确率只有12%，几乎完全被欺骗。"}]}]}]}]},{"ID":"20250915163746-xb5y9a2","Type":"NodeParagraph","Properties":{"id":"20250915163746-xb5y9a2","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914161519-70z370p.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163746-942rmzv","Type":"NodeBlockquote","Properties":{"id":"20250915163746-942rmzv","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-rtxihnf","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-rtxihnf","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.15：GPT-3生成的、人类最容易辨别的新闻文章示例"}]},{"ID":"20250915163746-py0d1zk","Type":"NodeParagraph","Properties":{"id":"20250915163746-py0d1zk","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163746-tc7in1x","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-tc7in1x","updated":"20250915163746"},"Children":[{"ID":"20250915163746-xtgd2ev","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-xtgd2ev","updated":"20250915163746"},"Children":[{"ID":"20250915163746-9zep5cs","Type":"NodeParagraph","Properties":{"id":"20250915163746-9zep5cs","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标题:"},{"Type":"NodeText","Data":" 斯塔尔的税收承诺引来梅根·凯利的嘲讽 (Star’s Tax Promise Draws Megyn Kelly’s Sarcasm)"}]}]},{"ID":"20250915163746-olx6ksz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-olx6ksz","updated":"20250915163746"},"Children":[{"ID":"20250915163746-bob6kqg","Type":"NodeParagraph","Properties":{"id":"20250915163746-bob6kqg","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"副标题:"},{"Type":"NodeText","Data":" 华金·菲尼克斯承诺为每个奖项穿同一件燕尾服 (Joaquin Phoenix pledged to wear the same tuxedo for each awards event)"}]}]},{"ID":"20250915163746-luhxby3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-luhxby3","updated":"20250915163746"},"Children":[{"ID":"20250915163746-uvo1ohu","Type":"NodeParagraph","Properties":{"id":"20250915163746-uvo1ohu","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文章:"},{"Type":"NodeText","Data":" (文章内容细节略，描述了演员华金·菲尼克斯的环保承诺以及主持人梅根·凯利在脱口秀上的反应。)"}]}]},{"ID":"20250915163746-r9x4jbj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-r9x4jbj","updated":"20250915163746"},"Children":[{"ID":"20250915163746-idry7o7","Type":"NodeParagraph","Properties":{"id":"20250915163746-idry7o7","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" 人类最容易从人类撰写的文章中区分出来的GPT-3生成的新闻文章（准确率：61%）。"}]}]}]},{"ID":"20250915163746-dz44liw","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-dz44liw","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-q5716fy","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-q5716fy","updated":"20250915163746"},"Children":[{"ID":"20250915163746-5ju4ga3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-5ju4ga3","updated":"20250915163746"},"Children":[{"ID":"20250915163746-q09atz1","Type":"NodeParagraph","Properties":{"id":"20250915163746-q09atz1","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"这个示例虽然仍然连贯，但可能在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"细节、逻辑或风格上存在一些瑕疵"},{"Type":"NodeText","Data":"，使得超过60%的人能够识别出其机器生成的痕迹。这表明模型的生成能力并非完美无瑕。"}]}]}]}]},{"ID":"20250915163746-nrcymnt","Type":"NodeParagraph","Properties":{"id":"20250915163746-nrcymnt","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.5 学习和使用新词 (Learning and Using Novel Words)"}]},{"ID":"20250915163746-w1w60i1","Type":"NodeParagraph","Properties":{"id":"20250915163746-w1w60i1","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"一项在发展语言学中研究的任务是[CB78]，即人类作者学习和使用新词的能力，例如，在句子中看到一个词一次后，能够使用它，或者相反地，仅通过一次使用就能推断出一个词的含义。我们定性地测试了GPT-3执行前一项任务的能力。具体来说，我们给GPT-3一个不存在的词的定义，比如“Gigramuru”，然后要求它在一个句子中使用它。我们为5个不同的示例（一个单独的）提供了五个之前的示例..."}]},{"ID":"20250915163746-q8vqyfi","Type":"NodeParagraph","Properties":{"id":"20250915163746-q8vqyfi","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250914161528-7v54uwn.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915163746-ggu4s0s","Type":"NodeBlockquote","Properties":{"id":"20250915163746-ggu4s0s","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-b64u3ml","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915163746-b64u3ml","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.16：GPT-3在少样本任务“使用新词造句”中的补全示例"}]},{"ID":"20250915163746-v0irhlr","Type":"NodeParagraph","Properties":{"id":"20250915163746-v0irhlr","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915163746-stw5gs7","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-stw5gs7","updated":"20250915163746"},"Children":[{"ID":"20250915163746-tj9zp6l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-tj9zp6l","updated":"20250915163746"},"Children":[{"ID":"20250915163746-qke5kg3","Type":"NodeParagraph","Properties":{"id":"20250915163746-qke5kg3","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例1 (whatpu):"}]},{"ID":"20250915163746-rhc42av","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-rhc42av","updated":"20250915163746"},"Children":[{"ID":"20250915163746-aasts4k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-aasts4k","updated":"20250915163746"},"Children":[{"ID":"20250915163746-e852oao","Type":"NodeParagraph","Properties":{"id":"20250915163746-e852oao","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “whatpu”是一种生活在坦桑尼亚的毛茸茸的小动物。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我们去非洲旅行，看到了这些非常可爱的whatpus。"}]}]}]}]},{"ID":"20250915163746-9elxt01","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-9elxt01","updated":"20250915163746"},"Children":[{"ID":"20250915163746-zuvjd2i","Type":"NodeParagraph","Properties":{"id":"20250915163746-zuvjd2i","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例2 (farduddle):"}]},{"ID":"20250915163746-iupfr9w","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-iupfr9w","updated":"20250915163746"},"Children":[{"ID":"20250915163746-ybkv2gh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ybkv2gh","updated":"20250915163746"},"Children":[{"ID":"20250915163746-u8iue1q","Type":"NodeParagraph","Properties":{"id":"20250915163746-u8iue1q","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “farduddle”的意思是跳起来让人发笑。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有一天，当我和我的小妹妹玩的时候，她真的很兴奋，开始做这些疯狂的farduddles。"}]}]}]}]},{"ID":"20250915163746-3bndjbj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-3bndjbj","updated":"20250915163746"},"Children":[{"ID":"20250915163746-zgb1qx6","Type":"NodeParagraph","Properties":{"id":"20250915163746-zgb1qx6","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例3 (yalubalu):"}]},{"ID":"20250915163746-d92ifhq","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-d92ifhq","updated":"20250915163746"},"Children":[{"ID":"20250915163746-scpq3g0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-scpq3g0","updated":"20250915163746"},"Children":[{"ID":"20250915163746-egyimwp","Type":"NodeParagraph","Properties":{"id":"20250915163746-egyimwp","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “yalubalu”是一种看起来像个大南瓜的水果。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我去了特立尼达旅行，我尝试了这种在花园里种植的叫做yalubalu的水果。它很美味。"}]}]}]}]},{"ID":"20250915163746-agl38sc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-agl38sc","updated":"20250915163746"},"Children":[{"ID":"20250915163746-0zwmms3","Type":"NodeParagraph","Properties":{"id":"20250915163746-0zwmms3","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例4 (Burringo):"}]},{"ID":"20250915163746-stvslxv","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-stvslxv","updated":"20250915163746"},"Children":[{"ID":"20250915163746-3latxmr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-3latxmr","updated":"20250915163746"},"Children":[{"ID":"20250915163746-ijrzvbx","Type":"NodeParagraph","Properties":{"id":"20250915163746-ijrzvbx","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “Burringo”是一种加速非常快的汽车。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在我们的车库里，我们有一辆我父亲每天开去上班的Burringo。"}]}]}]}]},{"ID":"20250915163746-1cfkxyi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-1cfkxyi","updated":"20250915163746"},"Children":[{"ID":"20250915163746-c8xdqp3","Type":"NodeParagraph","Properties":{"id":"20250915163746-c8xdqp3","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例5 (Gigamuru):"}]},{"ID":"20250915163746-uwxghhk","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-uwxghhk","updated":"20250915163746"},"Children":[{"ID":"20250915163746-8w9re9r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-8w9re9r","updated":"20250915163746"},"Children":[{"ID":"20250915163746-8cigmla","Type":"NodeParagraph","Properties":{"id":"20250915163746-8cigmla","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “Gigamuru”是一种日本乐器。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我有一个我叔叔作为礼物送给我的Gigamuru。我喜欢在家里弹奏它。"}]}]}]}]},{"ID":"20250915163746-jvnjbu1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-jvnjbu1","updated":"20250915163746"},"Children":[{"ID":"20250915163746-sai1sxx","Type":"NodeParagraph","Properties":{"id":"20250915163746-sai1sxx","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例6 (screeg):"}]},{"ID":"20250915163746-3ynguv2","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-3ynguv2","updated":"20250915163746"},"Children":[{"ID":"20250915163746-ugeq0oo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ugeq0oo","updated":"20250915163746"},"Children":[{"ID":"20250915163746-x17m0h8","Type":"NodeParagraph","Properties":{"id":"20250915163746-x17m0h8","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示:"},{"Type":"NodeText","Data":" “screeg”的意思是在空中挥舞一把剑。一个使用这个词的句子例子是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我们练习了几个小时的尖叫，然后我们出去吃了冰淇淋。"}]}]}]}]},{"ID":"20250915163746-potq65i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-potq65i","updated":"20250915163746"},"Children":[{"ID":"20250915163746-efahh48","Type":"NodeParagraph","Properties":{"id":"20250915163746-efahh48","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明:"},{"Type":"NodeText","Data":" GPT-3在一个少样本任务中的补全，即在一个句子中使用一个新词。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加粗"},{"Type":"NodeText","Data":"的补全是GPT-3的，纯文本是人类的提示。在第一个示例中，提示和补全都是由人类提供的；这之后作为后续示例的条件，其中GPT-3接收额外的提示并提供这里显示的补全。具体任务是提供GPT-3其他没有条件限制的补全。"}]}]}]},{"ID":"20250915163746-1059gns","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-1059gns","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-5hho74x","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-5hho74x","updated":"20250915163746"},"Children":[{"ID":"20250915163746-jn78r1s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-jn78r1s","updated":"20250915163746"},"Children":[{"ID":"20250915163746-t8wllkq","Type":"NodeParagraph","Properties":{"id":"20250915163746-t8wllkq","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"这张图展示了GPT-3"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"惊人的快速学习和泛化能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915163746-lzhbs4k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-lzhbs4k","updated":"20250915163746"},"Children":[{"ID":"20250915163746-86ppwuy","Type":"NodeParagraph","Properties":{"id":"20250915163746-86ppwuy","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一步到位的学习 (One-shot Learning)"},{"Type":"NodeText","Data":": 模型只需要看到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个"},{"Type":"NodeText","Data":"“定义+例句”的模式，就能立刻理解任务要求，并为后续给出的新词和定义生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语法正确、语义恰当"},{"Type":"NodeText","Data":"的句子。"}]}]},{"ID":"20250915163746-ytfb482","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-ytfb482","updated":"20250915163746"},"Children":[{"ID":"20250915163746-z1i0kp6","Type":"NodeParagraph","Properties":{"id":"20250915163746-z1i0kp6","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越模仿"},{"Type":"NodeText","Data":": 模型生成的句子不仅仅是对示例的简单模仿。例如，它能正确地将名词“whatpu”变为复数“whatpus”，将动词“screeg”变为过去式“screeged”（尽管生成的句子有点奇怪）。这表明它"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将新词整合进了其已有的语法和语义框架中"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250915163746-igdbt34","Type":"NodeParagraph","Properties":{"id":"20250915163746-igdbt34","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"不存在的词被定义并用在一个句子中，所以任务是在之前的示例中看到一个不存在的词的定义和用法后，在少样本中执行。图3.16显示了6个示例，其中前几个示例是人类生成的，第一个答案是人类生成的作为条件，而所有后续答案都是由GPT-3生成的，没有重新尝试或挑选任何提示。在所有情况下，生成的句子似乎都是对单词的正确或至少是合理的使用。在最后一个示例中，模型生成了动词“screeg”（即“screeged”）的合理变化形式，尽管最终的句子有点奇怪（“screeged at each other”），尽管在它能描述一场玩具剑斗的意义上是合理的。总的来说，GPT-3似乎至少能初步胜任在一个句子中使用新词的任务。"}]},{"ID":"20250915163746-qamroz8","Type":"NodeParagraph","Properties":{"id":"20250915163746-qamroz8","updated":"20250915163748"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.9.6 语法改错 (Correcting English Grammar)"}]},{"ID":"20250915163746-dmqv22b","Type":"NodeParagraph","Properties":{"id":"20250915163746-dmqv22b","updated":"20250915163748"},"Children":[{"Type":"NodeText","Data":"另一项可以很好地用少样本学习来设置的任务是纠正英语语法。我们通过给出“Poor English input: \u003c句子\u003e\\n Good English output: \u003c句子\u003e”形式的提示来测试GPT-3。我们给了GPT-3一个人类生成的示例，然后要求它纠正5个更多的示例（没有任何遗漏或重复）。结果显示在图3.17中。"}]},{"ID":"20250915163746-b8qeyfv","Type":"NodeBlockquote","Properties":{"id":"20250915163746-b8qeyfv","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-uq4mxf6","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-uq4mxf6","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915163746-vu2lt86","Type":"NodeParagraph","Properties":{"id":"20250915163746-vu2lt86","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本节缺少图3.17"},{"Type":"NodeText","Data":"，但根据文本描述，我们可以推断出其核心内容。"}]},{"ID":"20250915163746-rbkagey","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-rbkagey","updated":"20250915163746"},"Children":[{"ID":"20250915163746-dt5yrwu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-dt5yrwu","updated":"20250915163746"},"Children":[{"ID":"20250915163746-6tyaxpx","Type":"NodeParagraph","Properties":{"id":"20250915163746-6tyaxpx","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强大的零/少样本语法能力"},{"Type":"NodeText","Data":": 类似于使用新词，语法改错也是一个极佳的上下文学习应用场景。通过提供一个“错误 -\u003e 正确”的示例，模型就能理解任务模式，并对新的错误句子进行修改。这利用了模型在预训练阶段学到的海量关于正确语法的知识。这项能力是当前所有大语言模型应用（如写作助手、翻译润色）的基础。"}]}]}]}]},{"ID":"20250915163746-emrtsla","Type":"NodeThematicBreak","Properties":{"id":"20250915163746-emrtsla","updated":"20250915163748"}},{"ID":"20250915163746-1vmk10v","Type":"NodeBlockquote","Properties":{"id":"20250915163746-1vmk10v","updated":"20250915163748"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915163746-gsq3q13","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915163746-gsq3q13","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250915163746-ux665u0","Type":"NodeParagraph","Properties":{"id":"20250915163746-ux665u0","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"本节（3.9）是GPT-3论文中最具启发性和前瞻性的部分，它通过一系列专门设计的、非传统的任务，系统地探测了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越传统NLP基准的、更接近通用智能的能力"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915163746-g0a52ir","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915163746-g0a52ir","updated":"20250915163746"},"Children":[{"ID":"20250915163746-3ebzovb","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915163746-3ebzovb","updated":"20250915163746"},"Children":[{"ID":"20250915163746-4fz2k0r","Type":"NodeParagraph","Properties":{"id":"20250915163746-4fz2k0r","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“涌现”能力的集中展示"},{"Type":"NodeText","Data":": 本节是“能力涌现”现象的集中体现。无论是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算术能力（图3.10）"},{"Type":"NodeText","Data":"还是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符号操作能力（图3.11）"},{"Type":"NodeText","Data":"，都在模型规模跨越某个巨大门槛后，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从无到有地突然出现"},{"Type":"NodeText","Data":"。这强有力地证明了，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"量的积累（模型规模）可以带来质的飞跃（新能力的诞生）"},{"Type":"NodeText","Data":"，这是缩放法则背后最深刻的含义。"}]}]},{"ID":"20250915163746-kktbpxb","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915163746-kktbpxb","updated":"20250915163746"},"Children":[{"ID":"20250915163746-iz8auf6","Type":"NodeParagraph","Properties":{"id":"20250915163746-iz8auf6","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越语言的抽象推理"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915163746-q9wd148","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-q9wd148","updated":"20250915163746"},"Children":[{"ID":"20250915163746-g5zipv0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-g5zipv0","updated":"20250915163746"},"Children":[{"ID":"20250915163746-jl2azam","Type":"NodeParagraph","Properties":{"id":"20250915163746-jl2azam","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算术"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单词乱序"},{"Type":"NodeText","Data":"任务证明了模型具备了一定程度的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符号操作和过程模拟能力"},{"Type":"NodeText","Data":"，它不再仅仅是处理自然语言，而是可以学习和执行抽象的规则。"}]}]},{"ID":"20250915163746-q9k154o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-q9k154o","updated":"20250915163746"},"Children":[{"ID":"20250915163746-3bqchb5","Type":"NodeParagraph","Properties":{"id":"20250915163746-3bqchb5","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAT类比"},{"Type":"NodeText","Data":"任务的成功（图3.12），则证明了模型能够理解和推理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词语之间高度抽象的语义关系"},{"Type":"NodeText","Data":"，其表现甚至超过了人类平均水平，这是其强大认知能力的重要标志。"}]}]}]}]},{"ID":"20250915163746-03qftqr","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915163746-03qftqr","updated":"20250915163746"},"Children":[{"ID":"20250915163746-h6nay02","Type":"NodeParagraph","Properties":{"id":"20250915163746-h6nay02","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以假乱真的创造力"},{"Type":"NodeText","Data":":"}]},{"ID":"20250915163746-zv199gb","Type":"NodeList","ListData":{},"Properties":{"id":"20250915163746-zv199gb","updated":"20250915163746"},"Children":[{"ID":"20250915163746-jse32a9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-jse32a9","updated":"20250915163746"},"Children":[{"ID":"20250915163746-gulr0b6","Type":"NodeParagraph","Properties":{"id":"20250915163746-gulr0b6","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"新闻生成"},{"Type":"NodeText","Data":"任务（表3.11/3.12, 图3.13）的结果是本节乃至整篇论文"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最具社会影响力的发现"},{"Type":"NodeText","Data":"。GPT-3生成的文本能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在统计上与人类创作无法区分"},{"Type":"NodeText","Data":"，这不仅是技术上的巨大成功，也敲响了关于信息真实性、内容创作和人工智能伦理的警钟。"}]}]},{"ID":"20250915163746-g6r3dkq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915163746-g6r3dkq","updated":"20250915163746"},"Children":[{"ID":"20250915163746-lsyzpg9","Type":"NodeParagraph","Properties":{"id":"20250915163746-lsyzpg9","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"使用新词造句"},{"Type":"NodeText","Data":"（图3.16）则展示了模型惊人的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"快速学习和创造性泛化"},{"Type":"NodeText","Data":"能力。它不是死板地模仿，而是能将新概念无缝地融入其庞大的语言知识体系中，并进行创造性的应用。"}]}]}]}]},{"ID":"20250915163746-qh7dxlx","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250915163746-qh7dxlx","updated":"20250915163746"},"Children":[{"ID":"20250915163746-tf91pcr","Type":"NodeParagraph","Properties":{"id":"20250915163746-tf91pcr","updated":"20250915163746"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用能力的统一框架"},{"Type":"NodeText","Data":": 本节的所有任务，尽管五花八门，但都被置于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"同一个上下文学习框架"},{"Type":"NodeText","Data":"下解决。模型无需任何架构改动或微调，仅通过改变提示中的几个示例，就能在算术、符号操作、抽象推理和内容创作等截然不同的任务间自由切换。这完美地诠释了论文的核心思想——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个足够大的语言模型，本身就是一个通用的、可通过上下文指令进行编程的“处理器”"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250915163746-ni9g7r1","Type":"NodeParagraph","Properties":{"id":"20250915163746-ni9g7r1","updated":"20250915163746"},"Children":[{"Type":"NodeText","Data":"总结而言，第3.9节通过一系列巧妙的实验设计，将我们对语言模型的认知从一个“特定任务的解决者”提升到了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通用问题求解器”"},{"Type":"NodeText","Data":"的层面。它所揭示的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力、抽象推理能力和创造能力"},{"Type":"NodeText","Data":"，是GPT-3对人工智能领域最根本、最深远的贡献，并直接开启了我们今天所处的大语言模型时代。直接开启了我们今天所处的大语言模型时代。"}]}]}]},{"ID":"20250915165137-c6dx258","Type":"NodeParagraph","Properties":{"id":"20250915165137-c6dx258","updated":"20250915165137"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915165137-6vtua5u.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250915165027-4tky38k","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915165027-4tky38k","updated":"20250915165027"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915165027-3yq9chz","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915165027-3yq9chz","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3.17：GPT-3在少样本任务“纠正英语语法”中的代表性补全"}]},{"ID":"20250915165027-31d2kb0","Type":"NodeParagraph","Properties":{"id":"20250915165027-31d2kb0","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图片内容翻译:"}]},{"ID":"20250915165027-wzp5xmx","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-wzp5xmx","updated":"20250915165027"},"Children":[{"ID":"20250915165027-pn613jb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-pn613jb","updated":"20250915165027"},"Children":[{"ID":"20250915165027-adbefot","Type":"NodeParagraph","Properties":{"id":"20250915165027-adbefot","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 1:"}]},{"ID":"20250915165027-q9ci087","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-q9ci087","updated":"20250915165027"},"Children":[{"ID":"20250915165027-35bfsks","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-35bfsks","updated":"20250915165027"},"Children":[{"ID":"20250915165027-nfrdm6n","Type":"NodeParagraph","Properties":{"id":"20250915165027-nfrdm6n","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: I eated the purple berries."}]}]},{"ID":"20250915165027-ijytges","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-ijytges","updated":"20250915165027"},"Children":[{"ID":"20250915165027-aohdo7u","Type":"NodeParagraph","Properties":{"id":"20250915165027-aohdo7u","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"好英语输出: I ate the purple berries."}]}]}]}]},{"ID":"20250915165027-j6uvr3a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-j6uvr3a","updated":"20250915165027"},"Children":[{"ID":"20250915165027-au6gtod","Type":"NodeParagraph","Properties":{"id":"20250915165027-au6gtod","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 2:"}]},{"ID":"20250915165027-hlrmoyo","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-hlrmoyo","updated":"20250915165027"},"Children":[{"ID":"20250915165027-wy8mimp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-wy8mimp","updated":"20250915165027"},"Children":[{"ID":"20250915165027-s4cricp","Type":"NodeParagraph","Properties":{"id":"20250915165027-s4cricp","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: Thank you for picking me as your designer. I'd appreciate it."}]}]},{"ID":"20250915165027-zwsim7d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-zwsim7d","updated":"20250915165027"},"Children":[{"ID":"20250915165027-vrqm13w","Type":"NodeParagraph","Properties":{"id":"20250915165027-vrqm13w","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"好英语输出: Thank you for choosing me as your designer. I appreciate it."}]}]}]}]},{"ID":"20250915165027-cxb9klx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-cxb9klx","updated":"20250915165027"},"Children":[{"ID":"20250915165027-98yv8fz","Type":"NodeParagraph","Properties":{"id":"20250915165027-98yv8fz","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 3:"}]},{"ID":"20250915165027-w2ahqv3","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-w2ahqv3","updated":"20250915165027"},"Children":[{"ID":"20250915165027-rq3w99n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-rq3w99n","updated":"20250915165027"},"Children":[{"ID":"20250915165027-td94w6r","Type":"NodeParagraph","Properties":{"id":"20250915165027-td94w6r","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: The mentioned changes have done. or I did the alteration that you requested. or I changed things you wanted and did the modifications."}]}]},{"ID":"20250915165027-23a3etw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-23a3etw","updated":"20250915165027"},"Children":[{"ID":"20250915165027-wxxq6jt","Type":"NodeParagraph","Properties":{"id":"20250915165027-wxxq6jt","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"好英语输出: The requested changes have been made. or I made the alteration that you requested. or I changed things you wanted and made the modifications."}]}]}]}]},{"ID":"20250915165027-xnnaih6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-xnnaih6","updated":"20250915165027"},"Children":[{"ID":"20250915165027-vgna0ah","Type":"NodeParagraph","Properties":{"id":"20250915165027-vgna0ah","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 4:"}]},{"ID":"20250915165027-14zmixb","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-14zmixb","updated":"20250915165027"},"Children":[{"ID":"20250915165027-movtj89","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-movtj89","updated":"20250915165027"},"Children":[{"ID":"20250915165027-mk7nejj","Type":"NodeParagraph","Properties":{"id":"20250915165027-mk7nejj","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: I'd be more than happy to work with you in another project."}]}]},{"ID":"20250915165027-w0vo5kg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-w0vo5kg","updated":"20250915165027"},"Children":[{"ID":"20250915165027-uo6q7gh","Type":"NodeParagraph","Properties":{"id":"20250915165027-uo6q7gh","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"好英语输出: I'd be more than happy to work with you on another project."}]}]}]}]},{"ID":"20250915165027-iwym2jt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-iwym2jt","updated":"20250915165027"},"Children":[{"ID":"20250915165027-bkwmib5","Type":"NodeParagraph","Properties":{"id":"20250915165027-bkwmib5","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 5:"}]},{"ID":"20250915165027-946g89t","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-946g89t","updated":"20250915165027"},"Children":[{"ID":"20250915165027-pqqy1td","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-pqqy1td","updated":"20250915165027"},"Children":[{"ID":"20250915165027-qlr7aaj","Type":"NodeParagraph","Properties":{"id":"20250915165027-qlr7aaj","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: Please provide me with a short brief of the design you're looking for and that'd be nice if you could share some examples or project you did before."}]}]},{"ID":"20250915165027-336zc1m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-336zc1m","updated":"20250915165027"},"Children":[{"ID":"20250915165027-jr1o2i6","Type":"NodeParagraph","Properties":{"id":"20250915165027-jr1o2i6","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"好英语输出: Please provide me with a brief description of the design you're looking for and that would be nice if you could share some examples or projects you have done before."}]}]}]}]},{"ID":"20250915165027-9obbjq8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-9obbjq8","updated":"20250915165027"},"Children":[{"ID":"20250915165027-ynepztr","Type":"NodeParagraph","Properties":{"id":"20250915165027-ynepztr","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 6:"}]},{"ID":"20250915165027-mndnsiq","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-mndnsiq","updated":"20250915165027"},"Children":[{"ID":"20250915165027-v49qdo0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-v49qdo0","updated":"20250915165027"},"Children":[{"ID":"20250915165027-hovc6w8","Type":"NodeParagraph","Properties":{"id":"20250915165027-hovc6w8","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: The patient was died."}]}]},{"ID":"20250915165027-snbkga4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-snbkga4","updated":"20250915165027"},"Children":[{"ID":"20250915165027-b9rlljd","Type":"NodeParagraph","Properties":{"id":"20250915165027-b9rlljd","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"好英语输出: The patient died."}]}]}]}]},{"ID":"20250915165027-mb0uytc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-mb0uytc","updated":"20250915165027"},"Children":[{"ID":"20250915165027-xthtr1b","Type":"NodeParagraph","Properties":{"id":"20250915165027-xthtr1b","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 7:"}]},{"ID":"20250915165027-ad8iwro","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-ad8iwro","updated":"20250915165027"},"Children":[{"ID":"20250915165027-31aqc1n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-31aqc1n","updated":"20250915165027"},"Children":[{"ID":"20250915165027-dkgxni8","Type":"NodeParagraph","Properties":{"id":"20250915165027-dkgxni8","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: We think that Leslie likes ourselves."}]}]},{"ID":"20250915165027-ygbd314","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-ygbd314","updated":"20250915165027"},"Children":[{"ID":"20250915165027-4ev8o20","Type":"NodeParagraph","Properties":{"id":"20250915165027-4ev8o20","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"好英语输出: We think that Leslie likes us."}]}]}]}]},{"ID":"20250915165027-6wgvfo5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-6wgvfo5","updated":"20250915165027"},"Children":[{"ID":"20250915165027-kww7w4m","Type":"NodeParagraph","Properties":{"id":"20250915165027-kww7w4m","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 8:"}]},{"ID":"20250915165027-fdb8utv","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-fdb8utv","updated":"20250915165027"},"Children":[{"ID":"20250915165027-kjkj2dv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-kjkj2dv","updated":"20250915165027"},"Children":[{"ID":"20250915165027-803fns1","Type":"NodeParagraph","Properties":{"id":"20250915165027-803fns1","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: Janet broke Bill on the finger."}]}]},{"ID":"20250915165027-g5o6p6h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-g5o6p6h","updated":"20250915165027"},"Children":[{"ID":"20250915165027-t8rr3rn","Type":"NodeParagraph","Properties":{"id":"20250915165027-t8rr3rn","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"好英语输出: Janet broke Bill's finger."}]}]}]}]},{"ID":"20250915165027-0uxozlr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-0uxozlr","updated":"20250915165027"},"Children":[{"ID":"20250915165027-7vnp6i0","Type":"NodeParagraph","Properties":{"id":"20250915165027-7vnp6i0","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 9:"}]},{"ID":"20250915165027-lb1dyrl","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-lb1dyrl","updated":"20250915165027"},"Children":[{"ID":"20250915165027-5ba04ul","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-5ba04ul","updated":"20250915165027"},"Children":[{"ID":"20250915165027-z76vu0w","Type":"NodeParagraph","Properties":{"id":"20250915165027-z76vu0w","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: Mary arranged for, in St. Louis, John to rent a house cheap."}]}]},{"ID":"20250915165027-s4xwu8j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-s4xwu8j","updated":"20250915165027"},"Children":[{"ID":"20250915165027-psawjvq","Type":"NodeParagraph","Properties":{"id":"20250915165027-psawjvq","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"好英语输出: Mary arranged for John to rent a house in St. Louis."}]}]}]}]},{"ID":"20250915165027-bstdjou","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-bstdjou","updated":"20250915165027"},"Children":[{"ID":"20250915165027-4d1zycf","Type":"NodeParagraph","Properties":{"id":"20250915165027-4d1zycf","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 10:"}]},{"ID":"20250915165027-kqkl44a","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-kqkl44a","updated":"20250915165027"},"Children":[{"ID":"20250915165027-92z0wdc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-92z0wdc","updated":"20250915165027"},"Children":[{"ID":"20250915165027-9orcpnr","Type":"NodeParagraph","Properties":{"id":"20250915165027-9orcpnr","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: Today I have went to the store to to buys some many bottle of water."}]}]},{"ID":"20250915165027-5eldx4m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-5eldx4m","updated":"20250915165027"},"Children":[{"ID":"20250915165027-9uu9lnm","Type":"NodeParagraph","Properties":{"id":"20250915165027-9uu9lnm","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"好英语输出: Today I went to the store to buy some bottles of water."}]}]}]}]},{"ID":"20250915165027-abfar20","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-abfar20","updated":"20250915165027"},"Children":[{"ID":"20250915165027-rjiju2f","Type":"NodeParagraph","Properties":{"id":"20250915165027-rjiju2f","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例 11:"}]},{"ID":"20250915165027-nwtlzbu","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-nwtlzbu","updated":"20250915165027"},"Children":[{"ID":"20250915165027-jea3y6k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-jea3y6k","updated":"20250915165027"},"Children":[{"ID":"20250915165027-crrlyyj","Type":"NodeParagraph","Properties":{"id":"20250915165027-crrlyyj","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"差英语输入: I have tried to hit ball with bat, but my swing is has miss."}]}]},{"ID":"20250915165027-wtb3xiq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-wtb3xiq","updated":"20250915165027"},"Children":[{"ID":"20250915165027-k3fzvbp","Type":"NodeParagraph","Properties":{"id":"20250915165027-k3fzvbp","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"好英语输出: I tried to hit the ball with the bat, but my swing missed."}]}]}]}]}]},{"ID":"20250915165027-vxmic96","Type":"NodeParagraph","Properties":{"id":"20250915165027-vxmic96","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解说明翻译:"}]},{"ID":"20250915165027-9amcuuk","Type":"NodeParagraph","Properties":{"id":"20250915165027-9amcuuk","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"GPT-3在少样本任务“纠正英语语法”中的代表性补全。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加粗字体"},{"Type":"NodeText","Data":"是GPT-3的补全，纯文本是人类的提示。在最初的几个示例中，提示和补全都是由人类提供的；这之后作为后续示例的条件，GPT-3接收额外的提示并提供补全。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"除了最初的几个作为条件的示例和“差英语输入/好英语输出”的框架外，没有向GPT-3提供特定于任务的训练"},{"Type":"NodeText","Data":"。我们注意到，“差”英语和“好”英语之间的区别（以及这些术语本身）是复杂的、上下文相关的和有争议的。如提到租房的例子所示，模型对什么是“好”的假设甚至可能导致它犯错（在这里，模型不仅调整了语法，还删除了单词“cheap”，从而改变了含义）。"}]},{"ID":"20250915165027-idr0bip","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915165027-idr0bip","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250915165027-ef0eqq3","Type":"NodeParagraph","Properties":{"id":"20250915165027-ef0eqq3","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"这张图生动地展示了GPT-3作为一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强大的、零样本/少样本的语法和风格润色工具"},{"Type":"NodeText","Data":"的潜力。"}]},{"ID":"20250915165027-omdbi47","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915165027-omdbi47","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心能力：模式识别与知识应用"}]},{"ID":"20250915165027-96d1m8r","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-96d1m8r","updated":"20250915165027"},"Children":[{"ID":"20250915165027-by3bbyf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-by3bbyf","updated":"20250915165027"},"Children":[{"ID":"20250915165027-dq0zne6","Type":"NodeParagraph","Properties":{"id":"20250915165027-dq0zne6","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"快速学习任务格式"},{"Type":"NodeText","Data":": 模型只需要看几个“差英语输入 -\u003e 好英语输出”的例子，就能立刻理解这个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"抽象的指令"},{"Type":"NodeText","Data":"。它学会了任务的目标是“改进”第一个句子，并以指定格式输出结果。"}]}]},{"ID":"20250915165027-dehz06w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-dehz06w","updated":"20250915165027"},"Children":[{"ID":"20250915165027-r8w010d","Type":"NodeParagraph","Properties":{"id":"20250915165027-r8w010d","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用内置的语法知识"},{"Type":"NodeText","Data":": GPT-3利用其在海量文本预训练中内化的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"庞大语法和文体知识"},{"Type":"NodeText","Data":"来执行修改。它能纠正各种类型的错误，包括："}]},{"ID":"20250915165027-26hfygf","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-26hfygf","updated":"20250915165027"},"Children":[{"ID":"20250915165027-dyn3pyx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-dyn3pyx","updated":"20250915165027"},"Children":[{"ID":"20250915165027-40if27x","Type":"NodeParagraph","Properties":{"id":"20250915165027-40if27x","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动词时态"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"eated"},{"Type":"NodeText","Data":"​ → "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"ate"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"have went"},{"Type":"NodeText","Data":"​ → "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"went"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"is has miss"},{"Type":"NodeText","Data":"​ → "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"missed"},{"Type":"NodeText","Data":"​"}]}]},{"ID":"20250915165027-8um234o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-8um234o","updated":"20250915165027"},"Children":[{"ID":"20250915165027-85vyjpj","Type":"NodeParagraph","Properties":{"id":"20250915165027-85vyjpj","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词汇选择/搭配"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"picking"},{"Type":"NodeText","Data":"​ → "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"choosing"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"on the finger"},{"Type":"NodeText","Data":"​ → "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Bill's finger"},{"Type":"NodeText","Data":"​ (所有格)"}]}]},{"ID":"20250915165027-wiv7f1z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-wiv7f1z","updated":"20250915165027"},"Children":[{"ID":"20250915165027-fwov2bk","Type":"NodeParagraph","Properties":{"id":"20250915165027-fwov2bk","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代词使用"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"ourselves"},{"Type":"NodeText","Data":"​ → "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"us"},{"Type":"NodeText","Data":"​"}]}]},{"ID":"20250915165027-0xz4k7t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-0xz4k7t","updated":"20250915165027"},"Children":[{"ID":"20250915165027-amwdm2v","Type":"NodeParagraph","Properties":{"id":"20250915165027-amwdm2v","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冗余和简洁性"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"was died"},{"Type":"NodeText","Data":"​ → "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"died"},{"Type":"NodeText","Data":"​ (died本身就是不及物动词)"}]}]},{"ID":"20250915165027-f6tylmt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-f6tylmt","updated":"20250915165027"},"Children":[{"ID":"20250915165027-gmg6t65","Type":"NodeParagraph","Properties":{"id":"20250915165027-gmg6t65","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"句子结构和流畅性"},{"Type":"NodeText","Data":": 示例5中，模型将一个口语化的、结构松散的句子改写得更书面、更流畅。"}]}]}]}]}]},{"ID":"20250915165027-pcm2y87","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915165027-pcm2y87","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越语法：风格与常识的介入"}]},{"ID":"20250915165027-mi30wv9","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-mi30wv9","updated":"20250915165027"},"Children":[{"ID":"20250915165027-5ijb4j2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-5ijb4j2","updated":"20250915165027"},"Children":[{"ID":"20250915165027-56midj8","Type":"NodeParagraph","Properties":{"id":"20250915165027-56midj8","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"这张图最深刻的洞见来自于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例9"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915165027-nod5dgx","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165027-nod5dgx","updated":"20250915165027"},"Children":[{"ID":"20250915165027-ggpl25v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-ggpl25v","updated":"20250915165027"},"Children":[{"ID":"20250915165027-5inaohe","Type":"NodeParagraph","Properties":{"id":"20250915165027-5inaohe","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输入"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Mary arranged for, in St. Louis, John to rent a house cheap."},{"Type":"NodeText","Data":"​"}]}]},{"ID":"20250915165027-jxln0i9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-jxln0i9","updated":"20250915165027"},"Children":[{"ID":"20250915165027-91rn6nk","Type":"NodeParagraph","Properties":{"id":"20250915165027-91rn6nk","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输出"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Mary arranged for John to rent a house in St. Louis."},{"Type":"NodeText","Data":"​"}]}]}]}]},{"ID":"20250915165027-0cts4r8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-0cts4r8","updated":"20250915165027"},"Children":[{"ID":"20250915165027-wrtq1ys","Type":"NodeParagraph","Properties":{"id":"20250915165027-wrtq1ys","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不仅仅是语法修正"},{"Type":"NodeText","Data":": 模型不仅调整了语序，使句子更通顺，还"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主动删除了单词“cheap”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915165027-lqcocah","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-lqcocah","updated":"20250915165027"},"Children":[{"ID":"20250915165027-2eqb7n5","Type":"NodeParagraph","Properties":{"id":"20250915165027-2eqb7n5","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"潜在的“偏见”或“常识”"},{"Type":"NodeText","Data":": 作者敏锐地指出，这可能是因为模型从其训练数据中学到了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文体上的“常识”"},{"Type":"NodeText","Data":"——在正式的、“好”的英语中，明确提及“便宜地”租房可能不那么常见或“得体”。因此，模型做出了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越纯粹语法规则的、带有价值判断的修改"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915165027-ee8awg1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165027-ee8awg1","updated":"20250915165027"},"Children":[{"ID":"20250915165027-4jmk7jp","Type":"NodeParagraph","Properties":{"id":"20250915165027-4jmk7jp","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“好”的复杂性"},{"Type":"NodeText","Data":": 这个例子完美地诠释了图解说明中的观点：“好”英语的定义是复杂的、上下文相关的。模型的修改虽然可能在某些情况下是合适的，但也"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改变了句子的原始语义"},{"Type":"NodeText","Data":"，这揭示了AI进行文本润色时可能存在的风险和挑战。"}]}]}]},{"ID":"20250915165027-tedb186","Type":"NodeThematicBreak","Properties":{"id":"20250915165027-tedb186","updated":"20250915165027"}},{"ID":"20250915165027-23hlxg2","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915165027-23hlxg2","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250915165027-3sbro2p","Type":"NodeParagraph","Properties":{"id":"20250915165027-3sbro2p","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"这张关于语法改错的图，是理解GPT-3"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用语言能力"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习机制"},{"Type":"NodeText","Data":"的一个绝佳窗口。"}]},{"ID":"20250915165027-klxzi2v","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250915165027-klxzi2v","updated":"20250915165027"},"Children":[{"ID":"20250915165027-gc7nmx0","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250915165027-gc7nmx0","updated":"20250915165027"},"Children":[{"ID":"20250915165027-gxhzyoi","Type":"NodeParagraph","Properties":{"id":"20250915165027-gxhzyoi","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的强大范例"},{"Type":"NodeText","Data":": 语法改错任务完美地展示了上下文学习的精髓。通过提供一个简单的“输入-输出”模板和一两个例子，用户就能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“编程”"},{"Type":"NodeText","Data":"这个巨大的语言模型，使其成为一个定制化的语法修正工具，而无需进行任何复杂的微调。这是其作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用工具"},{"Type":"NodeText","Data":"潜力的直接体现。"}]}]},{"ID":"20250915165027-u82p6bq","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250915165027-u82p6bq","updated":"20250915165027"},"Children":[{"ID":"20250915165027-59wvdi1","Type":"NodeParagraph","Properties":{"id":"20250915165027-59wvdi1","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内化知识的深度"},{"Type":"NodeText","Data":": GPT-3能够修正如此多样化的错误，表明它在预训练阶段"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不仅仅是记住了词序列，而是真正内化了一套深刻的、关于英语语法、词汇和风格的复杂规则体系"},{"Type":"NodeText","Data":"。这些知识是隐式地存储在其参数中的，并可以通过上下文提示被有效地“激活”和应用。"}]}]},{"ID":"20250915165027-x7sxcl6","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250915165027-x7sxcl6","updated":"20250915165027"},"Children":[{"ID":"20250915165027-i19v14g","Type":"NodeParagraph","Properties":{"id":"20250915165027-i19v14g","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"智能的“副作用”——偏见与价值判断"},{"Type":"NodeText","Data":": 示例9中删除“cheap”的行为，是理解大语言模型行为模式的关键。它告诉我们，模型的决策"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并非总是基于严格的逻辑或语法规则"},{"Type":"NodeText","Data":"，而是深受其训练数据中蕴含的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统计模式、文体惯例和社会偏见"},{"Type":"NodeText","Data":"的影响。模型认为“好”的英文不应该出现“cheap”，这是一个基于其“经验”的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"价值判断"},{"Type":"NodeText","Data":"，而非语法要求。"}]}]},{"ID":"20250915165027-khgbpqd","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250915165027-khgbpqd","updated":"20250915165027"},"Children":[{"ID":"20250915165027-3txiqis","Type":"NodeParagraph","Properties":{"id":"20250915165027-3txiqis","updated":"20250915165027"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人机协作的未来"},{"Type":"NodeText","Data":": 这个例子预示了未来人与AI协作的模式和挑战。AI可以作为强大的助手，提供语法和风格上的建议，但其修改"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并非总是中立或完全符合用户的本意"},{"Type":"NodeText","Data":"。最终的判断和决策权仍然需要掌握在人类用户手中。理解AI可能带有的这些“偏见”，是有效利用这类工具的前提。"}]}]}]},{"ID":"20250915165027-16enpxe","Type":"NodeParagraph","Properties":{"id":"20250915165027-16enpxe","updated":"20250915165027"},"Children":[{"Type":"NodeText","Data":"总结而言，图3.17不仅展示了GPT-3在实用任务（语法改错）上的强大能力，更通过一个微妙的例子，深刻地揭示了其智能行为背后的复杂性——它是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合了语言规则、统计模式和从数据中习得的“世界观”的智能"},{"Type":"NodeText","Data":"，这既是其强大能力之所在，也是其潜在风险之根源。"}]}]},{"ID":"20250915165213-w8vp5qy","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250915165213-w8vp5qy","updated":"20250915165213"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250915165213-e7uyc44","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250915165213-e7uyc44","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析：GPT-3论文的核心贡献与深远影响"}]},{"ID":"20250915165213-wucrm6p","Type":"NodeParagraph","Properties":{"id":"20250915165213-wucrm6p","updated":"20250915165213"},"Children":[{"Type":"NodeText","Data":"通过对上述所有章节的系统性回顾，我们可以将这篇开创性论文的贡献、发现和启示归纳为以下几个核心层面。这不仅是对一份研究报告的解读，更是对一个人工智能新纪元开端的剖析。"}]},{"ID":"20250915165213-4npfvua","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915165213-4npfvua","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1. 理论基石：可预测的“缩放法则” (Scaling Laws)"}]},{"ID":"20250915165213-qyfpwxv","Type":"NodeParagraph","Properties":{"id":"20250915165213-qyfpwxv","updated":"20250915165213"},"Children":[{"Type":"NodeText","Data":"贯穿整篇论文的理论核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“缩放法则”"},{"Type":"NodeText","Data":"的成功验证。图3.1中那条平滑下降的幂律曲线是所有后续惊人成果的基石。它雄辩地证明了，语言模型的性能并非随机或不可预测的，而是随着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型规模、数据量和计算投入"},{"Type":"NodeText","Data":"的增加而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测地、持续地提升"},{"Type":"NodeText","Data":"。这一发现将大型模型的研究从“炼金术”般的尝试，转变为一种更具工程确定性的科学，为后续投入巨量资源研发更大模型（如GPT-4等）的决策提供了坚实的理论依据。"}]},{"ID":"20250915165213-j6sy1ri","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915165213-j6sy1ri","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2. 范式革命：从“微调”到“上下文学习”"}]},{"ID":"20250915165213-t128uto","Type":"NodeParagraph","Properties":{"id":"20250915165213-t128uto","updated":"20250915165213"},"Children":[{"Type":"NodeText","Data":"GPT-3最重要的贡献，是提出并验证了一种全新的、更灵活高效的AI应用范式——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（In-context Learning）"},{"Type":"NodeText","Data":"。它系统地挑战了此前占主导地位的“预训练+微调”模式。"}]},{"ID":"20250915165213-3cszyi9","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165213-3cszyi9","updated":"20250915165213"},"Children":[{"ID":"20250915165213-1522i5f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165213-1522i5f","updated":"20250915165213"},"Children":[{"ID":"20250915165213-6ioudou","Type":"NodeParagraph","Properties":{"id":"20250915165213-6ioudou","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调 (Fine-Tuning)"},{"Type":"NodeText","Data":"：像一个专科生，需要为每一门新“课程”（任务）做大量的“作业”（成千上万的标注数据）来调整自己的“知识结构”（模型权重）。"}]}]},{"ID":"20250915165213-tqnqern","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165213-tqnqern","updated":"20250915165213"},"Children":[{"ID":"20250915165213-i31rxxn","Type":"NodeParagraph","Properties":{"id":"20250915165213-i31rxxn","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (In-Context Learning)"},{"Type":"NodeText","Data":"：则像一个博学通识的天才，无需改变自己的知识结构，仅通过在“考卷”（提示）上阅读"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"寥寥数个例题（Few-Shot）"},{"Type":"NodeText","Data":"，甚至只看"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一道例题（One-Shot）"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅读题干（Zero-Shot）"},{"Type":"NodeText","Data":"，就能迅速理解任务要求并给出高质量的解答。"}]}]}]},{"ID":"20250915165213-f14a6jx","Type":"NodeParagraph","Properties":{"id":"20250915165213-f14a6jx","updated":"20250915165213"},"Children":[{"Type":"NodeText","Data":"这一转变极大地降低了模型适应新任务的门槛，催生了“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程（Prompt Engineering）"},{"Type":"NodeText","Data":"”这一全新领域，使得一个单一的、巨大的模型成为了一个可以通过自然语言进行“编程”的通用任务处理器。"}]},{"ID":"20250915165213-lgn1hs6","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915165213-lgn1hs6","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3. 惊人的“能力涌现”：通用智能的曙光"}]},{"ID":"20250915165213-k86jew0","Type":"NodeParagraph","Properties":{"id":"20250915165213-k86jew0","updated":"20250915165213"},"Children":[{"Type":"NodeText","Data":"论文中最激动人心的部分，莫过于在第3.9节中展示的、模型在训练时从未明确学习过却在规模达到顶峰时突然出现的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“涌现能力”（Emergent Abilities）"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250915165213-6im5etv","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165213-6im5etv","updated":"20250915165213"},"Children":[{"ID":"20250915165213-56y6il6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165213-56y6il6","updated":"20250915165213"},"Children":[{"ID":"20250915165213-mmuzlqj","Type":"NodeParagraph","Properties":{"id":"20250915165213-mmuzlqj","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算术能力"},{"Type":"NodeText","Data":"：图3.10清晰地显示，算术能力在模型参数达到1750亿时"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从无到有地爆发"},{"Type":"NodeText","Data":"。模型甚至会犯“不进位”这类与人类相似的错误，表明它在尝试模拟一个计算过程，而非死记硬背。"}]}]},{"ID":"20250915165213-rekf0lc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165213-rekf0lc","updated":"20250915165213"},"Children":[{"ID":"20250915165213-63a2h4a","Type":"NodeParagraph","Properties":{"id":"20250915165213-63a2h4a","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符号操作与抽象推理"},{"Type":"NodeText","Data":"：单词乱序、SAT类比等任务的成功，证明了模型具备了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越单纯语言模仿的抽象规则学习和符号操作能力"},{"Type":"NodeText","Data":"。它能“看穿”词元（Token）的表象，深入字符层面进行操作，并理解词语间高度抽象的逻辑关系，甚至在SAT类比上"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越了人类平均水平"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915165213-vacb1fk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165213-vacb1fk","updated":"20250915165213"},"Children":[{"ID":"20250915165213-e98oib1","Type":"NodeParagraph","Properties":{"id":"20250915165213-e98oib1","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以假乱真的创造力"},{"Type":"NodeText","Data":"：新闻文章生成任务的结果是其创造能力的巅峰体现。在图3.13和表3.11/3.12中，175B模型生成的文章使人类的辨别准确率"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"降至52%"},{"Type":"NodeText","Data":"，几乎与随机猜测无异。这不仅是技术上的巨大飞跃，也标志着AI生成内容（AIGC）时代的真正到来。"}]}]}]},{"ID":"20250915165213-ttenvzl","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915165213-ttenvzl","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4. 模型即知识库：内化世界知识的突破"}]},{"ID":"20250915165213-gqbtw7q","Type":"NodeParagraph","Properties":{"id":"20250915165213-gqbtw7q","updated":"20250915165213"},"Children":[{"Type":"NodeText","Data":"第3.2节的“闭卷问答”实验，是论文的另一个里程碑式贡献。通过在TriviaQA等任务上，以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“无微调+闭卷”"},{"Type":"NodeText","Data":"的极简形式，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"匹敌甚至超越"},{"Type":"NodeText","Data":"了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“微调+开卷（检索外部文档）”"},{"Type":"NodeText","Data":"的复杂系统，GPT-3证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个足够大的语言模型本身就可以成为一个庞大、可查询的知识库"},{"Type":"NodeText","Data":"。知识不再仅仅是存储在外部数据库中的符号，而是可以被"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐式地、高度压缩地编码在模型的亿万参数之中"},{"Type":"NodeText","Data":"，并通过上下文提示被灵活地调用。"}]},{"ID":"20250915165213-9wqrpsd","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915165213-9wqrpsd","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5. 清晰的能力边界：诚实的自我剖析"}]},{"ID":"20250915165213-3lswwnh","Type":"NodeParagraph","Properties":{"id":"20250915165213-3lswwnh","updated":"20250915165213"},"Children":[{"Type":"NodeText","Data":"一篇伟大的论文不仅在于展示成功，更在于坦诚地面对失败。GPT-3的论文在这方面堪称典范，它精准地为我们画出了模型的能力边界。"}]},{"ID":"20250915165213-ui3htdr","Type":"NodeList","ListData":{},"Properties":{"id":"20250915165213-ui3htdr","updated":"20250915165213"},"Children":[{"ID":"20250915165213-frbe10e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165213-frbe10e","updated":"20250915165213"},"Children":[{"ID":"20250915165213-9ru3nc5","Type":"NodeParagraph","Properties":{"id":"20250915165213-9ru3nc5","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逻辑与推理的短板"},{"Type":"NodeText","Data":"：在需要严谨科学推理（如ARC Challenge）、数字推理（如DROP）的任务上，GPT-3表现极差，这暴露了其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深层逻辑和符号运算能力的缺失"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915165213-zsha2oq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165213-zsha2oq","updated":"20250915165213"},"Children":[{"ID":"20250915165213-ph48w77","Type":"NodeParagraph","Properties":{"id":"20250915165213-ph48w77","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"句子对比较的“阿喀琉斯之踵”"},{"Type":"NodeText","Data":"：在自然语言推理（NLI，如图3.9的ANLI）和部分SuperGLUE子任务（如WiC）上，GPT-3表现疲软。这揭示了其一个核心弱点："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不擅长需要精确对齐和比较两个独立文本片段语义关系的任务"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250915165213-ldxjh57","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250915165213-ldxjh57","updated":"20250915165213"},"Children":[{"ID":"20250915165213-x6p8hdy","Type":"NodeParagraph","Properties":{"id":"20250915165213-x6p8hdy","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据偏见的烙印"},{"Type":"NodeText","Data":"：翻译任务（图3.4）中“翻译到英语”远强于“从英语翻译”的表现，赤裸裸地展示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练数据分布不均"},{"Type":"NodeText","Data":"所带来的能力偏斜。模型是其数据的一面镜子，忠实地反映了数据中的偏见。"}]}]}]},{"ID":"20250915165213-itz0zkr","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250915165213-itz0zkr","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6. 开启新时代：社会与伦理影响的预警"}]},{"ID":"20250915165213-dyn7rck","Type":"NodeParagraph","Properties":{"id":"20250915165213-dyn7rck","updated":"20250915165213"},"Children":[{"Type":"NodeText","Data":"GPT-3的论文不仅是一篇技术文档，更是一份深刻的社会预警书。新闻生成实验的结果，直接将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"信息茧房、虚假信息泛滥、内容创作领域的颠覆"},{"Type":"NodeText","Data":"等潜在的社会伦理问题摆在了全世界面前。论文的作者们清醒地意识到了这一点，并在后续章节中进行了讨论，这为今天如火如荼的AI安全、对齐和伦理研究奠定了基础。"}]},{"ID":"20250915165213-p8xo517","Type":"NodeParagraph","Properties":{"id":"20250915165213-p8xo517","updated":"20250915165213"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总而言之，GPT-3的这篇论文是人工智能发展史上的一个分水岭。它用无可辩驳的、系统性的实验证据，证明了通过“野蛮”地扩大模型规模，可以实现从量变到质变的飞跃，催生出前所未有的通用能力和“智能”的火花。它不仅确立了“大语言模型+上下文学习”这一新的技术范式，更深刻地揭示了这一范式所蕴含的巨大潜力和与之相伴的严峻挑战，从而定义了此后数年乃至未来更长时间内人工智能领域的核心议程。"}]}]}]}