{"ID":"20250924222506-p7vjkme","Spec":"1","Type":"NodeDocument","Properties":{"id":"20250924222506-p7vjkme","title":"07 ","type":"doc","updated":"20250924224352"},"Children":[{"ID":"20250924222533-k98nby2","Type":"NodeParagraph","Properties":{"id":"20250924222533-k98nby2","updated":"20250924222533"},"Children":[{"Type":"NodeText","Data":"好的，我将开始对这份文档进行翻译和解析。由于内容较长，我会按照意义单位分段输出。这是第一部分的内容。"}]},{"ID":"20250924222533-2fvin6z","Type":"NodeThematicBreak","Properties":{"id":"20250924222533-2fvin6z","updated":"20250924222533"}},{"ID":"20250924222533-43ezkj7","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222533-43ezkj7","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉语言基础模型提示工程的系统性综述"}]},{"ID":"20250924222533-adrix5t","Type":"NodeParagraph","Properties":{"id":"20250924222533-adrix5t","updated":"20250924222534"},"Children":[{"Type":"NodeText","Data":"Jindong Gu, Zhen Han, Shuo Chen, Ahmad Beirami, Bailan He, Gengyuan Zhang, Ruotong Liao, Yao Qin, Volker Tresp, Philip Torr"}]},{"ID":"20250924222533-m5qxa76","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222533-m5qxa76","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"摘要"}]},{"ID":"20250924222533-htiy2on","Type":"NodeParagraph","Properties":{"id":"20250924222533-htiy2on","updated":"20250924222534"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程 (Prompt engineering)"},{"Type":"NodeText","Data":" 是一种技术，它通过增强一个大型预训练模型以任务相关的“提示”（prompts）来使其适应新任务。提示可以作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然语言指令"},{"Type":"NodeText","Data":"被手动创建，也可以作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然语言指令"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"向量表示"},{"Type":"NodeText","Data":"被自动生成。提示工程使得模型能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅基于提示进行预测"},{"Type":"NodeText","Data":"，而无需更新模型参数，从而更容易地将大型预训练模型应用于现实世界的任务中。在过去几年里，提示工程在自然语言处理领域得到了充分的研究。最近，它在视觉语言建模中也受到了广泛的研究。然而，目前缺乏对预训练"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉语言模型（vision-language models）"},{"Type":"NodeText","Data":" 提示工程的系统性概述。本文旨在对三种视觉语言模型的前沿提示工程研究提供一个全面的综述："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态到文本生成模型（multimodal-to-text generation models）"},{"Type":"NodeText","Data":" （如 Flamingo）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配模型（image-text matching models）"},{"Type":"NodeText","Data":" （如 CLIP）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文生图生成模型（text-to-image generation models）"},{"Type":"NodeText","Data":" （如 Stable Diffusion）。对于每种类型的模型，我们都总结和讨论了其简要的模型摘要、提示方法、基于提示的应用以及相应的责任和诚信问题。此外，我们还讨论了在视觉语言模型、语言模型和视觉模型上进行提示的共性和差异。最后，我们总结了挑战、未来方向和研究机会，以促进该主题的未来研究。"}]},{"ID":"20250924222533-u35c5py","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222533-u35c5py","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"索引术语"}]},{"ID":"20250924222533-s8o8g32","Type":"NodeParagraph","Properties":{"id":"20250924222533-s8o8g32","updated":"20250924222534"},"Children":[{"Type":"NodeText","Data":"提示工程、视觉语言模型、多模多态模型、自然语言处理、计算机视觉。"}]},{"ID":"20250924222533-d4mbc19","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222533-d4mbc19","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1. 引入"}]},{"ID":"20250924222533-gmv7b7w","Type":"NodeParagraph","Properties":{"id":"20250924222533-gmv7b7w","updated":"20250924222534"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程 (Prompt engineering)"},{"Type":"NodeText","Data":" 是一种将大型预训练模型（也称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础模型 (foundation model)"},{"Type":"NodeText","Data":"）适应新任务的方法，它通过使用任务特定的提示来增强模型的输入。具体来说，模型的输入被一个额外的部分——即所谓的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示 (prompt)"},{"Type":"NodeText","Data":"——所增强。这个提示可以是被手动创建的自然语言指令，自动生成的自然语言指令，或自动生成的向量表示。自然语言指令也被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"离散提示 (discrete prompts)"},{"Type":"NodeText","Data":" 或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示 (hard prompts)"},{"Type":"NodeText","Data":"，而向量表示则被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连续提示 (continuous prompts)"},{"Type":"NodeText","Data":" 或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示 (soft prompts)"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924222533-hf700p0","Type":"NodeParagraph","Properties":{"id":"20250924222533-hf700p0","updated":"20250924222534"},"Children":[{"Type":"NodeText","Data":"提示工程确实与大型预训练模型的出现相伴相生并日益受到重视，共同引领了机器学习（ML）的范式转变。传统的范式需要标记大量数据，然后从零开始训练一个任务特定的ML模型，或者微调一个预训练的大型模型。模型的性能在很大程度上依赖于标记数据的质量和数量，而这可能是资源密集型的。此外，传统范式要求在一定程度上调整模型的参数，例如在从零开始训练ML模型时需要调整全部参数，在完全微调预训练模型时也是如此，而在参数高效微调的情况下则调整部分参数。这限制了ML模型的可扩展性，并要求为每个任务都保留一个特定的模型副本。"}]},{"ID":"20250924222533-2ch7tm5","Type":"NodeParagraph","Properties":{"id":"20250924222533-2ch7tm5","updated":"20250924222534"},"Children":[{"Type":"NodeText","Data":"最近，通过提示一个预训练的大型模型来使其适应特定任务已成为一种新趋势。提示工程的核心思想是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在输入的同时提供提示，利用模型已有的知识来引导它解决新任务"},{"Type":"NodeText","Data":"。如果提示是人类可解释的自然语言（硬提示），相关的研究被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (In-Context Learning)"},{"Type":"NodeText","Data":"，它使模型能够从任务指令、带有一些示例的演示或上下文中的支持信息中学习。此外，提示也可以是连续的向量表示（软提示）。相关的工作被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示调优 (Prompt-Tuning)"},{"Type":"NodeText","Data":"，它直接在模型的嵌入空间中优化提示。"}]},{"ID":"20250924222533-hpmkt6i","Type":"NodeParagraph","Properties":{"id":"20250924222533-hpmkt6i","updated":"20250924222534"},"Children":[{"Type":"NodeText","Data":"与传统范式相比，提示工程具有多重优势。首先，它"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只需要少量标记数据"},{"Type":"NodeText","Data":"就能使预训练模型适应新任务，这极大地减少了人工监督和微调所需的计算资源。其次，提示工程使预训练模型能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅基于提示对新任务进行预测"},{"Type":"NodeText","Data":"，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无需更新任何模型参数"},{"Type":"NodeText","Data":"，从而允许使用同一个模型服务于大规模的下游任务。这使得将大规模预训练模型应用于现实世界的应用成为可能。"}]},{"ID":"20250924222533-8s7blj6","Type":"NodeParagraph","Properties":{"id":"20250924222533-8s7blj6","updated":"20250924222534"},"Children":[{"Type":"NodeText","Data":"提示工程首先在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然语言处理 (NLP)"},{"Type":"NodeText","Data":" 中被研究和推广，随后在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计算机视觉 (computer vision)"},{"Type":"NodeText","Data":" 以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉语言模型 (VLMs)"},{"Type":"NodeText","Data":" 中获得了极大的关注。尽管在NLP领域有大量关于提示工程的文献，但目前还没有系统的概述来深入了解预训练视觉语言模型（VLMs）中提示工程的现状，而这些模型本身也带来了独特的挑战。"}]},{"ID":"20250924222533-u1f6mmf","Type":"NodeParagraph","Properties":{"id":"20250924222533-u1f6mmf","updated":"20250924222534"},"Children":[{"Type":"NodeText","Data":"在本文中，我们的目标是通过提供一个关于前沿提示工程研究的全面综述来弥补这一差距。"}]},{"ID":"20250924222533-jpqc0xp","Type":"NodeBlockquote","Properties":{"id":"20250924222533-jpqc0xp","updated":"20250924222534"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250924222533-9h5gf5u","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222533-9h5gf5u","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250924222533-6jazev4","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222533-6jazev4","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心概念与范式转变"}]},{"ID":"20250924222533-dvrpjez","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222533-dvrpjez","updated":"20250924222533"},"Children":[{"ID":"20250924222533-5vkb9p7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222533-5vkb9p7","updated":"20250924222533"},"Children":[{"ID":"20250924222533-crfz19s","Type":"NodeParagraph","Properties":{"id":"20250924222533-crfz19s","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"什么是提示工程？"},{"Type":"NodeText","Data":" 作者开篇即明确了核心概念："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程"},{"Type":"NodeText","Data":"不是去修改或重新训练一个大模型，而是通过在输入端巧妙地“喂”给它一些额外信息（即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示"},{"Type":"NodeText","Data":"），来引导这个强大的、通用的基础模型去完成一个特定的新任务。这就像是给一个知识渊博但不知具体任务的专家下达清晰的指令。"}]}]},{"ID":"20250924222533-91gsbur","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222533-91gsbur","updated":"20250924222533"},"Children":[{"ID":"20250924222533-o1q1ms6","Type":"NodeParagraph","Properties":{"id":"20250924222533-o1q1ms6","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示 vs. 软提示"},{"Type":"NodeText","Data":": 文章清晰地划分了两种提示类型。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示"},{"Type":"NodeText","Data":"是人类能读懂的自然语言指令，比如“请翻译这句话”，这种方式催生了“上下文学习”（In-Context Learning）。而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示"},{"Type":"NodeText","Data":"则是机器才能理解的、可以被优化的数字向量，它直接在模型的“大脑”层面（嵌入空间）工作，这种方式被称为“提示调优”（Prompt-Tuning）。"}]}]},{"ID":"20250924222533-8f0fkv5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222533-8f0fkv5","updated":"20250924222533"},"Children":[{"ID":"20250924222533-4cu8oqh","Type":"NodeParagraph","Properties":{"id":"20250924222533-4cu8oqh","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"范式革命"},{"Type":"NodeText","Data":": 作者强调了提示工程带来的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本性转变"},{"Type":"NodeText","Data":"。传统的机器学习流程是“数据 -\u003e 训练/微调 -\u003e 特定模型”，这个过程耗时耗力，且每个任务都需要一个独立的模型。而提示工程开创了“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用大模型 + 任务提示 -\u0026gt; 直接出结果"},{"Type":"NodeText","Data":"”的新范式，其核心优势在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效"},{"Type":"NodeText","Data":"（数据需求少）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"经济"},{"Type":"NodeText","Data":"（计算资源消耗少）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"灵活"},{"Type":"NodeText","Data":"（一个模型应对多种任务）。"}]}]}]},{"ID":"20250924222533-4ajnehc","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222533-4ajnehc","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本文的研究动机与贡献"}]},{"ID":"20250924222533-45nbhc0","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222533-45nbhc0","updated":"20250924222533"},"Children":[{"ID":"20250924222533-7gpr9vr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222533-7gpr9vr","updated":"20250924222533"},"Children":[{"ID":"20250924222533-diziint","Type":"NodeParagraph","Properties":{"id":"20250924222533-diziint","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"研究空白"},{"Type":"NodeText","Data":": 作者指出了当前研究领域的一个关键缺口——虽然提示工程在纯文本（NLP）和纯图像（CV）领域已有大量研究，但在结合了这二者的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉语言模型（VLMs）"},{"Type":"NodeText","Data":" 领域，还缺少一个全面、系统的梳理。"}]}]},{"ID":"20250924222533-ncpcha9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222533-ncpcha9","updated":"20250924222533"},"Children":[{"ID":"20250924222533-013l77c","Type":"NodeParagraph","Properties":{"id":"20250924222533-013l77c","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心贡献"},{"Type":"NodeText","Data":": 本文的定位非常清晰，它不是提出一种新方法，而是作为一篇"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综述性文章"},{"Type":"NodeText","Data":"，旨在系统性地整理和总结VLM领域的提示工程研究。具体来说，它将聚焦于三大类模型："}]},{"ID":"20250924222533-c98dyir","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924222533-c98dyir","updated":"20250924222533"},"Children":[{"ID":"20250924222533-xpdfu88","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924222533-xpdfu88","updated":"20250924222533"},"Children":[{"ID":"20250924222533-y5vq27u","Type":"NodeParagraph","Properties":{"id":"20250924222533-y5vq27u","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态到文本生成 (Multimodal-to-Text Generation)"},{"Type":"NodeText","Data":"：看图说话、视觉问答等。"}]}]},{"ID":"20250924222533-pwvgqtc","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924222533-pwvgqtc","updated":"20250924222533"},"Children":[{"ID":"20250924222533-0xep7o7","Type":"NodeParagraph","Properties":{"id":"20250924222533-0xep7o7","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配 (Image-Text Matching)"},{"Type":"NodeText","Data":"：判断图片和文字是否相关。"}]}]},{"ID":"20250924222533-izilam8","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250924222533-izilam8","updated":"20250924222533"},"Children":[{"ID":"20250924222533-wzypvua","Type":"NodeParagraph","Properties":{"id":"20250924222533-wzypvua","updated":"20250924222533"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文生图 (Text-to-Image Generation)"},{"Type":"NodeText","Data":"：根据文字描述生成图片。"}]}]}]}]}]},{"ID":"20250924222533-gu5q75p","Type":"NodeParagraph","Properties":{"id":"20250924222533-gu5q75p","updated":"20250924222533"},"Children":[{"Type":"NodeText","Data":"这部分内容为整篇论文奠定了基础，明确了研究对象、核心概念以及本文希望解决的问题，为读者构建了一个清晰的认知框架。"}]}]},{"ID":"20250924222706-rsyd7d5","Type":"NodeParagraph","Properties":{"id":"20250924222706-rsyd7d5","updated":"20250924222706"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。这是第二部分的内容，涵盖了论文的第1页末尾到第2页。"}]},{"ID":"20250924222706-iewg1i2","Type":"NodeThematicBreak","Properties":{"id":"20250924222706-iewg1i2","updated":"20250924222706"}},{"ID":"20250924222706-9fk2af3","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222706-9fk2af3","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1 JINDONG GU 等人：视觉语言基础模型提示工程的系统性综述"}]},{"ID":"20250924222706-3fy7zct","Type":"NodeParagraph","Properties":{"id":"20250924222706-3fy7zct","updated":"20250924222707"},"Children":[{"Type":"NodeText","Data":"在视觉语言模型（VLMs）上。具体来说，我们旨在通过提供一个关于在三种视觉语言模型上的前沿提示工程研究的全面综述来弥补这一差距："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态到文本生成模型"},{"Type":"NodeText","Data":"（例如，Flamingo）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配模型"},{"Type":"NodeText","Data":"（例如，CLIP）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文生图生成模型"},{"Type":"NodeText","Data":"（例如，Stable Diffusion）。对于每种类型的模型，我们都总结和讨论了其简要的模型摘要、提示方法、基于提示的应用以及相应的责任和诚信问题。此外，我们还讨论了在视觉语言模型、语言模型和视觉模型上进行提示的共性和差异。最后，我们总结了挑战、未来方向和研究机会，以促进该主题的未来研究。"}]},{"ID":"20250924222706-5t0uz0g","Type":"NodeParagraph","Properties":{"id":"20250924222706-5t0uz0g","updated":"20250924222707"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"Fig 1"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"https://storage.googleapis.com/assistly-images/20250915145749-dft42d1.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250924222706-kfi97cy","Type":"NodeParagraph","Properties":{"id":"20250924222706-kfi97cy","updated":"20250924222707"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 1：视觉语言基础模型"},{"Type":"NodeText","Data":"。本文系统地总结了视觉语言基础模型中提示工程的前沿研究。本工作聚焦于三种主要类型的视觉语言模型，即子图a中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态到文本生成模型"},{"Type":"NodeText","Data":"（例如，Flamingo），子图b中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配模型"},{"Type":"NodeText","Data":"（例如，CLIP），以及子图c中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文生图生成模型"},{"Type":"NodeText","Data":"（例如，Stable Diffusion）。每种类型的更多细节将在后续章节中介绍。"}]},{"ID":"20250924222706-druerct","Type":"NodeParagraph","Properties":{"id":"20250924222706-druerct","updated":"20250924222707"},"Children":[{"Type":"NodeText","Data":"在对预训练的VLM进行工程设计时，我们根据模板的可读性将提示方法分为两大类，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示"},{"Type":"NodeText","Data":"。硬提示可以进一步分为四个子类别，即任务指令、上下文学习、基于检索的提示和思维链提示。另一方面，软提示是可以使用基于梯度的方法进行微调的连续向量。请注意，本综述主要关注"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"保持模型架构不变"},{"Type":"NodeText","Data":"的提示方法，因此，像P-tuning和LoRa那样向模型中引入额外模块的方法，不属于本综述的主要范围。"}]},{"ID":"20250924222706-7fwbiba","Type":"NodeParagraph","Properties":{"id":"20250924222706-7fwbiba","updated":"20250924222707"},"Children":[{"Type":"NodeText","Data":"我们研究了三种类型的VLM上的提示工程，它们分别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态到文本生成模型"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配模型"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文生图生成模型"},{"Type":"NodeText","Data":"。每种模型类型的清晰定义在2.1节中提供。此外，我们从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器"},{"Type":"NodeText","Data":"的角度对现有的提示工程方法进行分类，如图1所示，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码端提示（encoder-side prompting）"},{"Type":"NodeText","Data":" 或 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码端提示（decode-side prompting）"},{"Type":"NodeText","Data":"，其中提示分别被添加到编码器和解码器中。"}]},{"ID":"20250924222706-lbsum4c","Type":"NodeParagraph","Properties":{"id":"20250924222706-lbsum4c","updated":"20250924222707"},"Children":[{"Type":"NodeText","Data":"本文的其余部分组织如下。在第2节中，我们总结并定义了本综述中使用的分类法和符号。第3、4和5节分别介绍了多模态到文本生成模型、图文匹配模型和文生图生成模型上提示工程的当前进展，其中每一节首先介绍相应模型的预备知识，然后详细讨论提示方法，接着探讨这些提示方法的应用和相关的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"责任AI（responsible AI）"},{"Type":"NodeText","Data":" 考量。第6节对单模态模型和VLM的提示进行了比较，并深入讨论了它们的相似之处和差异。最后，在第7节中，我们重点指出了挑战和潜在的研究方向。"}]},{"ID":"20250924222706-vlq0ewl","Type":"NodeParagraph","Properties":{"id":"20250924222706-vlq0ewl","updated":"20250924222707"},"Children":[{"Type":"NodeText","Data":"为了方便文献检索，我们还建立并发布了一个项目页面¹，其中整理并列出了与我们主题相关的论文。"}]},{"ID":"20250924222706-c3hud6d","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222706-c3hud6d","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2 分类法"}]},{"ID":"20250924222706-xg2969t","Type":"NodeParagraph","Properties":{"id":"20250924222706-xg2969t","updated":"20250924222707"},"Children":[{"Type":"NodeText","Data":"在本节中，将介绍与VLM上的提示工程相关的术语和符号。"}]},{"ID":"20250924222706-49lpbno","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222706-49lpbno","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.1 术语"}]},{"ID":"20250924222706-64nf3am","Type":"NodeParagraph","Properties":{"id":"20250924222706-64nf3am","updated":"20250924222707"},"Children":[{"Type":"NodeText","Data":"这是一份术语及其描述的列表。请注意，我们为读者提供的是一般性描述，而非正式定义。"}]},{"ID":"20250924222706-14mttho","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222706-14mttho","updated":"20250924222707"},"Children":[{"ID":"20250924222706-rcpptgd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-rcpptgd","updated":"20250924222706"},"Children":[{"ID":"20250924222706-h7dz88y","Type":"NodeParagraph","Properties":{"id":"20250924222706-h7dz88y","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示 (Prompt)"},{"Type":"NodeText","Data":"：向模型提供的额外信息或提示，以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"引导其行为"},{"Type":"NodeText","Data":"或帮助其执行特定任务；"}]}]},{"ID":"20250924222706-jm1i2ta","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-jm1i2ta","updated":"20250924222706"},"Children":[{"ID":"20250924222706-49k5ypd","Type":"NodeParagraph","Properties":{"id":"20250924222706-49k5ypd","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示方法 (Prompting Method)"},{"Type":"NodeText","Data":"：一种将提示整合到输入中以引导模型行为或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提升模型性能"},{"Type":"NodeText","Data":"的方法；"}]}]},{"ID":"20250924222706-54a5gxt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-54a5gxt","updated":"20250924222706"},"Children":[{"ID":"20250924222706-hvz3k11","Type":"NodeParagraph","Properties":{"id":"20250924222706-hvz3k11","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态到文本生成 (Multimodal-to-Text Generation)"},{"Type":"NodeText","Data":"：从多模态输入数据（例如，视觉和语言数据的组合）生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本描述或叙述"},{"Type":"NodeText","Data":"；"}]}]},{"ID":"20250924222706-6lztvsr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-6lztvsr","updated":"20250924222706"},"Children":[{"ID":"20250924222706-346a1oh","Type":"NodeParagraph","Properties":{"id":"20250924222706-346a1oh","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配 (Image-Text Matching)"},{"Type":"NodeText","Data":"：在图像和文本描述之间建立"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语义关系或对齐"},{"Type":"NodeText","Data":"；"}]}]},{"ID":"20250924222706-7vb8b6x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-7vb8b6x","updated":"20250924222706"},"Children":[{"ID":"20250924222706-113qgfi","Type":"NodeParagraph","Properties":{"id":"20250924222706-113qgfi","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文生图生成 (Text-to-Image Generation)"},{"Type":"NodeText","Data":"：从文本描述中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成视觉图像"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250924222706-140qx7l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-140qx7l","updated":"20250924222706"},"Children":[{"ID":"20250924222706-fimarb7","Type":"NodeParagraph","Properties":{"id":"20250924222706-fimarb7","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (In-context Learning)"},{"Type":"NodeText","Data":"：一种提示方法，通过在相关上下文中为模型提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令或演示"},{"Type":"NodeText","Data":"，使其能够在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无需额外训练"},{"Type":"NodeText","Data":"的情况下解决新任务。"}]}]},{"ID":"20250924222706-kyrw1mh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-kyrw1mh","updated":"20250924222706"},"Children":[{"ID":"20250924222706-ik5vozg","Type":"NodeParagraph","Properties":{"id":"20250924222706-ik5vozg","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链 (Chain-of-thought)"},{"Type":"NodeText","Data":"：一种提示方法，通过指示模型生成一系列"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"中间步骤"},{"Type":"NodeText","Data":"来增强其推理能力，这些步骤引导其解决一个多步骤问题并达到最终解决方案。"}]}]}]},{"ID":"20250924222706-sk6gado","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222706-sk6gado","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.2 符号"}]},{"ID":"20250924222706-u9x8egt","Type":"NodeParagraph","Properties":{"id":"20250924222706-u9x8egt","updated":"20250924222707"},"Children":[{"Type":"NodeText","Data":"这些是整篇论文中遵循的数学符号（表1）。除非另有说明，本工作的所有公式都将遵循这些符号。"}]},{"ID":"20250924222706-191wbe4","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222706-191wbe4","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3 多模态到文本生成中的提示模型"}]},{"ID":"20250924222706-4s4ytbx","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222706-4s4ytbx","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.1 多模态到文本生成的预备知识"}]},{"ID":"20250924222706-pxsqatz","Type":"NodeParagraph","Properties":{"id":"20250924222706-pxsqatz","updated":"20250924222707"},"Children":[{"Type":"NodeText","Data":"大型语言模型（LLMs）在NLP领域展现了令人印象深刻的能力，这促使研究人员探索将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉模态"},{"Type":"NodeText","Data":"整合到这些模型的训练框架中的方法。这种整合旨在增强它们的语言能力，并将其适用性扩展到多模态任务中。"}]},{"ID":"20250924222706-mt9hdxk","Type":"NodeBlockquote","Properties":{"id":"20250924222706-mt9hdxk","updated":"20250924222707"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250924222706-alvrdy3","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222706-alvrdy3","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250924222706-ozgm2o8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222706-ozgm2o8","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图1的深度解析"}]},{"ID":"20250924222706-kq7ecpu","Type":"NodeParagraph","Properties":{"id":"20250924222706-kq7ecpu","updated":"20250924222706"},"Children":[{"Type":"NodeText","Data":"这张图是全文的“地图”，直观地展示了本文要讨论的三大核心VLM类型及其工作原理："}]},{"ID":"20250924222706-01lq9ln","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222706-01lq9ln","updated":"20250924222706"},"Children":[{"ID":"20250924222706-wf9iamn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-wf9iamn","updated":"20250924222706"},"Children":[{"ID":"20250924222706-ludhgbs","Type":"NodeParagraph","Properties":{"id":"20250924222706-ludhgbs","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(a) 多模态到文本生成 (Multimodal-to-Text Generation)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250924222706-aaqbh5c","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222706-aaqbh5c","updated":"20250924222706"},"Children":[{"ID":"20250924222706-dtl0v32","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-dtl0v32","updated":"20250924222706"},"Children":[{"ID":"20250924222706-kldtfn8","Type":"NodeParagraph","Properties":{"id":"20250924222706-kldtfn8","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输入"},{"Type":"NodeText","Data":": 图像（火烈鸟）+ 文本提示（“What is it in the image?” - 图中是什么？）。"}]}]},{"ID":"20250924222706-29yxqfg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-29yxqfg","updated":"20250924222706"},"Children":[{"ID":"20250924222706-ymo4v9d","Type":"NodeParagraph","Properties":{"id":"20250924222706-ymo4v9d","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程"},{"Type":"NodeText","Data":": 一个预训练的视觉语言模型（V-L Model）同时理解图像和文本。"}]}]},{"ID":"20250924222706-prc5ywr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-prc5ywr","updated":"20250924222706"},"Children":[{"ID":"20250924222706-ncxp5tk","Type":"NodeParagraph","Properties":{"id":"20250924222706-ncxp5tk","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输出"},{"Type":"NodeText","Data":": 一段描述性的文本（“This is a flamingo.” - 这是一只火烈鸟。）。"}]}]},{"ID":"20250924222706-nefddr2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-nefddr2","updated":"20250924222706"},"Children":[{"ID":"20250924222706-8yc6lej","Type":"NodeParagraph","Properties":{"id":"20250924222706-8yc6lej","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心功能"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理解多模态输入，生成文本输出"},{"Type":"NodeText","Data":"。这涵盖了图像描述、视觉问答等任务。"}]}]}]}]},{"ID":"20250924222706-lv7krpe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-lv7krpe","updated":"20250924222706"},"Children":[{"ID":"20250924222706-k50h2hm","Type":"NodeParagraph","Properties":{"id":"20250924222706-k50h2hm","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(b) 图文匹配 (Image-Text Matching)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250924222706-r6stvn5","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222706-r6stvn5","updated":"20250924222706"},"Children":[{"ID":"20250924222706-oqomtwv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-oqomtwv","updated":"20250924222706"},"Children":[{"ID":"20250924222706-781okse","Type":"NodeParagraph","Properties":{"id":"20250924222706-781okse","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输入"},{"Type":"NodeText","Data":": 一张图像（小狗）和一个文本描述（“pepper the assie pup” - 给这只小狗调味）。"}]}]},{"ID":"20250924222706-gsadblp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-gsadblp","updated":"20250924222706"},"Children":[{"ID":"20250924222706-3h8k1yb","Type":"NodeParagraph","Properties":{"id":"20250924222706-3h8k1yb","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程"},{"Type":"NodeText","Data":": 图像通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像编码器（Image Encoder）"},{"Type":"NodeText","Data":" 转换成向量，文本通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本编码器（Text Encoder）"},{"Type":"NodeText","Data":" 转换成向量。模型的目标是判断这两个向量在语义空间中是否“匹配”（Match）。"}]}]},{"ID":"20250924222706-vdv1dbn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-vdv1dbn","updated":"20250924222706"},"Children":[{"ID":"20250924222706-84nlz31","Type":"NodeParagraph","Properties":{"id":"20250924222706-84nlz31","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输出"},{"Type":"NodeText","Data":": 一个匹配/不匹配的判断或一个相似度分数。"}]}]},{"ID":"20250924222706-0wiz4n4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-0wiz4n4","updated":"20250924222706"},"Children":[{"ID":"20250924222706-zld8i2w","Type":"NodeParagraph","Properties":{"id":"20250924222706-zld8i2w","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心功能"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"判断图文是否相关"},{"Type":"NodeText","Data":"。这是CLIP等模型的核心能力，也是实现零样本图像分类的基础。"}]}]}]}]},{"ID":"20250924222706-wu4b7pk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-wu4b7pk","updated":"20250924222706"},"Children":[{"ID":"20250924222706-zy7y51a","Type":"NodeParagraph","Properties":{"id":"20250924222706-zy7y51a","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(c) 文生图生成 (Text-to-Image Generation)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250924222706-y8ncs2g","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222706-y8ncs2g","updated":"20250924222706"},"Children":[{"ID":"20250924222706-bgqiyp5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-bgqiyp5","updated":"20250924222706"},"Children":[{"ID":"20250924222706-sauqgy0","Type":"NodeParagraph","Properties":{"id":"20250924222706-sauqgy0","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输入"},{"Type":"NodeText","Data":": 一段文本描述（“Happy vegetables waiting for supper” - 等待晚餐的快乐蔬菜们）。"}]}]},{"ID":"20250924222706-l4pe1wz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-l4pe1wz","updated":"20250924222706"},"Children":[{"ID":"20250924222706-qrtvnbc","Type":"NodeParagraph","Properties":{"id":"20250924222706-qrtvnbc","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程"},{"Type":"NodeText","Data":": 一个预训练的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成模型（Generative Model）"},{"Type":"NodeText","Data":" 理解文本的语义，并将其转化为像素。"}]}]},{"ID":"20250924222706-5rq17v5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-5rq17v5","updated":"20250924222706"},"Children":[{"ID":"20250924222706-q23cagb","Type":"NodeParagraph","Properties":{"id":"20250924222706-q23cagb","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输出"},{"Type":"NodeText","Data":": 一张与文本描述相符的图像。"}]}]},{"ID":"20250924222706-pthokrm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-pthokrm","updated":"20250924222706"},"Children":[{"ID":"20250924222706-abullfd","Type":"NodeParagraph","Properties":{"id":"20250924222706-abullfd","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心功能"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理解文本输入，生成图像输出"},{"Type":"NodeText","Data":"。这是Stable Diffusion、Midjourney等应用的核心技术。"}]}]}]}]}]},{"ID":"20250924222706-52a0ezb","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222706-52a0ezb","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"研究范围与分类框架"}]},{"ID":"20250924222706-6f1599s","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222706-6f1599s","updated":"20250924222706"},"Children":[{"ID":"20250924222706-3ja0w1f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-3ja0w1f","updated":"20250924222706"},"Children":[{"ID":"20250924222706-xgoqcv8","Type":"NodeParagraph","Properties":{"id":"20250924222706-xgoqcv8","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心分类"},{"Type":"NodeText","Data":": 作者明确了本文对“提示方法”的核心分类标准："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可读性"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924222706-gntt9cf","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222706-gntt9cf","updated":"20250924222706"},"Children":[{"ID":"20250924222706-0mg9rgd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-0mg9rgd","updated":"20250924222706"},"Children":[{"ID":"20250924222706-9e6yuq1","Type":"NodeParagraph","Properties":{"id":"20250924222706-9e6yuq1","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示 (Hard Prompt)"},{"Type":"NodeText","Data":": 人类能读懂的指令。"}]}]},{"ID":"20250924222706-8znhnbc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-8znhnbc","updated":"20250924222706"},"Children":[{"ID":"20250924222706-04jrhe5","Type":"NodeParagraph","Properties":{"id":"20250924222706-04jrhe5","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示 (Soft Prompt)"},{"Type":"NodeText","Data":": 机器才能理解的、可优化的向量。"}]}]}]}]},{"ID":"20250924222706-gi0pu2d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-gi0pu2d","updated":"20250924222706"},"Children":[{"ID":"20250924222706-oj82lcb","Type":"NodeParagraph","Properties":{"id":"20250924222706-oj82lcb","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法论的界定"},{"Type":"NodeText","Data":": 作者特别强调，本文只关注那些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不改变模型底层结构"},{"Type":"NodeText","Data":"的提示方法。像P-tuning和LoRa这类需要给模型“加挂”额外小模块的技术，虽然也属于参数高效微调的范畴，但因其改变了模型架构，故不在本文的讨论范围内。这体现了研究的严谨性和边界的清晰性。"}]}]},{"ID":"20250924222706-e70826o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-e70826o","updated":"20250924222706"},"Children":[{"ID":"20250924222706-k0dylls","Type":"NodeParagraph","Properties":{"id":"20250924222706-k0dylls","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"论文结构导览"},{"Type":"NodeText","Data":": 作者清晰地预告了文章的结构，让读者可以预期接下来的内容：先定义基础（第2节），然后分别深入探讨三种VLM的提示工程（第3、4、5节），再进行横向对比（第6节），最后总结挑战与未来（第7节）。"}]}]}]},{"ID":"20250924222706-71poyd3","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222706-71poyd3","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"术语定义"}]},{"ID":"20250924222706-xhomv21","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222706-xhomv21","updated":"20250924222706"},"Children":[{"ID":"20250924222706-6x74zqm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-6x74zqm","updated":"20250924222706"},"Children":[{"ID":"20250924222706-o199fa4","Type":"NodeParagraph","Properties":{"id":"20250924222706-o199fa4","updated":"20250924222706"},"Children":[{"Type":"NodeText","Data":"这部分内容像是一本“词典”，为非专业读者扫清了阅读障碍。作者对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示（Prompt）"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（In-context Learning）"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（Chain-of-thought）"},{"Type":"NodeText","Data":" 等关键概念给出了简洁明了的解释。"}]},{"ID":"20250924222706-p6y8xgn","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222706-p6y8xgn","updated":"20250924222706"},"Children":[{"ID":"20250924222706-9yshurj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-9yshurj","updated":"20250924222706"},"Children":[{"ID":"20250924222706-5fjimo9","Type":"NodeParagraph","Properties":{"id":"20250924222706-5fjimo9","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习"},{"Type":"NodeText","Data":"的关键在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“无需额外训练”"},{"Type":"NodeText","Data":"，模型通过看几个例子就能学会新任务。"}]}]},{"ID":"20250924222706-hwk315r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-hwk315r","updated":"20250924222706"},"Children":[{"ID":"20250924222706-6wiih92","Type":"NodeParagraph","Properties":{"id":"20250924222706-6wiih92","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链"},{"Type":"NodeText","Data":"的关键在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“生成中间步骤”"},{"Type":"NodeText","Data":"，它模仿人类的思考过程，通过分解问题来提升复杂推理的准确性。"}]}]}]}]}]},{"ID":"20250924222706-m38kq42","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222706-m38kq42","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态到文本生成模型的引言"}]},{"ID":"20250924222706-u0w82ow","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222706-u0w82ow","updated":"20250924222706"},"Children":[{"ID":"20250924222706-n8kqmjs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222706-n8kqmjs","updated":"20250924222706"},"Children":[{"ID":"20250924222706-h583f33","Type":"NodeParagraph","Properties":{"id":"20250924222706-h583f33","updated":"20250924222706"},"Children":[{"Type":"NodeText","Data":"这部分为第3章做了铺垫，点明了这类模型的核心动机："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"让强大的语言模型（LLMs）也能“看懂”世界"},{"Type":"NodeText","Data":"。通过将视觉信息融入LLM，可以极大地扩展其应用范围，从纯文本任务走向更丰富的多模态任务。"}]}]}]},{"ID":"20250924222706-q5c2szm","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222706-q5c2szm","updated":"20250924222706"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250924222706-aqznfuu","Type":"NodeParagraph","Properties":{"id":"20250924222706-aqznfuu","updated":"20250924222706"},"Children":[{"Type":"NodeText","Data":"这一部分是论文的“序言”和“目录”，起到了承上启下的关键作用。它首先通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图1"},{"Type":"NodeText","Data":"生动地展示了本文要探讨的三大核心视觉语言模型的工作模式，为读者建立了直观的理解。接着，作者详细阐述了本文的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"研究范围"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分类框架"},{"Type":"NodeText","Data":"，特别是对“硬提示”和“软提示”的划分，以及对“不改变模型架构”的方法论限制，这为整篇综述设定了清晰的边界。术语表的提供进一步降低了读者的理解门槛。最后，引出下一章的主题——多模态到文本生成，并点明其研究动机。"}]},{"ID":"20250924222706-8f176rh","Type":"NodeParagraph","Properties":{"id":"20250924222706-8f176rh","updated":"20250924222706"},"Children":[{"Type":"NodeText","Data":"总体来看，这部分内容组织严谨，逻辑清晰，成功地将读者从宏观的引言引导至具体的模型分析，为后续深入探讨打下了坚实的基础。"}]}]},{"ID":"20250924222815-xi29uuj","Type":"NodeParagraph","Properties":{"id":"20250924222815-xi29uuj","updated":"20250924222815"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。这是第三部分的内容，涵盖了论文的第3页。"}]},{"ID":"20250924222815-wabm7sx","Type":"NodeThematicBreak","Properties":{"id":"20250924222815-wabm7sx","updated":"20250924222815"}},{"ID":"20250924222815-ac778lr","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222815-ac778lr","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3"}]},{"ID":"20250924222815-nhugjmd","Type":"NodeParagraph","Properties":{"id":"20250924222815-nhugjmd","updated":"20250924222817"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 1：本文使用的数学符号列表。这些符号在全文中均被遵循。"}]},{"ID":"20250924222815-o36wefd","Type":"NodeTable","TableAligns":[1,1],"Properties":{"colgroup":"|","id":"20250924222815-o36wefd","updated":"20250924222817"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"符号"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"描述"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"一张清晰的输入图像"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"t"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"与图像配对的句子"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"y"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"图像的真实类别标签"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{X}"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"输入分布"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"f(\\cdot)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"一个视觉语言模型"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"f_v(\\cdot)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"一个视觉编码器"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"f_t(\\cdot)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"一个文本编码器"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\{v_i\\}_1^M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"视觉 token"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\{c_i\\}_1^M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"文本 token"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\{z_i^v\\}_1^M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"视觉提示 token"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\{z_i^t\\}_1^M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"文本提示 token"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"H^l"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"目标网络的第 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"l"},{"Type":"NodeText","Data":" 层"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"标签词 token"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"H_k^l"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"目标模型第 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"l"},{"Type":"NodeText","Data":" 层中的第 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"k"},{"Type":"NodeText","Data":" 个激活值"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"z^i"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"模型输出的 logits"}]}]}]},{"ID":"20250924222815-tj40t3m","Type":"NodeParagraph","Properties":{"id":"20250924222815-tj40t3m","updated":"20250924222817"},"Children":[{"Type":"NodeText","Data":"为了与LLMs采用的训练方法保持一致，基于生成的视觉语言模型（VLMs）通常包含三个基本组件："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本特征"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉特征"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"融合模块"},{"Type":"NodeText","Data":"。这些组件协同工作，使模型能够有效地利用文本和视觉信息来生成连贯且与上下文相关的输出。"}]},{"ID":"20250924222815-n6rtyq7","Type":"NodeParagraph","Properties":{"id":"20250924222815-n6rtyq7","updated":"20250924222817"},"Children":[{"Type":"NodeText","Data":"将视觉模态融入LLMs为各种应用开辟了激动人心的机会，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉常识推理"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉问答"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态对话系统"},{"Type":"NodeText","Data":"等。通过结合文本和视觉线索，VLMs有潜力对多模态数据提供更全面的理解，并产生与人类推理和感知相符的输出。此外，在VLMs中，文本和视觉特征的融合在无缝整合来自两种模态的信息方面起着至关重要的作用。这种融合过程使模型能够捕捉文本和视觉元素之间的相互依赖和互动，从而产生更准确和与上下文相关的生成结果。"}]},{"ID":"20250924222815-74lx3y2","Type":"NodeParagraph","Properties":{"id":"20250924222815-74lx3y2","updated":"20250924222817"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本特征 (Text Feature)"},{"Type":"NodeText","Data":"。早期的VLM研究通常采用BERT引入的预处理技术。原始文本经过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分词 (tokenization)"},{"Type":"NodeText","Data":"，并与特殊 token "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[CLS]"},{"Type":"NodeText","Data":"​ 和 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[SEP]"},{"Type":"NodeText","Data":"​ 连接，表示为 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;[CLS], c_1, ..., c_m, [SEP]\u0026gt;"},{"Type":"NodeText","Data":"​，其中 token "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"c_i"},{"Type":"NodeText","Data":" 与一个词嵌入相关联。然而，随着语言模型研究的进展，更先进的模型已经出现，展示了如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链推理"},{"Type":"NodeText","Data":"等新兴能力。在这些进步的基础上，最新一代的VLMs已经采用了像T5和GPTs这样强大的语言模型，这进一步增强了它们的语言能力。"}]},{"ID":"20250924222815-g7x0c32","Type":"NodeParagraph","Properties":{"id":"20250924222815-g7x0c32","updated":"20250924222817"},"Children":[{"Type":"NodeText","Data":"为了在输入中容纳不同的模态，近期的工作引入了新的特殊 token。例如， 引入了一个额外的图像分类 token "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[CLS_I]"},{"Type":"NodeText","Data":"​，而 使用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;image\u0026gt;"},{"Type":"NodeText","Data":"​ 和 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;/image\u0026gt;"},{"Type":"NodeText","Data":"​ 来指示编码图像嵌入的开始和结束，并使用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;s\u0026gt;"},{"Type":"NodeText","Data":"​ 和 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;/s\u0026gt;"},{"Type":"NodeText","Data":"​ 来标记序列的开始和结束。在另一种方法中， 采用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;BOS\u0026gt;"},{"Type":"NodeText","Data":"​ 表示“序列开始”，用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;EOC\u0026gt;"},{"Type":"NodeText","Data":"​ 表示“块结束”。这些特殊 token 用于区分和识别不同模态之间的边界，允许模型有效地处理和利用多模态信息。"}]},{"ID":"20250924222815-el8lhha","Type":"NodeParagraph","Properties":{"id":"20250924222815-el8lhha","updated":"20250924222817"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉特征 (Visual Feature)"},{"Type":"NodeText","Data":"。为了获得对两种模态输入的一致性表示（即嵌入序列），图像 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x"},{"Type":"NodeText","Data":" 被转换为一个嵌入向量序列："},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"X = \u003cv_1, v_2, ..., v_M\u003e"},{"Type":"NodeText","Data":"。准确地表示图像所传达的信息对于下游任务至关重要，但这可能具有挑战性。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CNN 结构"},{"Type":"NodeText","Data":"在以往的研究中常被用于提取图像特征。例如，像ViLBERT和VL-T5这样的模型采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Faster R-CNN"},{"Type":"NodeText","Data":"来检测图像中的物体区域，并将它们编码为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"感兴趣区域 (Region-Of-Interest, ROI)"},{"Type":"NodeText","Data":" 特征序列。然而，这种方法可能会忽略图像中的重要区域。为了解决这个限制，像OFA和Flamingo这样的方法利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ResNet"},{"Type":"NodeText","Data":"来编码整个图像的信息，考虑了更广泛的上下文。此外，利用transformer架构强大的特征提取能力，像SimVLM、PaLI、MAGMA和BLIP2这样的模型采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉Transformer (ViT)"},{"Type":"NodeText","Data":" 架构进行图像表示。这使得它们能够有效地捕捉视觉信息并将其融入多模态框架中。"}]},{"ID":"20250924222815-5w1ledg","Type":"NodeParagraph","Properties":{"id":"20250924222815-5w1ledg","updated":"20250924222817"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"融合模块 (Fusion Module)"},{"Type":"NodeText","Data":"。融合模块在整合文本和图像嵌入以创建"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"联合表示 (joint representation)"},{"Type":"NodeText","Data":" 方面起着至关重要的作用。一个精心设计的融合模块可以捕捉模态间的互动和关系，防止信息丢失，避免语义不匹配，减轻偏见，并实现全面的理解。例如，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉问答 (VQA)"},{"Type":"NodeText","Data":" 中，融合模块使模型能够同时利用文本和视觉信息来理解问题和相应的图像，从而得出准确的答案。为了提高答案生成的能力，可以为不同的任务手动设计提示，并将其作为输入的一部分包含在融合模块中。这些提示作为额外的线索或信息，引导模型对问题和图像的理解。对于基于生成的VLM，根据视觉和文本模态的整合方式，主要有两种类型的融合模块方法："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器作为多模态融合模块"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器作为多模态融合模块"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924222815-0wq2unf","Type":"NodeParagraph","Properties":{"id":"20250924222815-0wq2unf","updated":"20250924222817"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器作为多模态融合模块"},{"Type":"NodeText","Data":"的方法中，像VL-T5、SimVLM、OFA和PaLI这样的模型专注于在早期阶段创建一个结合了两种模态的联合表示。其整体公式可以表示为：\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"y = G(\\mathcal{E}(X_{input}))"},{"Type":"NodeText","Data":" (1)\n其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"X_{input}"},{"Type":"NodeText","Data":" 表示给定的输入， "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"y"},{"Type":"NodeText","Data":" 表示相应的真实标签。融合编码器函数 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{E}"},{"Type":"NodeText","Data":" 整合视觉和文本信息以创建一个捕捉它们互动和依赖关系的联合表示。这个融合后的表示随后被送入生成模块 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"G"},{"Type":"NodeText","Data":"，该模块进行进一步处理并为下游任务生成期望的输出。"}]},{"ID":"20250924222815-2b7pa8x","Type":"NodeParagraph","Properties":{"id":"20250924222815-2b7pa8x","updated":"20250924222817"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器作为多模态融合模块"},{"Type":"NodeText","Data":"的方法中，像Frozen、Flamingo和MAGMA这样的模型直接在解码阶段结合视觉和文本信息，而没有在早期阶段明确地创建一个联合表示。"}]},{"ID":"20250924222815-yy3p1w6","Type":"NodeBlockquote","Properties":{"id":"20250924222815-yy3p1w6","updated":"20250924222817"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250924222815-pmwgm4h","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222815-pmwgm4h","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250924222815-wedftc4","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222815-wedftc4","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表1：数学符号"}]},{"ID":"20250924222815-096f9hq","Type":"NodeParagraph","Properties":{"id":"20250924222815-096f9hq","updated":"20250924222815"},"Children":[{"Type":"NodeText","Data":"这个表格为读者提供了一份“速查手册”，定义了论文中将要使用的所有数学符号。这有助于确保后续公式和描述的清晰性和一致性。例如，它明确区分了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"原始的视觉/文本token"},{"Type":"NodeText","Data":"（"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"v_i, c_i"},{"Type":"NodeText","Data":"）和用于提示工程的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可学习的提示token"},{"Type":"NodeText","Data":"（"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"z_i^v, z_i^t"},{"Type":"NodeText","Data":"）。"}]},{"ID":"20250924222815-d6gymba","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222815-d6gymba","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成式VLM的核心组件"}]},{"ID":"20250924222815-kli7hlv","Type":"NodeParagraph","Properties":{"id":"20250924222815-kli7hlv","updated":"20250924222815"},"Children":[{"Type":"NodeText","Data":"作者将生成式视觉语言模型（VLMs）拆解为三个核心部分，这有助于理解其工作原理："}]},{"ID":"20250924222815-2rx4ci5","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924222815-2rx4ci5","updated":"20250924222815"},"Children":[{"ID":"20250924222815-3fplv4c","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924222815-3fplv4c","updated":"20250924222815"},"Children":[{"ID":"20250924222815-4gvcdpr","Type":"NodeParagraph","Properties":{"id":"20250924222815-4gvcdpr","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本特征 (Text Feature)"},{"Type":"NodeText","Data":": 负责处理和理解文字输入。作者指出了一个重要的演进：从早期类似BERT使用固定特殊符号（如"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[CLS]"},{"Type":"NodeText","Data":"​）的方式，发展到为了适应图文混合输入而设计出更灵活的符号（如"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;image\u0026gt;"},{"Type":"NodeText","Data":"​），并开始利用像GPT系列这样具备"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链"},{"Type":"NodeText","Data":"能力的新一代大型语言模型（LLMs）作为其文本处理的“大脑”。"}]}]},{"ID":"20250924222815-7kho5fs","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924222815-7kho5fs","updated":"20250924222815"},"Children":[{"ID":"20250924222815-uw6pzyx","Type":"NodeParagraph","Properties":{"id":"20250924222815-uw6pzyx","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉特征 (Visual Feature)"},{"Type":"NodeText","Data":": 负责处理和理解图像输入。这里同样存在一个技术演进路径：从早期使用CNN（如Faster R-CNN）来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检测特定物体区域（ROI）"},{"Type":"NodeText","Data":" 的方法，这种方法可能“只见树木，不见森林”；发展到后来使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ResNet"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ViT（视觉Transformer）"},{"Type":"NodeText","Data":" 来处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"整张图像"},{"Type":"NodeText","Data":"，从而获得更全面、更上下文感知的视觉信息。"}]}]},{"ID":"20250924222815-5emuxwv","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250924222815-5emuxwv","updated":"20250924222815"},"Children":[{"ID":"20250924222815-4doqoup","Type":"NodeParagraph","Properties":{"id":"20250924222815-4doqoup","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"融合模块 (Fusion Module)"},{"Type":"NodeText","Data":": 这是VLM的“心脏”，负责将来自文本和视觉的信息"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无缝地结合起来"},{"Type":"NodeText","Data":"，形成一个统一的、多模态的理解。作者强调，一个好的融合模块至关重要，它能避免“鸡同鸭讲”（语义不匹配），保留关键信息，并最终实现对复杂场景的深入理解。"}]}]}]},{"ID":"20250924222815-y44hncu","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924222815-y44hncu","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两种主流的融合架构"}]},{"ID":"20250924222815-jnnswl1","Type":"NodeParagraph","Properties":{"id":"20250924222815-jnnswl1","updated":"20250924222815"},"Children":[{"Type":"NodeText","Data":"作者进一步将融合模块划分为两种主流的技术路线，这对于理解不同VLM模型的设计哲学至关重要："}]},{"ID":"20250924222815-gb61fsi","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924222815-gb61fsi","updated":"20250924222815"},"Children":[{"ID":"20250924222815-2r7fysk","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924222815-2r7fysk","updated":"20250924222815"},"Children":[{"ID":"20250924222815-0ayskvw","Type":"NodeParagraph","Properties":{"id":"20250924222815-0ayskvw","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器架构 (Encoder-Decoder)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250924222815-4w9p4y1","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222815-4w9p4y1","updated":"20250924222815"},"Children":[{"ID":"20250924222815-of4fpy2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222815-of4fpy2","updated":"20250924222815"},"Children":[{"ID":"20250924222815-txqi458","Type":"NodeParagraph","Properties":{"id":"20250924222815-txqi458","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工作方式"},{"Type":"NodeText","Data":": 这种架构倾向于在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"早期阶段"},{"Type":"NodeText","Data":"就将视觉和文本信息“搅拌”在一起，通过一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"融合编码器（Fusion Encoder）"},{"Type":"NodeText","Data":" 生成一个包含了两种模态信息的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"联合表示"},{"Type":"NodeText","Data":"。然后，一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码器"},{"Type":"NodeText","Data":"基于这个联合表示来生成最终的文本输出。"}]}]},{"ID":"20250924222815-uc9ski9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222815-uc9ski9","updated":"20250924222815"},"Children":[{"ID":"20250924222815-iiopinm","Type":"NodeParagraph","Properties":{"id":"20250924222815-iiopinm","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"比喻"},{"Type":"NodeText","Data":": 就像厨师先把所有食材（视觉和文本）一起放进搅拌机打成混合果汁（联合表示），然后再用这杯果汁去做蛋糕（生成文本）。"}]}]},{"ID":"20250924222815-y2fhei5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222815-y2fhei5","updated":"20250924222815"},"Children":[{"ID":"20250924222815-gw37jqm","Type":"NodeParagraph","Properties":{"id":"20250924222815-gw37jqm","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代表模型"},{"Type":"NodeText","Data":": VL-T5, OFA等。"}]}]}]}]},{"ID":"20250924222815-owpsc9v","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924222815-owpsc9v","updated":"20250924222815"},"Children":[{"ID":"20250924222815-xkf9jzq","Type":"NodeParagraph","Properties":{"id":"20250924222815-xkf9jzq","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器架构 (Decoder-Only)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250924222815-v4msw9g","Type":"NodeList","ListData":{},"Properties":{"id":"20250924222815-v4msw9g","updated":"20250924222815"},"Children":[{"ID":"20250924222815-xtyq8aj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222815-xtyq8aj","updated":"20250924222815"},"Children":[{"ID":"20250924222815-0skk7zv","Type":"NodeParagraph","Properties":{"id":"20250924222815-0skk7zv","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工作方式"},{"Type":"NodeText","Data":": 这种架构更加直接，它不在早期进行显式的融合。而是直接将视觉信息和文本信息"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一起喂给解码器"},{"Type":"NodeText","Data":"，让解码器在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成文本的过程中"},{"Type":"NodeText","Data":"“边看边说”，动态地结合两种信息。"}]}]},{"ID":"20250924222815-p8ytmyx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222815-p8ytmyx","updated":"20250924222815"},"Children":[{"ID":"20250924222815-k3zs5sg","Type":"NodeParagraph","Properties":{"id":"20250924222815-k3zs5sg","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"比喻"},{"Type":"NodeText","Data":": 就像一个同声传译员，一边看着屏幕上的图像（视觉信息），一边听着提示词（文本信息），然后实时地生成翻译（输出文本）。"}]}]},{"ID":"20250924222815-bis9kgu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924222815-bis9kgu","updated":"20250924222815"},"Children":[{"ID":"20250924222815-zd38vvy","Type":"NodeParagraph","Properties":{"id":"20250924222815-zd38vvy","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代表模型"},{"Type":"NodeText","Data":": Flamingo, MAGMA等。"}]}]}]}]}]},{"ID":"20250924222815-k3yjojw","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924222815-k3yjojw","updated":"20250924222815"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250924222815-u3if5rs","Type":"NodeParagraph","Properties":{"id":"20250924222815-u3if5rs","updated":"20250924222815"},"Children":[{"Type":"NodeText","Data":"这一部分深入剖析了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态到文本生成模型"},{"Type":"NodeText","Data":"的内部构造和技术演进。它首先通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表格"},{"Type":"NodeText","Data":"规范了全文的数学语言，然后将复杂的VLM模型拆解为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本、视觉、融合"},{"Type":"NodeText","Data":"这三大易于理解的核心组件。"}]},{"ID":"20250924222815-t4290if","Type":"NodeParagraph","Properties":{"id":"20250924222815-t4290if","updated":"20250924222815"},"Children":[{"Type":"NodeText","Data":"对于文本和视觉特征部分，作者不仅介绍了当前的主流技术（如ViT、GPT），还追溯了其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术发展脉络"},{"Type":"NodeText","Data":"（从ROI检测到全局图像理解），这让读者能更好地理解为什么现有模型会采用这些设计。"}]},{"ID":"20250924222815-4cssz36","Type":"NodeParagraph","Properties":{"id":"20250924222815-4cssz36","updated":"20250924222815"},"Children":[{"Type":"NodeText","Data":"最核心的贡献在于对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"融合模块"},{"Type":"NodeText","Data":"的深入分析，并清晰地划分出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器"},{"Type":"NodeText","Data":"这两种主流架构。这两种架构代表了不同的设计哲学：前者强调“先融合再生成”，后者强调“在生成中融合”。理解这两种架构的区别是后续理解不同VLM模型（如Flamingo vs. VL-T5）如何应用提示工程的关键。"}]},{"ID":"20250924222815-u0irp7r","Type":"NodeParagraph","Properties":{"id":"20250924222815-u0irp7r","updated":"20250924222815"},"Children":[{"Type":"NodeText","Data":"总体而言，这一部分为第3章后续关于提示方法的详细讨论提供了必要的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"背景知识"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术铺垫"},{"Type":"NodeText","Data":"，内容详实，结构清晰，为读者构建了一个关于生成式VLM工作原理的坚实基础。"}]}]},{"ID":"20250924223319-woeb7xr","Type":"NodeParagraph","Properties":{"id":"20250924223319-woeb7xr","updated":"20250924223319"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。这是第四部分的内容，涵盖了论文的第4页和第5页的部分内容，重点介绍了多模-文生成模型中的提示方法。"}]},{"ID":"20250924223319-7tanzwd","Type":"NodeThematicBreak","Properties":{"id":"20250924223319-7tanzwd","updated":"20250924223319"}},{"ID":"20250924223319-o75ki8l","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223319-o75ki8l","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4"}]},{"ID":"20250924223319-uaigr3g","Type":"NodeParagraph","Properties":{"id":"20250924223319-uaigr3g","updated":"20250924223320"},"Children":[{"Type":"NodeText","Data":"这种方法允许模型在生成过程中有效地融合两种模态，并产生与上下文相关的输出。其公式可以表示为：\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"y = G(X_{input})"},{"Type":"NodeText","Data":" (2)\n一个特殊的例子是PICa，它将图像表示为文本描述，并利用GPT-3作为融合模块。这种方法将图像视为文本，并利用像GPT-3这样的预训练语言模型，根据纯文本输入来生成输出。"}]},{"ID":"20250924223319-gqzzuj9","Type":"NodeParagraph","Properties":{"id":"20250924223319-gqzzuj9","updated":"20250924223320"},"Children":[{"Type":"NodeText","Data":"此外，BLIP-2研究了两种不同模块的融合集成：基于解码器的OPT和基于编码器-解码器的FlanT5。该研究进一步分析了这些融合模块各自提供的优势和好处。"}]},{"ID":"20250924223319-3o3tqo4","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223319-3o3tqo4","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.2 多模态-文本提示方法"}]},{"ID":"20250924223319-0fke6g6","Type":"NodeParagraph","Properties":{"id":"20250924223319-0fke6g6","updated":"20250924223320"},"Children":[{"Type":"NodeText","Data":"图2阐释了提示方法的分类。提示方法分为两大类："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示"},{"Type":"NodeText","Data":"，这是劳动密集型、手动制作的、带有离散token的文本提示；以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示"},{"Type":"NodeText","Data":"，这是可优化的、可学习的张量，与输入嵌入连接，但由于它们与真实词嵌入不符，因此缺乏人类可读性。"}]},{"ID":"20250924223319-iydkn2w","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250924223319-iydkn2w","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.2.1 硬提示"}]},{"ID":"20250924223319-655w2dk","Type":"NodeParagraph","Properties":{"id":"20250924223319-655w2dk","updated":"20250924223320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示"},{"Type":"NodeText","Data":"涉及手动制作的、可解释的文本token，例如，在字幕任务的输入前添加“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"A photo of"},{"Type":"NodeText","Data":" ”。硬提示可以进一步分为四个子类别："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务指令 (task instruction)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (in-context learning)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于检索的提示 (retrieval-based prompting)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链提示 (chain-of-thought prompting)"},{"Type":"NodeText","Data":"。值得注意的是，基于检索的提示通常用于为上下文学习选择样本。"}]},{"ID":"20250924223319-yy8xrn9","Type":"NodeParagraph","Properties":{"id":"20250924223319-yy8xrn9","updated":"20250924223320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务指令提示 (Task Instruction Prompting)"},{"Type":"NodeText","Data":"。此方法涉及使用精心设计的提示，提供明确的任务相关指令来引导模型的行为。此方法的公式可以表示为 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"X_{input} = \\mathcal{H}(x, t)"},{"Type":"NodeText","Data":"。这里，"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{H}"},{"Type":"NodeText","Data":" 作为任务指令函数，接收图像 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x"},{"Type":"NodeText","Data":" 和文本 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"t"},{"Type":"NodeText","Data":" 作为输入，并产生修改后的输入表示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"X_{input}"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223319-ti8gpw0","Type":"NodeParagraph","Properties":{"id":"20250924223319-ti8gpw0","updated":"20250924223320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (In-context Learning)"},{"Type":"NodeText","Data":"。上下文学习是一种方法，其中模型接触到一系列相关的示例或提示，使其能够从提供的上下文中学习和泛化。上下文学习方法可以用方程 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"X_{input} = \\mathcal{H}(\\mathcal{C}, x, t)"},{"Type":"NodeText","Data":" 表示。这里，"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{H}"},{"Type":"NodeText","Data":" 表示任务指令函数，它将给定的上下文 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{C}"},{"Type":"NodeText","Data":" 与图像 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x"},{"Type":"NodeText","Data":" 和文本 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"t"},{"Type":"NodeText","Data":" 的输入相结合。由此产生的修改后的输入表示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"X_{input}"},{"Type":"NodeText","Data":" 捕捉了模型对上下文的理解，并用于生成连贯且与上下文相关的响应。通过将模型暴露于一系列相关示例或提示，上下文学习方法促进了在理解和生成响应方面的性能提升。"}]},{"ID":"20250924223319-8rhpbd1","Type":"NodeParagraph","Properties":{"id":"20250924223319-8rhpbd1","updated":"20250924223320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于检索的提示 (Retrieval-based Prompting)"},{"Type":"NodeText","Data":"。这是一种使用检索技术选择提示或上下文的方法。在这种方法中，模型从提示池或外部知识库中检索相关的提示或上下文，以指导其生成或决策过程。基于检索的提示方法可以用公式 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{C} = \\mathcal{R}(x, t)"},{"Type":"NodeText","Data":" 表示。在此方程中，"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{R}"},{"Type":"NodeText","Data":" 表示检索方法，它根据图像 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x"},{"Type":"NodeText","Data":" 和文本 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"t"},{"Type":"NodeText","Data":" 的输入收集相关的提示或上下文。然后，检索到的上下文 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{C}"},{"Type":"NodeText","Data":" 被用来指导模型的生成或决策过程。值得注意的是，检索方法 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{R}"},{"Type":"NodeText","Data":" 会根据具体方法和可用的提示池或知识库而变化。这种方法允许模型从现有信息中受益，并通过在生成过程中利用相关提示或上下文来提高其性能。"}]},{"ID":"20250924223319-gchqv6g","Type":"NodeParagraph","Properties":{"id":"20250924223319-gchqv6g","updated":"20250924223320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链提示 (Chain-of-Thought Prompting)"},{"Type":"NodeText","Data":"。这是一种模型被提示一系列相互递进的指令或问题的方法。链中的每个提示都会增加上下文或缩小焦点，使模型能够生成更连贯和与上下文相符的响应。这种方法帮助模型在整个对话中保持一个逻辑上的“链条”。思维链提示方法的公式不涉及一个具体的方程，而是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"迭代应用提示"},{"Type":"NodeText","Data":"的过程。在链的每一步 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"l"},{"Type":"NodeText","Data":" 中，模型从前一个提示的响应被用作下一个提示的输入。这可以表示为 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"T^{l+1} = \\mathcal{T}^l(x, t)"},{"Type":"NodeText","Data":"。这里 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"T"},{"Type":"NodeText","Data":" 代表提示函数，它接收图像 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x"},{"Type":"NodeText","Data":" 和文本 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"t"},{"Type":"NodeText","Data":" 作为输入并生成一个响应。第 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"l"},{"Type":"NodeText","Data":" 个提示的输出，表示为 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{F}(x,t)"},{"Type":"NodeText","Data":"，作为第 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"(l+1)"},{"Type":"NodeText","Data":" 个提示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"T^{l+1}"},{"Type":"NodeText","Data":" 的输入。通过逐步建立在前一个提示的基础上，思维链提示方法的迭代性质帮助模型保持连贯性，并生成与对话演变上下文相符的响应。"}]},{"ID":"20250924223319-6bdshlz","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250924223319-6bdshlz","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"3.2.2 软提示"}]},{"ID":"20250924223319-lgyv1ul","Type":"NodeParagraph","Properties":{"id":"20250924223319-lgyv1ul","updated":"20250924223320"},"Children":[{"Type":"NodeText","Data":"与硬提示不同，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示"},{"Type":"NodeText","Data":"的特点是可以使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于梯度的方法"},{"Type":"NodeText","Data":"进行微调的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连续向量"},{"Type":"NodeText","Data":"。例如，这个过程可能涉及将一个可学习的向量与输入嵌入连接起来，然后优化这些向量以与特定数据集对齐。软提示可以根据新token是在模型架构内部被整合还是仅仅附加到输入来进行分类。这种区别通常涉及两种特定的策略："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示调优 (prompt tuning)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀token调优 (prefix token tuning)"},{"Type":"NodeText","Data":"。然而，本综ुत只关注不涉及修改底层模型本身的提示方法，因此像P-tuning和LoRa这样改变模型基本结构的技术，不在本研究的主要范围内。"}]},{"ID":"20250924223319-ls20v06","Type":"NodeParagraph","Properties":{"id":"20250924223319-ls20v06","updated":"20250924223320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示调优 (Prompt Tuning)"},{"Type":"NodeText","Data":"。提示调优创建连续的向量表示作为输入提示。在训练过程中，模型学习"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化这些提示"},{"Type":"NodeText","Data":"，旨在提高其在特定任务上的性能。这种方法使模型能够根据其对任务的理解动态生成有效的提示。提示调优的目标，使用提示参数 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_p"},{"Type":"NodeText","Data":"，可以表示如下：\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\underset{x_p}{\\arg\\min} \\, \\mathcal{L}(\\mathcal{F}(y_i, x_p) | Y_{\u003ci}, X_{input})"},{"Type":"NodeText","Data":" (3)\n其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{F}(y_i, x_p)"},{"Type":"NodeText","Data":" 表示在给定提示参数 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_p"},{"Type":"NodeText","Data":" 时的模型输出。这里 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"Y_{\u003ci}"},{"Type":"NodeText","Data":" 表示先前生成的输出，而 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"X_{input}"},{"Type":"NodeText","Data":" 指的是基于提示的修改后输入。提示调优的目标是最小化模型输出与期望输出之间的损失 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{L}"},{"Type":"NodeText","Data":"，给定先前生成的输出和修改后的输入。通过提示调优不断优化提示，模型可以调整其行为并在特定任务上提高其性能。基于模型理解动态生成有效提示，增强了其生成准确且与上下文相关的响应的能力。"}]},{"ID":"20250924223319-m5hd7gm","Type":"NodeParagraph","Properties":{"id":"20250924223319-m5hd7gm","updated":"20250924223320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀token调优 (Prefix Token Tuning)"},{"Type":"NodeText","Data":"。与提示调优类似，前缀token调优涉及向输入添加"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务特定的向量"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223319-xwtyk7s","Type":"NodeParagraph","Properties":{"id":"20250924223319-xwtyk7s","updated":"20250924223320"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"Fig 2"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"https://storage.googleapis.com/assistly-images/20250915150242-6eayjcy.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250924223319-od47aei","Type":"NodeParagraph","Properties":{"id":"20250924223319-od47aei","updated":"20250924223320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 2：多模态到文本生成中的提示方法。"},{"Type":"NodeText","Data":" 提示方法可以根据模板的可读性分为两大类：硬提示和软提示。硬提示包含四个子类别：任务指令、上下文学习、基于检索的提示和思维链提示。软提示分为两种策略：提示调优和前缀token调优，这取决于它们是在模型架构内部添加新token还是仅仅将它们附加到输入。然而，本研究主要关注避免改变基础模型的提示方法，排除了像P-tuning和LoRa这样修改模型核心结构的技术。"}]},{"ID":"20250924223319-ngj9iq5","Type":"NodeParagraph","Properties":{"id":"20250924223319-ngj9iq5","updated":"20250924223320"},"Children":[{"Type":"NodeText","Data":"然而，在这种情况下，这些向量被插入到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"所有模型层"},{"Type":"NodeText","Data":"中，并且可以独立地进行训练和更新，同时保持预训练模型的其余参数"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223319-555tao9","Type":"NodeParagraph","Properties":{"id":"20250924223319-555tao9","updated":"20250924223320"},"Children":[{"Type":"NodeText","Data":"值得注意的是，这些提示方法并非相互排斥。它们可以组合使用以在各种设置和任务中实现期望的结果。提示方法的选择取决于具体的任务、数据集的可用性以及模型行为所需的控制和定制水平。"}]},{"ID":"20250924223319-xvz2sp4","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223319-xvz2sp4","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.3 VLM中提示技术的进展"}]},{"ID":"20250924223319-tl7cqvg","Type":"NodeParagraph","Properties":{"id":"20250924223319-tl7cqvg","updated":"20250924223320"},"Children":[{"Type":"NodeText","Data":"本节将概述在各种VLM中用于提升性能的提示技术。为了清晰和结构化的呈现，模型将根据其融合模块分为两种主要类型：1）使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器"},{"Type":"NodeText","Data":"作为融合模块的模型，以及2）使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器"},{"Type":"NodeText","Data":"作为融合模块的模型。"}]},{"ID":"20250924223319-xxhmmn9","Type":"NodeParagraph","Properties":{"id":"20250924223319-xxhmmn9","updated":"20250924223320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"使用编码器-解码器作为融合模块的提示模型 (Prompting Models with Encoder-decoder as the Fusion Module)"},{"Type":"NodeText","Data":"。早期的VLM研究通常涉及在transformer编码器之上设计任务特定的架构。然而，最近的进展引入了一个统一的视觉-语言框架，该框架将编码器作为融合模块。这类模型的著名例子包括VL-T5、SimVLM和OFA。它们主要采用两种提示方法："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"手工制作的指令"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示调优"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223319-3fpgh4o","Type":"NodeParagraph","Properties":{"id":"20250924223319-3fpgh4o","updated":"20250924223320"},"Children":[{"Type":"NodeText","Data":"VL-T5和OFA都利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本前缀作为提示"},{"Type":"NodeText","Data":"。例如，“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"vqa:"},{"Type":"NodeText","Data":"​”用于视觉问答，“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"caption:"},{"Type":"NodeText","Data":"​”用于图像字幕任务。SimVLM引入了前缀“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"a photo of:"},{"Type":"NodeText","Data":"​”来提高解码字幕的质量。此外，VL-T5引入了共享的视觉哨兵token（"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;vis_i\u0026gt;"},{"Type":"NodeText","Data":"​）来指定感兴趣区域（RoI）特征中对应的图像区域。文本哨兵token（"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;text_i\u0026gt;"},{"Type":"NodeText","Data":"​）则用于替换连续的文本。类似地，OFA生成位置token来指定区域的位置（"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;x1, y1, x2, y2\u0026gt;"},{"Type":"NodeText","Data":"​）。这些特殊的token有助于视觉和文本信息的结构化整合。"}]},{"ID":"20250924223319-q576zet","Type":"NodeParagraph","Properties":{"id":"20250924223319-q576zet","updated":"20250924223320"},"Children":[{"Type":"NodeText","Data":"基于这些特殊token，VL-T5利用提示“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"caption region: \u0026lt;vis_i\u0026gt;"},{"Type":"NodeText","Data":"​”来进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"区域描述 (grounded captioning)"},{"Type":"NodeText","Data":" 任务，指示模型应根据指定的视觉区域生成字幕。OFA则使用模板“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Q: what color is the car in the region? region: \u0026lt;x1,y1,x2,y2\u0026gt; A:"},{"Type":"NodeText","Data":"​”来提示其提出的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"区域问答 (grounded question answering)"},{"Type":"NodeText","Data":" 任务，为模型提供指令，要求它通过参照指定的视觉区域来回答问题。在OFA上的提示调优被 所探索，他们在每一层引入了可调的提示嵌入。实验结果表明，这种轻量级的提示调优方法不仅高效，而且对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性攻击"},{"Type":"NodeText","Data":"具有弹性。"}]},{"ID":"20250924223319-khaze9u","Type":"NodeParagraph","Properties":{"id":"20250924223319-khaze9u","updated":"20250924223320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"使用解码器作为融合模块的提示模型 (Prompting Models with Decoder-based Fusion Module)"},{"Type":"NodeText","Data":"。另一条研究路线侧重于在VLM中利用解码器作为融合模块。Frozen和BLIP-2是采用图像条件前缀调优的典范模型。Frozen引入了在整合视觉信息作为前缀的同时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"保持LLM语言能力"},{"Type":"NodeText","Data":"的概念。它通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结模型"},{"Type":"NodeText","Data":"并训练一个单独的视觉编码器来表示图像来实现这一点。在Frozen中，视觉信息被表示为一个由两个嵌入组成的序列，作为视觉前缀。作者还提出了任务引导技术，例如指示模型“用dax或blicket回答”，并评估了模型在下游任务中使用不同形式和数量的上下文学习的性能。为了有效地促进跨模态对齐，BLIP-2"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不微调视觉编码器"},{"Type":"NodeText","Data":"。相反，它引入了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"查询Transformer（Q-Former）"},{"Type":"NodeText","Data":"，从冻结的图像编码器中提取视觉特征，使用提取的查询嵌入作为软视觉提示。MAGMA遵循与Frozen类似的方法，在保持语言模型冻结的同时，整合了一个新的图像前缀编码器。任务指令，如“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"A picture of "},{"Type":"NodeText","Data":"​”被用于图像字幕。Flamingo探索了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本学习"},{"Type":"NodeText","Data":"的能力，并采用了多种提示技术。作者引入了特殊token，"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;BOS\u0026gt;"},{"Type":"NodeText","Data":"​（序列开始）和"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;EOC\u0026gt;"},{"Type":"NodeText","Data":"​（块结束），以区分样本对。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本"},{"Type":"NodeText","Data":"场景中，使用不包含相应视觉信息的文本提示。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本"},{"Type":"NodeText","Data":"设置中，对不同任务采用不同的格式（例如，视觉问答任务使用“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Question: {question} Answer: {answer}"},{"Type":"NodeText","Data":"​”），并利用基于检索的上下文示例选择（RICES）方法来选择合适的样本对作为提示。还采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示集成 (Prompt ensembling)"},{"Type":"NodeText","Data":" 技术来计算最终分数。"}]},{"ID":"20250924223319-drve735","Type":"NodeBlockquote","Properties":{"id":"20250924223319-drve735","updated":"20250924223320"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250924223319-8vm0qof","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223319-8vm0qof","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250924223319-g817td5","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223319-g817td5","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示方法的系统性分类 (图2)"}]},{"ID":"20250924223319-wpu9gy8","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223319-wpu9gy8","updated":"20250924223319"},"Children":[{"ID":"20250924223319-mqhdtac","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-mqhdtac","updated":"20250924223319"},"Children":[{"ID":"20250924223319-70970m4","Type":"NodeParagraph","Properties":{"id":"20250924223319-70970m4","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心框架"},{"Type":"NodeText","Data":": 图2是理解本章内容的关键。它将多模态-文本生成中的提示方法组织成一个清晰的树状结构。顶层是基于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可读性"},{"Type":"NodeText","Data":"划分的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250924223319-mwkk4re","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-mwkk4re","updated":"20250924223319"},"Children":[{"ID":"20250924223319-9f4b3rs","Type":"NodeParagraph","Properties":{"id":"20250924223319-9f4b3rs","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示的“工具箱”"},{"Type":"NodeText","Data":": 硬提示被进一步细分为四种策略，每种策略都有不同的应用场景："}]},{"ID":"20250924223319-lj25ys8","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924223319-lj25ys8","updated":"20250924223319"},"Children":[{"ID":"20250924223319-aayne44","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924223319-aayne44","updated":"20250924223319"},"Children":[{"ID":"20250924223319-uvt3x3q","Type":"NodeParagraph","Properties":{"id":"20250924223319-uvt3x3q","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务指令 (Task Instruction)"},{"Type":"NodeText","Data":": 最直接的方式，告诉模型“你要做什么”，比如“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"caption this image:"},{"Type":"NodeText","Data":"​”。"}]}]},{"ID":"20250924223319-fdk6lci","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924223319-fdk6lci","updated":"20250924223319"},"Children":[{"ID":"20250924223319-l8wja23","Type":"NodeParagraph","Properties":{"id":"20250924223319-l8wja23","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (In-context Learning)"},{"Type":"NodeText","Data":": 模仿人类学习，给模型看一两个“例子”，让它举一反三。"}]}]},{"ID":"20250924223319-636af92","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250924223319-636af92","updated":"20250924223319"},"Children":[{"ID":"20250924223319-gjf63qf","Type":"NodeParagraph","Properties":{"id":"20250924223319-gjf63qf","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于检索的提示 (Retrieval-based)"},{"Type":"NodeText","Data":": 更智能的上下文学习，不是随机给例子，而是先从一个大的知识库里“检索”出最相关的例子再喂给模型。"}]}]},{"ID":"20250924223319-7r6isa2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250924223319-7r6isa2","updated":"20250924223319"},"Children":[{"ID":"20250924223319-61yc0e0","Type":"NodeParagraph","Properties":{"id":"20250924223319-61yc0e0","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链 (Chain-of-Thought)"},{"Type":"NodeText","Data":": 解决复杂问题时，引导模型“一步一步来”，先生成中间推理过程，再给出最终答案。"}]}]}]}]},{"ID":"20250924223319-e2yiq7w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-e2yiq7w","updated":"20250924223319"},"Children":[{"ID":"20250924223319-bykinbo","Type":"NodeParagraph","Properties":{"id":"20250924223319-bykinbo","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示的“调优”策略"},{"Type":"NodeText","Data":": 软提示的核心是“学习”，即通过梯度下降找到最优的提示向量。它们被分为："}]},{"ID":"20250924223319-934zaru","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924223319-934zaru","updated":"20250924223319"},"Children":[{"ID":"20250924223319-x8aq8ub","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924223319-x8aq8ub","updated":"20250924223319"},"Children":[{"ID":"20250924223319-mpp8flo","Type":"NodeParagraph","Properties":{"id":"20250924223319-mpp8flo","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示调优 (Prompt Tuning)"},{"Type":"NodeText","Data":": 相对简单，在输入层添加可学习的向量。"}]}]},{"ID":"20250924223319-xi3rncr","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924223319-xi3rncr","updated":"20250924223319"},"Children":[{"ID":"20250924223319-zfj22hz","Type":"NodeParagraph","Properties":{"id":"20250924223319-zfj22hz","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀调优 (Prefix Tuning)"},{"Type":"NodeText","Data":": 更深入，在模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每一层"},{"Type":"NodeText","Data":"都添加可学习的向量，影响更深远。"}]}]}]}]},{"ID":"20250924223319-wa8plpi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-wa8plpi","updated":"20250924223319"},"Children":[{"ID":"20250924223319-o8ksypy","Type":"NodeParagraph","Properties":{"id":"20250924223319-o8ksypy","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"边界的明确"},{"Type":"NodeText","Data":": 作者再次强调，本文只讨论"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不改变模型结构"},{"Type":"NodeText","Data":"的方法，P-tuning和LoRa等被排除在外。"}]}]}]},{"ID":"20250924223319-chkhjp9","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223319-chkhjp9","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体模型中的提示技术应用"}]},{"ID":"20250924223319-s6tvdzr","Type":"NodeParagraph","Properties":{"id":"20250924223319-s6tvdzr","updated":"20250924223319"},"Children":[{"Type":"NodeText","Data":"作者将VLM模型按其“心脏”——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"融合模块"},{"Type":"NodeText","Data":"——的不同，分为两类来分别讨论提示技术的应用，这使得分析非常有条理。"}]},{"ID":"20250924223319-zafiy09","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924223319-zafiy09","updated":"20250924223319"},"Children":[{"ID":"20250924223319-ipef1zt","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924223319-ipef1zt","updated":"20250924223319"},"Children":[{"ID":"20250924223319-ymog1bl","Type":"NodeParagraph","Properties":{"id":"20250924223319-ymog1bl","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器架构 (Encoder-Decoder Fusion) 模型 (如 VL-T5, OFA)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250924223319-0luqekm","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223319-0luqekm","updated":"20250924223319"},"Children":[{"ID":"20250924223319-z07rr8i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-z07rr8i","updated":"20250924223319"},"Children":[{"ID":"20250924223319-swxekqz","Type":"NodeParagraph","Properties":{"id":"20250924223319-swxekqz","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示应用"},{"Type":"NodeText","Data":": 这类模型擅长使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构化的硬提示"},{"Type":"NodeText","Data":"。它们设计了特殊的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“哨兵token”"},{"Type":"NodeText","Data":" (如"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;vis_i\u0026gt;"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;x1,y1,x2,y2\u0026gt;"},{"Type":"NodeText","Data":"​)，像GPS坐标一样，精确地将文本指令（如“描述这个区域”）与图像中的特定位置关联起来。这使得它们在需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确定位"},{"Type":"NodeText","Data":"的任务（如区域描述/问答）上表现出色。"}]}]},{"ID":"20250924223319-gjixkxc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-gjixkxc","updated":"20250924223319"},"Children":[{"ID":"20250924223319-yyi6lxa","Type":"NodeParagraph","Properties":{"id":"20250924223319-yyi6lxa","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示应用"},{"Type":"NodeText","Data":": 实验表明，在这类模型上进行轻量级的提示调优，不仅能提升效率，还能意外地增强模型抵抗"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性攻击"},{"Type":"NodeText","Data":"的能力。"}]}]}]}]},{"ID":"20250924223319-fjj2tbs","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924223319-fjj2tbs","updated":"20250924223319"},"Children":[{"ID":"20250924223319-1a44xkk","Type":"NodeParagraph","Properties":{"id":"20250924223319-1a44xkk","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器架构 (Decoder-Only Fusion) 模型 (如 Flamingo, BLIP-2)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250924223319-62uvghp","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223319-62uvghp","updated":"20250924223319"},"Children":[{"ID":"20250924223319-dl15nqc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-dl15nqc","updated":"20250924223319"},"Children":[{"ID":"20250924223319-v99anaj","Type":"NodeParagraph","Properties":{"id":"20250924223319-v99anaj","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心理念"},{"Type":"NodeText","Data":": 这类模型的关键思想是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“保护”强大的预训练语言模型（LLM）"},{"Type":"NodeText","Data":"。它们通常会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结LLM的参数"},{"Type":"NodeText","Data":"，以保留其强大的语言生成和推理能力，然后想办法将视觉信息作为一种“条件”或“前缀”注入进去。"}]}]},{"ID":"20250924223319-6sshfon","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-6sshfon","updated":"20250924223319"},"Children":[{"ID":"20250924223319-eezgq5e","Type":"NodeParagraph","Properties":{"id":"20250924223319-eezgq5e","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉信息注入方式"},{"Type":"NodeText","Data":":"}]},{"ID":"20250924223319-92xah1g","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223319-92xah1g","updated":"20250924223319"},"Children":[{"ID":"20250924223319-jf1tnkn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-jf1tnkn","updated":"20250924223319"},"Children":[{"ID":"20250924223319-uasu5gx","Type":"NodeParagraph","Properties":{"id":"20250924223319-uasu5gx","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Frozen/MAGMA"},{"Type":"NodeText","Data":": 训练一个专门的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉编码器"},{"Type":"NodeText","Data":"，将图像转换成一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉前缀"},{"Type":"NodeText","Data":"（一种软提示），然后拼接到文本输入前面，一起喂给冻结的LLM。"}]}]},{"ID":"20250924223319-iauvdaj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-iauvdaj","updated":"20250924223319"},"Children":[{"ID":"20250924223319-pc0n62u","Type":"NodeParagraph","Properties":{"id":"20250924223319-pc0n62u","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BLIP-2"},{"Type":"NodeText","Data":": 提出了一种更精巧的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Q-Former"},{"Type":"NodeText","Data":"结构，它像一个“信息过滤器”，主动地从一个冻结的视觉模型中“查询”出对当前文本最有用的视觉特征，形成高效的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软视觉提示"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250924223319-hd334m8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-hd334m8","updated":"20250924223319"},"Children":[{"ID":"20250924223319-6c907yp","Type":"NodeParagraph","Properties":{"id":"20250924223319-6c907yp","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习大师 - Flamingo"},{"Type":"NodeText","Data":": Flamingo是这类模型中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（少样本学习）"},{"Type":"NodeText","Data":" 的集大成者。它不仅使用硬提示模板来规范问答格式，还引入了智能的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RICES方法"},{"Type":"NodeText","Data":"来自动检索和挑选最高质量的“示例”放入提示中，最大化模型的少样本学习效果。"}]}]}]}]}]},{"ID":"20250924223319-bdz6gkf","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223319-bdz6gkf","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250924223319-8cb93mb","Type":"NodeParagraph","Properties":{"id":"20250924223319-8cb93mb","updated":"20250924223319"},"Children":[{"Type":"NodeText","Data":"这一部分是论文的核心技术章节之一，它系统地梳理了多模态-文本生成模型中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程方法论"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223319-6ab0hg2","Type":"NodeParagraph","Properties":{"id":"20250924223319-6ab0hg2","updated":"20250924223319"},"Children":[{"Type":"NodeText","Data":"首先，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图2"},{"Type":"NodeText","Data":"和详细的文字描述，作者建立了一个全面且清晰的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示方法分类体系"},{"Type":"NodeText","Data":"。这个体系不仅涵盖了从简单指令到复杂思维链的各种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示"},{"Type":"NodeText","Data":"策略，也区分了不同深度的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示"},{"Type":"NodeText","Data":"调优技术。这为理解和比较不同论文中的提示方法提供了一个统一的框架。"}]},{"ID":"20250924223319-kzbl7o8","Type":"NodeParagraph","Properties":{"id":"20250924223319-kzbl7o8","updated":"20250924223319"},"Children":[{"Type":"NodeText","Data":"其次，本部分最精彩之处在于，它没有孤立地介绍技术，而是将这些技术与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体的模型架构"},{"Type":"NodeText","Data":"（编码器-解码器 vs. 仅解码器）紧密结合。通过分析VL-T5、OFA、Flamingo、BLIP-2等代表性模型，读者可以清晰地看到："}]},{"ID":"20250924223319-awoyf12","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223319-awoyf12","updated":"20250924223319"},"Children":[{"ID":"20250924223319-75rvhyi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-75rvhyi","updated":"20250924223319"},"Children":[{"ID":"20250924223319-sokds1l","Type":"NodeParagraph","Properties":{"id":"20250924223319-sokds1l","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同的架构偏好不同的提示策略"},{"Type":"NodeText","Data":"：编码器-解码器模型因其结构，更适合处理需要精确定位的结构化硬提示；而仅解码器模型为了保护LLM，则更倾向于将视觉信息转化为软提示（视觉前缀）进行注入。"}]}]},{"ID":"20250924223319-jqv354u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223319-jqv354u","updated":"20250924223319"},"Children":[{"ID":"20250924223319-a9kr0ua","Type":"NodeParagraph","Properties":{"id":"20250924223319-a9kr0ua","updated":"20250924223319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的演进趋势"},{"Type":"NodeText","Data":"：从简单的手工模板，到复杂的思维链，再到自动检索示例的上下文学习，以及高效的可学习软提示，提示工程正变得越来越"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动化、智能化和精细化"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250924223319-8uf98vy","Type":"NodeParagraph","Properties":{"id":"20250924223319-8uf98vy","updated":"20250924223319"},"Children":[{"Type":"NodeText","Data":"总体而言，这一部分内容深入浅出，既有理论高度（分类框架），又有实践深度（模型案例），成功地向读者展示了在多模态-文本生成领域，研究人员是如何运用五花八门的提示技术来“驯服”和“激发”强大的视觉语言模型的。"}]}]},{"ID":"20250924223719-cobeg5o","Type":"NodeParagraph","Properties":{"id":"20250924223719-cobeg5o","updated":"20250924223719"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。这是第五部分的内容，涵盖了论文的第6页和第7页的部分内容，主要讨论了提示工程在具体应用中的理解、应用和伦理考量。"}]},{"ID":"20250924223719-p3mjqh4","Type":"NodeThematicBreak","Properties":{"id":"20250924223719-p3mjqh4","updated":"20250924223719"}},{"ID":"20250924223719-p53wiym","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223719-p53wiym","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6"}]},{"ID":"20250924223719-8xeq5j8","Type":"NodeParagraph","Properties":{"id":"20250924223719-8xeq5j8","updated":"20250924223720"},"Children":[{"Type":"NodeText","Data":"对于像HatefulMemes这样的特定任务，设计的提示旨在整合提供的OCR（光学字符识别）信息。此外，还为呈现的对话专门设计了手工制作的对话提示。将LLMs的多语言能力扩展到了VLMs，而无需冻结任何参数。他们通过在提示指令中明确指定目标语言来实现这一点。例如，一个提示可以被表述为“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Generate the alt_text in \u0026lt;lang\u0026gt;"},{"Type":"NodeText","Data":"​”，其中"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;lang\u0026gt;"},{"Type":"NodeText","Data":"​代表与所需文本字符串相关联的语言代码。此外，微软提出了一系列"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模大语言模型（MLLM）"},{"Type":"NodeText","Data":"，即Kosmos-1和Kosmos-2。这些模型具备感知不同模态和评估多种任务的能力，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态思维链"},{"Type":"NodeText","Data":"提示场景。文本指令被用来使模型更好地理解下游任务。例如，在Kosmos-1中，像“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Here are three/four/eight images:"},{"Type":"NodeText","Data":"​”和“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"The following image is:"},{"Type":"NodeText","Data":"​”这样的短语被用于Raven IQ测试。在思维链提示中，Kosmos-1首先使用一个提示（例如，“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Introduce this picture in detail:"},{"Type":"NodeText","Data":"​”）来引导模型生成一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基本原理（rationale）"},{"Type":"NodeText","Data":"。然后，一个结合了所生成原理的任务感知提示被用来产生最终结果。基于Kosmos-1，Kosmos-2通过使用带有边界框的文本跨度作为提示，整合了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定位 (grounding)"},{"Type":"NodeText","Data":" 和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指代 (referring)"},{"Type":"NodeText","Data":" 能力，即“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;p\u0026gt; text span \u0026lt;/p\u0026gt;\u0026lt;box\u0026gt;\u0026lt;loc1\u0026gt;\u0026lt;loc2\u0026gt;\u0026lt;/box\u0026gt;"},{"Type":"NodeText","Data":"​”，其中"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;loc1\u0026gt;"},{"Type":"NodeText","Data":"​和"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;loc2\u0026gt;"},{"Type":"NodeText","Data":"​是位置token，"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;p\u0026gt;"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;/p\u0026gt;"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;box\u0026gt;"},{"Type":"NodeText","Data":"​和"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026lt;/box\u0026gt;"},{"Type":"NodeText","Data":"​分别是特殊的边界和文本跨度token。"}]},{"ID":"20250924223719-bmt2u4j","Type":"NodeParagraph","Properties":{"id":"20250924223719-bmt2u4j","updated":"20250924223720"},"Children":[{"Type":"NodeText","Data":"PICa采用了一种不同的方法，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不学习视觉嵌入"},{"Type":"NodeText","Data":"。相反，它将图像转换为文本描述，并直接查询GPT-3来预测答案。利用GPT-3的少样本学习能力，PICa仅需在推理时使用少量上下文示例，即可适应视觉问答（VQA）任务。GPT-4，作为ChatGPT的最新版本，已被引入作为一个先进的VLM。除了采用任务特定的硬提示外，GPT-4还结合了上下文学习方法来处理像AP艺术史这样的复杂任务。"}]},{"ID":"20250924223719-ds4cgwq","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223719-ds4cgwq","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.4 理解提示 (Understanding Prompting)"}]},{"ID":"20250924223719-bddu3ue","Type":"NodeParagraph","Properties":{"id":"20250924223719-bddu3ue","updated":"20250924223720"},"Children":[{"Type":"NodeText","Data":"为了深入理解在多模态到文本生成模型中影响提示的因素，将介绍以下几个方面："}]},{"ID":"20250924223719-07ed23n","Type":"NodeParagraph","Properties":{"id":"20250924223719-07ed23n","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据集特定的前缀 (Dataset-specific Prefixes)"},{"Type":"NodeText","Data":"。文本提示的选择可以显著影响模型的性能。VL-T5在视觉问答（VQA）和GQA任务上都实验了单一前缀“vqa”。结果表明，单个模型可以有效地处理多个VQA任务，而无需数据集特定的前缀。"}]},{"ID":"20250924223719-oyvbnhy","Type":"NodeParagraph","Properties":{"id":"20250924223719-oyvbnhy","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结语言模型 (Freezing the Language Model)"},{"Type":"NodeText","Data":"。许多在多模态到文本生成模型中关于提示的探索都依赖于语言模型的强大生成能力。为了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"保留LLMs的广泛能力"},{"Type":"NodeText","Data":"，像Frozen、MAGMA、Flamingo和BLiP2这样的方法在训练期间"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结语言模型"},{"Type":"NodeText","Data":"。这可以防止知识丢失，并能够保留提示能力。另一方面，像OFA和KOSMOS-1这样的方法直接采用编码器-解码器结构，没有额外的模型组件来追求统一模型。然而，仅微调语言模型可能导致语言能力的下降。为了解决这个问题，OFA和KOSMOS-1在训练期间都"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加入了纯语言任务"},{"Type":"NodeText","Data":"，以防止语言能力的损失。"}]},{"ID":"20250924223719-4stvu9k","Type":"NodeParagraph","Properties":{"id":"20250924223719-4stvu9k","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (In-context Learning)"},{"Type":"NodeText","Data":"。最近的研究表明，语言模型的上下文学习能力可以成功地转移到视觉-语言生成模型中。Frozen展现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"快速概念绑定"},{"Type":"NodeText","Data":"的能力，使模型仅用少量示例就能将一个新词与一个视觉类别关联起来，并立即恰当地使用该词。虽然模型在双向设置（两个新词）中表现良好，但这种能力未能转移到五向设置（五个新词）。实验结果还表明，增加上下文学习样本的数量可以增强模型性能，但存在一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"饱和点"},{"Type":"NodeText","Data":"，额外的重复内容甚至可能导致性能下降。在Flamingo的案例中也得出了类似的结论。Flamingo和Kosmos-1都证明，采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单独的文本提示"},{"Type":"NodeText","Data":"而不是图文对可以提高模型性能。然而，需要注意的是，使用单独的文本提示可能会给模型带来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"偏见"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223719-jufvnmf","Type":"NodeParagraph","Properties":{"id":"20250924223719-jufvnmf","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示调优 (Prompt Tuning)"},{"Type":"NodeText","Data":"。对生成式多模态模型中的提示调优进行了一项研究。他们的发现表明，在各种任务中，提示调优始终比微调表现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更强的鲁棒性"},{"Type":"NodeText","Data":"。该研究还强调了不同设置对提示性能的影响，揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更长、参数更多的提示"},{"Type":"NodeText","Data":"可以促进改进。然而，存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"边际效用递减"},{"Type":"NodeText","Data":"的问题，过长的提示甚至可能对性能产生不利影响。此外，结果表明，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"底层"},{"Type":"NodeText","Data":"插入提示可能会带来更好的性能。"}]},{"ID":"20250924223719-3piv6nz","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223719-3piv6nz","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.5 提示的应用"}]},{"ID":"20250924223719-s9h8viv","Type":"NodeParagraph","Properties":{"id":"20250924223719-s9h8viv","updated":"20250924223720"},"Children":[{"Type":"NodeText","Data":"提示已在许多涉及文本生成的视觉-语言任务中被广泛采用，展示了有希望的结果，并启发了一种新的学习范式，即上下文学习。"}]},{"ID":"20250924223719-vi5umu2","Type":"NodeParagraph","Properties":{"id":"20250924223719-vi5umu2","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉问答 (Visual Question Answering)"},{"Type":"NodeText","Data":"。VQA的目标是训练模型理解图像中的信息并用自然语言回答关于它的问题。上下文提示在少样本和零样本场景中显示出惊人的结果。一些工作还将提示应用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"网页问答"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"区域问答"},{"Type":"NodeText","Data":"。网页问答旨在从网页中找到问题的答案，这需要理解文本的语义和结构。Huang等人使用模板提示“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Given the context below from the web page, extract the answer from the given text like this: Question: Who is the publisher of this book? Answer: Penguin Books Ltd. Context: {WebText} Q: {question} A: {answer}"},{"Type":"NodeText","Data":"​”，其中{WebText}代表从网页中提取的文本。区域问答最初是为了反映One For All（OFA）模型的强可移植性而设计的。在这个任务中，模型应该回答关于某个特定区域的问题，并且为硬提示设计了特殊的区域token。"}]},{"ID":"20250924223719-h44zute","Type":"NodeParagraph","Properties":{"id":"20250924223719-h44zute","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉常识推理 (Visual Commonsense Reasoning)"},{"Type":"NodeText","Data":"。这项任务需要理解现实世界中日常物体的属性，例如物体大小推理和物体颜色推理。模型被要求预测大小或颜色关系。Kosmos模型在零样本场景中使用示例提示，如“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Is {Item1} larger than {Item2}? {Answer}"},{"Type":"NodeText","Data":"​”和“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"The color of {Object} is? {Answer}"},{"Type":"NodeText","Data":"​”，并取得了有希望的结果。"}]},{"ID":"20250924223719-je9431e","Type":"NodeParagraph","Properties":{"id":"20250924223719-je9431e","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本图像分类 (Zero-shot Image Classification)"},{"Type":"NodeText","Data":"。提示与大型预训练多模态模型的结合，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"域外测试数据"},{"Type":"NodeText","Data":"上显示出很强的可移植性，例如零样本图像分类。Kosmos将输入图像与像“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"The photo of the"},{"Type":"NodeText","Data":"​”这样的提示连接起来，让模型用预测的类别来完成提示句子。此外，为了在分类中融入额外的规则，Kosmos还发送类别描述以及提示，来引导模型针对特定类别进行预测。"}]},{"ID":"20250924223719-olba6sd","Type":"NodeParagraph","Properties":{"id":"20250924223719-olba6sd","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像描述 (Image Captioning)"},{"Type":"NodeText","Data":"。给定一张图像生成描述是一项典型的多模态到文本生成任务，需要理解视觉和语言信息。提示主要用于少样本和零样本场景，并展示了强大的能力。Flamingo和PaLI采用提示在少样本设置中生成图像描述。例如，PaLI使用提示“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Generate the alt_text in EN"},{"Type":"NodeText","Data":"​”来生成图像描述。在零样本设置中也研究了提示，例如BLIP-2、MAGMA、SimVLM和OFA。"}]},{"ID":"20250924223719-8ywuww2","Type":"NodeParagraph","Properties":{"id":"20250924223719-8ywuww2","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"聊天机器人 (Chatbot)"},{"Type":"NodeText","Data":"。像ChatGPT这样的聊天机器人的出现是人工智能研究中最显著的突破之一。像Visual ChatGPT和GPT4这样的后续工作将聊天机器人扩展到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态应用"},{"Type":"NodeText","Data":"，支持图像和文本提示。Visual ChatGPT基于ChatGPT和视觉基础模型构建。它使用一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示管理器（Prompt Manager）"},{"Type":"NodeText","Data":" 来指定输入输出格式，将视觉信息转换为语言格式，并处理不同视觉基础模型的历史记录。GPT4能够接受由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像和文本组成的提示"},{"Type":"NodeText","Data":"，这让用户可以通过生成文本输出来指定任何视觉和语言任务，给定任意交错的文本和图像提示。此外，一些工作将GPT迁移到特定领域，例如在生物医学研究上的BiomedGPT。"}]},{"ID":"20250924223719-91g5iyq","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223719-91g5iyq","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.6 提示的责任AI考量"}]},{"ID":"20250924223719-q0refen","Type":"NodeParagraph","Properties":{"id":"20250924223719-q0refen","updated":"20250924223720"},"Children":[{"Type":"NodeText","Data":"基于语言的VLM继承了底层LLM和视觉模型的风险，例如在用图像提示时出现的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性别和种族偏见"},{"Type":"NodeText","Data":"。关于LLM伦理的几项调查已经存在。一些工作研究了VLM对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然分布偏移"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性鲁棒性"},{"Type":"NodeText","Data":"的鲁棒性。最近的一项研究调查了VLM上提示调优对自然分布偏移的鲁棒性。此外，通过整合多尺度图像特征，提出了在VLM上进行鲁棒的提示调优。"}]},{"ID":"20250924223719-rxnxuuj","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223719-rxnxuuj","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4 图像-文本匹配中的提示模型"}]},{"ID":"20250924223719-4ouboaf","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223719-4ouboaf","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.1 图像-文本匹配模型的预备知识"}]},{"ID":"20250924223719-1vwzzip","Type":"NodeParagraph","Properties":{"id":"20250924223719-1vwzzip","updated":"20250924223720"},"Children":[{"Type":"NodeText","Data":"基于匹配的VLM引入了一种新颖的训练范式，促进了联合多模态表示的获取。该领域的杰出模型，如CLIP、ALIGN、ALBEF和Multi-Event CLIP，利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比学习技术"},{"Type":"NodeText","Data":"来实现图像和文本的联合表示，其学习目标是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"拉近图文对的表示，同时推开非配对的表示"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223719-iytkijs","Type":"NodeParagraph","Properties":{"id":"20250924223719-iytkijs","updated":"20250924223720"},"Children":[{"Type":"NodeText","Data":"通过扩展训练数据集和扩大模型参数，基于匹配的模型在广泛的下游任务中表现出适应性，包括零样本基准和微调场景。"}]},{"ID":"20250924223719-48qlk1d","Type":"NodeParagraph","Properties":{"id":"20250924223719-48qlk1d","updated":"20250924223720"},"Children":[{"Type":"NodeText","Data":"根据提示的目标，现有方法可以分为三类："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示文本编码器"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示视觉编码器"},{"Type":"NodeText","Data":"，或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"联合提示两个分支"},{"Type":"NodeText","Data":"，如图3所示。这些方法旨在增强VLM在最近研究中的灵活性和任务特定性能。"}]},{"ID":"20250924223719-fkeqww1","Type":"NodeParagraph","Properties":{"id":"20250924223719-fkeqww1","updated":"20250924223720"},"Children":[{"Type":"NodeText","Data":"一个经典的匹配损失公式如下，用以对齐图像和文本嵌入，包含一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图到文损失"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"L_{i2t}"},{"Type":"NodeText","Data":" 和一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文到图损失"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"L_{t2i}"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223719-u9c7p8i","Type":"NodeParagraph","Properties":{"id":"20250924223719-u9c7p8i","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L_{i2t} = -\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{\\exp(\\text{sim}(f_v(v_i), f_t(t_i)) / \\tau)}{\\sum_{j=1}^{N} \\exp(\\text{sim}(f_v(v_i), f_t(t_j)) / \\tau)}"},{"Type":"NodeText","Data":" (4)"}]},{"ID":"20250924223719-kisvzfy","Type":"NodeParagraph","Properties":{"id":"20250924223719-kisvzfy","updated":"20250924223720"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L_{t2i} = -\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{\\exp(\\text{sim}(f_t(t_i), f_v(v_i)) / \\tau)}{\\sum_{j=1}^{N} \\exp(\\text{sim}(f_t(t_i), f_v(v_j)) / \\tau)}"},{"Type":"NodeText","Data":" (5)"}]},{"ID":"20250924223719-08uxk80","Type":"NodeParagraph","Properties":{"id":"20250924223719-08uxk80","updated":"20250924223720"},"Children":[{"Type":"NodeText","Data":"通过提示，我们用以下可学习的提示来替换模型输入：对于文本提示："},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"f_t([\\{c_i\\}_1^M, \\{z_i^t\\}_1^M])"},{"Type":"NodeText","Data":"；对于通用的视觉提示："},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"f_v([\\{v_i\\}_1^M, \\{z_i^v\\}_1^M])"},{"Type":"NodeText","Data":"，其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"M"},{"Type":"NodeText","Data":" 是我们使用的提示数量。"}]},{"ID":"20250924223719-2ntn6i5","Type":"NodeBlockquote","Properties":{"id":"20250924223719-2ntn6i5","updated":"20250924223720"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250924223719-ycptze5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223719-ycptze5","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250924223719-emxpw19","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223719-emxpw19","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级提示技术的应用 (KOSMOS \u0026amp; GPT-4)"}]},{"ID":"20250924223719-7fa9tt1","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223719-7fa9tt1","updated":"20250924223719"},"Children":[{"ID":"20250924223719-vj6cvcq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-vj6cvcq","updated":"20250924223719"},"Children":[{"ID":"20250924223719-0xocvi3","Type":"NodeParagraph","Properties":{"id":"20250924223719-0xocvi3","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态思维链 (Multimodal Chain-of-Thought)"},{"Type":"NodeText","Data":": KOSMOS模型展示了一种更高级的提示用法。它不再是简单地“问-答”，而是先通过一个引导性提示（如“详细介绍这张图”）让模型生成一段"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分析或推理（rationale）"},{"Type":"NodeText","Data":"，然后再将这段推理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"作为新的上下文"},{"Type":"NodeText","Data":"，结合原始任务进行提问。这模仿了人类的“先思考，再回答”模式，极大地提升了处理复杂问题的能力。"}]}]},{"ID":"20250924223719-zt03kyi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-zt03kyi","updated":"20250924223719"},"Children":[{"ID":"20250924223719-yonyf90","Type":"NodeParagraph","Properties":{"id":"20250924223719-yonyf90","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定位与指代 (Grounding and Referring)"},{"Type":"NodeText","Data":": KOSMOS-2通过引入特殊的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"位置token"},{"Type":"NodeText","Data":"，实现了文本和图像中特定物体的精确链接。这使得模型不仅能“看懂”图像，还能准确地回答“哪个是……”或“……在哪里”这类需要空间定位的问题。"}]}]},{"ID":"20250924223719-43dn3oc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-43dn3oc","updated":"20250924223719"},"Children":[{"ID":"20250924223719-boj8y6y","Type":"NodeParagraph","Properties":{"id":"20250924223719-boj8y6y","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-4的“任意交错”能力"},{"Type":"NodeText","Data":": GPT-4将多模态交互提升到了新的高度，用户可以在一个提示中自由地混合文本和图像，实现更自然、更复杂的指令。这标志着VLM从处理单一图文对，迈向了能够理解"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态文档或对话"},{"Type":"NodeText","Data":"的阶段。"}]}]}]},{"ID":"20250924223719-tx0sr90","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223719-tx0sr90","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深入理解提示工程的“为什么”"}]},{"ID":"20250924223719-a9a2o63","Type":"NodeParagraph","Properties":{"id":"20250924223719-a9a2o63","updated":"20250924223719"},"Children":[{"Type":"NodeText","Data":"这一节从四个关键角度探讨了提示工程的内在机制和最佳实践："}]},{"ID":"20250924223719-j6hzhmz","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924223719-j6hzhmz","updated":"20250924223719"},"Children":[{"ID":"20250924223719-k9khxgp","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924223719-k9khxgp","updated":"20250924223719"},"Children":[{"ID":"20250924223719-yesq0n0","Type":"NodeParagraph","Properties":{"id":"20250924223719-yesq0n0","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示的泛化性"},{"Type":"NodeText","Data":": 实验表明，精心设计的前缀（如“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"vqa:"},{"Type":"NodeText","Data":"​”）具有良好的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化能力"},{"Type":"NodeText","Data":"，无需为每个特定的数据集都设计一套新的提示，这降低了提示工程的门槛。"}]}]},{"ID":"20250924223719-kkwt0qq","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924223719-kkwt0qq","updated":"20250924223719"},"Children":[{"ID":"20250924223719-fpurqea","Type":"NodeParagraph","Properties":{"id":"20250924223719-fpurqea","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结 vs. 微调的权衡"},{"Type":"NodeText","Data":": 这是一个核心的设计抉择。"}]},{"ID":"20250924223719-ecsk5an","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223719-ecsk5an","updated":"20250924223719"},"Children":[{"ID":"20250924223719-3kjply0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-3kjply0","updated":"20250924223719"},"Children":[{"ID":"20250924223719-b7f9s16","Type":"NodeParagraph","Properties":{"id":"20250924223719-b7f9s16","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结LLM (Freeze LLM)"},{"Type":"NodeText","Data":": 像Flamingo和BLIP-2这样做，最大的好处是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完整保留了LLM强大的语言和推理能力"},{"Type":"NodeText","Data":"，避免了在多模态微调中这些能力被“污染”或遗忘。"}]}]},{"ID":"20250924223719-66afdn6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-66afdn6","updated":"20250924223719"},"Children":[{"ID":"20250924223719-fxjcjfl","Type":"NodeParagraph","Properties":{"id":"20250924223719-fxjcjfl","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"端到端微调 (Fine-tune All)"},{"Type":"NodeText","Data":": 像OFA和KOSMOS这样做，追求的是一个更“统一”的模型。但为了防止模型“忘记”如何说人话，它们必须在训练中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混入纯文本任务"},{"Type":"NodeText","Data":"作为“复习”。"}]}]}]}]},{"ID":"20250924223719-xho1o2m","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250924223719-xho1o2m","updated":"20250924223719"},"Children":[{"ID":"20250924223719-hzknsbg","Type":"NodeParagraph","Properties":{"id":"20250924223719-hzknsbg","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的“饱和效应”"},{"Type":"NodeText","Data":": 上下文学习虽好，但并非“多多益善”。实验发现，提供过多的示例不仅不会带来性能提升，甚至可能因为信息冗余而导致性能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"下降"},{"Type":"NodeText","Data":"。此外，一个有趣的发现是，只提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纯文本的示例"},{"Type":"NodeText","Data":"（没有配对的图片）有时比提供完整的图文对效果更好，但这可能引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"偏见"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250924223719-pi34u8n","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250924223719-pi34u8n","updated":"20250924223719"},"Children":[{"ID":"20250924223719-juw3wik","Type":"NodeParagraph","Properties":{"id":"20250924223719-juw3wik","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示调优的最佳实践"},{"Type":"NodeText","Data":": 研究表明，对于软提示的调优，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更长（参数更多）的提示"},{"Type":"NodeText","Data":"通常效果更好，但同样存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"边际效应递减"},{"Type":"NodeText","Data":"。一个关键的工程技巧是，将可学习的提示向量"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"插入到模型的更底层"},{"Type":"NodeText","Data":"，能更有效地影响整个模型的行为。"}]}]}]},{"ID":"20250924223719-c9bu50v","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223719-c9bu50v","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的应用场景展示"}]},{"ID":"20250924223719-qs67g1x","Type":"NodeParagraph","Properties":{"id":"20250924223719-qs67g1x","updated":"20250924223719"},"Children":[{"Type":"NodeText","Data":"这一节像一个“成果展”，展示了提示工程在各种视觉语言任务中的广泛应用和巨大成功："}]},{"ID":"20250924223719-di3034o","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223719-di3034o","updated":"20250924223719"},"Children":[{"ID":"20250924223719-80swsqe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-80swsqe","updated":"20250924223719"},"Children":[{"ID":"20250924223719-2t7pdwa","Type":"NodeParagraph","Properties":{"id":"20250924223719-2t7pdwa","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础任务"},{"Type":"NodeText","Data":": 在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉问答"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识推理"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像描述"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本分类"},{"Type":"NodeText","Data":"等经典任务中，提示工程（尤其是上下文学习）已经成为激发VLM潜能的关键手段。"}]}]},{"ID":"20250924223719-pj0jrlj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-pj0jrlj","updated":"20250924223719"},"Children":[{"ID":"20250924223719-6a0t5i0","Type":"NodeParagraph","Properties":{"id":"20250924223719-6a0t5i0","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"新颖应用"},{"Type":"NodeText","Data":": 提示工程的应用已扩展到更复杂的场景，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"网页问答"},{"Type":"NodeText","Data":"（需要理解结构化信息）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"区域问答"},{"Type":"NodeText","Data":"（需要精确定位）。"}]}]},{"ID":"20250924223719-enaj73z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-enaj73z","updated":"20250924223719"},"Children":[{"ID":"20250924223719-sq3ciof","Type":"NodeParagraph","Properties":{"id":"20250924223719-sq3ciof","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"引爆应用 - 聊天机器人"},{"Type":"NodeText","Data":": Visual ChatGPT和GPT-4的出现，标志着提示工程从研究走向了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模应用"},{"Type":"NodeText","Data":"。通过一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示管理器（Prompt Manager）"},{"Type":"NodeText","Data":" 来协调不同的模型和处理复杂的输入格式，VLM的能力被前所未有地释放出来，实现了真正意义上的多模态对话。"}]}]}]},{"ID":"20250924223719-w87yry4","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223719-w87yry4","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"责任与伦理的警钟"}]},{"ID":"20250924223719-palrkxx","Type":"NodeParagraph","Properties":{"id":"20250924223719-palrkxx","updated":"20250924223719"},"Children":[{"Type":"NodeText","Data":"作者在最后强调了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"负责任AI (Responsible AI)"},{"Type":"NodeText","Data":" 的重要性。VLM既然继承了LLM的智慧，也必然继承了其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"偏见"},{"Type":"NodeText","Data":"。模型可能会在无意中产生带有性别、种族歧视的内容。同时，模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"鲁棒性"},{"Type":"NodeText","Data":"（抵抗分布变化和对抗攻击的能力）也是一个亟待解决的问题。"}]},{"ID":"20250924223719-qbyoy7s","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223719-qbyoy7s","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配模型的引入"}]},{"ID":"20250924223719-hfhcnoj","Type":"NodeParagraph","Properties":{"id":"20250924223719-hfhcnoj","updated":"20250924223719"},"Children":[{"Type":"NodeText","Data":"在进入新的大章节时，作者首先介绍了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配模型"},{"Type":"NodeText","Data":"的核心思想。与生成模型不同，这类模型的核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习一个联合的嵌入空间"},{"Type":"NodeText","Data":"。其训练目标非常直观：在那个空间里，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"匹配的图文对应该互相靠近，不匹配的则应该互相远离"},{"Type":"NodeText","Data":"。这个过程依赖于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比学习 (Contrastive Learning)"},{"Type":"NodeText","Data":" 和相应的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"匹配损失函数 (公式4和5)"},{"Type":"NodeText","Data":"。这个基础为后续讨论如何对这类模型的文本和视觉两端分别进行提示打下了基础。"}]},{"ID":"20250924223719-80l2n4y","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223719-80l2n4y","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250924223719-ej77ly8","Type":"NodeParagraph","Properties":{"id":"20250924223719-ej77ly8","updated":"20250924223719"},"Children":[{"Type":"NodeText","Data":"这一部分内容非常丰富，从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体技术"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内在机理"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"广泛应用"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"伦理考量"},{"Type":"NodeText","Data":"，对多模态-文本生成中的提示工程进行了全方位的剖析。"}]},{"ID":"20250924223719-sgknx2t","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223719-sgknx2t","updated":"20250924223719"},"Children":[{"ID":"20250924223719-in4ix1n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-in4ix1n","updated":"20250924223719"},"Children":[{"ID":"20250924223719-308jyht","Type":"NodeParagraph","Properties":{"id":"20250924223719-308jyht","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“怎么做”到“为什么”的升华"},{"Type":"NodeText","Data":": 如果说前一部分侧重于介绍“有哪些提示方法”，那么这一部分则更深入地探讨了“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为什么这些方法有效"},{"Type":"NodeText","Data":"”以及“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何更有效地使用它们"},{"Type":"NodeText","Data":"”。关于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结LLM的权衡"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习的饱和点"},{"Type":"NodeText","Data":"以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示调优的最佳位置"},{"Type":"NodeText","Data":"的讨论，都为从业者提供了宝贵的实践指导。"}]}]},{"ID":"20250924223719-18ruw9o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-18ruw9o","updated":"20250924223719"},"Children":[{"ID":"20250924223719-wj9vroz","Type":"NodeParagraph","Properties":{"id":"20250924223719-wj9vroz","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用驱动的价值体现"},{"Type":"NodeText","Data":": 通过展示提示工程在从VQA到多模态聊天机器人等一系列应用中的成功，作者有力地证明了这项技术的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实用价值"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"巨大潜力"},{"Type":"NodeText","Data":"。特别是Visual ChatGPT的例子，揭示了“提示工程”本身可以作为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心模块（Prompt Manager）"},{"Type":"NodeText","Data":"，来调度和整合多个基础模型，完成更复杂的任务。"}]}]},{"ID":"20250924223719-8r8528k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-8r8528k","updated":"20250924223719"},"Children":[{"ID":"20250924223719-x8n5nun","Type":"NodeParagraph","Properties":{"id":"20250924223719-x8n5nun","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术与责任并重"},{"Type":"NodeText","Data":": 作者在章节末尾及时地敲响了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"伦理警钟"},{"Type":"NodeText","Data":"，提醒读者在追求技术进步的同时，必须关注其可能带来的社会风险，如偏见和鲁棒性问题。这体现了研究的全面性和社会责任感。"}]}]},{"ID":"20250924223719-bz1e5d3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223719-bz1e5d3","updated":"20250924223719"},"Children":[{"ID":"20250924223719-go7evg5","Type":"NodeParagraph","Properties":{"id":"20250924223719-go7evg5","updated":"20250924223719"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"承上启下"},{"Type":"NodeText","Data":": 在完美收官多模态-文本生成这一大章节后，作者通过介绍"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配模型"},{"Type":"NodeText","Data":"的核心原理，为下一章节的讨论做好了平滑的过渡。对比学习和匹配损失的介绍，为读者理解为什么可以对文本和视觉编码器进行提示提供了必要的背景知识。"}]}]}]},{"ID":"20250924223719-9j8c39l","Type":"NodeParagraph","Properties":{"id":"20250924223719-9j8c39l","updated":"20250924223719"},"Children":[{"Type":"NodeText","Data":"总体来看，这一部分是论文的核心精华之一，它不仅有深度（机理分析），也有广度（应用案例），更有高度（伦理思考），全面展示了提示工程在VLM领域的理论与实践全景。"}]}]},{"ID":"20250924223916-u23dnrm","Type":"NodeParagraph","Properties":{"id":"20250924223916-u23dnrm","updated":"20250924223916"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。这是第六部分的内容，涵盖了论文的第7页到第9页的部分内容，主要聚焦于图文匹配模型中的提示工程方法。"}]},{"ID":"20250924223916-zcoyxw4","Type":"NodeThematicBreak","Properties":{"id":"20250924223916-zcoyxw4","updated":"20250924223916"}},{"ID":"20250924223916-dmylx5s","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223916-dmylx5s","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7"}]},{"ID":"20250924223916-f1rsh22","Type":"NodeParagraph","Properties":{"id":"20250924223916-f1rsh22","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"Kosmos将输入图像与像“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"The photo of the"},{"Type":"NodeText","Data":"​”这样的提示连接起来，让模型用预测的类别来完成提示句子。此外，为了在分类中融入额外的规则，Kosmos还发送类别描述以及提示，来引导模型针对特定类别进行预测。"}]},{"ID":"20250924223916-ks8e1z1","Type":"NodeParagraph","Properties":{"id":"20250924223916-ks8e1z1","updated":"20250924223917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像描述 (Image Captioning)"},{"Type":"NodeText","Data":"。给定一张图像生成描述是一项典型的多模态到文本生成任务，需要理解视觉和语言信息。提示主要用于少样本和零样本场景，并展示了强大的能力。Flamingo和PaLI采用提示在少样本设置中生成图像描述。例如，PaLI使用提示“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Generate the alt_text in EN"},{"Type":"NodeText","Data":"​”来生成图像描述。在零样本设置中也研究了提示，例如BLIP-2、MAGMA、SimVLM和OFA。"}]},{"ID":"20250924223916-9b7p3dp","Type":"NodeParagraph","Properties":{"id":"20250924223916-9b7p3dp","updated":"20250924223917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"聊天机器人 (Chatbot)"},{"Type":"NodeText","Data":"。像ChatGPT这样的聊天机器人的出现是人工智能研究中最显著的突破之一。像Visual ChatGPT和GPT4这样的后续工作将聊天机器人扩展到多模态应用，支持图像和文本提示。Visual ChatGPT基于ChatGPT和视觉基础模型构建。它使用一个提示管理器（Prompt Manager）来指定输入输出格式，将视觉信息转换为语言格式，并处理不同视觉基础模型的历史记录。GPT4能够接受由图像和文本组成的提示，这让用户可以通过生成文本输出来指定任何视觉和语言任务，给定任意交-错的文本和图像提示。此外，一些工作将GPT迁移到特定领域，例如在生物医学研究上的BiomedGPT。"}]},{"ID":"20250924223916-1i961i8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223916-1i961i8","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.6 提示的责任AI考量"}]},{"ID":"20250924223916-t2f9czw","Type":"NodeParagraph","Properties":{"id":"20250924223916-t2f9czw","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"基于语言的VLM继承了底层LLM和视觉模型的风险，例如在用图像提示时出现的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性别和种族偏见"},{"Type":"NodeText","Data":"。关于LLM伦理的几项调查已经存在。一些工作研究了VLM对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然分布偏移"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性鲁棒性"},{"Type":"NodeText","Data":"的鲁棒性。最近的一项研究调查了VLM上提示调优对自然分布偏移的鲁棒性。此外，通过整合多尺度图像特征，提出了在VLM上进行鲁棒的提示调优。"}]},{"ID":"20250924223916-e4rnb88","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223916-e4rnb88","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4 图像-文本匹配中的提示模型"}]},{"ID":"20250924223916-didf3w8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223916-didf3w8","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.1 图像-文本匹配模型的预备知识"}]},{"ID":"20250924223916-r15d4g9","Type":"NodeParagraph","Properties":{"id":"20250924223916-r15d4g9","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"基于匹配的VLM引入了一种新颖的训练范式，促进了联合多模态表示的获取。该领域的杰出模型，如CLIP、ALIGN、ALBEF和Multi-Event CLIP，利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比学习技术"},{"Type":"NodeText","Data":"来实现图像和文本的联合表示，其学习目标是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"拉近图文对的表示，同时推开非配对的表示"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223916-4ha3dqn","Type":"NodeParagraph","Properties":{"id":"20250924223916-4ha3dqn","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"通过扩展训练数据集和扩大模型参数，基于匹配的模型在广泛的下游任务中表现出适应性，包括零样本基准和微调场景。"}]},{"ID":"20250924223916-8tg5w1x","Type":"NodeParagraph","Properties":{"id":"20250924223916-8tg5w1x","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"根据提示的目标，现有方法可以分为三类："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示文本编码器"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示视觉编码器"},{"Type":"NodeText","Data":"，或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"联合提示两个分支"},{"Type":"NodeText","Data":"，如图3所示。这些方法旨在增强VLM在最近研究中的灵活性和任务特定性能。"}]},{"ID":"20250924223916-qtry05a","Type":"NodeParagraph","Properties":{"id":"20250924223916-qtry05a","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"一个经典的匹配损失公式如下，用以对齐图像和文本嵌入，包含一个图到文损失 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L_{i2t}"},{"Type":"NodeText","Data":" 和一个文到图损失 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L_{t2i}"},{"Type":"NodeText","Data":"。\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L_{i2t} = -\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{\\exp(\\text{sim}(f_v(v_i), f_t(t_i)) / \\tau)}{\\sum_{j=1}^{N} \\exp(\\text{sim}(f_v(v_i), f_t(t_j)) / \\tau)}"},{"Type":"NodeText","Data":" (4)"}]},{"ID":"20250924223916-odiknoc","Type":"NodeParagraph","Properties":{"id":"20250924223916-odiknoc","updated":"20250924223917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L_{t2i} = -\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{\\exp(\\text{sim}(f_t(t_i), f_v(v_i)) / \\tau)}{\\sum_{j=1}^{N} \\exp(\\text{sim}(f_t(t_i), f_v(v_j)) / \\tau)}"},{"Type":"NodeText","Data":" (5)\n通过提示，我们用以下可学习的提示来替换模型输入：对于文本提示："},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"f_t([\\{c_i\\}_1^M, \\{z_i^t\\}_1^M])"},{"Type":"NodeText","Data":" 和对于一般的视觉提示："},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"f_v([\\{v_i\\}_1^M, \\{z_i^v\\}_1^M])"},{"Type":"NodeText","Data":"，其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"M"},{"Type":"NodeText","Data":" 是我们使用的提示数量。"}]},{"ID":"20250924223916-htu9eh6","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223916-htu9eh6","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.2 提示VLM的文本编码器"}]},{"ID":"20250924223916-skrnl91","Type":"NodeParagraph","Properties":{"id":"20250924223916-skrnl91","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"提示语言模型的研究由来已久。如3.2节所讨论的，我们将提示分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬提示"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示"},{"Type":"NodeText","Data":"。如图3(a)所示，可学习的文本提示在有监督的方式下对图文对进行优化。最近的工作也研究了无标签数据的不同场景。在本节中，我们将深入探讨软提示的细节，探索不同类型，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全局提示"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务特定提示"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实例特定提示"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223916-zwrk62s","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250924223916-zwrk62s","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"4.2.1 硬提示"}]},{"ID":"20250924223916-k6qs5iz","Type":"NodeParagraph","Properties":{"id":"20250924223916-k6qs5iz","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"在VLM的背景下提示语言模型已被广泛研究。提示的引入在发现和利用大规模预训练语言模型方面发挥了关键作用。文本提示减少了手工制作文本模板（例如，“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"a photo of a [CAT]"},{"Type":"NodeText","Data":"​”）的需求，使模型能够理解和响应特定任务，而无需明确的任务特定训练，展示了模型的灵活性和多功能性。利用硬提示来测试其在多个任务上的零样本性能。硬提示需要大量的领域专业知识，并且通常成本高昂。这催生了一种新的学习范-式，即仔细优化提示以提升性能。"}]},{"ID":"20250924223916-ya3sicv","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250924223916-ya3sicv","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"4.2.2 软提示"}]},{"ID":"20250924223916-wav4z8h","Type":"NodeParagraph","Properties":{"id":"20250924223916-wav4z8h","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"选择一个合适的提示是一项复杂的任务，需要经验和领域专业知识，并显著影响模型性能。这就提出了一个重要问题：我们能否使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于梯度下降的学习方法"},{"Type":"NodeText","Data":"动态地“搜索”最优提示？"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示"},{"Type":"NodeText","Data":"是指在其设计中包含"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可学习参数"},{"Type":"NodeText","Data":"的提示。我们将软提示分为三类："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全局软提示 (global soft prompts)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分组特定提示 (group-specific prompts)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实例特定提示 (instance-specific prompts)"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223916-tu7vozx","Type":"NodeParagraph","Properties":{"id":"20250924223916-tu7vozx","updated":"20250924223917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全局软提示 (Global Soft Prompt)"},{"Type":"NodeText","Data":"。一种直接而强大的使语言模型适应下游任务的方法是专门为这些任务修改模板token。等研究在处理新任务时，采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可学习的提示作为输入token嵌入"},{"Type":"NodeText","Data":"。与微调整个模型相比，学习一小组提示嵌入参数被证明在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数效率"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据效率"},{"Type":"NodeText","Data":"上更高。这些被称为“全局软提示”的提示，在一个任务中对所有实例都一致使用。术语“全局”表示它们在整个任务中的普遍使用，使模型能够在不同输入间泛化并表现良好。"}]},{"ID":"20250924223916-yea6fia","Type":"NodeParagraph","Properties":{"id":"20250924223916-yea6fia","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"Fig 3"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"https://storage.googleapis.com/assistly-images/20250915150550-y27k71s.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250924223916-0m9zhxk","Type":"NodeParagraph","Properties":{"id":"20250924223916-0m9zhxk","updated":"20250924223917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 3：图文匹配VLM中的提示调优可以应用于不同的分支"},{"Type":"NodeText","Data":"：(a) 文本提示，(b) 视觉提示，和 (c) 统一提示，作用于输入数据。浅蓝色框表示可学习参数。匹配损失被用来优化一小组可学习参数，在损失公式中，"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"q"},{"Type":"NodeText","Data":" 表示查询模态，"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"k"},{"Type":"NodeText","Data":" 表示目标模态。"}]},{"ID":"20250924223916-t11ox6c","Type":"NodeParagraph","Properties":{"id":"20250924223916-t11ox6c","updated":"20250924223917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分组特定提示 (Group-specific Prompt)"},{"Type":"NodeText","Data":"。最近的几项研究已经采用了专门为适应不同任务或输入类型而定制的一组软提示。这些模型使模型能够动态地查询和选择合适的提示。使用一组软提示来适应不同的任务/类型。不同的提示根据输入数据被查询。CoOp发现，为不同类别使用不同的上下文提示（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类别特定上下文"},{"Type":"NodeText","Data":"）可以增强在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"细粒度分类"},{"Type":"NodeText","Data":"中的性能。使用任务特定的提示来使CLIP适应广泛的视频理解任务。提出了使用MVLPT，为源任务和目标任务设置不同的任务提示，以在任务特定的提示之间共享知识。"}]},{"ID":"20250924223916-u6i038m","Type":"NodeParagraph","Properties":{"id":"20250924223916-u6i038m","updated":"20250924223917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实例特定提示 (Instance-specific Prompt)"},{"Type":"NodeText","Data":"。虽然在某些情况下有效，但任务分组的提示可能会遭受"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过拟合"},{"Type":"NodeText","Data":"问题，并且可能难以适应未见过的类别或新颖的样本。相反，实例特定的提示旨在为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单个样本定制提示"},{"Type":"NodeText","Data":"，允许更个性化和自适应的方法。CoCoOp是一个采用实例自适应提示的模型，特别是实例特定的提示，而不是仅仅依赖于全局提示。这种方法已被证明可以增强模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化能力"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924223916-26t0rpq","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223916-26t0rpq","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.3 提示VLM的图像编码器"}]},{"ID":"20250924223916-xwcxb2n","Type":"NodeParagraph","Properties":{"id":"20250924223916-xwcxb2n","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"随着自然语言处理中提示调优的成就，人们也努力将这一概念扩展到视觉输入。根据设计视觉提示的方式，我们将其分为两类："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"补丁式提示 (patch-wise prompts)"},{"Type":"NodeText","Data":"，其中提示作为视觉补丁被添加到原始图像前；以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标注式提示 (annotation prompts)"},{"Type":"NodeText","Data":"，它涉及直接在原始图像上标注提示。"}]},{"ID":"20250924223916-xrr16mp","Type":"NodeParagraph","Properties":{"id":"20250924223916-xrr16mp","updated":"20250924223917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"补丁式提示 (Patch-wise Prompts)"},{"Type":"NodeText","Data":"。将可学习的补丁作为视觉提示添加是向VLM中整合视觉线索的一种直观方法。就像文本软提示作为输入token一样，引入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示调优 (VPT)"},{"Type":"NodeText","Data":"，它学习一小组视觉提示作为视觉补丁。这些补丁与输入图像连接，以使预训练模型适应新任务。VPT研究了在输入层和潜在层中的视觉提示，并表现优于大多数其他适应方法，如完全微调。类似地，探索了使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉扰动"},{"Type":"NodeText","Data":"作为一种视觉提示技术。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性重编程"},{"Type":"NodeText","Data":"，模型学会向输入图像中添加视觉提示。此外，将补丁化的视觉token作为可学习的输入嵌入。提出了将归一化的视觉提示应用于增强图像，释放了视觉提示在不同数据设置中的潜力。在促进提示多样性方面，为数据的不同子集采用不同的视觉提示。"}]},{"ID":"20250924223916-n8yaplj","Type":"NodeParagraph","Properties":{"id":"20250924223916-n8yaplj","updated":"20250924223917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标注式提示 (Annotation Prompts)"},{"Type":"NodeText","Data":"。视觉提示也可以通过直接操作图像来显式地执行，类似于标注过程，我们称之为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标注式提示"},{"Type":"NodeText","Data":"。中引入的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"彩色提示调优 (CPT)"},{"Type":"NodeText","Data":" 专注于将图像的特定区域"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"着色"},{"Type":"NodeText","Data":"作为视觉提示。通过整合颜色线索，引导模型定位物体并更好地理解视觉上下文。探索了使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标注"},{"Type":"NodeText","Data":"，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"红圈"},{"Type":"NodeText","Data":"，作为一种创新的视觉提示设计。这些标注作为线索，引导模型的注意力到特定的感兴趣区域，从而增强其对图像的理解。该研究深入探讨了CLIP通过巧妙使用视觉提示来理解图像的新兴能力。此外，提出了使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例输入和输出图像"},{"Type":"NodeText","Data":"作为视觉提示。通过提供一对展示了期望任务（如图像修复、边缘检测或图像上色）的图像，引导模型根据提供的示例完成类似的任务。这些研究展示了显式视觉提示方法的创造性和有效使用，并为提高模型性能提供了一种实用且可解释的方法。"}]},{"ID":"20250924223916-1mvz9r5","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223916-1mvz9r5","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.4 VLM上的统一提示"}]},{"ID":"20250924223916-lltfm0o","Type":"NodeParagraph","Properties":{"id":"20250924223916-lltfm0o","updated":"20250924223917"},"Children":[{"Type":"NodeText","Data":"随着提示工程在视觉和语言分支的不断发展，最近在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"联合提示 (joint prompting)"},{"Type":"NodeText","Data":" 方面也取得了进展。这种方法旨在通过利用来自视觉和语言领域的提示来增强基于匹配的VLM。如图3所示，两个分支中的可学习提示都被优化。根据视觉提示和文本提示是否相互独立，它们可以被分类为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"耦合统一提示"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解耦统一提示"},{"Type":"NodeText","Data":"，在我们接下来的讨论中。"}]},{"ID":"20250924223916-7keb7yf","Type":"NodeParagraph","Properties":{"id":"20250924223916-7keb7yf","updated":"20250924223917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"耦合统一提示 (Coupled Unified Prompting)"},{"Type":"NodeText","Data":"。UPT指出了提示单一模态并不适用于所有情况的问题：文本提示可能难以处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类内视觉差异大"},{"Type":"NodeText","Data":"的数据，而视觉提示可能难以处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类间视觉差异小"},{"Type":"NodeText","Data":"的数据。因此，它采用了一个微小的神经网络来优化可学习的视觉和文本提示，并联合进行微调，从而超越了单模'态提示。"}]},{"ID":"20250924223916-39sjjoe","Type":"NodeBlockquote","Properties":{"id":"20250924223916-39sjjoe","updated":"20250924223917"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250924223916-oybzbt2","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223916-oybzbt2","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250924223916-4om1dgp","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223916-4om1dgp","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图3的深度解析"}]},{"ID":"20250924223916-kmharqr","Type":"NodeParagraph","Properties":{"id":"20250924223916-kmharqr","updated":"20250924223916"},"Children":[{"Type":"NodeText","Data":"这张图是理解本章内容的核心，它直观地展示了在图文匹配模型（如CLIP）上进行提示调优的三种主要策略："}]},{"ID":"20250924223916-z2dgxoc","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223916-z2dgxoc","updated":"20250924223916"},"Children":[{"ID":"20250924223916-qpi7tqs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-qpi7tqs","updated":"20250924223916"},"Children":[{"ID":"20250924223916-c3f54kd","Type":"NodeParagraph","Properties":{"id":"20250924223916-c3f54kd","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(a) 文本提示 (Text Prompting)"},{"Type":"NodeText","Data":": 这是最常见的方式。在文本输入端（例如，“a photo of a \u003c"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"prompt"},{"Type":"NodeText","Data":"​\u003e puppy”）加入可学习的参数（浅蓝色框）。模型在训练时，只更新这些提示参数，目标是让最终的文本嵌入能更好地与对应的图像嵌入匹配。"}]}]},{"ID":"20250924223916-yo1xhov","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-yo1xhov","updated":"20250924223916"},"Children":[{"ID":"20250924223916-vk0xocp","Type":"NodeParagraph","Properties":{"id":"20250924223916-vk0xocp","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(b) 视觉提示 (Visual Prompting)"},{"Type":"NodeText","Data":": 这是一种更创新的方式。在图像输入端加入可学习的参数。这可以理解为给图片打上一个可学习的“视觉水印”或“补丁”，让模型在处理这张图时，能更好地朝目标概念对齐。"}]}]},{"ID":"20250924223916-jairdrt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-jairdrt","updated":"20250924223916"},"Children":[{"ID":"20250924223916-inzeax2","Type":"NodeParagraph","Properties":{"id":"20250924223916-inzeax2","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(c) 统一提示 (Unified Prompting)"},{"Type":"NodeText","Data":": 这是最全面的策略。同时在文本和视觉两端都加入可学习的提示，并进行联合优化。这允许模型从两个模态同时进行微调，以达到最佳的匹配效果。"}]}]},{"ID":"20250924223916-o4y256c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-o4y256c","updated":"20250924223916"},"Children":[{"ID":"20250924223916-jmxt9qg","Type":"NodeParagraph","Properties":{"id":"20250924223916-jmxt9qg","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心机制"},{"Type":"NodeText","Data":": 无论哪种方式，优化的驱动力都来自于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"匹配损失函数"},{"Type":"NodeText","Data":"（公式中的"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"L"},{"Type":"NodeText","Data":"​）。这个损失函数衡量了查询模-态（"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"q"},{"Type":"NodeText","Data":"​，比如图像）和目标模态（"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"k"},{"Type":"NodeText","Data":"​，比如文本）的匹配程度，并通过反向传播来更新那些浅蓝色的可学习参数。"}]}]}]},{"ID":"20250924223916-43hysps","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223916-43hysps","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本编码器提示的演进"}]},{"ID":"20250924223916-b66f7p1","Type":"NodeParagraph","Properties":{"id":"20250924223916-b66f7p1","updated":"20250924223916"},"Children":[{"Type":"NodeText","Data":"软提示（可学习的提示）是本节的重点，作者将其演进分为三个阶段，体现了从“一刀切”到“量身定制”的精细化过程："}]},{"ID":"20250924223916-v5aetv4","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924223916-v5aetv4","updated":"20250924223916"},"Children":[{"ID":"20250924223916-b9nluxx","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924223916-b9nluxx","updated":"20250924223916"},"Children":[{"ID":"20250924223916-325cmy7","Type":"NodeParagraph","Properties":{"id":"20250924223916-325cmy7","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全局软提示 (Global Soft Prompt)"},{"Type":"NodeText","Data":": 这是最基础的形式。为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"整个任务"},{"Type":"NodeText","Data":"（比如，ImageNet分类）只学习"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一套"},{"Type":"NodeText","Data":"提示参数。它的优点是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效"},{"Type":"NodeText","Data":"，用极少的参数就能达到很好的效果。"}]}]},{"ID":"20250924223916-44nenzr","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924223916-44nenzr","updated":"20250924223916"},"Children":[{"ID":"20250924223916-6flhg34","Type":"NodeParagraph","Properties":{"id":"20250924223916-6flhg34","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分组特定提示 (Group-specific Prompt)"},{"Type":"NodeText","Data":": 进阶版。研究人员发现，对于某些复杂任务（如细粒度分类），给"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每个类别"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每组相似的类别"},{"Type":"NodeText","Data":"学习一套专属的提示，效果会更好。比如，为“哈士奇”和“金毛”学习不同的提示。这增加了模型的灵活性。"}]}]},{"ID":"20250924223916-c91ylta","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250924223916-c91ylta","updated":"20250924223916"},"Children":[{"ID":"20250924223916-nb1xqhs","Type":"NodeParagraph","Properties":{"id":"20250924223916-nb1xqhs","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实例特定提示 (Instance-specific Prompt)"},{"Type":"NodeText","Data":": 终极形态。更进一步，为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每一张图片"},{"Type":"NodeText","Data":"动态生成一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"独一无二"},{"Type":"NodeText","Data":"的提示。这种方法可以最大程度地适应输入的具体内容，从而获得最佳的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化能力"},{"Type":"NodeText","Data":"，有效避免了对训练数据的过拟合。"}]}]}]},{"ID":"20250924223916-rxxij8o","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223916-rxxij8o","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像编码器提示的创新"}]},{"ID":"20250924223916-h1g1vyq","Type":"NodeParagraph","Properties":{"id":"20250924223916-h1g1vyq","updated":"20250924223916"},"Children":[{"Type":"NodeText","Data":"将提示的概念从文本引入视觉，是一个重要的创新。作者将其分为两种富有创意的方式："}]},{"ID":"20250924223916-d0zhycl","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924223916-d0zhycl","updated":"20250924223916"},"Children":[{"ID":"20250924223916-drt7atk","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924223916-drt7atk","updated":"20250924223916"},"Children":[{"ID":"20250924223916-5xduqhy","Type":"NodeParagraph","Properties":{"id":"20250924223916-5xduqhy","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"补丁式提示 (Patch-wise Prompts)"},{"Type":"NodeText","Data":": 这种方法比较直观，它学习一些小的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“视觉补丁”"},{"Type":"NodeText","Data":"（就像便利贴），然后把它们“贴”在原始图像上一起送入模型。这些“补丁”包含了任务相关的信息，引导模型关注正确的特征。这种方法甚至可以借鉴"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性攻击"},{"Type":"NodeText","Data":"的思想，学习一种人眼不易察觉但对模型影响巨大的“视觉扰动”作为提示。"}]}]},{"ID":"20250924223916-kmaveu0","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924223916-kmaveu0","updated":"20250924223916"},"Children":[{"ID":"20250924223916-ia214lb","Type":"NodeParagraph","Properties":{"id":"20250924223916-ia214lb","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标注式提示 (Annotation Prompts)"},{"Type":"NodeText","Data":": 这种方法更具"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可解释性"},{"Type":"NodeText","Data":"，它模仿人类的标注行为。"}]},{"ID":"20250924223916-c8mx5bi","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223916-c8mx5bi","updated":"20250924223916"},"Children":[{"ID":"20250924223916-yxvsah7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-yxvsah7","updated":"20250924223916"},"Children":[{"ID":"20250924223916-pw7n4vw","Type":"NodeParagraph","Properties":{"id":"20250924223916-pw7n4vw","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"颜色/形状标注"},{"Type":"NodeText","Data":": 比如，用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"彩色"},{"Type":"NodeText","Data":"高亮图像的某个区域，或者在目标物体上画一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"红圈"},{"Type":"NodeText","Data":"，来引导模型的注意力。"}]}]},{"ID":"20250924223916-8pspt17","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-8pspt17","updated":"20250924223916"},"Children":[{"ID":"20250924223916-4s5ypua","Type":"NodeParagraph","Properties":{"id":"20250924223916-4s5ypua","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例式提示"},{"Type":"NodeText","Data":": 这是最有趣的一种。给模型看一对“输入-输出”的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例图片"},{"Type":"NodeText","Data":"（比如，一张黑白照片和它的上色版本），然后给它一张新的黑白照片，模型就能“心领神会”，知道现在的任务是“上色”。这极大地扩展了视觉提示的应用场景。"}]}]}]}]}]},{"ID":"20250924223916-xti9k0f","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924223916-xti9k0f","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一提示的协同效应"}]},{"ID":"20250924223916-bze0pr6","Type":"NodeParagraph","Properties":{"id":"20250924223916-bze0pr6","updated":"20250924223916"},"Children":[{"Type":"NodeText","Data":"统一提示是前两种方法的结合，其核心思想是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"协同增效"},{"Type":"NodeText","Data":"。UPT的研究指出了单一模态提示的局限性："}]},{"ID":"20250924223916-w08giek","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223916-w08giek","updated":"20250924223916"},"Children":[{"ID":"20250924223916-chd3xa0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-chd3xa0","updated":"20250924223916"},"Children":[{"ID":"20250924223916-bwtipvw","Type":"NodeParagraph","Properties":{"id":"20250924223916-bwtipvw","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本提示的短板"},{"Type":"NodeText","Data":": 当一个类别内部的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外观差异巨大"},{"Type":"NodeText","Data":"时（比如，“椅子”有各种各样的形态），单一的文本描述很难概括所有情况。"}]}]},{"ID":"20250924223916-95m3dnk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-95m3dnk","updated":"20250924223916"},"Children":[{"ID":"20250924223916-m51g1lb","Type":"NodeParagraph","Properties":{"id":"20250924223916-m51g1lb","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示的短板"},{"Type":"NodeText","Data":": 当不同类别之间"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外观非常相似"},{"Type":"NodeText","Data":"时（比如，不同品种的鸟），仅靠视觉提示可能难以区分。"}]}]}]},{"ID":"20250924223916-vjccbxj","Type":"NodeParagraph","Properties":{"id":"20250924223916-vjccbxj","updated":"20250924223916"},"Children":[{"Type":"NodeText","Data":"因此，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"同时优化视觉和文本提示"},{"Type":"NodeText","Data":"（即耦合统一提示），可以让两个模态互相补充，取长补短，从而在更复杂的场景下达到更好的性能。"}]},{"ID":"20250924223916-e42y933","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924223916-e42y933","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250924223916-gihy421","Type":"NodeParagraph","Properties":{"id":"20250924223916-gihy421","updated":"20250924223916"},"Children":[{"Type":"NodeText","Data":"这一部分深入且系统地探讨了在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配模型"},{"Type":"NodeText","Data":"中，如何将“提示”这一概念从文本域创造性地扩展到视觉域，并最终实现两者的协同。"}]},{"ID":"20250924223916-px10nrw","Type":"NodeList","ListData":{},"Properties":{"id":"20250924223916-px10nrw","updated":"20250924223916"},"Children":[{"ID":"20250924223916-yknnn9y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-yknnn9y","updated":"20250924223916"},"Children":[{"ID":"20250924223916-bc8ckzh","Type":"NodeParagraph","Properties":{"id":"20250924223916-bc8ckzh","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从文本到视觉的类比与创新"},{"Type":"NodeText","Data":": 本章最核心的贡献是清晰地展示了研究人员如何通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类比"},{"Type":"NodeText","Data":"（将文本token类比为视觉补丁）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"创新"},{"Type":"NodeText","Data":"（模仿人类标注行为）来设计"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示"},{"Type":"NodeText","Data":"。特别是“示例式提示”的提出，为与模型的交互开辟了一种全新的、非语言的、高度直观的范式。"}]}]},{"ID":"20250924223916-x6o1n0p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-x6o1n0p","updated":"20250924223916"},"Children":[{"ID":"20250924223916-9au3dcg","Type":"NodeParagraph","Properties":{"id":"20250924223916-9au3dcg","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的精细化演进"},{"Type":"NodeText","Data":": 在文本提示部分，从“全局”到“分组”再到“实例特定”的演进路径，清晰地揭示了提示工程正朝着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更自适应、更个性化"},{"Type":"NodeText","Data":"的方向发展。这不仅是技术的进步，也反映了研究人员对模型行为理解的加深。"}]}]},{"ID":"20250924223916-jtmxyhv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-jtmxyhv","updated":"20250924223916"},"Children":[{"ID":"20250924223916-6979tnp","Type":"NodeParagraph","Properties":{"id":"20250924223916-6979tnp","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"协同与互补的思想"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一提示"},{"Type":"NodeText","Data":"的提出，是基于对单一模-态局限性的深刻洞察。它强调了在多模态任务中，不同模态的信息应该是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"互补"},{"Type":"NodeText","Data":"而非孤立的。通过联合优化，可以实现"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"1+1\u0026gt;2"},{"Type":"NodeText","Data":"​的效果。"}]}]},{"ID":"20250924223916-sdp4sks","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924223916-sdp4sks","updated":"20250924223916"},"Children":[{"ID":"20250924223916-u23gb2f","Type":"NodeParagraph","Properties":{"id":"20250924223916-u23gb2f","updated":"20250924223916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文并茂的直观展示"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图3"},{"Type":"NodeText","Data":"的作用至关重要，它将抽象的三种提示策略（文本、视觉、统一）以极其直观的方式呈现出来，极大地帮助了读者理解这些方法的本质区别和联系。"}]}]}]},{"ID":"20250924223916-9zfw8w0","Type":"NodeParagraph","Properties":{"id":"20250924223916-9zfw8w0","updated":"20250924223916"},"Children":[{"Type":"NodeText","Data":"总体来看，这一部分内容不仅全面梳理了图文匹配模型中的提示方法，更重要的是，它揭示了提示工程作为一个通用思想，如何能够被灵活地、创造性地应用于不同的模态，并通过多模态的协同作用，解决更具挑战性的问题。"}]}]},{"ID":"20250924224108-b6cz29v","Type":"NodeParagraph","Properties":{"id":"20250924224108-b6cz29v","updated":"20250924224108"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。这是第七部分的内容，涵盖了论文的第9页到第11页的部分内容，主要介绍了统一提示的后续内容、提示工程在图文匹配下游任务中的应用，以及文生图模型中的提示工程。"}]},{"ID":"20250924224108-s1n7pia","Type":"NodeThematicBreak","Properties":{"id":"20250924224108-s1n7pia","updated":"20250924224108"}},{"ID":"20250924224108-t73osb3","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224108-t73osb3","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"9"}]},{"ID":"20250924224108-nvvssrm","Type":"NodeParagraph","Properties":{"id":"20250924224108-nvvssrm","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解耦统一提示 (Decoupled Unified Prompting)"},{"Type":"NodeText","Data":"。利用软提示进行视觉语言提示调优。这种方法克服了单一模态提示的局限性，在两种模态中都利用了提示。引入了一种创新的方法，将视觉提示与文本子提示进行对比，从而实现视觉定位和文本提示。通过对图像中的区域进行编码作为视觉子提示，模型可以在文本子提示中共同引用相关区域。MaPLe引入了两个分支的分层提示，并在两种模态中利用它们进行协同学习。通过利用视觉和语言分支之间的协同作用，联合提示在多模态理解中实现了显著的改进。"}]},{"ID":"20250924224108-ghlmg0r","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224108-ghlmg0r","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.5 提示的应用"}]},{"ID":"20250924224108-6rtfewy","Type":"NodeParagraph","Properties":{"id":"20250924224108-6rtfewy","updated":"20250924224109"},"Children":[{"Type":"NodeText","Data":"基于匹配的VLM展示了将学习到的表示迁移到下游任务的巨大潜力，例如图文检索、语义分割、关系检测和多模态任务。"}]},{"ID":"20250924224108-93kl3at","Type":"NodeParagraph","Properties":{"id":"20250924224108-93kl3at","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像分类 (Image Classification)"},{"Type":"NodeText","Data":"。图像分类是计算机视觉领域长期研究的课题。通过提示文本编码器来对目标类别进行分类的新方法已经得到了广泛的建议。基于提示的VLM在零样本和少样本分类方面表现出色。CLIP是一种使用固定提示，如“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"a photo of a [CLASS]"},{"Type":"NodeText","Data":"​”的典型模型。在CLIP之后，一些无需训练的工作也探索了预训练模型的能力。然而，手动制作的提示需要专业知识。为了克服这个问题，像CoOp这样的工作建议将提示的上下文作为可学习的参数。提示工程还显示出在更具挑战性的分类任务中的强大能力，例如长尾分类、多标签分类和少样本分类。"}]},{"ID":"20250924224108-p9pbj0g","Type":"NodeParagraph","Properties":{"id":"20250924224108-p9pbj0g","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本分类 (Text Classification)"},{"Type":"NodeText","Data":"。文本分类似乎与视觉语言模型（VLM）的领域只有轻微的重叠，因为该任务只涉及文本信息。然而，一些工作表明，利用VLM对不同类别进行文本分类具有显著优势。目标检测任务旨在同时识别图像中目标的位置和类别。对象边界框内的标签用于提示工程。在不使用标签的情况下，提出了Dual Context Optimization，它也使用正负提示对。为了解决CoOp的多模态学习问题，提出了文本到图像提示。对于在训练VLM中没有见过的类别，提示生成一个新的固定模板，例如，“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"a photo of a [CATEGORY] in the image"},{"Type":"NodeText","Data":"​”。引入了检测提示（DetPro）来学习连续提示表示。DetPro还使用区域提示来对齐图像区域和文本特征。"}]},{"ID":"20250924224108-f7vrva6","Type":"NodeParagraph","Properties":{"id":"20250924224108-f7vrva6","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉关系检测 (Visual Relation Detection)"},{"Type":"NodeText","Data":"。视觉关系检测是一项计算机视觉任务，旨在提取图像中对象之间存在的关系。提示调优促进了视觉关系检测，并利用了大型预训练VLM中强大的常识知识。一项工作专门为关系检测优化了连续的任务特定向量。提出了利用VLM进行零样本关系检测，并通过提示来增强图像区域和类别之间的对齐。"}]},{"ID":"20250924224108-wwtvz1z","Type":"NodeParagraph","Properties":{"id":"20250924224108-wwtvz1z","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关系提示 (Relation Prompting)"},{"Type":"NodeText","Data":"。在无需显式提示的情况下，为视频开放词汇关系检测提供了关系提示。"}]},{"ID":"20250924224108-nlt1vk4","Type":"NodeParagraph","Properties":{"id":"20250924224108-nlt1vk4","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语义分割 (Semantic Segmentation)"},{"Type":"NodeText","Data":"。语义分割是一项经典的计算机视觉任务，其目标是为图像中的每个像素分配一个类别标签。DenseCLIP将图像-文本级别的密集预测转换为像素-文本匹配。为了利用文本提示，类条件分割掩码被推广为视觉提示。最近，大型预训练模型在分割领域取得了巨大进展，它们将图像和分割掩码作为输入。"}]},{"ID":"20250924224108-umnhofx","Type":"NodeParagraph","Properties":{"id":"20250924224108-umnhofx","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域自适应 (Domain Adaptation)"},{"Type":"NodeText","Data":"。领域自适应，也称为无监督领域自适应，旨在将模型从有标签的源域迁移到无标签的目标域。提示学习还能够适应模型在测试时遇到的未知领域。一项工作通过提示学习来解决领域自适应问题。提出将实例特定的视觉提示和文本提示相结合，以保留来自预训练模型的语义特征，同时学习VIT和微调提示的连续阶段。"}]},{"ID":"20250924224108-vm5wgwx","Type":"NodeParagraph","Properties":{"id":"20250924224108-vm5wgwx","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续学习 (Continual Learning)"},{"Type":"NodeText","Data":"。持续学习旨在解决在非静态数据上的灾难性遗忘问题。提示学习成为一种有前途的持续学习方法。DualPrompt建议为每个输入实例查询任务不变的通用提示和任务特定的提示，然后再将它们输入到预训练模型中。DualPrompt、学习到问（L2P）等方法和特定于任务的指令都使用了来自通用和专家提示的补充知识，其中L2P只在目标模型中提示空白。"}]},{"ID":"20250924224108-exqspqp","Type":"NodeParagraph","Properties":{"id":"20250924224108-exqspqp","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域泛化 (Domain Generalization)"},{"Type":"NodeText","Data":"。领域泛化旨在将在一个或多个相关领域上学习到的模型推广到未见过的领域。封装了特定领域知识的提示，通过提示适配器生成，并与输入特征相结合。在测试时，通过相似性度量，从多个源域生成提示。"}]},{"ID":"20250924224108-7hp1qc8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224108-7hp1qc8","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.6 提示的责任AI考量"}]},{"ID":"20250924224108-0zgmr7r","Type":"NodeParagraph","Properties":{"id":"20250924224108-0zgmr7r","updated":"20250924224109"},"Children":[{"Type":"NodeText","Data":"AI的完整性和伦理已经引起了越来越多的关注，促使研究人员构建可信赖的、负责任的、无偏见的多模态模型。本节讨论模型鲁棒性、公平性、隐私和偏见。"}]},{"ID":"20250924224108-aeum2ic","Type":"NodeParagraph","Properties":{"id":"20250924224108-aeum2ic","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性鲁棒性 (Adversarial Robustness)"},{"Type":"NodeText","Data":"。鲁棒性分析评估了模型在不同条件下的性能和扰动。研究了VPT和微调在对抗性攻击下的零样本鲁棒性，发现在CLIP上VPT比微调更具鲁棒性。提出了利用语言来对抗通用视觉扰动，以提高零样本分类的鲁棒性。提示在测试时动态调整视觉提示，使其比传统的对抗性训练更有效。此外，作为对抗性提示的防御措施，它允许模型（例如即插即用的防御）在测试期间进行调整。研究了VLM在自然分布变化下的鲁棒性。DualPrompt、学习到问（L2P）等方法和特定于任务的指令都使用了来自通用和专家提示的补充知识，其中L2P只在目标模型中提示空白。"}]},{"ID":"20250924224108-ytqg60r","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224108-ytqg60r","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"10"}]},{"ID":"20250924224108-0yu8bf4","Type":"NodeParagraph","Properties":{"id":"20250924224108-0yu8bf4","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 4：提示生成模型"},{"Type":"NodeText","Data":"。一个典型的文生图生成框架的描绘，详细说明了诸如条件信息、图像编码器、生成模型、噪声注入、潜在空间表示和解码器等元素。条件信息可以采取多种形式，如硬提示、可学习的软提示或两者的组合。此外，提示可以以文本、视觉或两种格式呈现。"}]},{"ID":"20250924224108-h3geaet","Type":"NodeParagraph","Properties":{"id":"20250924224108-h3geaet","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示学习的后门攻击 (Backdoor Attack of Prompt Learning)"},{"Type":"NodeText","Data":"。研究了CLIP上的后门和投毒攻击，发现手动标记数据训练的CLIP受此类攻击的影响很大。研究表明，在噪声和未经整理的数据集上进行训练，使得后门和投毒攻击成为一个重大威胁。提出了一种名为BadEncoder的新后门攻击方法，并揭示了VLM面临的这种威胁。一旦预训练的图像编码器被注入后门，基于它为不同下游任务构建的分类器将同时继承后门行为。鉴于这种对后门攻击的脆弱性，提出了CleanCLIP作为一种微调框架，通过削弱后门攻击引入的学习到的虚假关联来防御。"}]},{"ID":"20250924224108-iufpcdf","Type":"NodeParagraph","Properties":{"id":"20250924224108-iufpcdf","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"公平与偏见 (Fairness and Bias)"},{"Type":"NodeText","Data":"。社会偏见是公平AI系统中的一个重要议题。广泛的研究已经探讨了偏见的各个方面。展示了CLIP模型中关于种族和性别错误分类的偏见分析。同时，许多现有工作专注于模型的去偏见。特别是，试图通过校准有偏见的提示文本来减轻偏见，使其倾向于无偏见的内容，而则建议通过对VLM输出进行后处理来减轻图像检索任务中的偏见结果。此外，引入了一个新的数据集去偏见流程，以健康数据增强数据集。"}]},{"ID":"20250924224108-mwiy6z7","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224108-mwiy6z7","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5 文生图生成中的提示模型"}]},{"ID":"20250924224108-glb6298","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224108-glb6298","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.1 文生图生成模型的预备知识"}]},{"ID":"20250924224108-6pld4mt","Type":"NodeParagraph","Properties":{"id":"20250924224108-6pld4mt","updated":"20250924224109"},"Children":[{"Type":"NodeText","Data":"本节概述了理解文生图生成中提示模型所需的预备知识，特别关注扩散模型。"}]},{"ID":"20250924224108-24rb4fh","Type":"NodeParagraph","Properties":{"id":"20250924224108-24rb4fh","updated":"20250924224109"},"Children":[{"Type":"NodeText","Data":"文生图生成自动地从自然语言描述中合成生动逼真的图像，并吸引了越来越多的关注。从开创性的工作DRAW开始，文生图生成模型取得了众多突破。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成对抗网络（GAN）"},{"Type":"NodeText","Data":" 随后被用于设计端到端可微的图像生成结构，并被许多工作所沿用。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"变分自编码器（VAE）"},{"Type":"NodeText","Data":" 也被用于生成图像。然而，这些模型是在小规模数据上训练的，缺乏泛化能力。由大规模数据集驱动的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自回归方法"},{"Type":"NodeText","Data":"，如DALL-E和Parti，被提出来，并展示了惊人的零样本生成能力。"}]},{"ID":"20250924224108-3671knj","Type":"NodeParagraph","Properties":{"id":"20250924224108-3671knj","updated":"20250924224109"},"Children":[{"Type":"NodeText","Data":"最近，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩散模型（DM）"},{"Type":"NodeText","Data":" 引发了另一波最先进的文生图生成模型。扩散模型，也称为扩散概率模型，起源于非平衡统计物理和序贯蒙特卡洛，其设计旨在拟合任何数据分布，同时保持可处理性。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"去噪扩散概率模型（DDPMs）"},{"Type":"NodeText","Data":" 首次在图像生成领域采用DM，并激励了整个生成模型社区。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理"},{"Type":"NodeText","Data":"时，DDPMs构建一个马尔可夫链，在有限的转换中从噪声数据生成图像，这被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逆向过程 (reverse process)"},{"Type":"NodeText","Data":"。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练"},{"Type":"NodeText","Data":"时，DDPMs从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前向过程 (forward process)"},{"Type":"NodeText","Data":" 中学习，即向自然图像中添加噪声并由模型进行估计。给定一个来自分布 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"q"},{"Type":"NodeText","Data":" 的清晰图像 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_0"},{"Type":"NodeText","Data":"，扩散步骤 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"T"},{"Type":"NodeText","Data":" 和超参数 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\beta_t"},{"Type":"NodeText","Data":"，前向过程生成 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_T"},{"Type":"NodeText","Data":" 如下：\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"q(x_{1:T}|x_0) := \\prod_{t=1}^T q(x_t|x_{t-1})"},{"Type":"NodeText","Data":" (6)\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"q(x_t|x_{t-1}) := \\mathcal{N}(x_t; \\sqrt{1-\\beta_t}x_{t-1}, \\beta_t I)"},{"Type":"NodeText","Data":" (7)\n任意步骤 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"t"},{"Type":"NodeText","Data":" 的带噪图像可以重新表述为：\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"q(x_t|x_0) := \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t}x_0, (1-\\bar{\\alpha}_t)I)"},{"Type":"NodeText","Data":" (8)\n其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\alpha_t := 1 - \\beta_t"},{"Type":"NodeText","Data":", "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\bar{\\alpha}_t := \\prod_{s=0}^t \\alpha_s"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924224108-pw6m1qq","Type":"NodeParagraph","Properties":{"id":"20250924224108-pw6m1qq","updated":"20250924224109"},"Children":[{"Type":"NodeText","Data":"给定定义的前向过程，DDPM在逆向过程中进行训练，从 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"p_\\theta(x_T)"},{"Type":"NodeText","Data":" 开始，其损失定义为：\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L(\\theta) := \\mathbb{E}_{t, x_0, \\epsilon} \\left[ ||\\epsilon - \\epsilon_\\theta(\\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon, t)||^2 \\right]"},{"Type":"NodeText","Data":" (9)\n其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"t"},{"Type":"NodeText","Data":" 在1和 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"T"},{"Type":"NodeText","Data":" 之间均匀分布，"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\epsilon \\sim \\mathcal{N}(0, I)"},{"Type":"NodeText","Data":" 是随机噪声，而 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\epsilon_\\theta"},{"Type":"NodeText","Data":" 是由 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\theta"},{"Type":"NodeText","Data":" 参数化的噪声预测器。"}]},{"ID":"20250924224108-8ozyy3q","Type":"NodeParagraph","Properties":{"id":"20250924224108-8ozyy3q","updated":"20250924224109"},"Children":[{"Type":"NodeText","Data":"通过整合额外的控制信息，通常以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本提示"},{"Type":"NodeText","Data":"的形式，扩散模型中逆向过程的效率得到了显著增强，以控制合成结果而不是随机采样。这种基于文本的生成已经巩固了其作为文生图生成领域开创性基础的地位。因此，让 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\Gamma"},{"Type":"NodeText","Data":" 成为一个将条件输入提示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"P"},{"Type":"NodeText","Data":" 映射到条件向量 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"c := \\Gamma(P)"},{"Type":"NodeText","Data":" 的编码器，条件学习目标已扩展为包含代表文本提示的 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"c"},{"Type":"NodeText","Data":"：\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L(\\theta) := \\mathbb{E}_{t, x_0, \\epsilon, c} \\left[ ||\\epsilon - \\epsilon_\\theta(\\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon, t, c)||^2 \\right]"},{"Type":"NodeText","Data":" (10)"}]},{"ID":"20250924224108-b342bm1","Type":"NodeParagraph","Properties":{"id":"20250924224108-b342bm1","updated":"20250924224109"},"Children":[{"Type":"NodeText","Data":"图4展示了一个典型的文生图生成框架，突出了其关键组件和功能，包括（1）固定的或可学习的条件信息，如硬文本提示或可学习的软提示。条件信息可以是文本形式或其他模态；（2）输入图像的编码器 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{E}"},{"Type":"NodeText","Data":"；（3）一个生成模型，如扩散模型、自回归模型或GAN；（4）噪声注入或干扰；（5）潜在空间或低分辨率图像中的特征表示；（6）用于图像解码或超分辨率以实现高保真度生成的解码器 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{D}"},{"Type":"NodeText","Data":"。训练过程涉及利用数据集、损失函数和优化技术来训练模型，以基于文本提示生成连贯且视觉上吸引人的图像。在推理阶段，训练好的模型被用来根据用户指定的提示生成图像。提示的制定起着至关重要的作用，因为它支配着与模型的通信，并影响图像生成的期望结果。本节重点关注文生图生成中的提示工程及其应用。"}]},{"ID":"20250924224108-0ulrd7f","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224108-0ulrd7f","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.2 理解提示"}]},{"ID":"20250924224108-6bma3cm","Type":"NodeParagraph","Properties":{"id":"20250924224108-6bma3cm","updated":"20250924224109"},"Children":[{"Type":"NodeText","Data":"为了更深入地理解影响生成图像的因素，我们将从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语义"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示多样性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可控提示"},{"Type":"NodeText","Data":"的角度来介绍文生图中的提示设计。"}]},{"ID":"20250924224108-bljiipt","Type":"NodeParagraph","Properties":{"id":"20250924224108-bljiipt","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语义提示设计 (Semantic Prompt Design)"},{"Type":"NodeText","Data":"。提示语义的艺术对扩散模型中的图像生成有显著影响。提示中的语言成分，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"形容词"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"名词"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专有名词"},{"Type":"NodeText","Data":"，以不同但一致的方式影响图像生成。虽然描述符（简单的形容词）巧妙地影响输出，但名词更有效地引入新内容。有趣的是，使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"艺术家的名字"},{"Type":"NodeText","Data":"倾向于生成与原始图像显著偏离的图像，而加入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"光照短语"},{"Type":"NodeText","Data":"可以极大地改变图像内容和氛围。因此，可以通过清晰的、基于名词的陈述、有效的种子和模仿艺术家风格来提高图像生成的质量。"}]},{"ID":"20250924224108-dfnm36o","Type":"NodeParagraph","Properties":{"id":"20250924224108-dfnm36o","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过提示实现生成多样化 (Diversify Generation with Prompt)"},{"Type":"NodeText","Data":"。除了直接以语义方式手工制作单个提示外，最近的工作还尝试了各种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示修饰符"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"\\mathcal{M}"},{"Type":"NodeText","Data":"，专注于通过 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{P}' = \\mathcal{M}(\\mathcal{P})"},{"Type":"NodeText","Data":" 来增强初始提示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{P}"},{"Type":"NodeText","Data":" 的多样性，其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{P}'"},{"Type":"NodeText","Data":" 是多样化的提示。DiffuMask探索了两种提示修饰符 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{M}"},{"Type":"NodeText","Data":" 的策略，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于检索的提示"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"带子类的提示"},{"Type":"NodeText","Data":"，其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{P}"},{"Type":"NodeText","Data":" 设置为“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Photo of a [sub-class] car in the street"},{"Type":"NodeText","Data":"​”。具体来说，他们检索真实的图像和标题集，以标题作为生成合成图像的提示集。此外，他们根据主类从Wiki中选择子类。ImaginaryNet使用GPT2作为 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{M}"},{"Type":"NodeText","Data":"，给定目标对象的类名 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"y"},{"Type":"NodeText","Data":"，在“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"A photo of a"},{"Type":"NodeText","Data":"​”前缀短语的指导下，生成一个想象场景的完整描述 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"P_y"},{"Type":"NodeText","Data":"。该提示用于为想象中的监督对象检测任务生成多样化的、照片般逼真的想象图像。类似地，使用一个词到句的T5模型作为 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathcal{M}"},{"Type":"NodeText","Data":"，为特定标签空间 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"y"},{"Type":"NodeText","Data":" 生成详细的提示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"P_y"},{"Type":"NodeText","Data":"，从而通过丰富提示的多样性来最大化在数据稀缺设置中合成数据的潜力。这些方法进一步通过 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"I = G(\\mathcal{E}(\\mathcal{P}'))"},{"Type":"NodeText","Data":" 获得多样化的图像 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"I"},{"Type":"NodeText","Data":"，其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"G"},{"Type":"NodeText","Data":" 代表生成模型。"}]},{"ID":"20250924224108-asf2bcy","Type":"NodeParagraph","Properties":{"id":"20250924224108-asf2bcy","updated":"20250924224109"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成结果的复杂控制 (Complex Control of Synthesis Results)"},{"Type":"NodeText","Data":"。由于合成图像的生成通常因噪声注入和扩散模型的随机性而具有不一致性，最近在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂可控生成"},{"Type":"NodeText","Data":"领域涌现出新的工作。为避免用户提供掩码限制修改区域的局限性，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于提示的控制"},{"Type":"NodeText","Data":"正受到关注。OneWord旨在解决生成具有特定、难以用纯文本描述的主题的个性化图像的问题。因此，他们提出了一种提示方法，指定一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"占位符字符串"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"S_*"},{"Type":"NodeText","Data":" 来代表新概念，例如“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"a photograph of S* on the beach"},{"Type":"NodeText","Data":"​”，并关联其学习到的嵌入 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"v_*"},{"Type":"NodeText","Data":"。DreamBooth也做了类似的设计。他们不是创造新词，而是设计了将来自T5-XXL分词器的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稀有token"},{"Type":"NodeText","Data":"与特定主题及其粗略类名绑定的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(唯一标识符, 主题)"},{"Type":"NodeText","Data":" 对，例如“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"A [V] dog"},{"Type":"NodeText","Data":"​”，其中"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[V]"},{"Type":"NodeText","Data":"​是稀有token标识符。他们通过引入扩展的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类别先验保持损失"},{"Type":"NodeText","Data":"来在提示中保留类名的表示。Custom Diffusion将定制化扩展到一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多概念场景"},{"Type":"NodeText","Data":"，其中多个个性化概念被组合在同一张生成的图像中，例如同一张家庭照片中的多个家庭成员。他们为此设计了提示，包括为每个概念 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"i"},{"Type":"NodeText","Data":" 使用一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"唯一的修饰符token"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"S_i^*"},{"Type":"NodeText","Data":"，用不同的稀有token初始化，并放置在类别名称 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x"},{"Type":"NodeText","Data":" 之前。"}]},{"ID":"20250924224108-gb6hzba","Type":"NodeBlockquote","Properties":{"id":"20250924224108-gb6hzba","updated":"20250924224109"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250924224108-1fuxns6","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224108-1fuxns6","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250924224108-29gbhma","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224108-29gbhma","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一提示的两种模式"}]},{"ID":"20250924224108-1tx0jw5","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224108-1tx0jw5","updated":"20250924224108"},"Children":[{"ID":"20250924224108-0le4ans","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-0le4ans","updated":"20250924224108"},"Children":[{"ID":"20250924224108-ev3qety","Type":"NodeParagraph","Properties":{"id":"20250924224108-ev3qety","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"耦合 (Coupled) vs. 解耦 (Decoupled)"},{"Type":"NodeText","Data":": 这部分进一步细化了统一提示。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"耦合"},{"Type":"NodeText","Data":"提示意味着视觉和文本提示是通过一个共享的微型网络共同生成的，它们是“绑定”在一起的。而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解耦"},{"Type":"NodeText","Data":"提示则允许两个分支的提示有更多的独立性，例如通过让视觉提示与文本的“子提示”进行交互，从而实现更精细的控制，比如视觉定位（让模型知道文本的某部分对应图像的哪个区域）。"}]}]}]},{"ID":"20250924224108-gt11e5j","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224108-gt11e5j","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文匹配模型的应用拓展"}]},{"ID":"20250924224108-cljvtqb","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224108-cljvtqb","updated":"20250924224108"},"Children":[{"ID":"20250924224108-vyyx1ob","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-vyyx1ob","updated":"20250924224108"},"Children":[{"ID":"20250924224108-2fx09dh","Type":"NodeParagraph","Properties":{"id":"20250924224108-2fx09dh","updated":"20250924224108"},"Children":[{"Type":"NodeText","Data":"这一节展示了基于匹配的VLM（如CLIP）的强大"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"迁移能力"},{"Type":"NodeText","Data":"。通过提示工程，这些原本只为“匹配”任务训练的模型，被成功地应用于一系列下游任务："}]}]},{"ID":"20250924224108-vy0genh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-vy0genh","updated":"20250924224108"},"Children":[{"ID":"20250924224108-gz7t068","Type":"NodeParagraph","Properties":{"id":"20250924224108-gz7t068","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像/文本分类"},{"Type":"NodeText","Data":": 这是最直接的应用。通过将类别名放入模板（如“a photo of a [CLASS]”），就可以实现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本分类"},{"Type":"NodeText","Data":"。后续的CoOp等工作通过学习软提示，进一步提升了性能。"}]}]},{"ID":"20250924224108-io3yhfp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-io3yhfp","updated":"20250924224108"},"Children":[{"ID":"20250924224108-ubf8jba","Type":"NodeParagraph","Properties":{"id":"20250924224108-ubf8jba","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标检测/分割"},{"Type":"NodeText","Data":": 提示工程也被用于更复杂的、需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定位"},{"Type":"NodeText","Data":"的任务。例如，通过设计“区域提示”来将文本描述与图像中的特定区域对齐。"}]}]},{"ID":"20250924224108-2flu06r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-2flu06r","updated":"20250924224108"},"Children":[{"ID":"20250924224108-hgogv0h","Type":"NodeParagraph","Properties":{"id":"20250924224108-hgogv0h","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"新领域：领域自适应/持续学习"},{"Type":"NodeText","Data":": 提示工程被证明是解决这两个机器学习难题的有效工具。通过学习任务特定的提示，模型可以在不“忘记”旧知识（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"灾难性遗忘"},{"Type":"NodeText","Data":"）的情况下学习新任务，或者适应数据分布完全不同的新领域。"}]}]}]},{"ID":"20250924224108-h3bc8bi","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224108-h3bc8bi","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文生图模型的系统性介绍"}]},{"ID":"20250924224108-tg5tv36","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224108-tg5tv36","updated":"20250924224108"},"Children":[{"ID":"20250924224108-hclciej","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-hclciej","updated":"20250924224108"},"Children":[{"ID":"20250924224108-de4w6bs","Type":"NodeParagraph","Properties":{"id":"20250924224108-de4w6bs","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图4的角色"},{"Type":"NodeText","Data":": 这张图是理解本章的关键，它描绘了一个典型的文生图（特别是扩散模型）框架的“流水线”："}]}]}]},{"ID":"20250924224108-v58g1dv","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924224108-v58g1dv","updated":"20250924224108"},"Children":[{"ID":"20250924224108-ozjecsy","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924224108-ozjecsy","updated":"20250924224108"},"Children":[{"ID":"20250924224108-fs1tc6d","Type":"NodeParagraph","Properties":{"id":"20250924224108-fs1tc6d","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输入 (Prompt)"},{"Type":"NodeText","Data":": 一切的起点是用户的提示，可以是文本、图片，或者两者结合。"}]}]},{"ID":"20250924224108-qwn4o5o","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924224108-qwn4o5o","updated":"20250924224108"},"Children":[{"ID":"20250924224108-x54ldk8","Type":"NodeParagraph","Properties":{"id":"20250924224108-x54ldk8","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器 (Encoder)"},{"Type":"NodeText","Data":": 将这些输入转化成模型能理解的数学表示（条件向量"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"c"},{"Type":"NodeText","Data":"​）。"}]}]},{"ID":"20250924224108-v69knha","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250924224108-v69knha","updated":"20250924224108"},"Children":[{"ID":"20250924224108-4rkpai5","Type":"NodeParagraph","Properties":{"id":"20250924224108-4rkpai5","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成模型 (Generative Model)"},{"Type":"NodeText","Data":": 核心部分。它从一个纯噪声的图像开始，在提示的引导下，一步步地“去噪”，逐渐“雕刻”出最终的图像。"}]}]},{"ID":"20250924224108-l9j7ynx","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250924224108-l9j7ynx","updated":"20250924224108"},"Children":[{"ID":"20250924224108-2210w5t","Type":"NodeParagraph","Properties":{"id":"20250924224108-2210w5t","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输出 (Image)"},{"Type":"NodeText","Data":": 经过解码器，最终生成高清图像。"}]}]}]},{"ID":"20250924224108-enjytub","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224108-enjytub","updated":"20250924224108"},"Children":[{"ID":"20250924224108-2d4neh0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-2d4neh0","updated":"20250924224108"},"Children":[{"ID":"20250924224108-fi6cy68","Type":"NodeParagraph","Properties":{"id":"20250924224108-fi6cy68","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学原理"},{"Type":"NodeText","Data":": 作者简要介绍了扩散模型的数学基础（公式6-10）。核心思想是：模型学习的是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“逆向过程”"},{"Type":"NodeText","Data":"，即如何从一个加满噪声的图像（"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_t"},{"Type":"NodeText","Data":"）预测出原始的噪声（"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\epsilon"},{"Type":"NodeText","Data":"）。通过文本提示（"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"c"},{"Type":"NodeText","Data":"​）来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"引导"},{"Type":"NodeText","Data":"这个去噪过程，就可以控制最终生成的图像内容。"}]}]}]},{"ID":"20250924224108-u7ep8fs","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224108-u7ep8fs","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示设计的艺术与科学"}]},{"ID":"20250924224108-v8aum1j","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224108-v8aum1j","updated":"20250924224108"},"Children":[{"ID":"20250924224108-lga0wd7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-lga0wd7","updated":"20250924224108"},"Children":[{"ID":"20250924224108-ulvggvu","Type":"NodeParagraph","Properties":{"id":"20250924224108-ulvggvu","updated":"20250924224108"},"Children":[{"Type":"NodeText","Data":"这一节从三个层面剖析了如何制作高质量的文生图提示，从“术”到“道”："}]}]}]},{"ID":"20250924224108-2pfg0yp","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250924224108-2pfg0yp","updated":"20250924224108"},"Children":[{"ID":"20250924224108-ngl2z7w","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250924224108-ngl2z7w","updated":"20250924224108"},"Children":[{"ID":"20250924224108-ptt4nz3","Type":"NodeParagraph","Properties":{"id":"20250924224108-ptt4nz3","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语义层面 (Semantic)"},{"Type":"NodeText","Data":": 这是“术”。研究发现，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"名词"},{"Type":"NodeText","Data":"比形容词更能引入新内容，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"艺术家名"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"光照词"},{"Type":"NodeText","Data":"则能极大地改变风格和氛围。"}]}]},{"ID":"20250924224108-hu9rblt","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250924224108-hu9rblt","updated":"20250924224108"},"Children":[{"ID":"20250924224108-avfh1dg","Type":"NodeParagraph","Properties":{"id":"20250924224108-avfh1dg","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性层面 (Diversity)"},{"Type":"NodeText","Data":": 这是“法”。为了避免生成的图片千篇一律，研究者们使用GPT-2或T5等语言模型作为“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示扩展器"},{"Type":"NodeText","Data":"”，将简单的关键词（如“车”）自动扩展成丰富多样的场景描述（如“一辆在雨夜街道上飞驰的红色跑车”）。"}]}]},{"ID":"20250924224108-anvh126","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250924224108-anvh126","updated":"20250924224108"},"Children":[{"ID":"20250924224108-a7o35ho","Type":"NodeParagraph","Properties":{"id":"20250924224108-a7o35ho","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"控制层面 (Control)"},{"Type":"NodeText","Data":": 这是“道”。为了实现对生成内容的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精准控制"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"个性化定制"},{"Type":"NodeText","Data":"，研究者们发明了各种高级技术："}]},{"ID":"20250924224108-s25n7as","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224108-s25n7as","updated":"20250924224108"},"Children":[{"ID":"20250924224108-bq4n5i3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-bq4n5i3","updated":"20250924224108"},"Children":[{"ID":"20250924224108-71slyxy","Type":"NodeParagraph","Properties":{"id":"20250924224108-71slyxy","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"占位符/稀有Token"},{"Type":"NodeText","Data":": 像DreamBooth这样的技术，允许用户用一个特殊的词（如“[V]”）来“定义”一个新概念（比如，你自己的宠物狗），然后就可以在各种场景中生成它。"}]}]},{"ID":"20250924224108-2rmthhc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-2rmthhc","updated":"20250924224108"},"Children":[{"ID":"20250924224108-16ml6ea","Type":"NodeParagraph","Properties":{"id":"20250924224108-16ml6ea","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多概念组合"},{"Type":"NodeText","Data":": Custom Diffusion更进一步，允许用户同时定义多个新概念，并将它们"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"和谐地组合"},{"Type":"NodeText","Data":"在同一张图片中。"}]}]}]}]}]},{"ID":"20250924224108-tq7zjsf","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224108-tq7zjsf","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250924224108-drqsf4v","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224108-drqsf4v","updated":"20250924224108"},"Children":[{"ID":"20250924224108-58ec2f5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-58ec2f5","updated":"20250924224108"},"Children":[{"ID":"20250924224108-2q9vzbg","Type":"NodeParagraph","Properties":{"id":"20250924224108-2q9vzbg","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从匹配到生成，提示工程角色的转变"},{"Type":"NodeText","Data":": 在图文匹配模型中，提示工程主要扮演"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“适配器”"},{"Type":"NodeText","Data":"的角色，通过微调提示来使一个通用模型适应各种下游的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分析性任务"},{"Type":"NodeText","Data":"（分类、检测等）。而在文生图模型中，提示工程则扮演着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“指挥棒”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“画笔”"},{"Type":"NodeText","Data":"的角色，它直接"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主导和控制"},{"Type":"NodeText","Data":"着整个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成过程"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250924224108-98nosy5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-98nosy5","updated":"20250924224108"},"Children":[{"ID":"20250924224108-aztxtf1","Type":"NodeParagraph","Properties":{"id":"20250924224108-aztxtf1","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的“自动化”与“智能化”"},{"Type":"NodeText","Data":": 在文生图领域，提示工程不再仅仅是人工的“炼丹”，而是发展出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动化的流程"},{"Type":"NodeText","Data":"。利用大型语言模型来“丰富”和“多样化”初始提示，已经成为一种提高生成质量和多样性的重要方法。"}]}]},{"ID":"20250924224108-vmjoz4n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-vmjoz4n","updated":"20250924224108"},"Children":[{"ID":"20250924224108-xbt7104","Type":"NodeParagraph","Properties":{"id":"20250924224108-xbt7104","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“可控性”成为核心追求"},{"Type":"NodeText","Data":": 文生图技术发展的核心驱动力之一，就是不断追求对生成结果"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更强、更精细的控制力"},{"Type":"NodeText","Data":"。从简单的文本描述，到能够注入用户自定义概念（如DreamBooth），再到组合多个概念，提示工程正朝着实现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完全个性化和复杂场景构建"},{"Type":"NodeText","Data":"的方向发展。"}]}]},{"ID":"20250924224108-el72o8d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224108-el72o8d","updated":"20250924224108"},"Children":[{"ID":"20250924224108-237n7ji","Type":"NodeParagraph","Properties":{"id":"20250924224108-237n7ji","updated":"20250924224108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论与实践的结合"},{"Type":"NodeText","Data":": 文生图模型部分的介绍，很好地结合了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论基础"},{"Type":"NodeText","Data":"（扩散模型的数学原理）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实践技巧"},{"Type":"NodeText","Data":"（语义、多样性、控制）。这使得读者不仅能知其然（知道怎么写提示），还能知其所以然（理解为什么这样写有效）。"}]}]}]}]},{"ID":"20250924224352-u60769m","Type":"NodeParagraph","Properties":{"id":"20250924224352-u60769m","updated":"20250924224352"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。这是最后一部分的内容，涵盖了论文的第11页到结尾，主要讨论了文生图提示工程的高级应用、伦理考量，并将VLM中的提示工程与单模态模型进行对比，最后总结了挑战与未来方向。"}]},{"ID":"20250924224352-2x0rai1","Type":"NodeThematicBreak","Properties":{"id":"20250924224352-2x0rai1","updated":"20250924224352"}},{"ID":"20250924224352-ihnaa0f","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224352-ihnaa0f","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"11"}]},{"ID":"20250924224352-6i2kpy4","Type":"NodeParagraph","Properties":{"id":"20250924224352-6i2kpy4","updated":"20250924224355"},"Children":[{"Type":"NodeText","Data":"最近，文本提示已经无法满足图像处理任务的特定需求，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可控的文生图生成"},{"Type":"NodeText","Data":"正受到越来越多的关注。大量的任务特定输入条件，如由图像编码器编码的Canny边缘检测图，通过可训练的网络架构被添加到扩散模型中，这就是ControlNet的工作。额外的任务特定条件 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"c_f"},{"Type":"NodeText","Data":" 被添加到整体训练目标中，即 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L(\\theta) := \\mathbb{E}_{t, x_0, \\epsilon, c, c_f} [||\\epsilon - \\epsilon_\\theta(x_t, t, c, c_f))||^2]"},{"Type":"NodeText","Data":"。值得注意的是，为了提高编码器从控制图中识别语义的能力，并优化ControlNet在即使没有明确提示时的性能，ControlNet的训练利用了一种方法，其中一半的文本提示被随机替换为空字符串。"}]},{"ID":"20250924224352-q5jzkew","Type":"NodeParagraph","Properties":{"id":"20250924224352-q5jzkew","updated":"20250924224355"},"Children":[{"Type":"NodeText","Data":"合成结果的控制也可以在生成过程"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"之后"},{"Type":"NodeText","Data":"通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示编辑"},{"Type":"NodeText","Data":"方法来完成。为了绕开通常需要用户定义的空间固定掩码的需求，Prompt-to-Prompt可以通过仅仅"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编辑提示"},{"Type":"NodeText","Data":"（替换一个词、指定一种风格、改变形容词等）来编辑图像。这种操控是通过注入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交叉注意力图"},{"Type":"NodeText","Data":"来实现的，该图控制了在不同扩散步骤中，哪些像素关注提示文本中的哪些token。仅修改文本提示的基于提示的图像编辑方法提供了更直观的编辑体验。"}]},{"ID":"20250924224352-oamp5gy","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224352-oamp5gy","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.3 提示的应用"}]},{"ID":"20250924224352-ut9zwe2","Type":"NodeParagraph","Properties":{"id":"20250924224352-ut9zwe2","updated":"20250924224355"},"Children":[{"Type":"NodeText","Data":"在提示技术的辅助下，文生图扩散模型在数据生成应用中表现出色。本节研究它们在生成训练数据方面的功效，这些数据可以扩大和提升学习过程的范围和灵活性。此外，我们探索了这些模型在目标领域中制作多样化数据的多功能性，涵盖了图像、视频、3D模型和动作等多种输出格式。我们还揭示了其在复杂任务解决和对抗性攻击中的潜力。"}]},{"ID":"20250924224352-mjeuo2t","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250924224352-mjeuo2t","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"5.3.1 生成合成训练数据"}]},{"ID":"20250924224352-aw4pgjk","Type":"NodeParagraph","Properties":{"id":"20250924224352-aw4pgjk","updated":"20250924224355"},"Children":[{"Type":"NodeText","Data":"最近的进展引发了人们对将提示文生图模型作为创新的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成训练数据生成器"},{"Type":"NodeText","Data":"用于各种下游任务（如分割、目标检测和图像识别）的浓厚兴趣。通过复杂的提示工程，可以缓解数据稀缺和需要高分辨率合成图像等挑战。DiffuMask在5.2节中提到的提示工程策略，可以自动生成高分辨率的合成训练图像。其在提示和生成图像之间创建的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"像素级语义掩码"},{"Type":"NodeText","Data":"可以无缝地应用于分割任务，包括语义分割、开放词汇分割和在真实图像上的域泛化。ImaginaryNet生成合成数据来解决训练目标检测器时真实图像和标注不足的挑战。它利用LLM从类别标签生成场景描述，并提示文生图模型创建"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"想象中的训练数据"},{"Type":"NodeText","Data":"。在纯想象数据或混合想象与真实数据的不同训练设置下，目标检测器在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"想象监督目标检测任务（ISOD）"},{"Type":"NodeText","Data":" 中得到了增强，尤其是在真实图像和标注不可用的设置下。合成数据也被证明对图像识别任务是可行的，特别是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本和少样本"},{"Type":"NodeText","Data":"设置中。在一个两阶段的过程中创建合成数据用于图像识别。首先，使用目标类别名称合成新样本。"}]},{"ID":"20250924224352-xqse9co","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224352-xqse9co","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"12"}]},{"ID":"20250924224352-9bp0iz0","Type":"NodeParagraph","Properties":{"id":"20250924224352-9bp0iz0","updated":"20250924224355"},"Children":[{"Type":"NodeText","Data":"其次，使用一个微调过的语言模型将类别名称转换为丰富的、上下文多样化的语言提示，以使训练数据多样化。"}]},{"ID":"20250924224352-gebgfro","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250924224352-gebgfro","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"5.3.2 在目标领域中生成数据"}]},{"ID":"20250924224352-m0pdz6g","Type":"NodeParagraph","Properties":{"id":"20250924224352-m0pdz6g","updated":"20250924224355"},"Children":[{"Type":"NodeText","Data":"除了作为训练数据生成器的角色，扩散模型也作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标数据生成器"},{"Type":"NodeText","Data":"发挥着关键作用。重要的是，它们的能力超出了图像的生成。它们可以有效地生成视频数据、三维数据和动作数据，进一步拓宽了它们的应用范围和效用。"}]},{"ID":"20250924224352-3z0m5gd","Type":"NodeParagraph","Properties":{"id":"20250924224352-3z0m5gd","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本到视频生成 (Text-to-Video Generation)"},{"Type":"NodeText","Data":"。Make-A-Video是第一个将文生图（T2I）领域的巨大最新进展直接转化为文生视频（T2V）的方法，且"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无需成对的文本-视频数据"},{"Type":"NodeText","Data":"。它推断提示中的动作和事件，并通过利用联合的文本-图像先验知识来生成视频，从而绕开了对成对文本-视频数据的需求。Imagen Video将T2V生成推向了一个更高效的阶段，通过结合一个冻结的T5文本编码器、一个基础视频扩散模型和交错的空间与时间超分辨率扩散模型（即级联扩散模型），提供了更高分辨率的视频输出。然而，T2V的研究通常在编辑能力和在特定领域进行有效训练方面面临挑战。FateZero通过一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本的基于文本的编辑方法"},{"Type":"NodeText","Data":"克服了这些限制，该方法能够在真实世界的视频上编辑属性、风格和形状，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无需针对每个提示进行训练或使用特定的掩码"},{"Type":"NodeText","Data":"。具体来说，FateZero利用一对用户提供的源提示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"P_{src}"},{"Type":"NodeText","Data":" 和编辑提示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"P_{edit}"},{"Type":"NodeText","Data":"。源提示用于获取源视频帧的带噪潜在表示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_t"},{"Type":"NodeText","Data":"，然后 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_t"},{"Type":"NodeText","Data":" 在编辑提示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"P_{edit}"},{"Type":"NodeText","Data":" 的条件下进行去噪。Tune-A-Video通过在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单个文本-视频对"},{"Type":"NodeText","Data":"上进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一次性调优 (one-shot tuning)"},{"Type":"NodeText","Data":" 策略来解决计算昂贵的问题，且仅在视频的第一帧和前几帧上进行。这项研究的灵感来自于T2I模型在生成静止图像时能很好地理解提示中的动词，并且在扩展到T2V时表现出惊人的动作一致性。Tune-A-Video还具备编辑能力，通过从输入视频中捕捉关键的动作信息，并用保留了动作词的编辑后提示来合成新颖的视频。此外，基于文本提示的生成已经发展到多模态生成，例如，同时生成对齐的音频-视频对。"}]},{"ID":"20250924224352-e41irv1","Type":"NodeParagraph","Properties":{"id":"20250924224352-e41irv1","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本到3D生成 (Text-to-3D Generation)"},{"Type":"NodeText","Data":"。以前的工作面临着缺乏大规模标记的3D数据集和低效的3D数据去噪架构的挑战。因此，基于提示的生成已从T2I、T2V模型发展到文本到3D场景，其中可以从文本提示生成高质量的3D对象和场景。DreamFusion首先为每个文本提示随机初始化一个带有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"NeRF"},{"Type":"NodeText","Data":"的3D对象，并用可微的图像生成器 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"g(\\eta)"},{"Type":"NodeText","Data":" 产生2D图像渲染 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x = g(\\eta)"},{"Type":"NodeText","Data":"。这些渲染是从不同角度生成的，并与视角相关的提示前缀（如“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"overhead view"},{"Type":"NodeText","Data":"​”和“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"front view"},{"Type":"NodeText","Data":"​”）配对，然后由Imagen进行扩散和重建，即 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"q(x_t|x_0) := q(g(\\eta)_t|g(\\eta)_0)"},{"Type":"NodeText","Data":"。采样的噪声 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\epsilon"},{"Type":"NodeText","Data":" 引导一个梯度方向反向传播到NeRF参数 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\eta"},{"Type":"NodeText","Data":"。为了解决日益流行的DreamFusion在NeRF优化效率方面的问题，该问题导致低质量的3D模型和漫长的处理时间，Magic3D提出了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两阶段的从粗到精的优化框架"},{"Type":"NodeText","Data":"，即首先用Imagen从文本提示中获得一个粗糙的扩散先验，然后用高分辨率的潜在扩散模型（LDM）进行高效渲染。借鉴的思想，Magic3D能够通过在提示中将 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[V]"},{"Type":"NodeText","Data":"​ 标识符与3D对象绑定，实现对3D模型的个性化、基于提示的编辑。此外，可以通过在粗到精阶段用修改后的提示对LDM进行微调来实现基于提示的编辑。由于没有先验知识导致随机形状初始化，文本到3D生成中存在不准确和不忠实的结构，这促使Dream3D将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"显式的3D形状先验"},{"Type":"NodeText","Data":"引入到CLIP引导的3D优化过程中。具体来说，它将T2I模型和一个形状生成器连接起来，作为文本到形状的阶段，以在提示中生成带有形状组件的3D形状先验。然后，它利用3D形状先验来初始化NeRF，并用完整的提示进行优化。为了缩小合成图像和形状之间的差距，并受到的启发，Dream3D将渲染与风格化的文本提示后缀以“"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"a CLS in the style of *"},{"Type":"NodeText","Data":"​”的格式链接起来，其中CLS代表形状类别，* 是一个占位符token，需要与Stable Diffusion的权重一起优化其文本嵌入，以捕捉渲染图像的风格。"}]},{"ID":"20250924224352-0lkjd77","Type":"NodeParagraph","Properties":{"id":"20250924224352-0lkjd77","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本到动作生成 (Text-to-Motion Generation)"},{"Type":"NodeText","Data":"。另一个体现基于提示生成力量的领域是文本到动作（T2M）。MotionDiffuse是一个基于扩散模型的文本驱动的动作生成框架，以动作序列作为输入 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_0"},{"Type":"NodeText","Data":"。它有一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"身体部位独立的控制方案"},{"Type":"NodeText","Data":"，为每个身体部位在 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"m"},{"Type":"NodeText","Data":" 个细粒度提示 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"P_i"},{"Type":"NodeText","Data":"（其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"i \\in [1,m]"},{"Type":"NodeText","Data":"）下生成独立的序列，并预测每个部位 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\epsilon_t^{part} = \\epsilon_\\theta(x_t, t, \\Gamma(P_i))"},{"Type":"NodeText","Data":"。此外，它使用带有 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"m"},{"Type":"NodeText","Data":" 个区间的时间变化文本提示（表示为数组 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\{P_{i,j}, [l_{i,j}, r_{i,j}]\\}"},{"Type":"NodeText","Data":"）生成任意长度的连续动作合成，并预测 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\epsilon_t^{time}"},{"Type":"NodeText","Data":"。所有噪声都与其他部分相互插值，以实现连续的动作序列生成。与T2I、T2V和文本到3D类似，T2M合成也需要灵活的编辑能力。因此，FLAME通过新颖的基于transformer的扩散架构，实现了用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自由形式的语言描述"},{"Type":"NodeText","Data":"进行编辑。它将扩散时间步token、动作长度token、语言token和动作token作为输入token送入transformer，因此可以处理可变长度的动作序列。MDM也引入了可编辑性和可控性，其思想类似于图像修复，通过在时间域上为动作添加后缀和前缀。文本条件引导MDM填充缺失的身体部位，并执行特定的动作，同时保持其余部分在空间域上完整。"}]},{"ID":"20250924224352-usu1piw","Type":"NodeParagraph","Properties":{"id":"20250924224352-usu1piw","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂条件场景生成 (Complex Conditional Scene Generation)"},{"Type":"NodeText","Data":"。扩散模型的使用已扩展到单一目标数据生成之外，应用于各种场景，这些场景涉及生成更复杂的、根据特定用例和更复杂的条件输入定制的场景。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"机器人技术"},{"Type":"NodeText","Data":"中，文本引导被用来对我们现有的机器人操控数据集进行激进的数据增强，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"修复"},{"Type":"NodeText","Data":"各种未见过的物体、背景和干扰物来生成机器人场景。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动驾驶"},{"Type":"NodeText","Data":"中，利用扩散模型生成可控的、与周围环境上下文对齐的行人轨迹，从而能够模拟现实的行人行为。此外，扩散模型可以整合图形式的条件信息，这些图代表单个房间，以生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"房屋平面图"},{"Type":"NodeText","Data":"，促进了居住空间的设计和规划。"}]},{"ID":"20250924224352-75q87z4","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224352-75q87z4","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"13"}]},{"ID":"20250924224352-2rot5zr","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250924224352-2rot5zr","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong strong","TextMarkTextContent":"5.3.3 以提示为中心的复杂任务"}]},{"ID":"20250924224352-tr0x842","Type":"NodeParagraph","Properties":{"id":"20250924224352-tr0x842","updated":"20250924224355"},"Children":[{"Type":"NodeText","Data":"除了前面直接的文生其他（text-to-other）生成应用外，以提示为中心的复杂应用在各种场景中揭示了该领域真正的多功能性和潜力。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"讲故事"},{"Type":"NodeText","Data":"的背景下，StoryBook通过一系列以提示为中心的步骤，保留了一个具有一致角色面孔的视觉叙事故事书。它首先用LLM生成场景描述的提示，然后将这些提示输入到潜在扩散模型中，并使用指定的特殊token占位符 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"S_*"},{"Type":"NodeText","Data":"（如），以在生成过程中定位一致的角色面孔。类似地，提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态程序规划（MPP）"},{"Type":"NodeText","Data":" 任务，其中初始的逐步文本计划由LLM生成，然后作为提示输入到扩散模型中，以合成基于文本定位的图像计划。不同的是，图像计划通过图像描述被"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“言语化”"},{"Type":"NodeText","Data":" 返回给LLM，以修订初始计划，显示了多模态提示的潜力。"}]},{"ID":"20250924224352-l6zctyh","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224352-l6zctyh","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.4 提示的责任AI考量"}]},{"ID":"20250924224352-mei8p0h","Type":"NodeParagraph","Properties":{"id":"20250924224352-mei8p0h","updated":"20250924224355"},"Children":[{"Type":"NodeText","Data":"人工智能通过其强大的学习能力、变革性力量以及在社会各领域的深远影响，正在彻底改变我们的世界。它也引发了关于AI开发和应用中伦理问题、原则和诚信的激烈辩论。在全球范围内，人们围绕五个伦理原则达成了共识："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"透明度"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正义与公平"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非恶意"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"责任"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐私"},{"Type":"NodeText","Data":"。在本小节中，我们讨论在提示文生图生成模型时遇到的伦理问题。"}]},{"ID":"20250924224352-t2x8f1i","Type":"NodeParagraph","Properties":{"id":"20250924224352-t2x8f1i","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示的对抗性鲁棒性 (Adversarial Robustness of Prompt)"},{"Type":"NodeText","Data":"。对抗性攻击被引入到文生图扩散模型中，主要有两个目的。一些工作将扩散模型作为促进或防御对抗性攻击的工具。一些工作直接攻击扩散模型，旨在通过字符扰动来消除图像内容。作为将扩散模型引入对抗性攻击领域的先驱，DiffAttack揭示了扩散模型通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"操纵潜在空间而非像素空间"},{"Type":"NodeText","Data":"来制作具有令人满意的不可感知性和可迁移性的对抗性样本的潜力。这种方法保持了视觉质量，其嵌入扰动对人类是不可检测的，并且可以跨多种模型架构迁移。扩散模型可用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性净化"},{"Type":"NodeText","Data":"——一种移除对抗性扰动的防御策略。DiffPure实现了这种方法，在反转生成过程以恢复原始图像之前，向对抗性样本中添加极少量的噪声，从而展现出对强大自适应攻击的鲁棒防御能力。Zhuang等人研究了在没有端到端模型查询的情况下对Stable Diffusion的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"免查询攻击生成"},{"Type":"NodeText","Data":"。他们表明，Stable Diffusion的脆弱性根植于其文本编码器。一个五个字符的文本扰动就能够改变输出内容。"}]},{"ID":"20250924224352-wp8onat","Type":"NodeParagraph","Properties":{"id":"20250924224352-wp8onat","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示学习的后门攻击 (Backdoor Attack of Prompt Learning)"},{"Type":"NodeText","Data":"。对文生图生成模型的后门攻击旨在通过嵌入带有预定义后门触发器的输入，在推理过程中控制生成图像的内容。攻击者在训练期间秘密地向模型中注入后门，例如特定的文本字符，以触发模型生成具有预定义属性的图像，或者遵循隐藏的甚至恶意的描述。后门攻击可能导致不适当的输出，例如攻击性内容。另一方面，它也可以用于通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"给模型加水印"},{"Type":"NodeText","Data":"来进行版权保护。Struppek等人证明了文本编码器构成了主要的篡改风险。该攻击是一种师生方法，仅涉及通过动态生成后门目标和触发器来微调文本编码器。Zhai等人设计了三种类型的后门攻击，即像素后门、对象后门和风格后门，并证明了文生图扩散模型对后门攻击的脆弱性。Huang等人通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"个性化"},{"Type":"NodeText","Data":"探索了对后门攻击的脆弱性，以实现更高效的攻击。文生图个性化引导基于扩散的文生图模型通过自然语言生成用户提供的新颖概念。Huang等人针对两类个性化方法——Textual Inversion和DreamBooth——设计了后门攻击。"}]},{"ID":"20250924224352-nyg413n","Type":"NodeParagraph","Properties":{"id":"20250924224352-nyg413n","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"公平与偏见 (Fairness and Bias)"},{"Type":"NodeText","Data":"。生成式AI模型通常在从互联网上抓取的网络规模数据集上进行训练，不可避免地会受到有偏见的人类行为的影响。例如，Stable Diffusion只生成白人男性形象的消防员。一些研究开始更多地关注与文生图生成相关的公平性问题，并可分为三种范式：1）在学习前对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练数据进行预处理"},{"Type":"NodeText","Data":"以消除偏见，2）在训练期间通过在学习目标上"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"引入约束来强制公平性"},{"Type":"NodeText","Data":"，3）在部署阶段"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对模型结果进行后处理"},{"Type":"NodeText","Data":"以修改模型输出。"}]},{"ID":"20250924224352-bkuaeiu","Type":"NodeParagraph","Properties":{"id":"20250924224352-bkuaeiu","updated":"20250924224355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐私 (Privacy)"},{"Type":"NodeText","Data":"。在用于训练文生图模型的大量训练数据中，可能存在隐私敏感信息，例如人脸身份。这些信息在现实世界的应用中可能引发隐私风险，例如信息泄露。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成员推理攻击"},{"Type":"NodeText","Data":"是一种研究隐私泄露的方法，通过推断一个特定的数据样本是否被用于训练阶段（分别称为成员或非成员）。一些工作从成员推理攻击的角度研究了文生图生成模型的隐私风险。从提示的角度来看，Shen等人提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示窃取攻击"},{"Type":"NodeText","Data":"，该攻击从文生图生成模型生成的图像中窃取提示。高质量提示的创建可能具有挑战性、耗时且成本高昂。因此，成功的提示窃取攻击直接侵犯了知识产权，甚至可能危及提示交易市场的商业模式。"}]},{"ID":"20250924224352-ve0n3a9","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224352-ve0n3a9","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6 VLM提示 vs. 单模态模型"}]},{"ID":"20250924224352-dfoj24t","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224352-dfoj24t","updated":"20250924224354"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.1 自然语言处理中的提示"}]},{"ID":"20250924224352-ufotbm1","Type":"NodeParagraph","Properties":{"id":"20250924224352-ufotbm1","updated":"20250924224354"},"Children":[{"Type":"NodeText","Data":"本节总结了在文本语言模型上提示工程的现有研究。提示工程已在各种自然语言处理应用中被广泛采用，包括问答、文本分类、文本生成和信息提取等。最近的LLM，如InstructGPT和PALM2，通过提示展现了令人难以置信的泛化推理能力。早期的工作设计了自然语言模板，让预训练语言模型通过填空来解释其预测。Wei等人证明，通过在提示中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加入中间推理步骤"},{"Type":"NodeText","Data":"，可以显著提高LLM的性能。具体来说，每个任务的提示包含几个手动演示，包括一个问题和一个导致答案的推理链。LLM学会遵循提示，并"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一步一步地思考"},{"Type":"NodeText","Data":"来解决给定的任务。Liu等人发现，提示的质量，即提示中示例的选择和给出的解释，..."}]},{"ID":"20250924224352-w3wvs0o","Type":"NodeBlockquote","Properties":{"id":"20250924224352-w3wvs0o","updated":"20250924224354"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250924224352-ph1scee","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224352-ph1scee","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250924224352-irgivzw","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224352-irgivzw","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级控制与编辑技术"}]},{"ID":"20250924224352-9am6uki","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224352-9am6uki","updated":"20250924224352"},"Children":[{"ID":"20250924224352-9pff7lg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-9pff7lg","updated":"20250924224352"},"Children":[{"ID":"20250924224352-n98j1pe","Type":"NodeParagraph","Properties":{"id":"20250924224352-n98j1pe","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ControlNet - “骨架”控制"},{"Type":"NodeText","Data":": ControlNet是文生图领域的一大突破，它允许用户提供一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“控制图”"},{"Type":"NodeText","Data":"（如Canny边缘图、姿态骨架图）作为额外的、非文本的提示。这使得生成的内容可以严格遵循用户给定的结构，实现了对图像布局、物体姿态等的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"像素级精准控制"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250924224352-td8pxzp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-td8pxzp","updated":"20250924224352"},"Children":[{"ID":"20250924224352-zshsvpx","Type":"NodeParagraph","Properties":{"id":"20250924224352-zshsvpx","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Prompt-to-Prompt - “魔法棒”式编辑"},{"Type":"NodeText","Data":": 这项技术实现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成后"},{"Type":"NodeText","Data":"的编辑，且极为直观。用户无需复杂的PS操作，只需"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"修改原始的文本提示"},{"Type":"NodeText","Data":"（比如把“猫”改成“狗”），算法就能通过操纵模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交叉注意力图"},{"Type":"NodeText","Data":"，智能地只修改图像中对应的部分，同时保持其他内容不变。"}]}]}]},{"ID":"20250924224352-tfpr5gu","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224352-tfpr5gu","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的应用：从数据到创意"}]},{"ID":"20250924224352-7by9n2d","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224352-7by9n2d","updated":"20250924224352"},"Children":[{"ID":"20250924224352-3u9tgxc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-3u9tgxc","updated":"20250924224352"},"Children":[{"ID":"20250924224352-l8p5r4a","Type":"NodeParagraph","Properties":{"id":"20250924224352-l8p5r4a","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成数据生成器"},{"Type":"NodeText","Data":": 这是提示工程最强大的应用之一。对于那些数据稀缺的领域（如医学影像、自动驾驶极端场景），研究者可以利用文生图模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"凭空创造"},{"Type":"NodeText","Data":"出大量高质量的训练数据。ImaginaryNet甚至展示了在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完全没有真实数据"},{"Type":"NodeText","Data":"的情况下，仅靠“想象”出的数据来训练一个目标检测器。"}]}]},{"ID":"20250924224352-ixzbtuv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-ixzbtuv","updated":"20250924224352"},"Children":[{"ID":"20250924224352-ss7bwpg","Type":"NodeParagraph","Properties":{"id":"20250924224352-ss7bwpg","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"跨越模态的生成 (T2V, T2-3D, T2M)"},{"Type":"NodeText","Data":": 提示工程驱动的生成模型已经突破了2D图像的限制，向更复杂的模态进军："}]}]},{"ID":"20250924224352-26e2whm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-26e2whm","updated":"20250924224352"},"Children":[{"ID":"20250924224352-8tsb7uk","Type":"NodeParagraph","Properties":{"id":"20250924224352-8tsb7uk","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"T2V (视频)"},{"Type":"NodeText","Data":": 核心挑战在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"时间上的一致性"},{"Type":"NodeText","Data":"。Tune-A-Video等工作通过“一次性调优”，让模型从单个视频中学会动作模式，从而生成或编辑出具有连贯动作的新视频。"}]}]},{"ID":"20250924224352-edoteq8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-edoteq8","updated":"20250924224352"},"Children":[{"ID":"20250924224352-tg33eld","Type":"NodeParagraph","Properties":{"id":"20250924224352-tg33eld","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"T2-3D (三维)"},{"Type":"NodeText","Data":": 核心挑战在于从2D信息中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推断出3D结构"},{"Type":"NodeText","Data":"。DreamFusion开创性地使用一个2D扩散模型作为“裁判”（通过损失函数），来指导一个3D表示（NeRF）的优化，最终“雕刻”出3D模型。Magic3D和Dream3D则通过引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"形状先验"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分阶段优化"},{"Type":"NodeText","Data":"来提升效率和质量。"}]}]},{"ID":"20250924224352-va74q1a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-va74q1a","updated":"20250924224352"},"Children":[{"ID":"20250924224352-dsrl8ud","Type":"NodeParagraph","Properties":{"id":"20250924224352-dsrl8ud","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"T2M (动作)"},{"Type":"NodeText","Data":": 核心在于生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符合物理规律且自然的动作序列"},{"Type":"NodeText","Data":"。MotionDiffuse等模型通过对身体不同部位进行独立控制和组合，实现了复杂的动作生成和编辑。"}]}]},{"ID":"20250924224352-6x06lwa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-6x06lwa","updated":"20250924224352"},"Children":[{"ID":"20250924224352-wdi8kqw","Type":"NodeParagraph","Properties":{"id":"20250924224352-wdi8kqw","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂任务与叙事"},{"Type":"NodeText","Data":": StoryBook和MPP的例子展示了提示工程在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多步骤、创造性任务"},{"Type":"NodeText","Data":"中的潜力。通过将LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规划能力"},{"Type":"NodeText","Data":"和扩散模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成能力"},{"Type":"NodeText","Data":"相结合，可以完成像“生成一本图文并茂的故事书”或“规划并可视化一个多模态流程”这样的复杂任务。"}]}]}]},{"ID":"20250924224352-yclvkja","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224352-yclvkja","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"责任AI的深度考量"}]},{"ID":"20250924224352-dylpmm6","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224352-dylpmm6","updated":"20250924224352"},"Children":[{"ID":"20250924224352-78z7z1g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-78z7z1g","updated":"20250924224352"},"Children":[{"ID":"20250924224352-rcecuyg","Type":"NodeParagraph","Properties":{"id":"20250924224352-rcecuyg","updated":"20250924224352"},"Children":[{"Type":"NodeText","Data":"这一节对文生图模型的伦理风险进行了迄今为止最全面的剖析："}]}]},{"ID":"20250924224352-m6sc4t4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-m6sc4t4","updated":"20250924224352"},"Children":[{"ID":"20250924224352-qeczm48","Type":"NodeParagraph","Properties":{"id":"20250924224352-qeczm48","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性攻击与防御"},{"Type":"NodeText","Data":": 攻击者可以通过微小的、人眼无法察觉的文本扰动（如5个字符）来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完全扭曲"},{"Type":"NodeText","Data":"生成内容。反过来，扩散模型本身也可以用来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“净化”"},{"Type":"NodeText","Data":" 被攻击的图像。"}]}]},{"ID":"20250924224352-yahwmcm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-yahwmcm","updated":"20250924224352"},"Children":[{"ID":"20250924224352-qgwx5kb","Type":"NodeParagraph","Properties":{"id":"20250924224352-qgwx5kb","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"后门攻击"},{"Type":"NodeText","Data":": 这是一个更隐蔽的威胁。攻击者可以在训练数据中埋下“后门”（如一个特定的词），使得模型在推理时一旦遇到这个“触发词”，就会生成攻击者预设的内容（比如攻击性图片或带有隐藏水印的图片）。"}]}]},{"ID":"20250924224352-86w1d6r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-86w1d6r","updated":"20250924224352"},"Children":[{"ID":"20250924224352-zde09kk","Type":"NodeParagraph","Properties":{"id":"20250924224352-zde09kk","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"公平与偏见"},{"Type":"NodeText","Data":": 作者指出了解决偏见的三种主要途径："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据层面"},{"Type":"NodeText","Data":"（清洗训练数据）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练层面"},{"Type":"NodeText","Data":"（加入公平性约束）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"部署层面"},{"Type":"NodeText","Data":"（后处理生成结果）。"}]}]},{"ID":"20250924224352-6jnmmet","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-6jnmmet","updated":"20250924224352"},"Children":[{"ID":"20250924224352-uhfoevz","Type":"NodeParagraph","Properties":{"id":"20250924224352-uhfoevz","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐私与知识产权"},{"Type":"NodeText","Data":": 这是一个新颖且重要的问题。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成员推理攻击"},{"Type":"NodeText","Data":"可以判断某张图片是否在训练集中，从而泄露隐私。而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示窃取攻击"},{"Type":"NodeText","Data":"则对创作者构成了直接威胁，攻击者可以从生成的图片中反推出高质量的提示，侵犯了创作者的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识产权"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250924224352-gpol8sa","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250924224352-gpol8sa","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与单模态模型的对比"}]},{"ID":"20250924224352-soxw56t","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224352-soxw56t","updated":"20250924224352"},"Children":[{"ID":"20250924224352-q92625c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-q92625c","updated":"20250924224352"},"Children":[{"ID":"20250924224352-x9v90zm","Type":"NodeParagraph","Properties":{"id":"20250924224352-x9v90zm","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"承上启下"},{"Type":"NodeText","Data":": 在详细探讨了VLM之后，作者开始进行横向对比，首先回顾了提示工程在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纯NLP领域"},{"Type":"NodeText","Data":"的根基。像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（Chain-of-Thought）"},{"Type":"NodeText","Data":" 这样的技术，最初就是为了提升LLM的复杂推理能力而提出的，现在这些思想正被迁移到多模态领域。"}]}]}]},{"ID":"20250924224352-axeipt8","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250924224352-axeipt8","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250924224352-ic8m2f4","Type":"NodeList","ListData":{},"Properties":{"id":"20250924224352-ic8m2f4","updated":"20250924224352"},"Children":[{"ID":"20250924224352-de7re2q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-de7re2q","updated":"20250924224352"},"Children":[{"ID":"20250924224352-646l5is","Type":"NodeParagraph","Properties":{"id":"20250924224352-646l5is","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“生成”到“创造”的飞跃"},{"Type":"NodeText","Data":": 这一部分展示了提示工程如何将文生图技术从简单的“图像生成器”提升为强大的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“世界模拟器”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“创意工具”"},{"Type":"NodeText","Data":"。无论是生成用于科研的合成数据，还是创造视频、3D模型和连贯的叙事，提示工程都是实现这一切的核心驱动力。"}]}]},{"ID":"20250924224352-y93lhtk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-y93lhtk","updated":"20250924224352"},"Children":[{"ID":"20250924224352-lvfrt3m","Type":"NodeParagraph","Properties":{"id":"20250924224352-lvfrt3m","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"控制的“粒度”越来越细"},{"Type":"NodeText","Data":": 从ControlNet的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构控制"},{"Type":"NodeText","Data":"，到Prompt-to-Prompt的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语义编辑"},{"Type":"NodeText","Data":"，再到DreamBooth的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"身份注入"},{"Type":"NodeText","Data":"，我们看到对生成过程的控制正变得前所未有的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精细和直观"},{"Type":"NodeText","Data":"。这极大地降低了普通用户进行专业级内容创作的门槛。"}]}]},{"ID":"20250924224352-6t0sy27","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-6t0sy27","updated":"20250924224352"},"Children":[{"ID":"20250924224352-jpao688","Type":"NodeParagraph","Properties":{"id":"20250924224352-jpao688","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术发展与伦理风险的赛跑"},{"Type":"NodeText","Data":": 本部分对责任AI的深入讨论是其一大亮点。它揭示了随着生成模型能力的指数级增长，其被滥用的风险（后门攻击、提示窃取）也变得空前严峻和多样化。这强调了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术发展必须与伦理规范、安全防护同步进行"},{"Type":"NodeText","Data":"，二者缺一不可。"}]}]},{"ID":"20250924224352-apnvek5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250924224352-apnvek5","updated":"20250924224352"},"Children":[{"ID":"20250924224352-sdpeu5r","Type":"NodeParagraph","Properties":{"id":"20250924224352-sdpeu5r","updated":"20250924224352"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"追根溯源，展望未来"},{"Type":"NodeText","Data":": 通过回顾提示工程在NLP领域的起源，作者为整篇综述做了一个漂亮的回环。这不仅让读者理解了许多VLM提示技术的思想来源，也暗示了未来的发展方向——将更多NLP领域的先进提示技术（如更复杂的推理链、检索增强等）与视觉信息进行更深度的融合。"}]}]}]},{"ID":"20250924224352-luyhklz","Type":"NodeParagraph","Properties":{"id":"20250924224352-luyhklz","updated":"20250924224352"},"Children":[{"Type":"NodeText","Data":"总体来看，这最后一部分内容从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用广度"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术深度"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"伦理高度"},{"Type":"NodeText","Data":"三个方面，为文生图领域的提示工程描绘了一幅完整而深刻的全景图，并为全文的最终总结和展望铺平了道路。"}]}]}]}