{"ID":"20250922190647-ln5pl0t","Spec":"1","Type":"NodeDocument","Properties":{"id":"20250922190647-ln5pl0t","title":"06 大模型综述","type":"doc","updated":"20250924145426"},"Children":[{"ID":"20250922194422-4isowv1","Type":"NodeParagraph","Properties":{"id":"20250922194422-4isowv1","updated":"20250923150736"},"Children":[{"Type":"NodeText","Data":"韦恩·辛·赵，周昆"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"，李俊毅"},{"Type":"NodeText","Data":"，唐天一，王晓蕾，侯宇鹏，闵颖倩，张贝辰，张俊杰，董子瞻，杜一凡，杨晨，陈宇硕，陈志鹏，蒋锦浩，任瑞阳，李一凡，唐馨宇，刘子康，刘沛宇，聂建云，温继荣"}]},{"ID":"20250922194422-6gxzfpu","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922194422-6gxzfpu","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"摘要"}]},{"ID":"20250922194422-pazx2sa","Type":"NodeParagraph","Properties":{"id":"20250922194422-pazx2sa","updated":"20250922194423"},"Children":[{"Type":"NodeText","Data":"自1950年代图灵测试被提出以来，人类一直在探索由机器掌握语言智能。语言本质上是一个由语法规则支配的复杂、精巧的人类表达系统。开发能够理解和掌握语言的强大人工智能（AI）算法是一项重大的挑战。作为一种主要方法，语言建模在过去二十年中为语言理解和生成被广泛研究，从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统计语言模型"},{"Type":"NodeText","Data":"演变为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"神经语言模型"},{"Type":"NodeText","Data":"。最近，通过在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模语料库"},{"Type":"NodeText","Data":"上预训练Transformer模型，提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练语言模型（PLM）"},{"Type":"NodeText","Data":"，在解决各种自然语言处理（NLP）任务中展现出强大的能力。由于研究人员发现模型规模的扩大可以带来模型能力的提升，他们通过将参数规模增加到更大的尺寸来进一步研究规模效应。有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅在性能上取得了显著提升，还展现出一些在小型语言模型（如BERT）中不存在的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特殊能力（例如，上下文学习）"},{"Type":"NodeText","Data":"。为了区分不同参数规模的语言模型，研究界创造了术语“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型语言模型（LLM）"},{"Type":"NodeText","Data":"”，用于指代规模巨大的PLM（例如，包含数百亿或数千亿参数）。最近，LLM的研究在学术界和工业界都取得了长足的进步，一个显著的进展是基于LLM开发的强大AI聊天机器人"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT"},{"Type":"NodeText","Data":"的推出，它吸引了社会的广泛关注。LLM的技术演进正在对整个AI社区产生重要影响，这将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"彻底改变我们开发和使用AI算法的方式"},{"Type":"NodeText","Data":"。考虑到这一快速的技术进步，在本综述中，我们通过介绍背景、关键发现和主流技术，回顾了LLM的最新进展。我们特别关注LLM的四个主要方面，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练、适配调整、利用和能力评估"},{"Type":"NodeText","Data":"。此外，我们还总结了开发LLM的可用资源，并讨论了未来方向的遗留问题。本综述对LLM的文献进行了最新的回顾，可以为研究人员和工程师提供有用的资源。"}]},{"ID":"20250922194422-7u1vp3p","Type":"NodeParagraph","Properties":{"id":"20250922194422-7u1vp3p","updated":"20250922194423"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"索引术语"},{"Type":"NodeText","Data":"—大型语言模型；涌现能力；适配调整；利用；对齐；能力评估。"}]},{"ID":"20250922194422-tdgq7s5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922194422-tdgq7s5","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1 INTRODUCTION (引言)"}]},{"ID":"20250922194422-g0wrkje","Type":"NodeBlockquote","Properties":{"id":"20250922194422-g0wrkje","updated":"20250922194423"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922194422-ptvqbqb","Type":"NodeParagraph","Properties":{"id":"20250922194422-ptvqbqb","updated":"20250922194422"},"Children":[{"Type":"NodeText","Data":"“我语言的极限意味着我世界的极限。”"}]},{"ID":"20250922194422-bsy45au","Type":"NodeParagraph","Properties":{"id":"20250922194422-bsy45au","updated":"20250922194422"},"Children":[{"Type":"NodeText","Data":"—路德维希·维特根斯坦"}]}]},{"ID":"20250922194422-h0llds5","Type":"NodeParagraph","Properties":{"id":"20250922194422-h0llds5","updated":"20250922194423"},"Children":[{"Type":"NodeText","Data":"语言是人类表达和交流的一项"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"突出能力"},{"Type":"NodeText","Data":"，它在儿童早期发展并在人的一生中不断演化。然而，机器无法自然地掌握以人类语言形式进行理解和交流的能力，除非配备了强大的人工智能（AI）算法。实现这一目标，让机器能够像人类一样阅读、写作和交流，一直是一个长期的研究挑战。"}]},{"ID":"20250922194422-p474euo","Type":"NodeParagraph","Properties":{"id":"20250922194422-p474euo","updated":"20250922194423"},"Children":[{"Type":"NodeText","Data":"从技术上讲，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言建模（LM）"},{"Type":"NodeText","Data":" 是提升机器语言智能的主要方法之一。总的来说，LM旨在对词序列的生成似然进行建模，从而预测未来（或缺失）词元的概率。LM的研究受到了文献的广泛关注，可以分为四个主要发展阶段："}]},{"ID":"20250922194422-9o3i90m","Type":"NodeList","ListData":{},"Properties":{"id":"20250922194422-9o3i90m","updated":"20250922194423"},"Children":[{"ID":"20250922194422-yloq10x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194422-yloq10x","updated":"20250922194422"},"Children":[{"ID":"20250922194422-60ewgpx","Type":"NodeParagraph","Properties":{"id":"20250922194422-60ewgpx","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统计语言模型（SLM）。"},{"Type":"NodeText","Data":" SLM [6–9] 是基于1990年代兴起的统计学习方法开发的。其基本思想是基于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"马尔可夫假设"},{"Type":"NodeText","Data":"建立词语预测模型，例如，根据最近的上下文预测下一个词。具有固定上下文长度 "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"n"},{"Type":"NodeText","Data":" 的SLM也被称为 "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"n"},{"Type":"NodeText","Data":"-gram语言模型，例如二元（bigram）和三元（trigram）语言模型。SLM已被广泛应用于提升信息检索（IR） 和自然语言处理（NLP）[12–14] 中的任务性能。然而，它们常常遭受"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"维度灾难"},{"Type":"NodeText","Data":"：准确估计高阶语言模型很困难，因为需要估计指数级数量的转移概率。因此，引入了专门设计的平滑策略，如回退估计 和古德-图灵估计，以缓解数据稀疏性问题。"}]}]},{"ID":"20250922194422-gxxj754","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194422-gxxj754","updated":"20250922194422"},"Children":[{"ID":"20250922194422-qpglttj","Type":"NodeParagraph","Properties":{"id":"20250922194422-qpglttj","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"神经语言模型（NLM）。"},{"Type":"NodeText","Data":" NLM 通过神经网络，如多层感知机（MLP）和循环神经网络（RNN），来刻画词序列的概率。作为一项杰出的贡献， 中的工作引入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词的分布式表示"},{"Type":"NodeText","Data":"的概念，并构建了基于聚合上下文特征（即分布式词向量）的词语预测函数。通过扩展为文本数据学习有效特征的思想，开发了一种通用的神经网络方法，为"}]}]}]},{"ID":"20250922194422-8tc7ouq","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250922194422-8tc7ouq","updated":"20250922194423"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922194422-6o5nxos","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922194422-6o5nxos","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922194422-h7g2232","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922194422-h7g2232","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"摘要部分解析"}]},{"ID":"20250922194422-6advt2d","Type":"NodeList","ListData":{},"Properties":{"id":"20250922194422-6advt2d","updated":"20250922194422"},"Children":[{"ID":"20250922194422-ybvm693","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194422-ybvm693","updated":"20250922194422"},"Children":[{"ID":"20250922194422-a744acm","Type":"NodeParagraph","Properties":{"id":"20250922194422-a744acm","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心概念演进"},{"Type":"NodeText","Data":": 摘要清晰地勾勒出从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统计语言模型 (SLM)"},{"Type":"NodeText","Data":" 到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"神经语言模型 (NLM)"},{"Type":"NodeText","Data":"，再到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练语言模型 (PLM)"},{"Type":"NodeText","Data":"，最终演变为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型语言模型 (LLM)"},{"Type":"NodeText","Data":" 的技术脉络。"}]}]},{"ID":"20250922194422-aeir3xq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194422-aeir3xq","updated":"20250922194422"},"Children":[{"ID":"20250922194422-n600qay","Type":"NodeParagraph","Properties":{"id":"20250922194422-n600qay","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM的关键特征"},{"Type":"NodeText","Data":": 强调了LLM与小型PLM的质的区别——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力"},{"Type":"NodeText","Data":" (Emergent Abilities)，特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习"},{"Type":"NodeText","Data":" (in-context learning)。这标志着模型从量变到质变。"}]}]},{"ID":"20250922194422-pk8rb7x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194422-pk8rb7x","updated":"20250922194422"},"Children":[{"ID":"20250922194422-6rhiq6c","Type":"NodeParagraph","Properties":{"id":"20250922194422-6rhiq6c","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT的里程碑意义"},{"Type":"NodeText","Data":": 点明了ChatGPT的推出是LLM发展中的一个关键事件，它极大地推动了LLM进入公众视野并引发了广泛的研究和应用兴趣。"}]}]},{"ID":"20250922194422-gzdmve8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194422-gzdmve8","updated":"20250922194422"},"Children":[{"ID":"20250922194422-15hth4n","Type":"NodeParagraph","Properties":{"id":"20250922194422-15hth4n","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综述的核心内容"},{"Type":"NodeText","Data":": 明确了本文将围绕"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练 (pre-training)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"适配调整 (adaptation tuning)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用 (utilization)"},{"Type":"NodeText","Data":" 和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力评估 (capacity evaluation)"},{"Type":"NodeText","Data":" 这四个核心方面展开，为读者提供了一个清晰的阅读路线图。"}]}]}]},{"ID":"20250922194422-dndieag","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922194422-dndieag","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"引言部分解析"}]},{"ID":"20250922194422-95goqqr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922194422-95goqqr","updated":"20250922194422"},"Children":[{"ID":"20250922194422-32p2fu5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194422-32p2fu5","updated":"20250922194422"},"Children":[{"ID":"20250922194422-jtf5deg","Type":"NodeParagraph","Properties":{"id":"20250922194422-jtf5deg","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言的本质与挑战"},{"Type":"NodeText","Data":": 开篇引用维特根斯坦的名言，强调了语言对于认知世界的重要性，并点出让机器掌握语言是一项根本性的AI挑战。"}]}]},{"ID":"20250922194422-zbtiobl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194422-zbtiobl","updated":"20250922194422"},"Children":[{"ID":"20250922194422-vakdmew","Type":"NodeParagraph","Properties":{"id":"20250922194422-vakdmew","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言建模的发展阶段"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922194422-ze52zva","Type":"NodeList","ListData":{},"Properties":{"id":"20250922194422-ze52zva","updated":"20250922194422"},"Children":[{"ID":"20250922194422-1tvke8p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194422-1tvke8p","updated":"20250922194422"},"Children":[{"ID":"20250922194422-q4laejn","Type":"NodeParagraph","Properties":{"id":"20250922194422-q4laejn","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统计语言模型 (SLM)"},{"Type":"NodeText","Data":": 基于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"马尔可夫假设"},{"Type":"NodeText","Data":"，使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"n-gram"},{"Type":"NodeText","Data":"进行建模。核心问题是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"维度灾难"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据稀疏性"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922194422-js1hnzz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194422-js1hnzz","updated":"20250922194422"},"Children":[{"ID":"20250922194422-wo61v49","Type":"NodeParagraph","Properties":{"id":"20250922194422-wo61v49","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"神经语言模型 (NLM)"},{"Type":"NodeText","Data":": 引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"神经网络"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词的分布式表示（词向量）"},{"Type":"NodeText","Data":"，这是一个里程碑式的进步，因为它能更好地捕捉词与词之间的语义关系。"}]}]}]}]}]}]},{"ID":"20250922194422-163cp1p","Type":"NodeBlockquote","Properties":{"id":"20250922194422-163cp1p","updated":"20250922194422"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922194422-d4uhrs1","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922194422-d4uhrs1","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922194422-d8rssyl","Type":"NodeParagraph","Properties":{"id":"20250922194422-d8rssyl","updated":"20250922194422"},"Children":[{"Type":"NodeText","Data":"第一部分作为文章的开端，起到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提纲挈领"},{"Type":"NodeText","Data":"的作用。"}]},{"ID":"20250922194422-n7qrdxw","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922194422-n7qrdxw","updated":"20250922194422"},"Children":[{"ID":"20250922194422-n7eetyy","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922194422-n7eetyy","updated":"20250922194422"},"Children":[{"ID":"20250922194422-pmgsbcq","Type":"NodeParagraph","Properties":{"id":"20250922194422-pmgsbcq","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"历史视角"},{"Type":"NodeText","Data":": 文章从图灵测试这一AI的“原点”谈起，将语言模型置于一个宏大的历史背景下，并清晰地梳理了从统计方法到神经网络，再到预训练和大规模化的四个发展阶段。这种分阶段的介绍方式，让读者，即使是对该领域不熟悉的，也能迅速建立起一个关于语言模型技术演进的框架。"}]}]},{"ID":"20250922194422-favj1h0","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922194422-favj1h0","updated":"20250922194422"},"Children":[{"ID":"20250922194422-39lvjhe","Type":"NodeParagraph","Properties":{"id":"20250922194422-39lvjhe","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"点明核心突破"},{"Type":"NodeText","Data":": 作者精准地抓住了大型语言模型（LLM）区别于其前身（PLM）的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心差异——“涌现能力”"},{"Type":"NodeText","Data":"。这不仅仅是模型变大了，而是模型的能力发生了质的飞跃。通过强调这一点，文章为后续深入探讨LLM的独特性质（如上下文学习、逐步推理等）奠定了基础。"}]}]},{"ID":"20250922194422-9yykgwy","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922194422-9yykgwy","updated":"20250922194422"},"Children":[{"ID":"20250922194422-472mw99","Type":"NodeParagraph","Properties":{"id":"20250922194422-472mw99","updated":"20250922194422"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确立论述框架"},{"Type":"NodeText","Data":": 摘要和引言的结尾部分明确了本文将要论述的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四个核心主题"},{"Type":"NodeText","Data":"：预训练、适配、利用和评估。这个“四段论”结构非常清晰，为整篇综述搭建了一个稳固的骨架。读者可以预期到，接下来的内容将围绕这四个方面系统地、深入地展开，从而对LLM有一个全面而立体的理解。"}]}]}]},{"ID":"20250922194422-dmud8yw","Type":"NodeParagraph","Properties":{"id":"20250922194422-dmud8yw","updated":"20250922194422"},"Children":[{"Type":"NodeText","Data":"总体而言，第一部分成功地向读者介绍了LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“前世今生”"},{"Type":"NodeText","Data":"，点明了其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命性的意义"},{"Type":"NodeText","Data":"，并清晰地预告了文章的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心结构"},{"Type":"NodeText","Data":"，为后续的详细论述做好了充分的铺垫。"}]}]},{"ID":"20250922194852-y3qvr7h","Type":"NodeParagraph","Properties":{"id":"20250922194852-y3qvr7h","updated":"20250924075604"},"Children":[{"Type":"NodeText","Data":"构建统一的端到端解决方案的各种NLP任务。此外，word2vec被提出来构建一个简化的浅层神经网络，用于学习分布式词语表示，这被证明在各种NLP任务中非常有效。这些研究开创了将语言模型用于表示学习（超越词序建模）的先河，对NLP领域产生了重要影响。"}]},{"ID":"20250922194852-172t64k","Type":"NodeList","ListData":{},"Properties":{"id":"20250922194852-172t64k","updated":"20250924075604"},"Children":[{"ID":"20250922194852-yvz97pd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-yvz97pd","updated":"20250922194852"},"Children":[{"ID":"20250922194852-8k4qbg9","Type":"NodeParagraph","Properties":{"id":"20250922194852-8k4qbg9","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练语言模型（PLM）。"},{"Type":"NodeText","Data":" 作为一项早期的尝试，ELMo 提出通过首先预训练一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"双向LSTM（biLSTM）网络"},{"Type":"NodeText","Data":"（而不是学习固定的词语表示）来捕获"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文感知的词语表示"},{"Type":"NodeText","Data":"，然后根据特定的下游任务对biLSTM网络进行微调。此外，基于具有自注意力机制的高度可并行的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Transformer架构"},{"Type":"NodeText","Data":"，BERT 提出通过在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模未标记语料库"},{"Type":"NodeText","Data":"上使用专门设计的预训练任务来预训练双向语言模型。这些预训练的上下文感知词语表示作为通用的语义特征非常有效，极大地提升了NLP任务的性能标杆。这项研究激发了大量的后续工作，确立了“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练和微调"},{"Type":"NodeText","Data":"”的学习范式。遵循这一范式，大量关于PLM的研究得以发展，引入了不同的架构（例如，GPT-2 和 BART）或改进的预训练策略。在这种范式中，通常需要对PLM进行微调以适应不同的下游任务。"}]}]},{"ID":"20250922194852-km2wodb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-km2wodb","updated":"20250922194852"},"Children":[{"ID":"20250922194852-zwfsn7f","Type":"NodeParagraph","Properties":{"id":"20250922194852-zwfsn7f","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型语言模型（LLM）。"},{"Type":"NodeText","Data":" 研究人员发现，扩展PLM（例如，扩展模型大小或数据大小）通常会带来下游任务模型能力的提升（即，遵循"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"）。"}]}]}]},{"ID":"20250924075820-aag4h9p","Type":"NodeParagraph","Properties":{"id":"20250924075820-aag4h9p","updated":"20250924075820"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250924075819-jm3j0m8.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922194852-pxayk6l","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922194852-pxayk6l","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 1：包含关键词“language model”和“large language model”的arXiv论文累积数量趋势图"}]},{"ID":"20250922194852-1xnbtp5","Type":"NodeParagraph","Properties":{"id":"20250922194852-1xnbtp5","updated":"20250924075604"},"Children":[{"Type":"NodeText","Data":"(a) 查询=“Language Model” (b) 查询=“Large Language Model”\n"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图注："},{"Type":"NodeText","Data":" 分别展示了自2018年6月和2019年10月以来，包含关键词“language model”和“large language model”的arXiv论文的累积数量趋势。统计数据是通过精确匹配查询标题或摘要中的关键词，按月份计算得出的。我们为这两个关键词设置了不同的x轴范围，因为“language model”的探索时间更早。我们标注了与LLM研究进展中的重要里程碑对应的点。在ChatGPT发布后出现了急剧增长：包含“large language model”的arXiv论文的平均日发布量从0.40篇增加到8.58篇（图1(b)）。"}]},{"ID":"20250922194852-dowu8h9","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250922194852-dowu8h9","updated":"20250924075604"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922194852-wgk8th5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922194852-wgk8th5","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922194852-b1bnko2","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922194852-b1bnko2","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图1解析"}]},{"ID":"20250922194852-8vpx0t3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922194852-8vpx0t3","updated":"20250922194852"},"Children":[{"ID":"20250922194852-ylzfvjb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-ylzfvjb","updated":"20250922194852"},"Children":[{"ID":"20250922194852-flmnuua","Type":"NodeParagraph","Properties":{"id":"20250922194852-flmnuua","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(a) “Language Model”趋势"},{"Type":"NodeText","Data":": 这条曲线相对平稳地增长，反映了语言模型作为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续研究领域"},{"Type":"NodeText","Data":"的稳健发展。其中标注的BERT、GPT-1/2等是该领域的重要里程碑，但并未引起爆炸性增长。"}]}]},{"ID":"20250922194852-wvkc8j5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-wvkc8j5","updated":"20250922194852"},"Children":[{"ID":"20250922194852-hhfh3sp","Type":"NodeParagraph","Properties":{"id":"20250922194852-hhfh3sp","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(b) “Large Language Model”趋势"},{"Type":"NodeText","Data":": 这条曲线的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"拐点"},{"Type":"NodeText","Data":"非常明显。在ChatGPT发布之前，关于大型语言模型的研究虽然在增长，但速度相对温和。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT的发布"},{"Type":"NodeText","Data":"（图中标注点）是引爆点，之后相关论文数量"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"呈指数级增长"},{"Type":"NodeText","Data":"，斜率急剧变陡。"}]}]},{"ID":"20250922194852-k1y81b5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-k1y81b5","updated":"20250922194852"},"Children":[{"ID":"20250922194852-a00394a","Type":"NodeParagraph","Properties":{"id":"20250922194852-a00394a","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比分析"},{"Type":"NodeText","Data":": 两图的对比清晰地表明，虽然语言模型研究历史悠久，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“大型”"},{"Type":"NodeText","Data":"语言模型，特别是ChatGPT所代表的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话式大型模型"},{"Type":"NodeText","Data":"，是近年来引爆整个AI领域研究热情的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"催化剂"},{"Type":"NodeText","Data":"。图(b)的急剧增长直观地展示了ChatGPT发布后，学术界对LLM的研究兴趣被"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"彻底点燃"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922194852-ktp8ohx","Type":"NodeParagraph","Properties":{"id":"20250922194852-ktp8ohx","updated":"20250924075604"},"Children":[{"Type":"NodeText","Data":"许多研究探索了通过训练一个更大的PLM（例如，1750亿参数的GPT-3和5400亿参数的PaLM）来挑战性能极限。尽管扩展主要是在模型大小上进行的（具有相似的架构和预训练任务），但这些大规模的PLM表现出与较小的PLM（例如，3.3亿参数的BERT和15亿参数的GPT-2）不同的行为，并显示出在解决一系列复杂任务时的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"惊人能力（称为涌现能力）"},{"Type":"NodeText","Data":"。例如，GPT-3可以通过上下文学习解决少样本任务，而GPT-2则表现不佳。因此，研究界为这些大规模PLM创造了术语“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型语言模型（LLM）"},{"Type":"NodeText","Data":"”，吸引了越来越多的研究关注（见图1）。LLM的一个卓越应用是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT"},{"Type":"NodeText","Data":"，它将GPT系列的LLM应用于对话，展现出与人类惊人的对话能力。我们可以观察到，在ChatGPT发布后，与LLM相关的arXiv论文数量急剧增加（图1）。"}]},{"ID":"20250922194852-18h6ikv","Type":"NodeParagraph","Properties":{"id":"20250922194852-18h6ikv","updated":"20250924075604"},"Children":[{"Type":"NodeText","Data":"如前所述，语言模型并非专为LLM而设的新技术概念，而是随着人工智能几十年的发展而演进的。早期的语言模型主要旨在建模和生成文本数据，而最新的语言模型（例如，GPT-4）则专注于解决复杂任务。从语言建模到任务解决，这是科学思维上的一次重要飞跃，也是理解语言模型研究历史发展的关键。从任务解决的角度看，四代语言模型展现了不同层次的模型能力。在图2中，我们从任务解决能力的角度描述了语言模型的演进过程。最初，统计语言模型主要辅助一些特定任务（例如，检索或语音任务），其中预测或估计的概率可以增强特定任务方法的性能。随后，神经语言模型专注于学习"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务无关的表示（例如，特征）"},{"Type":"NodeText","Data":"，旨在减少人工特征工程的努力。此外，预训练语言模型学习了可以根据下游任务进行优化的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文感知表示"},{"Type":"NodeText","Data":"。对于最新一代的语言模型，LLM通过探索模型能力的规模效应得到增强，可以被视为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用任务解决器"},{"Type":"NodeText","Data":"。总而言之，在演进过程中，语言模型可以解决的任务范围已大大扩展，并且语言模型所能达到的任务性能也得到了显著提升。"}]},{"ID":"20250924081005-gphzh6t","Type":"NodeParagraph","Properties":{"id":"20250924081005-gphzh6t","updated":"20250924081005"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250924081005-dlac9wz.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922194852-xlft53y","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922194852-xlft53y","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 2：从任务解决能力视角看四代语言模型的演进过程"}]},{"ID":"20250922194852-obu2750","Type":"NodeParagraph","Properties":{"id":"20250922194852-obu2750","updated":"20250924075604"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图注："},{"Type":"NodeText","Data":" 从任务解决能力的角度，展示了四代语言模型的演进过程。请注意，每个阶段的时间段可能不是很精确，我们主要是根据每个阶段最具代表性研究的发布日期来设定时间。对于神经语言模型，我们用两项代表性研究的论文标题缩写来命名这两种方法：NPLM（“一种神经概率语言模型”）和NLPS（“自然语言处理（几乎）从零开始”）。由于空间限制，我们没有在此图中列出所有代表性的研究。"}]},{"ID":"20250922194852-ljq5kvd","Type":"NodeBlockquote","Properties":{"fold":"1","id":"20250922194852-ljq5kvd","updated":"20250924075604"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922194852-ymqkv9v","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922194852-ymqkv9v","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922194852-ucwfjl8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922194852-ucwfjl8","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图2解析"}]},{"ID":"20250922194852-ufay8n9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922194852-ufay8n9","updated":"20250922194852"},"Children":[{"ID":"20250922194852-huh3vyt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-huh3vyt","updated":"20250922194852"},"Children":[{"ID":"20250922194852-xm72b4c","Type":"NodeParagraph","Properties":{"id":"20250922194852-xm72b4c","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心演进轴"},{"Type":"NodeText","Data":": 该图以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“任务解决能力”"},{"Type":"NodeText","Data":"为核心线索，清晰地展示了语言模型从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辅助工具"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用问题解决器"},{"Type":"NodeText","Data":"的演变路径。"}]}]},{"ID":"20250922194852-imgw00d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-imgw00d","updated":"20250922194852"},"Children":[{"ID":"20250922194852-r5qvhry","Type":"NodeParagraph","Properties":{"id":"20250922194852-r5qvhry","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四个阶段的角色定位"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922194852-8v5wnnz","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922194852-8v5wnnz","updated":"20250922194852"},"Children":[{"ID":"20250922194852-mym6w5q","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922194852-mym6w5q","updated":"20250922194852"},"Children":[{"ID":"20250922194852-zogulr8","Type":"NodeParagraph","Properties":{"id":"20250922194852-zogulr8","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统计语言模型 (Statistical LM)"},{"Type":"NodeText","Data":": 定位为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“特定任务助手 (Specific task helper)”"},{"Type":"NodeText","Data":"。它不能独立解决问题，而是通过提供概率估计来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辅助"},{"Type":"NodeText","Data":"其他算法（如信息检索）。"}]}]},{"ID":"20250922194852-y2crx5e","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922194852-y2crx5e","updated":"20250922194852"},"Children":[{"ID":"20250922194852-r6l49uy","Type":"NodeParagraph","Properties":{"id":"20250922194852-r6l49uy","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"神经语言模型 (Neural LM)"},{"Type":"NodeText","Data":": 定位为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“任务无关的特征学习器 (Task-agnostic feature learner)”"},{"Type":"NodeText","Data":"。核心贡献是学习"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词的分布式表示"},{"Type":"NodeText","Data":"，为下游任务提供通用的语义特征，减少了人工设计特征的需要。"}]}]},{"ID":"20250922194852-p1ague1","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922194852-p1ague1","updated":"20250922194852"},"Children":[{"ID":"20250922194852-nl203xk","Type":"NodeParagraph","Properties":{"id":"20250922194852-nl203xk","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练语言模型 (Pre-trained LM)"},{"Type":"NodeText","Data":": 定位为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“可迁移的NLP任务解决器 (Transferable NLP task solver)”"},{"Type":"NodeText","Data":"。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“预训练+微调”"},{"Type":"NodeText","Data":"的模式，能够适应并解决各种不同的NLP任务，成为一个通用的任务解决框架。"}]}]},{"ID":"20250922194852-p0zza3u","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922194852-p0zza3u","updated":"20250922194852"},"Children":[{"ID":"20250922194852-xjwnl0f","Type":"NodeParagraph","Properties":{"id":"20250922194852-xjwnl0f","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型语言模型 (LLM)"},{"Type":"NodeText","Data":": 定位为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通用任务解决器 (General-purpose task solver)”"},{"Type":"NodeText","Data":"。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示 (Prompting)"},{"Type":"NodeText","Data":"，它能够直接解决现实世界中的各种复杂任务，几乎不需要或完全不需要微调，更接近通用人工智能的理念。"}]}]}]}]},{"ID":"20250922194852-x694esc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-x694esc","updated":"20250922194852"},"Children":[{"ID":"20250922194852-xnt0qqq","Type":"NodeParagraph","Properties":{"id":"20250922194852-xnt0qqq","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"时间节点"},{"Type":"NodeText","Data":": 图中标注的时间节点（1990s, 2013, 2018, 2020）大致对应了每个阶段的代表性技术（n-gram, word2vec, BERT, GPT-3）的兴起时间，为这个演进过程提供了历史坐标。"}]}]}]},{"ID":"20250922194852-qccnzyv","Type":"NodeParagraph","Properties":{"id":"20250922194852-qccnzyv","updated":"20250922194852"},"Children":[{"Type":"NodeText","Data":"这张图通过一种高度概括且直观的方式，揭示了语言模型研究的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标和范式"},{"Type":"NodeText","Data":"的变迁：从最初的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“为特定任务打辅助”"},{"Type":"NodeText","Data":"，到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“提供通用特征”"},{"Type":"NodeText","Data":"，再到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“适配解决各类任务”"},{"Type":"NodeText","Data":"，最终演变为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“直接解决通用问题”"},{"Type":"NodeText","Data":"。这个演进过程不仅是技术能力的提升，更是AI研究思路的一次次跃迁。"}]}]},{"ID":"20250922194852-8mo5fd2","Type":"NodeParagraph","Properties":{"id":"20250922194852-8mo5fd2","updated":"20250924075604"},"Children":[{"Type":"NodeText","Data":"在现有文献中，PLM已被广泛讨论和综述，而LLM却很少被系统地回顾。为了激发我们的综述，我们首先强调LLM和PLM之间的三个主要区别。首先，LLM展现出一些在之前较小的PLM中可能观察不到的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"惊人的涌现能力"},{"Type":"NodeText","Data":"。这些能力是语言模型在复杂任务上表现的关键，使得AI算法变得前所未有的强大和有效。其次，LLM将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"彻底改变人类开发和使用AI算法的方式"},{"Type":"NodeText","Data":"。与小型PLM不同，访问LLM的主要方式是通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示接口"},{"Type":"NodeText","Data":"（例如，GPT-4 API）。人类必须理解LLM的工作方式，并以LLM能够遵循的方式格式化他们的任务。第三，LLM的开发"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不再明确区分研究和工程"},{"Type":"NodeText","Data":"。训练LLM需要在大规模数据处理和分布式并行训练方面有广泛的实践经验。为了开发有能力的LLM，研究人员必须解决复杂的工程问题，与工程师合作或自己成为工程师。"}]},{"ID":"20250922194852-tbzqe9t","Type":"NodeParagraph","Properties":{"id":"20250922194852-tbzqe9t","updated":"20250924075604"},"Children":[{"Type":"NodeText","Data":"如今，LLM正在对AI社区产生重大影响，ChatGPT和GPT-4的出现引发了对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用人工智能（AGI）"},{"Type":"NodeText","Data":"可能性的重新思考。OpenAI发表了一篇题为“为AGI及其未来规划”的技术文章，讨论了实现AGI的短期和长期计划，最近的一篇论文则认为GPT-4可能被视为AGI系统的早期版本。AI的研究领域正在被LLM的快速进展所"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命"},{"Type":"NodeText","Data":"。在NLP领域，LLM可以在一定程度上充当"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用的语言任务解决器"},{"Type":"NodeText","Data":"，研究范式已转向使用LLM。在IR领域，传统搜索引擎正受到通过AI聊天机器人（即ChatGPT）进行信息检索的新方式的挑战，而新版必应（New Bing）则初步尝试基于LLM来增强搜索结果。在CV领域，研究人员试图开发类似ChatGPT的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉-语言模型"},{"Type":"NodeText","Data":"，以便更好地服务于多模态对话，而GPT-4通过整合视觉信息已支持多模态输入。这股新技术浪潮可能会催生一个基于LLM的繁荣的真实世界应用生态系统。例如，微软365正在被LLM（即Copilot）赋能以自动化办公工作，而OpenAI支持在ChatGPT中使用插件来实现特殊功能。"}]},{"ID":"20250922194852-bt7ohz0","Type":"NodeParagraph","Properties":{"id":"20250922194852-bt7ohz0","updated":"20250924075604"},"Children":[{"Type":"NodeText","Data":"尽管取得了进展和影响，但LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基本原理仍未被很好地探索"},{"Type":"NodeText","Data":"。首先，为什么"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力"},{"Type":"NodeText","Data":"出现在LLM而不是较小的PLM中，这仍然是个谜。作为一个更普遍的问题，目前缺乏对促成LLM卓越能力的关键因素的深入、详细的调查。研究LLM何时以及如何获得这些能力非常重要。尽管对这个问题有一些有意义的讨论，但仍需要更多有原则的研究来揭开LLM的“秘密”。其次，研究界很难训练出有能力的LLM。由于对计算资源的巨大需求，进行重复性的、消融性的研究以调查各种训练策略的效果是非常昂贵的。实际上，LLM主要由工业界训练，其中许多重要的训练细节（例如，数据收集和清洗）并未向公众披露。第三，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将LLM与人类价值观或偏好对齐"},{"Type":"NodeText","Data":"是具有挑战性的。尽管LLM能力强大，但它们也可能产生有毒、虚构或有害的内容。这需要有效且高效的控制方法来消除使用LLM的潜在风险。"}]},{"ID":"20250922194852-mcl0ksn","Type":"NodeParagraph","Properties":{"id":"20250922194852-mcl0ksn","updated":"20250924075604"},"Children":[{"Type":"NodeText","Data":"面对机遇与挑战，LLM的研发需要更多的关注。为了提供对LLM的基本理解，本综述"}]},{"ID":"20250922194852-avqaazx","Type":"NodeBlockquote","Properties":{"id":"20250922194852-avqaazx","updated":"20250924075604"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922194852-om2gudl","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922194852-om2gudl","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922194852-w0renkf","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922194852-w0renkf","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM与PLM的核心区别"}]},{"ID":"20250922194852-z0ogoj3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922194852-z0ogoj3","updated":"20250922194852"},"Children":[{"ID":"20250922194852-52kyjdi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-52kyjdi","updated":"20250922194852"},"Children":[{"ID":"20250922194852-b41m2jr","Type":"NodeParagraph","Properties":{"id":"20250922194852-b41m2jr","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力 (Emergent Abilities)"},{"Type":"NodeText","Data":": 这是LLM最本质的特征。当模型规模足够大时，会产生质变，出现小模型不具备的能力。"}]}]},{"ID":"20250922194852-33q0xrf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-33q0xrf","updated":"20250922194852"},"Children":[{"ID":"20250922194852-z7x3bue","Type":"NodeParagraph","Properties":{"id":"20250922194852-z7x3bue","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交互方式的变革 (Revolutionizing Interaction)"},{"Type":"NodeText","Data":": 从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调 (fine-tuning)"},{"Type":"NodeText","Data":" 转向"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示 (prompting)"},{"Type":"NodeText","Data":"。用户不再需要成为模型训练专家，而是通过自然语言与模型交互，这极大地降低了AI的使用门槛。"}]}]},{"ID":"20250922194852-zsm2xoh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-zsm2xoh","updated":"20250922194852"},"Children":[{"ID":"20250922194852-jzp6zaf","Type":"NodeParagraph","Properties":{"id":"20250922194852-jzp6zaf","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"研究与工程的融合 (Blurring Research and Engineering)"},{"Type":"NodeText","Data":": 训练LLM本身就是一个巨大的系统工程，涉及数据处理、分布式计算等，单纯的算法研究已不足够，必须与工程实践紧密结合。"}]}]}]},{"ID":"20250922194852-244t0tk","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922194852-244t0tk","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM的深远影响与挑战"}]},{"ID":"20250922194852-unvyzam","Type":"NodeList","ListData":{},"Properties":{"id":"20250922194852-unvyzam","updated":"20250922194852"},"Children":[{"ID":"20250922194852-ps6ksx3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-ps6ksx3","updated":"20250922194852"},"Children":[{"ID":"20250922194852-cx4bgwh","Type":"NodeParagraph","Properties":{"id":"20250922194852-cx4bgwh","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重塑AI研究范式"},{"Type":"NodeText","Data":": LLM正在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“革命”"},{"Type":"NodeText","Data":"多个AI子领域，如自然语言处理（NLP）、信息检索（IR）和计算机视觉（CV），推动它们向"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更通用、更智能"},{"Type":"NodeText","Data":"的方向发展。"}]}]},{"ID":"20250922194852-sszm597","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-sszm597","updated":"20250922194852"},"Children":[{"ID":"20250922194852-xktphxi","Type":"NodeParagraph","Properties":{"id":"20250922194852-xktphxi","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通往AGI的曙光"},{"Type":"NodeText","Data":": ChatGPT和GPT-4的强大能力让人们重新审视"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用人工智能（AGI）"},{"Type":"NodeText","Data":" 的可能性，这标志着AI研究进入了一个新的阶段。"}]}]},{"ID":"20250922194852-qbodd3e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922194852-qbodd3e","updated":"20250922194852"},"Children":[{"ID":"20250922194852-zhellnh","Type":"NodeParagraph","Properties":{"id":"20250922194852-zhellnh","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心挑战"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922194852-8xpnaen","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922194852-8xpnaen","updated":"20250922194852"},"Children":[{"ID":"20250922194852-igro5fs","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922194852-igro5fs","updated":"20250922194852"},"Children":[{"ID":"20250922194852-21t5qea","Type":"NodeParagraph","Properties":{"id":"20250922194852-21t5qea","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“涌现能力”的奥秘"},{"Type":"NodeText","Data":": 为什么以及如何产生这些能力，其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基本原理"},{"Type":"NodeText","Data":"尚不清楚，这是当前研究的核心谜题之一。"}]}]},{"ID":"20250922194852-4sj0064","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922194852-4sj0064","updated":"20250922194852"},"Children":[{"ID":"20250922194852-gsz7pom","Type":"NodeParagraph","Properties":{"id":"20250922194852-gsz7pom","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高昂的训练成本"},{"Type":"NodeText","Data":": 巨大的计算资源需求使得LLM的训练主要由大型科技公司主导，这限制了学术界的研究，并导致训练过程"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺乏透明度"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922194852-sxhvbc9","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922194852-sxhvbc9","updated":"20250922194852"},"Children":[{"ID":"20250922194852-y25tkd9","Type":"NodeParagraph","Properties":{"id":"20250922194852-y25tkd9","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐难题 (Alignment Problem)"},{"Type":"NodeText","Data":": 如何确保LLM的行为符合人类的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"价值观"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"偏好"},{"Type":"NodeText","Data":"，避免产生有害、虚假的内容，是一个既关键又困难的挑战。"}]}]}]}]}]}]},{"ID":"20250922194852-44r81kc","Type":"NodeBlockquote","Properties":{"id":"20250922194852-44r81kc","updated":"20250922194852"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922194852-egw614j","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922194852-egw614j","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922194852-schphsz","Type":"NodeParagraph","Properties":{"id":"20250922194852-schphsz","updated":"20250922194852"},"Children":[{"Type":"NodeText","Data":"第二部分是对引言的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深化和扩展"},{"Type":"NodeText","Data":"，它从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术演进"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心特征"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深远影响"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重大挑战"},{"Type":"NodeText","Data":"四个维度，为读者构建了一个关于大型语言模型（LLM）的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"立体认知框架"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922194852-dqshrfs","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922194852-dqshrfs","updated":"20250922194852"},"Children":[{"ID":"20250922194852-e1u879s","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922194852-e1u879s","updated":"20250922194852"},"Children":[{"ID":"20250922194852-dmlpmzp","Type":"NodeParagraph","Properties":{"id":"20250922194852-dmlpmzp","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术脉络的细化"},{"Type":"NodeText","Data":": 在引言的基础上，本部分更详细地追溯了从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"word2vec"},{"Type":"NodeText","Data":"的表示学习，到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BERT"},{"Type":"NodeText","Data":"确立的“预训练+微调”范式，再到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3"},{"Type":"NodeText","Data":"通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"实现能力跃迁的完整路径。这一梳理不仅是技术的罗列，更是研究"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"范式（paradigm）"},{"Type":"NodeText","Data":" 变迁的展现。"}]}]},{"ID":"20250922194852-fhv57ky","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922194852-fhv57ky","updated":"20250922194852"},"Children":[{"ID":"20250922194852-n7sacbg","Type":"NodeParagraph","Properties":{"id":"20250922194852-n7sacbg","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心概念的具象化"},{"Type":"NodeText","Data":": 通过图1和图2，文章将抽象的概念变得直观。图1用数据揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT发布"},{"Type":"NodeText","Data":"作为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"引爆点"},{"Type":"NodeText","Data":"，如何点燃了整个学术界对LLM的研究热情。图2则以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“任务解决能力”"},{"Type":"NodeText","Data":"为主线，将语言模型的四代演进描绘成一个从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“辅助工具”"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通用问题解决器”"},{"Type":"NodeText","Data":"的清晰进化阶梯。这种图文并茂的方式极大地增强了内容的可理解性。"}]}]},{"ID":"20250922194852-zbv1324","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922194852-zbv1324","updated":"20250922194852"},"Children":[{"ID":"20250922194852-leuofbg","Type":"NodeParagraph","Properties":{"id":"20250922194852-leuofbg","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"影响的广度与深度"},{"Type":"NodeText","Data":": 文章强调LLM的影响是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命性"},{"Type":"NodeText","Data":"的，它不仅改变了AI社区内部的研究方向（NLP, IR, CV），更重要的是，它正在改变"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人与AI的交互方式"},{"Type":"NodeText","Data":"，并催生了全新的应用生态（如Copilot, ChatGPT插件）。同时，它将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用人工智能（AGI）"},{"Type":"NodeText","Data":" 这一终极目标重新拉回了现实讨论的中心。"}]}]},{"ID":"20250922194852-ly7swl7","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922194852-ly7swl7","updated":"20250922194852"},"Children":[{"ID":"20250922194852-zd1030e","Type":"NodeParagraph","Properties":{"id":"20250922194852-zd1030e","updated":"20250922194852"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"挑战的根本性"},{"Type":"NodeText","Data":": 作者没有回避LLM面临的深刻问题。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力的原理之谜"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高昂的训练成本与透明度缺失"},{"Type":"NodeText","Data":"、以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与人类价值观的对齐难题"},{"Type":"NodeText","Data":"，这三个挑战直指LLM发展的核心瓶颈。这展现了综述的客观性和深度，为后续的研究指明了最关键的方向。"}]}]}]},{"ID":"20250922194852-qzue8sl","Type":"NodeParagraph","Properties":{"id":"20250922194852-qzue8sl","updated":"20250922194852"},"Children":[{"Type":"NodeText","Data":"总结而言，第二部分不仅是对LLM是什么的解释，更是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“为什么LLM如此重要”"},{"Type":"NodeText","Data":"以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“LLM未来将走向何方（面临何种挑战）”"},{"Type":"NodeText","Data":"的深刻洞察。它成功地将技术细节、宏观影响和未来挑战融为一体，为读者提供了一个全面而富有启发性的概述。"}]}]},{"ID":"20250922200355-f8k40t0","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200355-f8k40t0","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2 OVERVIEW (概述)"}]},{"ID":"20250922200355-qkjsap8","Type":"NodeParagraph","Properties":{"id":"20250922200355-qkjsap8","updated":"20250922200358"},"Children":[{"Type":"NodeText","Data":"在本节中，我们对LLM的背景进行概述，然后总结GPT系列模型的技术演进。"}]},{"ID":"20250922200355-ukmk4w9","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200355-ukmk4w9","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.1 Background for LLMs (LLM的背景)"}]},{"ID":"20250922200355-axcvezp","Type":"NodeParagraph","Properties":{"id":"20250922200355-axcvezp","updated":"20250922200358"},"Children":[{"Type":"NodeText","Data":"通常，大型语言模型（LLM）指的是包含"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数千亿（或更多）参数"},{"Type":"NodeText","Data":"的Transformer语言模型，这些模型在海量文本数据上进行训练，例如GPT-3、PaLM、Galactica和LLaMA。LLM展现出强大的理解自然语言和（通过文本生成）解决复杂任务的能力。为了快速理解LLM的工作原理，本部分将介绍LLM的基础背景，包括规模法则、涌现能力和关键技术。"}]},{"ID":"20250922200355-m8ei4b7","Type":"NodeParagraph","Properties":{"id":"20250922200355-m8ei4b7","updated":"20250922200358"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Formulation of Scaling Laws for LLMs (LLM的规模法则公式)."},{"Type":"NodeText","Data":" 当前，LLM主要基于Transformer架构构建，其中多头注意力层以非常深的方式堆叠在神经网络中。现有的LLM采用了与小型语言模型相似的Transformer架构和预训练目标（例如，语言建模）。然而，LLM在模型大小、数据大小和总计算量上都进行了数量级的扩展。大量研究表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩展"},{"Type":"NodeText","Data":"可以极大地提升LLM的模型能力。因此，建立一种定量方法来描述规模效应是非常有用的。接下来，我们介绍两种代表性的Transformer语言模型规模法则。"}]},{"ID":"20250922200355-wiwrikk","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-wiwrikk","updated":"20250922200358"},"Children":[{"ID":"20250922200355-7r2kzzk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-7r2kzzk","updated":"20250922200355"},"Children":[{"ID":"20250922200355-61n822n","Type":"NodeParagraph","Properties":{"id":"20250922200355-61n822n","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"KM规模法则"},{"Type":"NodeText","Data":". 2020年，Kaplan等人（OpenAI团队）首次提出，将模型性能与三个主要因素——即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型大小"},{"Type":"NodeText","Data":" ("},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"N"},{"Type":"NodeText","Data":")、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据集大小"},{"Type":"NodeText","Data":" ("},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"D"},{"Type":"NodeText","Data":") 和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练计算量"},{"Type":"NodeText","Data":" ("},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"C"},{"Type":"NodeText","Data":")——之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幂律关系"},{"Type":"NodeText","Data":"进行建模。给定一个计算预算"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"c"},{"Type":"NodeText","Data":"，他们根据经验提出了三个基本的规模法则公式："}]},{"ID":"20250922200355-u43gexb","Type":"NodeParagraph","Properties":{"id":"20250922200355-u43gexb","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L(N) = (\\frac{N_c}{N})^{\\alpha_N}, \\alpha_N \\sim 0.076, N_c \\sim 8.8 \\times 10^{13}"},{"Type":"NodeText","Data":" (1)"}]},{"ID":"20250922200355-lfg8ure","Type":"NodeParagraph","Properties":{"id":"20250922200355-lfg8ure","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L(D) = (\\frac{D_c}{D})^{\\alpha_D}, \\alpha_D \\sim 0.095, D_c \\sim 5.4 \\times 10^{13}"}]},{"ID":"20250922200355-uxjniox","Type":"NodeParagraph","Properties":{"id":"20250922200355-uxjniox","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L(C) = (\\frac{C_c}{C})^{\\alpha_C}, \\alpha_C \\sim 0.050, C_c \\sim 3.1 \\times 10^{8}"}]},{"ID":"20250922200355-8duex0o","Type":"NodeParagraph","Properties":{"id":"20250922200355-8duex0o","updated":"20250922200355"},"Children":[{"Type":"NodeText","Data":"其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L(\\cdot)"},{"Type":"NodeText","Data":" 表示以nats为单位的交叉熵损失，OpenAI的一项后续研究表明，语言建模损失可以分解为两部分，即可归约损失（对真实分布和模型分布之间KL散度的估计）和不可归约损失（真实数据分布的熵）。这三条法则是通过在不同数据大小（2200万到230亿词元）、模型大小（768到15亿非嵌入参数）和训练计算量下，基于一些假设（例如，对一个因素的分析不应受到其他两个因素的瓶颈限制）拟合模型性能得出的。他们发现，模型性能与这三个因素有很强的依赖关系。"}]}]},{"ID":"20250922200355-mjz55ne","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-mjz55ne","updated":"20250922200355"},"Children":[{"ID":"20250922200355-5jy0346","Type":"NodeParagraph","Properties":{"id":"20250922200355-5jy0346","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Chinchilla规模法则。"},{"Type":"NodeText","Data":" 作为另一项代表性研究，Hoffmann等人（Google DeepMind团队）提出了一种替代形式的规模法则，用于指导LLM的计算最优训练。他们通过在更大范围的模型大小（7000万到160亿）和数据大小（50亿到5000亿词元）上进行严格实验，拟合出了一个相似但系数不同的规模法则，如下所示："}]},{"ID":"20250922200355-05mqmm5","Type":"NodeParagraph","Properties":{"id":"20250922200355-05mqmm5","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L(N, D) = E + \\frac{A}{N^\\alpha} + \\frac{B}{D^\\beta}"},{"Type":"NodeText","Data":" (2)"}]},{"ID":"20250922200355-3pbufks","Type":"NodeParagraph","Properties":{"id":"20250922200355-3pbufks","updated":"20250922200355"},"Children":[{"Type":"NodeText","Data":"其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"E = 1.69, A = 406.4, B = 410.7, \\alpha = 0.34"},{"Type":"NodeText","Data":" 且 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\beta = 0.28"},{"Type":"NodeText","Data":"。通过在约束条件 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"C \\approx 6ND"},{"Type":"NodeText","Data":" 下优化损失函数 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L(N, D)"},{"Type":"NodeText","Data":"，他们证明了计算预算在模型大小和数据大小上的最优分配可以推导如下："}]},{"ID":"20250922200355-v3dz5ts","Type":"NodeParagraph","Properties":{"id":"20250922200355-v3dz5ts","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"N_{opt}(C) = G(\\frac{C}{6})^a, D_{opt}(C) = G^{-1}(\\frac{C}{6})^b"},{"Type":"NodeText","Data":" (3)"}]},{"ID":"20250922200355-rl5yhrd","Type":"NodeParagraph","Properties":{"id":"20250922200355-rl5yhrd","updated":"20250922200355"},"Children":[{"Type":"NodeText","Data":"其中 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"a = \\frac{\\alpha}{\\alpha+\\beta}, b = \\frac{\\beta}{\\alpha+\\beta}"},{"Type":"NodeText","Data":" 并且 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"G"},{"Type":"NodeText","Data":" 是一个可以通过 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"A, B, \\alpha"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\beta"},{"Type":"NodeText","Data":" 计算出的缩放系数。"}]}]}]},{"ID":"20250922200355-ri0hpp6","Type":"NodeBlockquote","Properties":{"id":"20250922200355-ri0hpp6","updated":"20250922200358"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922200355-8wco0sb","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200355-8wco0sb","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922200355-17iplpd","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200355-17iplpd","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则的核心思想"}]},{"ID":"20250922200355-0vhlqv3","Type":"NodeParagraph","Properties":{"id":"20250922200355-0vhlqv3","updated":"20250922200355"},"Children":[{"Type":"NodeText","Data":"规模法则（Scaling Laws）试图回答一个核心问题："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在计算资源有限的情况下，如何最有效地分配资源（用于增加模型大小 vs. 增加数据量）以获得最佳性能？"}]},{"ID":"20250922200355-7rb6zrm","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-7rb6zrm","updated":"20250922200355"},"Children":[{"ID":"20250922200355-ypfwf29","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-ypfwf29","updated":"20250922200355"},"Children":[{"ID":"20250922200355-pl4qhry","Type":"NodeParagraph","Properties":{"id":"20250922200355-pl4qhry","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幂律关系"},{"Type":"NodeText","Data":": 核心发现是，模型的性能（通常用损失函数Loss来衡量）与模型大小（N）、数据大小（D）和计算量（C）之间存在着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测的幂律关系"},{"Type":"NodeText","Data":"。这意味着，性能的提升是平滑且可预测的，而不是随机的。"}]}]}]},{"ID":"20250922200355-hgl3il4","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200355-hgl3il4","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两种规模法则的对比与启示"}]},{"ID":"20250922200355-edgssyf","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922200355-edgssyf","updated":"20250922200355"},"Children":[{"ID":"20250922200355-jn4ndal","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922200355-jn4ndal","updated":"20250922200355"},"Children":[{"ID":"20250922200355-nz4mitg","Type":"NodeParagraph","Properties":{"id":"20250922200355-nz4mitg","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"KM规模法则 (OpenAI)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200355-u4k6idn","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-u4k6idn","updated":"20250922200355"},"Children":[{"ID":"20250922200355-pgzadn1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-pgzadn1","updated":"20250922200355"},"Children":[{"ID":"20250922200355-8u6s73y","Type":"NodeParagraph","Properties":{"id":"20250922200355-8u6s73y","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"公式解读"},{"Type":"NodeText","Data":": 公式(1)分别建立了损失L与N, D, C的独立关系。它的核心结论是，为了降低损失，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增加模型大小（N）比增加数据大小（D）更有效"},{"Type":"NodeText","Data":"（因为N的幂指数 "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\alpha_N"},{"Type":"NodeText","Data":" 较小，意味着损失随N的增加下降得更快，但这里的解读可能需要更仔细地审视原文的推导。更直接的解读是，给定一定的计算预算，KM法则倾向于分配更多的预算给模型大小）。"}]}]}]}]},{"ID":"20250922200355-f71q7wf","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922200355-f71q7wf","updated":"20250922200355"},"Children":[{"ID":"20250922200355-stvgsp2","Type":"NodeParagraph","Properties":{"id":"20250922200355-stvgsp2","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Chinchilla规模法则 (DeepMind)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200355-jg2w4t1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-jg2w4t1","updated":"20250922200355"},"Children":[{"ID":"20250922200355-iipmo7g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-iipmo7g","updated":"20250922200355"},"Children":[{"ID":"20250922200355-al07fv8","Type":"NodeParagraph","Properties":{"id":"20250922200355-al07fv8","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"公式解读"},{"Type":"NodeText","Data":": 公式(2)将N和D放在一个统一的公式中，更全面地描述了它们与损失L的关系。"}]}]},{"ID":"20250922200355-yuprgui","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-yuprgui","updated":"20250922200355"},"Children":[{"ID":"20250922200355-d5qu708","Type":"NodeParagraph","Properties":{"id":"20250922200355-d5qu708","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心修正"},{"Type":"NodeText","Data":": 通过公式(3)得出了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命性的结论"},{"Type":"NodeText","Data":"：为了达到计算最优，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型大小（N）和数据大小（D）应该按比例同步增长"},{"Type":"NodeText","Data":"。简单来说，如果你想把模型参数量加倍，那么你的训练数据量也应该差不多加倍。这修正了早期“模型越大越好”的简单认知。"}]}]}]}]}]},{"ID":"20250922200355-mt1vgfj","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200355-mt1vgfj","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实际意义"}]},{"ID":"20250922200355-sqidtz6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-sqidtz6","updated":"20250922200355"},"Children":[{"ID":"20250922200355-iqmayhc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-iqmayhc","updated":"20250922200355"},"Children":[{"ID":"20250922200355-glqdpud","Type":"NodeParagraph","Properties":{"id":"20250922200355-glqdpud","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指导模型训练"},{"Type":"NodeText","Data":": Chinchilla规模法则为训练大型语言模型提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“配方”"},{"Type":"NodeText","Data":"。例如，它指出许多早期的大模型（如GPT-3）其实是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“训练不足”"},{"Type":"NodeText","Data":"的——它们的模型参数量相对于其训练数据量来说太大了。如果用相同的计算预算，但是训练一个更小的模型，并使用更多的数据，效果会更好。"}]}]},{"ID":"20250922200355-gy5u5qn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-gy5u5qn","updated":"20250922200355"},"Children":[{"ID":"20250922200355-qadw30h","Type":"NodeParagraph","Properties":{"id":"20250922200355-qadw30h","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测性"},{"Type":"NodeText","Data":": 规模法则使得训练大型模型的过程变得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测"},{"Type":"NodeText","Data":"。研究人员可以通过训练一系列小模型来拟合规模曲线，从而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预测"},{"Type":"NodeText","Data":"出一个更大模型在训练完成后的性能，这有助于在耗费巨大资源之前评估训练计划的可行性。"}]}]}]}]},{"ID":"20250922200355-gxu85s7","Type":"NodeParagraph","Properties":{"id":"20250922200355-gxu85s7","updated":"20250922200358"},"Children":[{"Type":"NodeText","Data":"在给定的计算预算增加的情况下，KM规模法则倾向于将更大的预算分配给模型大小而不是数据大小，而Chinchilla规模法则则认为这两个大小应该"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以相等的比例增加"},{"Type":"NodeText","Data":"，即方程(3)中的"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"a"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"b"},{"Type":"NodeText","Data":"具有相似的值。"}]},{"ID":"20250922200355-5jdus5k","Type":"NodeParagraph","Properties":{"id":"20250922200355-5jdus5k","updated":"20250922200358"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Discussion on Scaling Laws (关于规模法则的讨论)."},{"Type":"NodeText","Data":" 在介绍了公式之后，我们继续从以下两个方面讨论规模法则，以增强对其的理解："}]},{"ID":"20250922200355-i9fuwc6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-i9fuwc6","updated":"20250922200358"},"Children":[{"ID":"20250922200355-1cmqd8k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-1cmqd8k","updated":"20250922200355"},"Children":[{"ID":"20250922200355-dg1pidd","Type":"NodeParagraph","Properties":{"id":"20250922200355-dg1pidd","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测的扩展 (Predictable scaling)."},{"Type":"NodeText","Data":" 在实践中，规模法则可用于指导LLM的训练，并且已被证明可以基于小模型的性能可靠地估计大模型的性能，这被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测的扩展"},{"Type":"NodeText","Data":"。可预测扩展对训练LLM的好处主要是双重的。首先，对于大型模型，严格地检验各种训练技巧或变体是不可行的，如果从小模型中获得的经验也能应用于大型模型，那将非常有帮助。例如，可以训练小型代理模型来为大型模型找到数据混合的最佳方案。其次，训练大型模型需要很长时间，常常会遇到训练损失飙升等问题，规模法则可用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"监控LLM的训练状态"},{"Type":"NodeText","Data":"，例如，及早发现异常性能。尽管规模法则描述了性能增加（或损失减少）的平滑趋势，但它也表明随着模型扩展，可能会出现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"收益递减"},{"Type":"NodeText","Data":"。OpenAI团队的一项实证研究表明，即使接近收益递减点（即接近不可归约损失），表示质量或语义内容仍然可以有效提升。这一发现表明，训练大型模型对于提升下游任务的性能是有前景的。为了进一步探索规模效应，一个潜在的问题是，可用于训练LLM的数据量实际上是有限的。随着模型规模的不断增加，公共文本数据很快将被LLM“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"耗尽"},{"Type":"NodeText","Data":"”。因此，研究规模法则如何应用于数据受限的情况将很有意义，在这种情况下，数据重复或增强可能有助于缓解数据稀``。"}]}]},{"ID":"20250922200355-dvuuduf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-dvuuduf","updated":"20250922200355"},"Children":[{"ID":"20250922200355-hzbi5im","Type":"NodeParagraph","Properties":{"id":"20250922200355-hzbi5im","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务级别的可预测性 (Task-level predictability)."},{"Type":"NodeText","Data":" 现有的规模法则研究大多是根据语言建模损失（例如，以nats为单位的每个词元的交叉熵损失）进行的，而在实践中，我们更关心LLM在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实际任务上的性能"},{"Type":"NodeText","Data":"。因此，一个基本问题是，语言建模损失的减少如何转化为任务性能的提升。直观地说，语言建模损失较小的模型在下游任务中往往会产生更好的性能，因为语言建模损失可以被视为模型整体能力的一个通用度量。GPT-4已经报告说，一些能力（例如，编码能力）可以通过规模法则准确预测。尽管如此，读者应该意识到，语言建模损失的直接减少"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并不总是"},{"Type":"NodeText","Data":"表示下游任务模型性能的提升。特别地，对于某些任务，会出现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逆规模扩展（inverse scaling）"},{"Type":"NodeText","Data":" 的现象，即随着语言建模损失的减少，任务性能反而变得更差。总的来说，探索和描述任务级别的规模法则更为困难，因为它可能还依赖于任务相关的信息（任务指标、任务难度等）。此外，某些能力（例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习"},{"Type":"NodeText","Data":"）根据规模法则是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不可预测"},{"Type":"NodeText","Data":"的，只有当模型大小超过一定水平时才能观察到（如下文所讨论）。"}]}]}]},{"ID":"20250922200355-ck51r7u","Type":"NodeParagraph","Properties":{"id":"20250922200355-ck51r7u","updated":"20250922200358"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Emergent Abilities of LLMs (LLM的涌现能力)."},{"Type":"NodeText","Data":" 在文献中，LLM的涌现能力被正式定义为“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在小模型中不存在但在大模型中出现的能力"},{"Type":"NodeText","Data":"”，这是区分LLM与以往PLM的最显著特征之一。它进一步引入了一个显著的特点，即当涌现能力出现时：当规模达到一定水平时，性能会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"显著高于随机水平"},{"Type":"NodeText","Data":"。通过类比，这种涌现模式与物理学中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相变现象"},{"Type":"NodeText","Data":"有密切联系。原则上，涌现能力可以与某些复杂任务相关联，但我们更关心的是可以应用于解决各种任务的通用能力。在这里，我们简要介绍LLM的三种典型涌现能力以及拥有这种能力的代表性模型。"}]},{"ID":"20250922200355-brywko9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-brywko9","updated":"20250922200358"},"Children":[{"ID":"20250922200355-xpkforw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-xpkforw","updated":"20250922200355"},"Children":[{"ID":"20250922200355-uf8o8rw","Type":"NodeParagraph","Properties":{"id":"20250922200355-uf8o8rw","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (In-context learning)."},{"Type":"NodeText","Data":" 上下文学习（ICL）能力由GPT-3正式引入：假设语言模型已获得自然语言指令和/或若干任务演示，它可以通过完成输入文本的词序列来为测试实例生成预期的输出，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无需额外的训练或梯度更新"},{"Type":"NodeText","Data":"。在GPT系列模型中，175B的GPT-3模型普遍展现出强大的ICL能力，但GPT-1和GPT-2模型则没有。这种能力也依赖于特定的下游任务。例如，ICL能力可以在算术任务（例如，3位数加减法）上为13B的GPT-3模型涌现，但175B的GPT-3在波斯语问答任务上甚至表现不佳。"}]}]},{"ID":"20250922200355-1lg2p86","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-1lg2p86","updated":"20250922200355"},"Children":[{"ID":"20250922200355-gmvpt1d","Type":"NodeParagraph","Properties":{"id":"20250922200355-gmvpt1d","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令遵循 (Instruction following)."},{"Type":"NodeText","Data":" 通过使用自然语言描述格式化的多任务数据集混合进行微调（称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"），LLM被证明在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"未见过的、同样以指令形式描述的任务"},{"Type":"NodeText","Data":"上表现良好。通过指令微调，LLM能够在不使用明确示例的情况下遵循新任务的指令，从而具有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改进的泛化能力"},{"Type":"NodeText","Data":"。根据的实验，经过指令微调的LaMDA-PT在模型大小达到68B时，在未见任务上的表现开始显著优于未经微调的模型，但对于8B或更小模型则不然。最近的一项研究发现，PaLM在四个评估基准（即MMLU, BBH, TyDiQA和MGSM）的各种任务上表现良好，至少需要62B的模型大小，尽管对于某些特定任务（例如，MMLU），更小的模型可能就足够了。"}]}]},{"ID":"20250922200355-ui5juz8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-ui5juz8","updated":"20250922200355"},"Children":[{"ID":"20250922200355-ryfmehv","Type":"NodeParagraph","Properties":{"id":"20250922200355-ryfmehv","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逐步推理 (Step-by-step reasoning)."},{"Type":"NodeText","Data":" 对于小型语言模型，通常很难解决涉及"}]}]}]},{"ID":"20250922200355-pc5parw","Type":"NodeBlockquote","Properties":{"id":"20250922200355-pc5parw","updated":"20250922200358"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922200355-88sdtck","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200355-88sdtck","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922200355-7hjcyov","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200355-7hjcyov","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关于规模法则的深入讨论"}]},{"ID":"20250922200355-7q75338","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-7q75338","updated":"20250922200355"},"Children":[{"ID":"20250922200355-ph76spc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-ph76spc","updated":"20250922200355"},"Children":[{"ID":"20250922200355-wv7mhi4","Type":"NodeParagraph","Properties":{"id":"20250922200355-wv7mhi4","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测性与收益递减"},{"Type":"NodeText","Data":": 作者指出了规模法则的两个核心特点。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测性"},{"Type":"NodeText","Data":"是其巨大价值所在，它让昂贵的LLM训练变得有章可循。但同时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"收益递减"},{"Type":"NodeText","Data":"也是一个无法回避的现实，这意味着无限扩大规模并不总是最高效的策略。"}]}]},{"ID":"20250922200355-4uhf30q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-4uhf30q","updated":"20250922200355"},"Children":[{"ID":"20250922200355-9fcfczv","Type":"NodeParagraph","Properties":{"id":"20250922200355-9fcfczv","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据瓶颈"},{"Type":"NodeText","Data":": 一个非常现实的问题被提出——高质量的训练数据是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有限"},{"Type":"NodeText","Data":"的。当模型规模大到一定程度，可能会出现“无米下锅”的窘境，这为“数据工程”（如数据增强、数据复用）的研究提供了动力。"}]}]},{"ID":"20250922200355-elr2opw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-elr2opw","updated":"20250922200355"},"Children":[{"ID":"20250922200355-8168z8n","Type":"NodeParagraph","Properties":{"id":"20250922200355-8168z8n","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务级可预测性的挑战"},{"Type":"NodeText","Data":": 这是对规模法则局限性的深刻洞察。语言模型损失的降低（模型更会“说话”）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不一定"},{"Type":"NodeText","Data":"等同于解决实际问题能力的提升。特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“逆规模扩展”"},{"Type":"NodeText","Data":"现象（模型越大，在某个任务上表现越差），揭示了我们对LLM能力的理解仍有盲区。这说明，我们需要超越单一的语言模型损失，发展更多维度的评估指标。"}]}]}]},{"ID":"20250922200355-gqjsl9z","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200355-gqjsl9z","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力——LLM的“魔法”"}]},{"ID":"20250922200355-h29r90l","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-h29r90l","updated":"20250922200355"},"Children":[{"ID":"20250922200355-0qnlx4a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-0qnlx4a","updated":"20250922200355"},"Children":[{"ID":"20250922200355-7aefvdr","Type":"NodeParagraph","Properties":{"id":"20250922200355-7aefvdr","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定义与特征"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“涌现能力”"},{"Type":"NodeText","Data":" 是LLM区别于小模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质变"},{"Type":"NodeText","Data":"标志。它不是平滑提升的，而是当模型规模跨过某个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“临界点”"},{"Type":"NodeText","Data":"后，性能突然"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“相变”"},{"Type":"NodeText","Data":"式地、显著地超过随机猜测水平。这解释了为什么LLM看起来如此“智能”。"}]}]},{"ID":"20250922200355-y7vpwlc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-y7vpwlc","updated":"20250922200355"},"Children":[{"ID":"20250922200355-ntz9914","Type":"NodeParagraph","Properties":{"id":"20250922200355-ntz9914","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三种典型的涌现能力"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200355-b02pxaq","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922200355-b02pxaq","updated":"20250922200355"},"Children":[{"ID":"20250922200355-r0rfc1r","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922200355-r0rfc1r","updated":"20250922200355"},"Children":[{"ID":"20250922200355-scuov4k","Type":"NodeParagraph","Properties":{"id":"20250922200355-scuov4k","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (In-context learning, ICL)"},{"Type":"NodeText","Data":": 这是LLM最神奇的能力之一。它能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在不进行任何参数更新的情况下，仅通过几个示例就学会一个新任务"},{"Type":"NodeText","Data":"。这颠覆了传统的“训练-微调”范式。"}]}]},{"ID":"20250922200355-3urup39","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922200355-3urup39","updated":"20250922200355"},"Children":[{"ID":"20250922200355-jrzdieb","Type":"NodeParagraph","Properties":{"id":"20250922200355-jrzdieb","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令遵循 (Instruction following)"},{"Type":"NodeText","Data":": 通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"，LLM能理解并执行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从未见过"},{"Type":"NodeText","Data":"的自然语言指令，展现了惊人的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化能力"},{"Type":"NodeText","Data":"。这是ChatGPT等对话模型的核心能力基础。"}]}]},{"ID":"20250922200355-7k7ib8i","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922200355-7k7ib8i","updated":"20250922200355"},"Children":[{"ID":"20250922200355-l5gmai0","Type":"NodeParagraph","Properties":{"id":"20250922200355-l5gmai0","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逐步推理 (Step-by-step reasoning)"},{"Type":"NodeText","Data":": LLM能够通过生成中间步骤来解决需要多步逻辑的复杂问题，如数学题。这表明LLM不仅仅是模式匹配，还具备了一定的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逻辑推理"},{"Type":"NodeText","Data":"能力。"}]}]}]}]},{"ID":"20250922200355-xuf9xjk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-xuf9xjk","updated":"20250922200355"},"Children":[{"ID":"20250922200355-twoitop","Type":"NodeParagraph","Properties":{"id":"20250922200355-twoitop","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现的“门槛”"},{"Type":"NodeText","Data":": 作者特别指出，这些能力通常只在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常大"},{"Type":"NodeText","Data":"的模型（如60B以上）中才显著出现，这强调了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“规模”"},{"Type":"NodeText","Data":"是解锁这些高级能力的关键钥匙。"}]}]}]}]},{"ID":"20250922200355-dkj3kl8","Type":"NodeBlockquote","Properties":{"id":"20250922200355-dkj3kl8","updated":"20250922200358"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922200355-0wgkvev","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200355-0wgkvev","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922200355-3k6xmz5","Type":"NodeParagraph","Properties":{"id":"20250922200355-3k6xmz5","updated":"20250922200355"},"Children":[{"Type":"NodeText","Data":"第三部分是本综述的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论核心"},{"Type":"NodeText","Data":"之一，它深入探讨了驱动大型语言模型（LLM）发展的两个最根本的概念："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则（Scaling Laws）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力（Emergent Abilities）"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922200355-qqubuz2","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922200355-qqubuz2","updated":"20250922200355"},"Children":[{"ID":"20250922200355-8um8ssn","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922200355-8um8ssn","updated":"20250922200355"},"Children":[{"ID":"20250922200355-62bn1ys","Type":"NodeParagraph","Properties":{"id":"20250922200355-62bn1ys","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“道”与“术”的关系"},{"Type":"NodeText","Data":": 如果说"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则是LLM发展的“道”"},{"Type":"NodeText","Data":"，那么"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力则是其“术”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922200355-rue21ty","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-rue21ty","updated":"20250922200355"},"Children":[{"ID":"20250922200355-ro6fgmy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-ro6fgmy","updated":"20250922200355"},"Children":[{"ID":"20250922200355-uas259s","Type":"NodeParagraph","Properties":{"id":"20250922200355-uas259s","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测的、平滑的、普遍的"},{"Type":"NodeText","Data":"规律。它告诉我们，只要持续投入资源（计算、数据、模型参数），模型的能力就会稳步提升。这是LLM发展的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"物理基础"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"宏观规律"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922200355-oegtw5r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-oegtw5r","updated":"20250922200355"},"Children":[{"ID":"20250922200355-jeh5gt9","Type":"NodeParagraph","Properties":{"id":"20250922200355-jeh5gt9","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不可预测的、突变的、神奇的"},{"Type":"NodeText","Data":"现象。它告诉我们，当规模达到某个临界点时，会发生质变，模型会突然“解锁”前所未有的新技能。这是LLM智能表现的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微观体现"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"神奇之处"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922200355-r8aiw5k","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922200355-r8aiw5k","updated":"20250922200355"},"Children":[{"ID":"20250922200355-6fks1p2","Type":"NodeParagraph","Properties":{"id":"20250922200355-6fks1p2","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论与实践的指导"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200355-9dt7pjb","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-9dt7pjb","updated":"20250922200355"},"Children":[{"ID":"20250922200355-a6sjq6l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-a6sjq6l","updated":"20250922200355"},"Children":[{"ID":"20250922200355-b6g75ni","Type":"NodeParagraph","Properties":{"id":"20250922200355-b6g75ni","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Chinchilla规模法则"},{"Type":"NodeText","Data":"的提出，为如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"经济高效"},{"Type":"NodeText","Data":"地训练LLM提供了重要的实践指导，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平衡模型大小和数据量"},{"Type":"NodeText","Data":"的投入，避免了早期“唯模型大小论”的误区。"}]}]},{"ID":"20250922200355-8dz1k14","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-8dz1k14","updated":"20250922200355"},"Children":[{"ID":"20250922200355-dwo1is9","Type":"NodeParagraph","Properties":{"id":"20250922200355-dwo1is9","updated":"20250922200355"},"Children":[{"Type":"NodeText","Data":"对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习、指令遵循、逐步推理"},{"Type":"NodeText","Data":"这三种典型涌现能力的阐述，解释了为什么LLM能够解决如此复杂和多样的任务。这为如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有效利用"},{"Type":"NodeText","Data":"LLM（即如何设计prompt）提供了理论依据。"}]}]}]}]},{"ID":"20250922200355-fq2cnqx","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922200355-fq2cnqx","updated":"20250922200355"},"Children":[{"ID":"20250922200355-sjgla7s","Type":"NodeParagraph","Properties":{"id":"20250922200355-sjgla7s","updated":"20250922200355"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"已知与未知的边界"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200355-s30qamh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200355-s30qamh","updated":"20250922200355"},"Children":[{"ID":"20250922200355-60lq37c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200355-60lq37c","updated":"20250922200355"},"Children":[{"ID":"20250922200355-hjcr7ap","Type":"NodeParagraph","Properties":{"id":"20250922200355-hjcr7ap","updated":"20250922200355"},"Children":[{"Type":"NodeText","Data":"本部分不仅阐述了我们已知的规律（如规模法则），也坦诚地指出了我们"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"未知的领域"},{"Type":"NodeText","Data":"。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务级可预测性的不确定性"},{"Type":"NodeText","Data":"（特别是“逆规模扩展”）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力的基本原理之谜"},{"Type":"NodeText","Data":"，都说明我们对LLM的理解还远未达到终点。这为未来的研究划定了清晰的边界和方向。"}]}]}]}]}]},{"ID":"20250922200355-27shtaj","Type":"NodeParagraph","Properties":{"id":"20250922200355-27shtaj","updated":"20250922200355"},"Children":[{"Type":"NodeText","Data":"总结来说，第三部分通过对规模法则和涌现能力的深入剖析，揭示了LLM发展的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“一体两面”"},{"Type":"NodeText","Data":"。一面是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于物理定律般可预测的、持续的量变"},{"Type":"NodeText","Data":"，另一面是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如同相变般不可预测的、惊人的质变"},{"Type":"NodeText","Data":"。正是这两者的结合，共同造就了今天大型语言模型的强大能力。这一部分的论述为理解LLM为何强大、如何训练以及未来研究方向提供了最核心的理论支柱。"}]}]},{"ID":"20250922200529-9qj0t8a","Type":"NodeParagraph","Properties":{"id":"20250922200529-9qj0t8a","updated":"20250924085505"},"Children":[{"Type":"NodeText","Data":"多个推理步骤的复杂任务，例如数学应用题。相比之下，借助"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）提示策略"},{"Type":"NodeText","Data":"，LLM可以通过利用包含推导最终答案的中间推理步骤的提示机制来解决此类任务。据推测，这种能力可能是通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对代码的训练"},{"Type":"NodeText","Data":"获得的。一项实证研究表明，当应用于模型大小"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大于60B"},{"Type":"NodeText","Data":"的PaLM和LaMDA变体时，CoT提示可以带来性能增益（在算术推理基准上），而当模型大小"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超过100B"},{"Type":"NodeText","Data":"时，其相对于标准提示的优势变得更加明显。此外，CoT提示带来的性能提升似乎也因不同任务而异，例如，对于PaLM来说，GSM8K \u003e MAWPS \u003e SWAMP。"}]},{"ID":"20250922200529-560zuxy","Type":"NodeParagraph","Properties":{"id":"20250922200529-560zuxy","updated":"20250924085505"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"How Emergent Abilities Relate to Scaling Laws (涌现能力与规模法则的关系)."},{"Type":"NodeText","Data":" 在现有文献中，规模法则和涌现能力为理解大型模型相对于小型模型的优势提供了两个视角。总的来说，规模法则（通常由语言建模损失来衡量）描述了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测"},{"Type":"NodeText","Data":"的性能关系，并可能带有收益递减效应，而涌现能力（通常由任务性能来衡量）是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不可预测"},{"Type":"NodeText","Data":"的，但一旦实际出现，其收益就非常可观。由于这两个视角反映了不同的性能趋势（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续提升 vs. 剧烈飞跃"},{"Type":"NodeText","Data":"），它们可能会导致不一致的发现或观察。关于涌现能力的合理性也存在广泛的争论。一个普遍的推测是，涌现能力可能部分归因于特殊任务的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估设置"},{"Type":"NodeText","Data":"（例如，不连续的评估指标）：当评估指标相应改变时，涌现能力曲线的陡峭度会消失。然而，在大多数任务上，LLM的性能在用户看来是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以不连续的方式感知的"},{"Type":"NodeText","Data":"。例如，最终用户更喜欢LLM生成能够成功通过测试用例的可靠代码，而不太关心在两个失败的代码之间选择错误更少的那一个。最近，一项研究提出了一种新的评估设置，可以扩大任务指标的分辨率，使任务性能更具可预测性。尽管有这些努力，但关于LLM工作机制的更基础性研究（例如，grokking¹⁰）仍需进行，以理解某些能力的涌现。规模法则和涌现能力之间的微妙关系可以通过与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类能力习得"},{"Type":"NodeText","Data":"的类比来解释¹¹。以说话能力为例。对于儿童，语言发展（尤其是婴儿期）也可以被视为一个多层次的过程，其中会出现“涌现能力”。特别地，语言能力在一段时间内会相对稳定，但只有在演进到另一个能力水平时才会发生质的变化（例如，从说简单的词到说简单的句子）。这样一个学习过程本质上是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不平滑和不稳定的"},{"Type":"NodeText","Data":"（即，语言能力并非以恒定速率发展），尽管孩子实际上每天都在成长。有趣的是，年轻的父母常常会为他们宝宝所展现出的说话能力的意外进步而感到惊讶。"}]},{"ID":"20250922200529-vnqgqxs","Type":"NodeParagraph","Properties":{"id":"20250922200529-vnqgqxs","updated":"20250924085505"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Key Techniques for LLMs (LLM的关键技术)."},{"Type":"NodeText","Data":" LLM演变成当前状态——通用且能干的学习器——经历了漫长的过程。在发展过程中，提出了许多重要的技术，这些技术极大地提升了LLM的能力。在这里，我们简要列出一些（潜在地）促成LLM成功的关键技术，如下所示。"}]},{"ID":"20250922200529-sx3wnjr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200529-sx3wnjr","updated":"20250924085505"},"Children":[{"ID":"20250922200528-12y1i80","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-12y1i80","updated":"20250922200528"},"Children":[{"ID":"20250922200529-4p17w3l","Type":"NodeParagraph","Properties":{"id":"20250922200529-4p17w3l","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩展 (Scaling)."},{"Type":"NodeText","Data":" 如前几部分所讨论的，Transformer语言模型中存在明显的扩展效应：更大的模型/数据规模和更多的训练计算量通常会带来模型能力的提升。作为两个代表性模型，GPT-3和PaLM通过将模型大小分别增加到175B和540B，探索了扩展的极限。由于计算预算通常是有限的，可以进一步利用规模法则来进行更计算高效的计算资源分配。例如，Chinchilla（拥有更多的训练词元）通过在相同计算预算下增加数据规模，其性能优于其对应模型Gopher（拥有更大的模型规模）。此外，数据扩展应伴随仔细的清洗过程，因为预训练数据的质量在模型能力中起着关键作用。"}]}]},{"ID":"20250922200528-qvoc9ii","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-qvoc9ii","updated":"20250922200528"},"Children":[{"ID":"20250922200529-2i4rimi","Type":"NodeParagraph","Properties":{"id":"20250922200529-2i4rimi","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练 (Training)."},{"Type":"NodeText","Data":" 由于模型规模巨大，成功训练一个有能力的LLM非常具有挑战性。需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分布式训练算法"},{"Type":"NodeText","Data":"来学习LLM的网络参数，其中通常会联合使用各种并行策略。为了支持分布式训练，已经发布了几个优化框架来促进并行算法的实现和部署，例如DeepSpeed和Megatron-LM。此外，优化技巧对于训练稳定性和模型性能也很重要，例如，重新启动以克服训练损失飙升和混合精度训练。最近，GPT-4提出了开发特殊的基础设施和优化方法，能够用小得多的模型可靠地预测大模型的性能。"}]}]},{"ID":"20250922200528-xrpw44l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-xrpw44l","updated":"20250922200528"},"Children":[{"ID":"20250922200529-pu2bnbs","Type":"NodeParagraph","Properties":{"id":"20250922200529-pu2bnbs","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力激发 (Ability eliciting)."},{"Type":"NodeText","Data":" 在大规模语料库上预训练后，LLM被赋予了作为通用任务解决器的潜在能力。当LLM执行某些特定任务时，这些能力可能不会被明确地展现出来。作为技术方法，设计合适的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务指令"},{"Type":"NodeText","Data":"或特定的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习策略"},{"Type":"NodeText","Data":"来激发这些能力是很有用的。例如，链式思维提示已被证明通过包含中间推理步骤来解决复杂的推理任务很有用。此外，我们可以用自然语言表达的任务描述对LLM进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"，以提高LLM在未见任务上的泛化能力。这些激发技术主要对应于LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力"},{"Type":"NodeText","Data":"，在小型语言模型上可能不会显示出相同的效果。"}]}]},{"ID":"20250922200528-w9o0inj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-w9o0inj","updated":"20250922200528"},"Children":[{"ID":"20250922200529-e5zg2wy","Type":"NodeParagraph","Properties":{"id":"20250922200529-e5zg2wy","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐调整 (Alignment tuning)."},{"Type":"NodeText","Data":" 由于LLM被训练来捕捉预训练语料库的数据特征（包括高质量和低质量数据），它们很可能生成对人类有毒、有偏见甚至有害的内容。有必要将LLM与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类价值观"},{"Type":"NodeText","Data":"对齐，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用、诚实和无害"},{"Type":"NodeText","Data":"。为此，InstructGPT设计了一种有效的调整方法，使LLM能够遵循预期的指令，该方法利用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"带有人类反馈的强化学习"},{"Type":"NodeText","Data":"技术。它将人类纳入训练循环，并采用精心设计的标注策略。ChatGPT确实是基于与InstructGPT类似的技术开发的，它在产生高质量、无害的响应方面表现出强大的对齐能力，例如，拒绝回答侮辱性问题。"}]}]}]},{"ID":"20250922200529-16aa1m8","Type":"NodeBlockquote","Properties":{"id":"20250922200529-16aa1m8","updated":"20250924085505"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922200529-7wxsltk","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200529-7wxsltk","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922200529-j8qn8n3","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200529-j8qn8n3","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力与规模法则的思辨"}]},{"ID":"20250922200529-01bidg3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200529-01bidg3","updated":"20250922200529"},"Children":[{"ID":"20250922200528-oli9wi7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-oli9wi7","updated":"20250922200528"},"Children":[{"ID":"20250922200529-d37p0c0","Type":"NodeParagraph","Properties":{"id":"20250922200529-d37p0c0","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两种视角，一个现实"},{"Type":"NodeText","Data":": 作者将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"（可预测的、连续的）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力"},{"Type":"NodeText","Data":"（不可预测的、突变的）定位为理解大模型能力的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两个不同但互补的视角"},{"Type":"NodeText","Data":"。这解释了为什么LLM的发展既有稳定的可预测性，又充满了惊喜。"}]}]},{"ID":"20250922200528-rhg5ssu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-rhg5ssu","updated":"20250922200528"},"Children":[{"ID":"20250922200529-8kgsuq6","Type":"NodeParagraph","Properties":{"id":"20250922200529-8kgsuq6","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估指标的影响"},{"Type":"NodeText","Data":": 一个深刻的洞见是，所谓的“涌现”可能部分源于我们"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估方式的粗糙"},{"Type":"NodeText","Data":"。例如，对于代码生成，我们只关心“能运行”或“不能运行”（一个0/1的不连续指标），这使得性能从0到1的跨越看起来像一次“涌现”。如果能设计更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"细粒度、连续"},{"Type":"NodeText","Data":"的评估指标，这种“涌现”曲线可能会变得平滑。"}]}]},{"ID":"20250922200528-dqhpwbc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-dqhpwbc","updated":"20250922200528"},"Children":[{"ID":"20250922200529-lkvwkk8","Type":"NodeParagraph","Properties":{"id":"20250922200529-lkvwkk8","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与人类学习的类比"},{"Type":"NodeText","Data":": 将LLM的能力发展与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"儿童学习说话"},{"Type":"NodeText","Data":"进行类比，是一个非常生动且有启发性的解释。儿童语言能力的提升也不是线性的，而是在平台期和突破期交替中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"阶段性跃迁"},{"Type":"NodeText","Data":"的。这为理解LLM为何会“涌现”能力提供了一个认知科学的视角。"}]}]}]},{"ID":"20250922200529-1wuh3c7","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200529-1wuh3c7","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM成功的“四大支柱”"}]},{"ID":"20250922200529-k05j422","Type":"NodeParagraph","Properties":{"id":"20250922200529-k05j422","updated":"20250922200529"},"Children":[{"Type":"NodeText","Data":"这部分内容高度概括了打造一个成功的LLM所必需的四项核心技术，可以视为LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“四大支柱”"},{"Type":"NodeText","Data":"："}]},{"ID":"20250922200529-4mhdsgz","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922200529-4mhdsgz","updated":"20250922200529"},"Children":[{"ID":"20250922200528-377ivl6","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922200528-377ivl6","updated":"20250922200528"},"Children":[{"ID":"20250922200529-cgae5m4","Type":"NodeParagraph","Properties":{"id":"20250922200529-cgae5m4","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩展 (Scaling)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础"},{"Type":"NodeText","Data":"。没有足够大的模型规模、数据量和计算投入，一切都无从谈起。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Chinchilla法则"},{"Type":"NodeText","Data":"再次被提及，强调了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据质量"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据与模型规模的平衡"},{"Type":"NodeText","Data":"是有效扩展的关键。"}]}]},{"ID":"20250922200528-a0hz20g","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922200528-a0hz20g","updated":"20250922200528"},"Children":[{"ID":"20250922200529-47eg8cb","Type":"NodeParagraph","Properties":{"id":"20250922200529-47eg8cb","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练 (Training)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实现手段"},{"Type":"NodeText","Data":"。面对巨大的模型，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分布式训练"},{"Type":"NodeText","Data":"是必需的工程技术。DeepSpeed和Megatron-LM等框架是实现这一目标的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键工具"},{"Type":"NodeText","Data":"。训练的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳定性"},{"Type":"NodeText","Data":"（如处理损失尖峰）是核心挑战。"}]}]},{"ID":"20250922200528-1hyidpw","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922200528-1hyidpw","updated":"20250922200528"},"Children":[{"ID":"20250922200529-yyj9u59","Type":"NodeParagraph","Properties":{"id":"20250922200529-yyj9u59","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力激发 (Ability Eliciting)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“解锁”潜能"},{"Type":"NodeText","Data":"的方法。模型预训练后只是获得了“潜力”，需要通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精巧的提示（Prompting）"},{"Type":"NodeText","Data":"，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（ICL）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"，或者通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调（Instruction Tuning）"},{"Type":"NodeText","Data":"，才能将这些潜力"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“激发”"},{"Type":"NodeText","Data":"出来，转化为解决实际任务的能力。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“用好”"},{"Type":"NodeText","Data":"LLM的关键。"}]}]},{"ID":"20250922200528-trkru2s","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922200528-trkru2s","updated":"20250922200528"},"Children":[{"ID":"20250922200529-jd0ngjp","Type":"NodeParagraph","Properties":{"id":"20250922200529-jd0ngjp","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐调整 (Alignment Tuning)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“驯服”野兽"},{"Type":"NodeText","Data":"的过程。原始的LLM可能生成有害、虚假的内容。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与人类价值观对齐"},{"Type":"NodeText","Data":"（遵循“有用、诚实、无害”原则），特别是使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"带有人类反馈的强化学习（RLHF）"},{"Type":"NodeText","Data":"，才能让LLM变得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"安全、可靠、可用"},{"Type":"NodeText","Data":"。这是确保LLM能被社会负责任地部署的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"安全阀"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922200529-r5vnzho","Type":"NodeBlockquote","Properties":{"id":"20250922200529-r5vnzho","updated":"20250922200529"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922200529-o36az2b","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200529-o36az2b","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922200529-gsmnovi","Type":"NodeParagraph","Properties":{"id":"20250922200529-gsmnovi","updated":"20250922200529"},"Children":[{"Type":"NodeText","Data":"第四部分在概念层面进行了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深入的思辨"},{"Type":"NodeText","Data":"，并从技术层面给出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高度的概括"},{"Type":"NodeText","Data":"，是理解LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“为何强大”"},{"Type":"NodeText","Data":"以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何打造”"},{"Type":"NodeText","Data":"的关键章节。"}]},{"ID":"20250922200529-ccygznv","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922200529-ccygznv","updated":"20250922200529"},"Children":[{"ID":"20250922200528-bhtsrqz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922200528-bhtsrqz","updated":"20250922200528"},"Children":[{"ID":"20250922200529-ra3ukff","Type":"NodeParagraph","Properties":{"id":"20250922200529-ra3ukff","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“是什么”到“为什么”的深化"},{"Type":"NodeText","Data":": 如果说前文主要在描述“LLM是什么”，这一部分则开始深入探讨“LLM为什么会这样”。通过将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"（连续性）与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力"},{"Type":"NodeText","Data":"（突变性）进行对比和关联，文章试图解释LLM能力发展的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内在机理"},{"Type":"NodeText","Data":"。特别是与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"儿童语言学习"},{"Type":"NodeText","Data":"的类比，为这个复杂的计算机科学问题提供了一个易于理解的、来自认知科学的隐喻，极大地增强了文章的启发性。"}]}]},{"ID":"20250922200528-i3vbwj3","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922200528-i3vbwj3","updated":"20250922200528"},"Children":[{"ID":"20250922200529-agfx2lb","Type":"NodeParagraph","Properties":{"id":"20250922200529-agfx2lb","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“四大支柱”的高度概括"},{"Type":"NodeText","Data":": 作者提炼出的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“扩展、训练、能力激发、对齐调整”"},{"Type":"NodeText","Data":"这四个关键技术点，可以被视为构建现代LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“标准操作流程”或“核心技术栈”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922200529-7rbnp2v","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200529-7rbnp2v","updated":"20250922200529"},"Children":[{"ID":"20250922200528-keqj08u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-keqj08u","updated":"20250922200528"},"Children":[{"ID":"20250922200529-lbwvoks","Type":"NodeParagraph","Properties":{"id":"20250922200529-lbwvoks","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩展"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前提和基础"},{"Type":"NodeText","Data":"，决定了能力的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上限"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922200528-twieazu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-twieazu","updated":"20250922200528"},"Children":[{"ID":"20250922200529-f8bk8qn","Type":"NodeParagraph","Properties":{"id":"20250922200529-f8bk8qn","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工程实现"},{"Type":"NodeText","Data":"，决定了能否"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"达到"},{"Type":"NodeText","Data":"这个上限。"}]}]},{"ID":"20250922200528-ny9nel6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-ny9nel6","updated":"20250922200528"},"Children":[{"ID":"20250922200529-8vy7lcg","Type":"NodeParagraph","Properties":{"id":"20250922200529-8vy7lcg","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力激发"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"使用技巧"},{"Type":"NodeText","Data":"，决定了能否"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"释放"},{"Type":"NodeText","Data":"已有的能力。"}]}]},{"ID":"20250922200528-xm9fmrw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200528-xm9fmrw","updated":"20250922200528"},"Children":[{"ID":"20250922200529-7lmq16b","Type":"NodeParagraph","Properties":{"id":"20250922200529-7lmq16b","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐调整"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"安全保障"},{"Type":"NodeText","Data":"，决定了模型能否被"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"负责任地应用"},{"Type":"NodeText","Data":"。\n这个框架不仅逻辑清晰，而且高度概括了近年来LLM研究和工程实践中的核心工作，为读者提供了一个宏观且实用的技术图景。"}]}]}]}]},{"ID":"20250922200528-98q0n2g","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922200528-98q0n2g","updated":"20250922200528"},"Children":[{"ID":"20250922200529-o66rz0h","Type":"NodeParagraph","Properties":{"id":"20250922200529-o66rz0h","updated":"20250922200529"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论与实践的结合"},{"Type":"NodeText","Data":": 这一部分巧妙地将理论探讨（如涌现能力的来源）与工程实践（如分布式训练框架、RLHF技术）结合起来。它既解释了LLM表现出的神奇现象，也指出了实现这些现象背后所需的坚实技术支撑。"}]}]}]},{"ID":"20250922200529-b9x39ph","Type":"NodeParagraph","Properties":{"id":"20250922200529-b9x39ph","updated":"20250922200529"},"Children":[{"Type":"NodeText","Data":"总结而言，第四部分是连接LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“现象”"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“本质”"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“理论”"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“实践”"},{"Type":"NodeText","Data":"的桥梁。它不仅让读者理解了LLM表面上的强大能力，更重要的是，揭示了支撑这些能力背后的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深刻原理和复杂的技术体系"},{"Type":"NodeText","Data":"。通过阅读这一部分，读者可以对如何从零开始构建一个安全、强大且有用的LLM有一个全面的、框架性的认识。"}]}]},{"ID":"20250922200704-wjjk7na","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200704-wjjk7na","updated":"20250924090557"},"Children":[{"ID":"20250922200704-hg7n5m2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-hg7n5m2","updated":"20250922200704"},"Children":[{"ID":"20250922200704-14mepjg","Type":"NodeParagraph","Properties":{"id":"20250922200704-14mepjg","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具操作 (Tools manipulation)."},{"Type":"NodeText","Data":" 从本质上讲，LLM被训练为基于海量纯文本语料库的文本生成器，因此在不以文本形式最佳表达的任务（例如，数值计算）上表现较差。此外，它们的能力也受限于预训练数据，例如，无法捕捉最新信息。为了解决这些问题，最近提出的一种技术是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用外部工具"},{"Type":"NodeText","Data":"来弥补LLM的不足。例如，LLM可以利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计算器"},{"Type":"NodeText","Data":"进行精确计算，并利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"搜索引擎"},{"Type":"NodeText","Data":"来检索未知信息。最近，ChatGPT已经启用了使用外部"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"插件"},{"Type":"NodeText","Data":"（现有的或新创建的应用程序）的机制，这可以类比为LLM的“眼睛和耳朵”。这种机制可以广泛扩展LLM的能力范围。"}]}]}]},{"ID":"20250922200704-6dji93x","Type":"NodeParagraph","Properties":{"id":"20250922200704-6dji93x","updated":"20250924090557"},"Children":[{"Type":"NodeText","Data":"此外，许多其他因素（例如，硬件的升级）也对LLM的成功做出了贡献。目前，我们将讨论限制在开发LLM的主要技术方法和关键发现上。"}]},{"ID":"20250922200704-5ja8e8r","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200704-5ja8e8r","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.2 Technical Evolution of GPT-series Models (GPT系列模型的技术演进)"}]},{"ID":"20250922200704-lxzhex7","Type":"NodeParagraph","Properties":{"id":"20250922200704-lxzhex7","updated":"20250924090557"},"Children":[{"Type":"NodeText","Data":"由于其与人类交流的出色能力，ChatGPT自发布以来点燃了AI社区的兴奋。ChatGPT是基于强大的GPT模型开发的，并具有专门优化的对话能力。考虑到对ChatGPT和GPT模型日益增长的兴趣，我们增加了一个关于GPT系列模型技术演进的特别讨论，以简要总结它们在过去几年中的发展历程。同时，我们绘制了一张描绘GPT系列模型技术演进的示意图，见图4。GPT模型的基本原理是通过语言建模将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"世界知识压缩"},{"Type":"NodeText","Data":"到一个仅包含解码器的Transformer模型中，从而使其能够恢复（或记忆）世界知识的语义，并充当通用任务解决器。成功的两个关键点在于：（I）训练能够准确预测下一个词的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器Transformer语言模型"},{"Type":"NodeText","Data":"，以及（II）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩大语言模型的大小"},{"Type":"NodeText","Data":"。总的来说，OpenAI在LLM上的研究大致可以分为以下几个阶段。"}]},{"ID":"20250922200704-uqjkmhz","Type":"NodeParagraph","Properties":{"id":"20250922200704-uqjkmhz","updated":"20250924090557"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Early Explorations (早期探索)."},{"Type":"NodeText","Data":" 根据对Ilya Sutskever（OpenAI的联合创始人兼首席科学家）的一次采访，用语言模型来构建智能系统的想法在OpenAI的早期就已经被探索，当时是尝试使用循环神经网络（RNN）。随着Transformer的出现，OpenAI开发了两款初始的GPT模型，即GPT-1和GPT-2，这可以被视为后续更强大模型（即GPT-3和GPT-4）的基础。"}]},{"ID":"20250922200704-23u28t4","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200704-23u28t4","updated":"20250924090557"},"Children":[{"ID":"20250922200704-dzcju97","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-dzcju97","updated":"20250922200704"},"Children":[{"ID":"20250922200704-grl8nmu","Type":"NodeParagraph","Properties":{"id":"20250922200704-grl8nmu","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-1."},{"Type":"NodeText","Data":" 2017年，谷歌推出了Transformer模型，OpenAI团队迅速将他们的语言建模工作调整到这个新的神经网络架构上。他们在2018年发布了第一个GPT模型，即GPT-1，并创造了缩写词GPT作为模型名称，代表"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成式预训练（Generative Pre-Training）"},{"Type":"NodeText","Data":"。GPT-1是基于一个生成式的、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器的Transformer架构"},{"Type":"NodeText","Data":"开发的，并采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无监督预训练"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有监督微调"},{"Type":"NodeText","Data":"的混合方法。GPT-1为GPT系列模型设定了核心架构，并确立了建模自然语言文本的基本原则，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预测下一个词"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922200704-psqvkws","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-psqvkws","updated":"20250922200704"},"Children":[{"ID":"20250922200704-kao2e72","Type":"NodeParagraph","Properties":{"id":"20250922200704-kao2e72","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-2."},{"Type":"NodeText","Data":" 遵循与GPT-1相似的架构，GPT-2将参数规模增加到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"15亿"},{"Type":"NodeText","Data":"，并在一个名为WebText的大型网页数据集上进行训练。正如GPT-2的论文中所声称的，它试图通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无监督的语言建模"},{"Type":"NodeText","Data":"来执行任务，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无需使用标记数据进行显式微调"},{"Type":"NodeText","Data":"。为了推动这种方法，他们为多任务解决引入了一种概率形式，即"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"p"},{"Type":"NodeText","Data":"(output|input, task)（类似的方法也已在中采用），该形式预测以输入和任务信息为条件的输出。为了对这种条件概率进行建模，语言文本可以自然地用作统一格式化输入、输出和任务信息的方式。通过这种方式，解决任务的过程可以被视为一个生成解决方案文本的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词语预测问题"},{"Type":"NodeText","Data":"。此外，他们为这个想法引入了一个更正式的主张：“由于（特定任务的）监督目标与无监督（语言建模）目标相同，只是在一部分序列上进行评估，因此无监督目标的全局最小值也是监督目标（对于各种任务）的全局最小值”。对这一主张的基本理解是，每个（NLP）任务都可以被视为基于世界文本子集的词语预测问题。因此，如果无监督语言建模被训练到具有足够的能力来恢复世界文本，它就能够解决各种任务。这些在GPT-2论文中的早期讨论在Ilya Sutskever接受Jensen Huang采访时得到了呼应：“神经网络学到的是产生该文本的过程的某种表示。这个文本实际上是世界的一个投影……你预测下一个词越准确，保真度就越高，你在这个过程中得到的分辨率就越高……”。"}]}]}]},{"ID":"20250922200704-wwzhl7o","Type":"NodeParagraph","Properties":{"id":"20250922200704-wwzhl7o","updated":"20250924090557"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Capacity Leap (能力飞跃)."},{"Type":"NodeText","Data":" 尽管GPT-2旨在成为一个“无监督多任务学习器”，但与监督微调的最新方法相比，其整体性能较差。由于其模型规模相对较小，它已被广泛用于下游任务的微调，尤其是对话任务。基于GPT-2，GPT-3"}]},{"ID":"20250922200704-gh0yvof","Type":"NodeBlockquote","Properties":{"id":"20250922200704-gh0yvof","updated":"20250924090557"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922200704-1vxwgyu","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200704-1vxwgyu","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922200704-3a0mfns","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200704-3a0mfns","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM的关键技术（续）"}]},{"ID":"20250922200704-7dv9lyw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200704-7dv9lyw","updated":"20250922200704"},"Children":[{"ID":"20250922200704-myu0y7o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-myu0y7o","updated":"20250922200704"},"Children":[{"ID":"20250922200704-encw8oy","Type":"NodeParagraph","Properties":{"id":"20250922200704-encw8oy","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具操作 (Tool Manipulation)"},{"Type":"NodeText","Data":": 这是对LLM能力边界的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重要扩展"},{"Type":"NodeText","Data":"。作者指出，LLM本质上是文本处理器，不擅长"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确计算"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"获取实时信息"},{"Type":"NodeText","Data":"。解决方案是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“外挂”"},{"Type":"NodeText","Data":"——让LLM学会调用外部工具（计算器、搜索引擎、API等），就像人类使用工具一样。ChatGPT的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"插件（Plugins）"},{"Type":"NodeText","Data":"机制是这一思想的里程碑式实现，它极大地扩展了LLM的应用场景，使其从一个“语言模型”向一个“智能中枢”演进。"}]}]}]},{"ID":"20250922200704-a4t67yo","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200704-a4t67yo","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT系列演进的核心思想"}]},{"ID":"20250922200704-pun7crq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200704-pun7crq","updated":"20250922200704"},"Children":[{"ID":"20250922200704-r54bau1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-r54bau1","updated":"20250922200704"},"Children":[{"ID":"20250922200704-jxacy1h","Type":"NodeParagraph","Properties":{"id":"20250922200704-jxacy1h","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一条核心主线"},{"Type":"NodeText","Data":": 整段内容的核心思想是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通过‘预测下一个词’这一简单任务，在一个足够大的、仅解码器的Transformer模型上，利用足够多的数据，可以‘压缩’世界知识，从而创造一个通用的任务解决器。”"},{"Type":"NodeText","Data":" 这条主线贯穿了从GPT-1到GPT-4的整个发展历程。"}]}]},{"ID":"20250922200704-21l26do","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-21l26do","updated":"20250922200704"},"Children":[{"ID":"20250922200704-upqsg61","Type":"NodeParagraph","Properties":{"id":"20250922200704-upqsg61","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两个关键支点"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200704-ayoyn8h","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922200704-ayoyn8h","updated":"20250922200704"},"Children":[{"ID":"20250922200704-e705vtr","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922200704-e705vtr","updated":"20250922200704"},"Children":[{"ID":"20250922200704-ql8x7s0","Type":"NodeParagraph","Properties":{"id":"20250922200704-ql8x7s0","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"架构选择"},{"Type":"NodeText","Data":": 坚定地选择了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器（Decoder-only）的Transformer架构"},{"Type":"NodeText","Data":"。这意味着模型天然就是为“生成”而生的。"}]}]},{"ID":"20250922200704-3z2ezjt","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922200704-3z2ezjt","updated":"20250922200704"},"Children":[{"ID":"20250922200704-b442peb","Type":"NodeParagraph","Properties":{"id":"20250922200704-b442peb","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模扩展 (Scaling Up)"},{"Type":"NodeText","Data":": 坚信"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩大模型规模"},{"Type":"NodeText","Data":"是提升能力的关键。"}]}]}]}]}]},{"ID":"20250922200704-le30gjp","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200704-le30gjp","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"各代GPT模型的角色定位"}]},{"ID":"20250922200704-hvoqq5y","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200704-hvoqq5y","updated":"20250922200704"},"Children":[{"ID":"20250922200704-7cx1dc8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-7cx1dc8","updated":"20250922200704"},"Children":[{"ID":"20250922200704-9rlpby1","Type":"NodeParagraph","Properties":{"id":"20250922200704-9rlpby1","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-1 (奠基者)"},{"Type":"NodeText","Data":": 确立了“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成式预训练 (Generative Pre-Training)"},{"Type":"NodeText","Data":"”的技术路线和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器"},{"Type":"NodeText","Data":"的核心架构。它提出了基本原则："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预测下一个词"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922200704-n1e59s3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-n1e59s3","updated":"20250922200704"},"Children":[{"ID":"20250922200704-nje4waw","Type":"NodeParagraph","Properties":{"id":"20250922200704-nje4waw","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-2 (探索者)"},{"Type":"NodeText","Data":": 是一次重要的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思想实验"},{"Type":"NodeText","Data":"。它首次大胆提出，一个足够强大的语言模型或许"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不需要为特定任务进行微调"},{"Type":"NodeText","Data":"，可以直接通过无监督的方式解决多种任务。这个想法在当时虽然性能不佳，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为GPT-3的上下文学习（In-context Learning）奠定了思想基础"},{"Type":"NodeText","Data":"。它将“解决任务”统一到了“词语预测”这一框架下。"}]}]},{"ID":"20250922200704-ryc1b7i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-ryc1b7i","updated":"20250922200704"},"Children":[{"ID":"20250922200704-wn8ermz","Type":"NodeParagraph","Properties":{"id":"20250922200704-wn8ermz","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3 (破局者)"},{"Type":"NodeText","Data":": 实现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力上的巨大飞跃（Capacity Leap）"},{"Type":"NodeText","Data":"。它用事实证明了GPT-2的设想——当模型规模大到一定程度时，确实可以通过“上下文学习”来解决各种任务，而无需微调。这是LLM发展史上的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分水岭"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922200704-2fvigkw","Type":"NodeBlockquote","Properties":{"id":"20250922200704-2fvigkw","updated":"20250924090557"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922200704-oowx2es","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200704-oowx2es","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922200704-gye0sr8","Type":"NodeParagraph","Properties":{"id":"20250922200704-gye0sr8","updated":"20250922200704"},"Children":[{"Type":"NodeText","Data":"第五部分是对LLM成功的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术根源"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思想演进"},{"Type":"NodeText","Data":"的一次深入剖析，它以OpenAI的GPT系列模型为案例，清晰地展示了一个伟大的技术是如何从一个简单的想法，通过不断地探索和迭代，最终成长为改变世界的力量。"}]},{"ID":"20250922200704-rjoxu0b","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922200704-rjoxu0b","updated":"20250922200704"},"Children":[{"ID":"20250922200704-a3h5gno","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922200704-a3h5gno","updated":"20250922200704"},"Children":[{"ID":"20250922200704-2wzuwkg","Type":"NodeParagraph","Properties":{"id":"20250922200704-2wzuwkg","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思想的连续性与演进"},{"Type":"NodeText","Data":": 本部分最精彩之处在于，它不仅仅是罗列GPT-1、2、3的技术参数，而是揭示了其背后"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一以贯之的设计哲学"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逐步演进的思想"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922200704-y8cas26","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200704-y8cas26","updated":"20250922200704"},"Children":[{"ID":"20250922200704-ry7q84b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-ry7q84b","updated":"20250922200704"},"Children":[{"ID":"20250922200704-b8hjk48","Type":"NodeParagraph","Properties":{"id":"20250922200704-b8hjk48","updated":"20250922200704"},"Children":[{"Type":"NodeText","Data":"从GPT-1确立"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“生成式预训练”"},{"Type":"NodeText","Data":"的根本路线。"}]}]},{"ID":"20250922200704-vnjgjuw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-vnjgjuw","updated":"20250922200704"},"Children":[{"ID":"20250922200704-qj21lz6","Type":"NodeParagraph","Properties":{"id":"20250922200704-qj21lz6","updated":"20250922200704"},"Children":[{"Type":"NodeText","Data":"到GPT-2提出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“无监督多任务学习”"},{"Type":"NodeText","Data":"的革命性猜想。"}]}]},{"ID":"20250922200704-qblxn0b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200704-qblxn0b","updated":"20250922200704"},"Children":[{"ID":"20250922200704-tktf0cu","Type":"NodeParagraph","Properties":{"id":"20250922200704-tktf0cu","updated":"20250922200704"},"Children":[{"Type":"NodeText","Data":"再到GPT-3通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"巨大的规模"},{"Type":"NodeText","Data":"，用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“上下文学习”"},{"Type":"NodeText","Data":"的惊人表现验证了这一猜想。\n这个过程展现了一种清晰的科研路径："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提出一个大胆的假设，然后通过扩大规模和工程实现来最终证明它"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922200704-ednvlu2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922200704-ednvlu2","updated":"20250922200704"},"Children":[{"ID":"20250922200704-l3o749v","Type":"NodeParagraph","Properties":{"id":"20250922200704-l3o749v","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心技术的高度凝练"},{"Type":"NodeText","Data":": 作者将GPT系列的成功归结为两个非常简单但核心的要素："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"（1）训练一个仅解码器的Transformer模型来预测下一个词；（2）不断扩大模型的规模"},{"Type":"NodeText","Data":"。这种高度的凝练，让读者能够穿透复杂的细节，抓住技术发展的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主干"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922200704-2vegiby","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922200704-2vegiby","updated":"20250922200704"},"Children":[{"ID":"20250922200704-vyp853t","Type":"NodeParagraph","Properties":{"id":"20250922200704-vyp853t","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对LLM能力的深刻理解"},{"Type":"NodeText","Data":": 引用Ilya Sutskever的访谈——“文本是世界的一个投影，预测下一个词越准，你对这个世界的理解就越深刻”——为“为什么预测下一个词如此强大”这一根本问题提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"哲学层面"},{"Type":"NodeText","Data":"的、富有启发性的解释。这提升了整个论述的深度。"}]}]},{"ID":"20250922200704-t0dwr0z","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922200704-t0dwr0z","updated":"20250922200704"},"Children":[{"ID":"20250922200704-7ttszhn","Type":"NodeParagraph","Properties":{"id":"20250922200704-7ttszhn","updated":"20250922200704"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“内部”到“外部”的能力扩展"},{"Type":"NodeText","Data":": 在讨论完GPT系列自身的演进后，文章引入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“工具操作”"},{"Type":"NodeText","Data":"的概念。这标志着LLM发展的下一个阶段：从一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"封闭的、依赖内部知识的模型"},{"Type":"NodeText","Data":"，演变为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放的、能够与外部世界（工具、API）交互的智能系统"},{"Type":"NodeText","Data":"。这为理解ChatGPT插件等新功能的意义提供了关键的背景。"}]}]}]},{"ID":"20250922200704-8n51um3","Type":"NodeParagraph","Properties":{"id":"20250922200704-8n51um3","updated":"20250922200704"},"Children":[{"Type":"NodeText","Data":"总结而言，第五部分通过对GPT系列发展史的回顾，不仅让读者了解了具体的技术细节，更重要的是，理解了这些技术背后的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"驱动思想和演进逻辑"},{"Type":"NodeText","Data":"。它告诉我们，LLM的成功并非偶然，而是一种设计哲学在巨大工程投入下必然的结果，并且其未来的发展将更加注重与外部世界的融合。"}]}]},{"ID":"20250922200841-uyv44qa","Type":"NodeParagraph","Properties":{"id":"20250922200841-uyv44qa","updated":"20250924091508"},"Children":[{"Type":"NodeText","Data":"通过扩展（几乎相同的）生成式预训练架构，展示了关键的能力飞跃。"}]},{"ID":"20250922200841-qf3ux27","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-qf3ux27","updated":"20250924091508"},"Children":[{"ID":"20250922200841-haebwu1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-haebwu1","updated":"20250922200841"},"Children":[{"ID":"20250922200841-dn6mvjr","Type":"NodeParagraph","Properties":{"id":"20250922200841-dn6mvjr","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3."},{"Type":"NodeText","Data":" GPT-3于2020年发布，它将模型参数扩展到了前所未有的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1750亿"},{"Type":"NodeText","Data":"。在GPT-3的论文中，它正式引入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（ICL）"},{"Type":"NodeText","Data":"的概念，该概念以少样本或零样本的方式利用LLM。ICL能以自然语言文本的形式“教导”（或指示）LLM理解任务。通过ICL，LLM的预训练和利用统一到了相同的语言建模范式：预训练预测以上下文为条件的后续文本序列，而ICL则在给定任务描述和演示的情况下，预测正确的任务解决方案，这个解决方案也可以被格式化为文本序列。GPT-3不仅在各种NLP任务上表现出色，还在一系列需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域适应"},{"Type":"NodeText","Data":"能力的特殊设计任务上表现优异。尽管GPT-3的论文没有明确讨论LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力"},{"Type":"NodeText","Data":"，但我们可以观察到可能超越基本规模法则的大幅性能飞跃，例如，更大的模型具有明显更强的ICL能力（如GPT-3论文原文图1.2所示）。总的来说，GPT-3可以被视为从PLM演进到LLM的旅程中的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"卓越里程碑"},{"Type":"NodeText","Data":"。它通过经验证明，将神经网络扩展到巨大的规模可以带来模型能力的巨大提升。"}]}]}]},{"ID":"20250922200841-p5cmifh","Type":"NodeParagraph","Properties":{"id":"20250922200841-p5cmifh","updated":"20250924091508"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Capacity Enhancement (能力增强)."},{"Type":"NodeText","Data":" 由于其强大的能力，GPT-3已成为OpenAI开发更强大LLM的基础模型。总的来说，OpenAI探索了两种主要方法来进一步改进GPT-3模型，即在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码数据上进行训练"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与人类偏好对齐"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250924091851-jd2lmnj","Type":"NodeParagraph","Properties":{"id":"20250924091851-jd2lmnj","updated":"20250924091851"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250924091850-rz9dohw.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922200841-vb6via4","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200841-vb6via4","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 4：GPT系列模型技术演进简图"}]},{"ID":"20250922200841-lwoogi7","Type":"NodeParagraph","Properties":{"id":"20250922200841-lwoogi7","updated":"20250924091508"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图注："},{"Type":"NodeText","Data":" 本图主要基于OpenAI的论文、博客文章和官方API绘制。图中，实线表示存在明确证据（例如，官方声明一个新模型是基于某个基础模型开发的）的演进路径，而虚线表示相对较弱的演进关系。"}]},{"ID":"20250922200841-x23z7u7","Type":"NodeBlockquote","Properties":{"id":"20250922200841-x23z7u7","updated":"20250922200841"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922200841-iva90ht","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200841-iva90ht","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922200841-7nqgw82","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200841-7nqgw82","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图4解析"}]},{"ID":"20250922200841-it4u7ox","Type":"NodeParagraph","Properties":{"id":"20250922200841-it4u7ox","updated":"20250922200841"},"Children":[{"Type":"NodeText","Data":"这张图以时间线的方式，清晰地展示了从GPT-1到GPT-4的技术迭代和能力演进路径，可以看作是OpenAI大模型研发的“科技树”。"}]},{"ID":"20250922200841-fhahiuj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-fhahiuj","updated":"20250922200841"},"Children":[{"ID":"20250922200841-erntvql","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-erntvql","updated":"20250922200841"},"Children":[{"ID":"20250922200841-wy8ayr6","Type":"NodeParagraph","Properties":{"id":"20250922200841-wy8ayr6","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主干演进路径"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200841-u09yrpk","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-u09yrpk","updated":"20250922200841"},"Children":[{"ID":"20250922200841-oad399r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-oad399r","updated":"20250922200841"},"Children":[{"ID":"20250922200841-i3l3scd","Type":"NodeParagraph","Properties":{"id":"20250922200841-i3l3scd","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-1 (2018.06)"},{"Type":"NodeText","Data":": 奠定了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器架构"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成式预训练"},{"Type":"NodeText","Data":"的基础。"}]}]},{"ID":"20250922200841-l46rwmg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-l46rwmg","updated":"20250922200841"},"Children":[{"ID":"20250922200841-c6jjmtw","Type":"NodeParagraph","Properties":{"id":"20250922200841-c6jjmtw","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-2 (2019.02)"},{"Type":"NodeText","Data":": 探索了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无监督多任务学习"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩大模型规模"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922200841-vfo2me1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-vfo2me1","updated":"20250922200841"},"Children":[{"ID":"20250922200841-nie9n10","Type":"NodeParagraph","Properties":{"id":"20250922200841-nie9n10","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3 (2020.05)"},{"Type":"NodeText","Data":": 实现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习"},{"Type":"NodeText","Data":"的能力，探索了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则的极限"},{"Type":"NodeText","Data":"，是能力飞跃的关键节点。"}]}]}]}]},{"ID":"20250922200841-uzwunlq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-uzwunlq","updated":"20250922200841"},"Children":[{"ID":"20250922200841-ghb4qs2","Type":"NodeParagraph","Properties":{"id":"20250922200841-ghb4qs2","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力增强分支"},{"Type":"NodeText","Data":": 从GPT-3开始，技术演进分为两条关键支线，最终汇合到GPT-3.5和ChatGPT。"}]},{"ID":"20250922200841-tvkw95o","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922200841-tvkw95o","updated":"20250922200841"},"Children":[{"ID":"20250922200841-1pr67tx","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922200841-1pr67tx","updated":"20250922200841"},"Children":[{"ID":"20250922200841-ruwqrsk","Type":"NodeParagraph","Properties":{"id":"20250922200841-ruwqrsk","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码能力增强 (+code)"},{"Type":"NodeText","Data":": GPT-3经过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码数据"},{"Type":"NodeText","Data":"的训练，进化为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Codex (2021.07)"},{"Type":"NodeText","Data":"，拥有了强大的代码生成和理解能力。这为模型带来了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逻辑推理"},{"Type":"NodeText","Data":"能力。"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"code-davinci-002"},{"Type":"NodeText","Data":"​ 是这个阶段的代表模型。"}]}]},{"ID":"20250922200841-cer31da","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922200841-cer31da","updated":"20250922200841"},"Children":[{"ID":"20250922200841-2waid9y","Type":"NodeParagraph","Properties":{"id":"20250922200841-2waid9y","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令遵循与对齐增强 (+instruction, +RLHF)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200841-jqm2mkt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-jqm2mkt","updated":"20250922200841"},"Children":[{"ID":"20250922200841-oetyxkq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-oetyxkq","updated":"20250922200841"},"Children":[{"ID":"20250922200841-9fivkqw","Type":"NodeParagraph","Properties":{"id":"20250922200841-9fivkqw","updated":"20250922200841"},"Children":[{"Type":"NodeText","Data":"通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调 (Instruction Following)"},{"Type":"NodeText","Data":"，模型学会了更好地理解和执行人类指令，进化为 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"text-davinci-002"},{"Type":"NodeText","Data":"​ (2022.03)。"}]}]},{"ID":"20250922200841-prqh6qd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-prqh6qd","updated":"20250922200841"},"Children":[{"ID":"20250922200841-z9nfm2o","Type":"NodeParagraph","Properties":{"id":"20250922200841-z9nfm2o","updated":"20250922200841"},"Children":[{"Type":"NodeText","Data":"通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"带有人类反馈的强化学习 (RLHF)"},{"Type":"NodeText","Data":" 进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐 (Human Alignment)"},{"Type":"NodeText","Data":"，模型学会了生成更符合人类价值观的、更有帮助的、无害的回答，进化为 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"text-davinci-003"},{"Type":"NodeText","Data":"​ (2022.09)。"}]}]}]}]}]}]},{"ID":"20250922200841-ripw23a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-ripw23a","updated":"20250922200841"},"Children":[{"ID":"20250922200841-389s8p3","Type":"NodeParagraph","Properties":{"id":"20250922200841-389s8p3","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"集大成者"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200841-7o7xrqf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-7o7xrqf","updated":"20250922200841"},"Children":[{"ID":"20250922200841-e7yay41","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-e7yay41","updated":"20250922200841"},"Children":[{"ID":"20250922200841-4nlhfg6","Type":"NodeParagraph","Properties":{"id":"20250922200841-4nlhfg6","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3.5 (2022.03)"},{"Type":"NodeText","Data":": 整合了代码能力和指令遵循能力，是一个综合能力更强的模型系列。"}]}]},{"ID":"20250922200841-ve1p0gd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-ve1p0gd","updated":"20250922200841"},"Children":[{"ID":"20250922200841-bmclrft","Type":"NodeParagraph","Properties":{"id":"20250922200841-bmclrft","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT (2022.11)"},{"Type":"NodeText","Data":": 在GPT-3.5的基础上，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话优化 (+chat)"},{"Type":"NodeText","Data":"，专门针对聊天场景进行了微调，最终展现出惊人的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合对话能力"},{"Type":"NodeText","Data":"。"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-3.5-turbo"},{"Type":"NodeText","Data":"​ 是其API版本。"}]}]}]}]},{"ID":"20250922200841-6ofbu4p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-6ofbu4p","updated":"20250922200841"},"Children":[{"ID":"20250922200841-6395ibu","Type":"NodeParagraph","Properties":{"id":"20250922200841-6395ibu","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"新的高峰"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200841-csuzgy0","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-csuzgy0","updated":"20250922200841"},"Children":[{"ID":"20250922200841-6nvinog","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-6nvinog","updated":"20250922200841"},"Children":[{"ID":"20250922200841-mp8ex7u","Type":"NodeParagraph","Properties":{"id":"20250922200841-mp8ex7u","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-4 (2023.03)"},{"Type":"NodeText","Data":": 在前代模型所有能力的基础上，实现了更强的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理能力"},{"Type":"NodeText","Data":"，并扩展到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态"},{"Type":"NodeText","Data":"领域（如图中未完全展示的视觉能力）。"}]}]}]}]}]},{"ID":"20250922200841-uk2qgzt","Type":"NodeParagraph","Properties":{"id":"20250922200841-uk2qgzt","updated":"20250922200841"},"Children":[{"Type":"NodeText","Data":"这张图清晰地揭示了现代强大LLM（如ChatGPT）的成功秘诀：它不仅仅是模型规模的堆砌，更是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础能力（来自GPT-3）、代码/逻辑能力（来自Codex）和人类对齐能力（来自InstructGPT/RLHF）"},{"Type":"NodeText","Data":"三者结合的产物，最后再通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话场景的专门优化"},{"Type":"NodeText","Data":"，才最终诞生。"}]}]},{"ID":"20250922200841-l5gj3k8","Type":"NodeParagraph","Properties":{"id":"20250922200841-l5gj3k8","updated":"20250924091508"},"Children":[{"Type":"NodeText","Data":"其细节如下。"}]},{"ID":"20250922200841-z55mpua","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-z55mpua","updated":"20250924091508"},"Children":[{"ID":"20250922200841-z7pg3nn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-z7pg3nn","updated":"20250922200841"},"Children":[{"ID":"20250922200841-xjgk3fw","Type":"NodeParagraph","Properties":{"id":"20250922200841-xjgk3fw","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在代码数据上进行训练 (Training on code data)."},{"Type":"NodeText","Data":" 原始GPT-3模型（在纯文本上预训练）的一个主要局限在于其在复杂任务上的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理能力"},{"Type":"NodeText","Data":"不足，例如，完成代码和解决数学问题。为了增强这种能力，OpenAI于2021年7月推出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Codex"},{"Type":"NodeText","Data":"，这是一个在大型GitHub代码语料库上进行微调的GPT模型。它证明了Codex可以解决非常困难的编程问题，并在解决数学问题上带来显著的性能提升。此外，2022年1月报道了一种训练文本和代码嵌入的对比方法，该方法被证明可以改善一系列相关任务（即，线性探针分类、文本搜索和代码搜索）。实际上，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3.5模型是基于一个以代码为基础的GPT模型（即"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong code","TextMarkTextContent":"code-davinci-002"},{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"）开发的"},{"Type":"NodeText","Data":"，这表明在代码数据上进行训练是提升GPT模型能力，尤其是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理能力"},{"Type":"NodeText","Data":"的一个非常有效的实践。此外，还有一种推测认为，在代码数据上的训练可以极大地提升LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链提示"},{"Type":"NodeText","Data":"能力，但这仍需更彻底的验证来进一步研究。"}]}]},{"ID":"20250922200841-wlws3ej","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-wlws3ej","updated":"20250922200841"},"Children":[{"ID":"20250922200841-azmaccm","Type":"NodeParagraph","Properties":{"id":"20250922200841-azmaccm","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐 (Human alignment)."},{"Type":"NodeText","Data":" OpenAI在人类对齐方面的相关研究可以追溯到2017年（或更早）：一篇题为“从人类偏好中学习”的博客文章发布在OpenAI博客上，描述了一项应用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习（RL）"},{"Type":"NodeText","Data":"来从人类标注的偏好比较中学习的工作（类似于InstructGPT中图12的奖励训练步骤）。在这篇RL论文发布后不久，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"近端策略优化（PPO）"},{"Type":"NodeText","Data":"的论文于2017年7月发表，该算法现已成为从人类偏好中学习的基础RL算法。随后在2020年1月，GPT-2使用前述的RL算法进行了微调，利用人类偏好来提升GPT-2在NLP任务上的能力。同年，另一项工作以类似的方式训练了一个摘要模型以优化人类偏好。基于这些前期工作，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"InstructGPT"},{"Type":"NodeText","Data":"于2022年1月被提出，用于改进GPT-3模型的人类对齐，它正式确立了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三阶段的从人类反馈中进行强化学习（RLHF）算法"},{"Type":"NodeText","Data":"。请注意，在OpenAI的论文和文档中，“指令微调”这个词似乎很少被使用，而是被"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在人类演示上进行监督微调"},{"Type":"NodeText","Data":"（即RLHF算法的第一步）所替代。除了提升指令遵循能力，RLHF算法对于缓解LLM生成有害或有毒内容的问题特别有用，这对于LLM在实践中的安全部署至关重要。OpenAI在一篇技术文章中描述了他们对对齐研究的方法，其中总结了三个有前景的方向：“训练AI系统使用人类反馈，以辅助人类评估，以及进行对齐研究”。"}]}]}]},{"ID":"20250922200841-qnhvaqm","Type":"NodeParagraph","Properties":{"id":"20250922200841-qnhvaqm","updated":"20250924091508"},"Children":[{"Type":"NodeText","Data":"这些增强技术带来了能力更强的改进版GPT-3模型，OpenAI称之为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3.5模型"},{"Type":"NodeText","Data":"（关于OpenAI API的讨论见3.1节）。"}]},{"ID":"20250922200841-ztj0zxx","Type":"NodeParagraph","Properties":{"id":"20250922200841-ztj0zxx","updated":"20250924091508"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"The Milestones of Language Models (语言模型的里程碑)."},{"Type":"NodeText","Data":" 基于所有的探索努力，OpenAI取得了两个主要的里程碑，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-4"},{"Type":"NodeText","Data":"，它们极大地提升了现有AI系统的能力标杆。"}]},{"ID":"20250922200841-khfh4hk","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-khfh4hk","updated":"20250924091508"},"Children":[{"ID":"20250922200841-j1qdiii","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-j1qdiii","updated":"20250922200841"},"Children":[{"ID":"20250922200841-mfa7wr7","Type":"NodeParagraph","Properties":{"id":"20250922200841-mfa7wr7","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT."},{"Type":"NodeText","Data":" 2022年11月，OpenAI发布了基于GPT模型（GPT-3.5和GPT-4）的对话模型ChatGPT。正如官方博客文章所介绍的，ChatGPT的训练方式与InstructGPT类似（在原文中被称为“InstructGPT的兄弟模型”），但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专门为对话进行了优化"},{"Type":"NodeText","Data":"。他们报告了ChatGPT和InstructGPT在数据收集设置上的一个区别：将人类生成的对话（扮演用户和AI两个角色）与InstructGPT数据集结合成对话格式来训练ChatGPT。ChatGPT在与人类交流方面展现出卓越的能力：拥有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"庞大的知识储备"},{"Type":"NodeText","Data":"，擅长"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学问题推理"},{"Type":"NodeText","Data":"，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多轮对话中准确追踪上下文"},{"Type":"NodeText","Data":"，并能很好地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与人类价值观对齐"},{"Type":"NodeText","Data":"以确保安全使用。随后，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"插件机制"},{"Type":"NodeText","Data":"在ChatGPT中得到支持，通过现有的工具或应用进一步扩展了ChatGPT的能力。到目前为止，它似乎是AI历史上最强大的聊天机器人。ChatGPT的推出对未来的AI研究产生了重大影响，为探索类人AI系统带来了曙光。"}]}]},{"ID":"20250922200841-uh46jpo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-uh46jpo","updated":"20250922200841"},"Children":[{"ID":"20250922200841-bdbk0r2","Type":"NodeParagraph","Properties":{"id":"20250922200841-bdbk0r2","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-4."},{"Type":"NodeText","Data":" 作为另一个显著的进展，GPT-4于2023年3月发布，它将文本输入扩展到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态信号"},{"Type":"NodeText","Data":"。总的来说，GPT-4在解决复杂任务方面比GPT-3.5具有更强的能力，在许多评估任务上显示出巨大的性能提升。最近的一项研究通过对人类生成的问题进行定性测试，跨越了各种困难任务，调查了GPT-4的能力，并表明GPT-4可以取得比之前GPT模型更优越的性能。此外，由于经过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"六个月的迭代对齐"},{"Type":"NodeText","Data":"（在RLHF训练中加入了额外的安全奖励信号），GPT-4对恶意或挑衅性查询的响应"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更安全"},{"Type":"NodeText","Data":"。在技术报告中，OpenAI强调了如何安全地开发GPT-4，并应用了多种干预策略来缓解LLM可能存在的问题，如幻觉、隐私和过度依赖。例如，他们引入了称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"红队测试"},{"Type":"NodeText","Data":"的机制来减少有害或有毒内容的生成。作为另一个重要方面，GPT-4是基于一个完善的、具有改进优化方法的深度学习基础设施开发的。他们引入了一种称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测扩展"},{"Type":"NodeText","Data":"的新机制，可以在模型训练期间用一小部分计算量准确预测最终性能。"}]}]},{"ID":"20250922200841-mlyqkvp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-mlyqkvp","updated":"20250922200841"},"Children":[{"ID":"20250922200841-lr1tc3h","Type":"NodeParagraph","Properties":{"id":"20250922200841-lr1tc3h","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-4V, GPT-4 turbo, and beyond."},{"Type":"NodeText","Data":" 基于为GPT-4所做的工作，OpenAI于2023年9月进一步发布了GPT-4V，专注于GPT-4视觉能力的安全部署。在GPT-4V的系统卡中，它广泛讨论了与视觉增强输入相关的风险评估和缓解。特别地，GPT-4V在各种应用场景中展现出强大的视觉能力，显示了其作为强大"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态学习系统"},{"Type":"NodeText","Data":"的巨大潜力。最近，在"}]}]}]},{"ID":"20250922200841-u48ngxg","Type":"NodeBlockquote","Properties":{"id":"20250922200841-u48ngxg","updated":"20250924091508"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922200841-zk6bfmy","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200841-zk6bfmy","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922200841-her12ks","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200841-her12ks","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力增强的两大支柱：代码与对齐"}]},{"ID":"20250922200841-ruw4fpb","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-ruw4fpb","updated":"20250922200841"},"Children":[{"ID":"20250922200841-y154zdl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-y154zdl","updated":"20250922200841"},"Children":[{"ID":"20250922200841-hzx0hcq","Type":"NodeParagraph","Properties":{"id":"20250922200841-hzx0hcq","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码训练 = 逻辑推理"},{"Type":"NodeText","Data":": GPT-3通过在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码数据"},{"Type":"NodeText","Data":"上训练，进化为Codex，并最终将这种能力融入GPT-3.5。这揭示了一个深刻的洞见："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码是结构化、逻辑化的语言，训练模型理解代码，能极大地提升其逻辑推理和思维链能力"},{"Type":"NodeText","Data":"。这是模型从“文科生”向“理科生”转变的关键一步。"}]}]},{"ID":"20250922200841-8f1bwjq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-8f1bwjq","updated":"20250922200841"},"Children":[{"ID":"20250922200841-nanwzfy","Type":"NodeParagraph","Properties":{"id":"20250922200841-nanwzfy","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐 = 可靠与安全"},{"Type":"NodeText","Data":": 通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF"},{"Type":"NodeText","Data":"技术，模型从“预测下一个词”的原始目标，转变为“生成人类偏好的内容”。这解决了LLM最关键的两个问题："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可用性"},{"Type":"NodeText","Data":"（更好地遵循指令）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"安全性"},{"Type":"NodeText","Data":"（避免有害内容）。这是让LLM走出实验室，能够被公众安全使用的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“社会化训练”"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922200841-z61ub7i","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922200841-z61ub7i","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"里程碑的意义：ChatGPT与GPT-4"}]},{"ID":"20250922200841-da11yzg","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-da11yzg","updated":"20250922200841"},"Children":[{"ID":"20250922200841-izmh5v9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-izmh5v9","updated":"20250922200841"},"Children":[{"ID":"20250922200841-lex56dr","Type":"NodeParagraph","Properties":{"id":"20250922200841-lex56dr","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200841-2gflvmx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-2gflvmx","updated":"20250922200841"},"Children":[{"ID":"20250922200841-69gkp1y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-69gkp1y","updated":"20250922200841"},"Children":[{"ID":"20250922200841-3rzhzwb","Type":"NodeParagraph","Properties":{"id":"20250922200841-3rzhzwb","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"集大成者"},{"Type":"NodeText","Data":": 它是GPT-3.5所有能力的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"产品化"},{"Type":"NodeText","Data":"体现。"}]}]},{"ID":"20250922200841-0oe7uym","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-0oe7uym","updated":"20250922200841"},"Children":[{"ID":"20250922200841-66kzeu1","Type":"NodeParagraph","Properties":{"id":"20250922200841-66kzeu1","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话优化"},{"Type":"NodeText","Data":": 专门为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话"},{"Type":"NodeText","Data":"场景进行优化，使其交互体验远超前代模型。"}]}]},{"ID":"20250922200841-wdfvntn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-wdfvntn","updated":"20250922200841"},"Children":[{"ID":"20250922200841-qjr04j8","Type":"NodeParagraph","Properties":{"id":"20250922200841-qjr04j8","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生态系统"},{"Type":"NodeText","Data":": 通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"插件机制"},{"Type":"NodeText","Data":"，它从一个聊天机器人演变为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平台"},{"Type":"NodeText","Data":"，连接了各种外部能力，预示了未来AI应用的新范式。"}]}]}]}]},{"ID":"20250922200841-lkztskb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-lkztskb","updated":"20250922200841"},"Children":[{"ID":"20250922200841-v44e6ox","Type":"NodeParagraph","Properties":{"id":"20250922200841-v44e6ox","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-4"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922200841-yc5qpbm","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-yc5qpbm","updated":"20250922200841"},"Children":[{"ID":"20250922200841-qh8t6f9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-qh8t6f9","updated":"20250922200841"},"Children":[{"ID":"20250922200841-7054luv","Type":"NodeParagraph","Properties":{"id":"20250922200841-7054luv","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力的新高峰"},{"Type":"NodeText","Data":": 在所有维度上都超越了GPT-3.5，尤其是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理"},{"Type":"NodeText","Data":"能力上。"}]}]},{"ID":"20250922200841-yfk1zxz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-yfk1zxz","updated":"20250922200841"},"Children":[{"ID":"20250922200841-5vk3njp","Type":"NodeParagraph","Properties":{"id":"20250922200841-5vk3njp","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态的突破"},{"Type":"NodeText","Data":": 首次原生支持"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉输入"},{"Type":"NodeText","Data":"，使LLM的感知能力从单一的文本扩展到了图像，是通往更通用AI的重要一步。"}]}]},{"ID":"20250922200841-bv1jvha","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-bv1jvha","updated":"20250922200841"},"Children":[{"ID":"20250922200841-fabaak1","Type":"NodeParagraph","Properties":{"id":"20250922200841-fabaak1","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更强的安全性"},{"Type":"NodeText","Data":": 经过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长达六个月的迭代对齐和红队测试"},{"Type":"NodeText","Data":"，其安全性远超前代。"}]}]},{"ID":"20250922200841-vsutp9i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-vsutp9i","updated":"20250922200841"},"Children":[{"ID":"20250922200841-kc8bfi7","Type":"NodeParagraph","Properties":{"id":"20250922200841-kc8bfi7","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工程的胜利"},{"Type":"NodeText","Data":": 引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“可预测扩展”"},{"Type":"NodeText","Data":"机制，表明OpenAI在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模模型训练的工程科学"},{"Type":"NodeText","Data":"上取得了重大突破，使得训练万亿参数模型的过程更加可控。"}]}]}]}]},{"ID":"20250922200841-jxnjhyw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-jxnjhyw","updated":"20250922200841"},"Children":[{"ID":"20250922200841-45y117w","Type":"NodeParagraph","Properties":{"id":"20250922200841-45y117w","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续迭代"},{"Type":"NodeText","Data":": GPT-4V, GPT-4 Turbo等后续版本的发布，表明LLM的演进是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"快速迭代"},{"Type":"NodeText","Data":"的过程，不断在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力、效率、多模态"},{"Type":"NodeText","Data":"等方面进行优化和扩展。"}]}]}]}]},{"ID":"20250922200841-e5un72f","Type":"NodeBlockquote","Properties":{"id":"20250922200841-e5un72f","updated":"20250924091508"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922200841-qd18jml","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922200841-qd18jml","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922200841-gkwq3hw","Type":"NodeParagraph","Properties":{"id":"20250922200841-gkwq3hw","updated":"20250922200841"},"Children":[{"Type":"NodeText","Data":"第六部分通过深入剖析GPT系列模型的演进，特别是从GPT-3到GPT-4的迭代，为我们揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"现代顶尖大型语言模型是如何“炼成”的"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922200841-conovr1","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922200841-conovr1","updated":"20250922200841"},"Children":[{"ID":"20250922200841-1tr13g2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922200841-1tr13g2","updated":"20250922200841"},"Children":[{"ID":"20250922200841-bc6lv36","Type":"NodeParagraph","Properties":{"id":"20250922200841-bc6lv36","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“大”到“强”的路径"},{"Type":"NodeText","Data":": 文章清晰地指出，仅仅拥有一个“大”模型（GPT-3）是不够的。要让模型变得真正“强大”和“可用”，必须经历两个关键的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“能力增强”"},{"Type":"NodeText","Data":"阶段："}]},{"ID":"20250922200841-xgx138f","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-xgx138f","updated":"20250922200841"},"Children":[{"ID":"20250922200841-wjru976","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-wjru976","updated":"20250922200841"},"Children":[{"ID":"20250922200841-1aodg0r","Type":"NodeParagraph","Properties":{"id":"20250922200841-1aodg0r","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码训练"},{"Type":"NodeText","Data":"：赋予模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逻辑和推理"},{"Type":"NodeText","Data":"的“骨架”。"}]}]},{"ID":"20250922200841-026vbmw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-026vbmw","updated":"20250922200841"},"Children":[{"ID":"20250922200841-d5rthgl","Type":"NodeParagraph","Properties":{"id":"20250922200841-d5rthgl","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐 (RLHF)"},{"Type":"NodeText","Data":"：为模型注入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"价值观和安全"},{"Type":"NodeText","Data":"的“灵魂”。\n这个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“基础模型 + 代码增强 + 人类对齐”"},{"Type":"NodeText","Data":"的三步范式，可以看作是当前业界打造SOTA（State-of-the-art）级别LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"黄金标准流程"},{"Type":"NodeText","Data":"。图4的演进图直观地展示了这一路径。"}]}]}]}]},{"ID":"20250922200841-ejmrogm","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922200841-ejmrogm","updated":"20250922200841"},"Children":[{"ID":"20250922200841-ddslivy","Type":"NodeParagraph","Properties":{"id":"20250922200841-ddslivy","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"产品化的最后一公里"},{"Type":"NodeText","Data":": ChatGPT的成功不仅仅是技术上的胜利，更是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"产品化"},{"Type":"NodeText","Data":"的胜利。它通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专门的对话优化"},{"Type":"NodeText","Data":"，极大地改善了用户体验，使其成为历史上第一个“出圈”的AI应用。这说明，先进的技术需要与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优秀的产品设计"},{"Type":"NodeText","Data":"相结合，才能真正释放其价值。"}]}]},{"ID":"20250922200841-67l4hi4","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922200841-67l4hi4","updated":"20250922200841"},"Children":[{"ID":"20250922200841-4p3w63d","Type":"NodeParagraph","Properties":{"id":"20250922200841-4p3w63d","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态与生态的未来"},{"Type":"NodeText","Data":": GPT-4的发布和ChatGPT插件机制的推出，共同指向了LLM的两个明确的未来方向："}]},{"ID":"20250922200841-r8n851l","Type":"NodeList","ListData":{},"Properties":{"id":"20250922200841-r8n851l","updated":"20250922200841"},"Children":[{"ID":"20250922200841-tccrkxm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-tccrkxm","updated":"20250922200841"},"Children":[{"ID":"20250922200841-8km7pjv","Type":"NodeParagraph","Properties":{"id":"20250922200841-8km7pjv","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态融合"},{"Type":"NodeText","Data":": AI将不再局限于文本，而是能够理解和处理包括图像、声音在内的多模态信息，更接近人类的感知方式。"}]}]},{"ID":"20250922200841-zfh3jq4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922200841-zfh3jq4","updated":"20250922200841"},"Children":[{"ID":"20250922200841-n9y7wqo","Type":"NodeParagraph","Properties":{"id":"20250922200841-n9y7wqo","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平台化与生态系统"},{"Type":"NodeText","Data":": LLM将成为连接各种数字服务的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"智能中枢"},{"Type":"NodeText","Data":"，通过API和插件构建一个庞大的应用生态系统。"}]}]}]}]},{"ID":"20250922200841-j7ttpgb","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922200841-j7ttpgb","updated":"20250922200841"},"Children":[{"ID":"20250922200841-hq94s23","Type":"NodeParagraph","Properties":{"id":"20250922200841-hq94s23","updated":"20250922200841"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工程科学的重要性"},{"Type":"NodeText","Data":": GPT-4引入的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“可预测扩展”"},{"Type":"NodeText","Data":"技术，虽然是一个工程细节，但意义重大。它标志着训练超大规模模型正在从一门“艺术”和“炼金术”，逐渐转变为一门"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测、可度量的“科学”"},{"Type":"NodeText","Data":"。这对于未来持续、高效地扩展模型至关重要。"}]}]}]},{"ID":"20250922200841-sa4ef9k","Type":"NodeParagraph","Properties":{"id":"20250922200841-sa4ef9k","updated":"20250922200841"},"Children":[{"Type":"NodeText","Data":"总结而言，第六部分提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“解剖麻雀”"},{"Type":"NodeText","Data":"式的案例分析。通过解剖GPT系列这只“麻雀”，我们不仅看到了其内部的精妙结构（技术演进），更理解了其成长和成功的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心逻辑"},{"Type":"NodeText","Data":"。它告诉我们，最顶尖的LLM是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"巨大规模、逻辑推理能力、人类价值观对齐和优秀产品设计"},{"Type":"NodeText","Data":"的集大成者。"}]}]},{"ID":"20250922201634-12j84c0","Type":"NodeParagraph","Properties":{"id":"20250922201634-12j84c0","updated":"20250924092648"},"Children":[{"Type":"NodeText","Data":"2023年11月，OpenAI在DevDay上发布了升级版的GPT-4模型，名为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-4 Turbo"},{"Type":"NodeText","Data":"，并进行了一系列技术改进。GPT-4 Turbo的特点在于其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提升的模型能力"},{"Type":"NodeText","Data":"（比GPT-4更强）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩展的知识源"},{"Type":"NodeText","Data":"（截至2023年4月）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长上下文窗口"},{"Type":"NodeText","Data":"（高达128k词元）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化的模型性能"},{"Type":"NodeText","Data":"（更便宜的价格），以及其他有用的功能更新（函数调用、可复现输出等）。与此同时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Assistants API"},{"Type":"NodeText","Data":"也被推出，以简化类智能体助手的快速开发。通过这个API，开发者可以在他们的应用中轻松创建目标导向的助手，利用特定的指令、额外的知识和工具。此外，这次新版本还增强了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态能力"},{"Type":"NodeText","Data":"（看、听、说），由GPT-4 Turbo with vision、DALL·E 3、文本到语音（TTS）和语音样本收听功能支持。这些改进极大地扩展了GPT模型的能力范围并提升了其任务性能。更重要的是，随着模型、API和功能的升级，应用生态系统将得到极大的加强。"}]},{"ID":"20250922201634-rxwh8pd","Type":"NodeParagraph","Properties":{"id":"20250922201634-rxwh8pd","updated":"20250924092648"},"Children":[{"Type":"NodeText","Data":"尽管取得了巨大进展，但这些高级LLM仍然存在局限性，例如，在某些特定情境下会产生带有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"事实错误"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幻觉"},{"Type":"NodeText","Data":"或潜在的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"风险性回应"},{"Type":"NodeText","Data":"。LLM的更多局限性或问题将在第7节中讨论。这给开发更强大、更安全的LLM带来了长期的研究挑战。从工程角度看，OpenAI采用了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"迭代部署策略"},{"Type":"NodeText","Data":"来开发模型和产品，遵循一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"五阶段的开发和部署生命周期"},{"Type":"NodeText","Data":"，旨在有效降低使用模型的潜在风险。接下来，我们将深入探讨技术细节，以便对它们的发展方式有一个具体的理解。"}]},{"ID":"20250922201634-uu7q58l","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922201634-uu7q58l","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3 RESOURCES OF LLMS (LLM的资源)"}]},{"ID":"20250922201634-dss0qo9","Type":"NodeParagraph","Properties":{"id":"20250922201634-dss0qo9","updated":"20250922201641"},"Children":[{"Type":"NodeText","Data":"考虑到开发或复现LLM所面临的技术挑战和对计算资源的巨大需求，这绝非易事。一个可行的方法是从现有的LLM中学习经验，并重用公开可用的资源进行增量开发或实验研究。在本节中，我们简要总结了用于开发LLM的公开可用资源，包括模型检查点（或API）、语料库和库。"}]},{"ID":"20250922201634-q4rklsy","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922201634-q4rklsy","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.1 Publicly Available Model Checkpoints or APIs (公开可用的模型检查点或API)"}]},{"ID":"20250922201634-rdt8om9","Type":"NodeParagraph","Properties":{"id":"20250922201634-rdt8om9","updated":"20250922201641"},"Children":[{"Type":"NodeText","Data":"考虑到模型预训练的巨大成本，训练有素的模型检查点对于研究社区研究和开发LLM至关重要。由于空间限制，我们只能选择性地讨论几个代表性的LLM。此外，对于推理，我们可以直接使用公共API来执行我们的任务，而无需在本地运行模型。接下来，我们将介绍公开可用的模型检查点和API。"}]},{"ID":"20250922201634-vq8l1dy","Type":"NodeParagraph","Properties":{"id":"20250922201634-vq8l1dy","updated":"20250922201641"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Publicly Available Model Checkpoints (公开可用的模型检查点)."},{"Type":"NodeText","Data":" 为了帮助研究人员根据资源预算和使用需求选择合适的模型，我们重点讨论模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数大小、训练所需的数据和计算资源、模型采用的相关技术及其在下游任务中的性能评估"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922201634-d20wndp","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-d20wndp","updated":"20250922201641"},"Children":[{"ID":"20250922201634-4cvkw0e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-4cvkw0e","updated":"20250922201634"},"Children":[{"ID":"20250922201634-su9ayvj","Type":"NodeParagraph","Properties":{"id":"20250922201634-su9ayvj","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA."},{"Type":"NodeText","Data":" LLaMA系列模型因其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有效性"},{"Type":"NodeText","Data":"而广受欢迎并受到广泛关注。从LLaMA、LLaMA-2、LLaMA-3到LLaMA-3.1，模型不断更新，开发仍在进行中。随着参数的增加（最大版本有405B）、更多的预训练词元（15T词元）和扩展的上下文窗口（128K），"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA-3.1"},{"Type":"NodeText","Data":"的能力得到了显著增强，并且它还集成了与模型协同工作的新组件，包括新的安全和保障工具。在评估中，LLaMA-3.1（405B版本）在各种基准（例如，MMLU, GSM8k, 和 HumanEval）上取得了与著名的闭源LLM（如GPT-4, GPT-4o, 和 Claude 3.5 Sonnet）相媲美的性能。LLaMA（65B版本）的预训练涉及2,048个A100-80G GPU，而LLaMA-3.1（405B版本）则涉及超过16,000个H100 GPU。"}]}]},{"ID":"20250922201634-l3hm2xe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-l3hm2xe","updated":"20250922201634"},"Children":[{"ID":"20250922201634-iszyafu","Type":"NodeParagraph","Properties":{"id":"20250922201634-iszyafu","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mistral."},{"Type":"NodeText","Data":" Mistral系列包括Mistral（7B）、Mistral NeMo（12B）、Mistral Large 2（123B）和Mixtral（8×7B和8×22B），它们因在各种主流基准（例如，MMLU和GSM8k）上的强大性能而广为人知。Mistral NeMo的特点是在12B的参数规模下拥有128K的长上下文窗口。虽然Mistral NeMo在训练时考虑了量化感知，但它能够在不牺牲性能的情况下实现FP8推理。Mistral Large 2是Mistral系列中最大且最强大的模型，支持11种自然语言和超过80种编程语言。Mixtral是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稀疏混合专家（SMoE）模型"},{"Type":"NodeText","Data":"，在推理过程中只激活部分参数，使其与同等大小的密集模型相比更加高效。"}]}]},{"ID":"20250922201634-85htfc3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-85htfc3","updated":"20250922201634"},"Children":[{"ID":"20250922201634-m3bfifz","Type":"NodeParagraph","Properties":{"id":"20250922201634-m3bfifz","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Gemma."},{"Type":"NodeText","Data":" Gemma是一个轻量级、强大且开放的模型系列，包括Gemma-1（2B和7B）和Gemma-2（2B, 9B, 和27B）。在预训练阶段，Gemma-2的2B、9B和27B版本分别在2T、8T和13T主要为英语的词元上进行训练。Gemma-2的最大版本在6144个TPUv5p芯片上训练。Gemma-2在多个基准（例如，ARC-c, MMLU, 和GSM8k）上取得了优异的性能。"}]}]},{"ID":"20250922201634-9qomoqv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-9qomoqv","updated":"20250922201634"},"Children":[{"ID":"20250922201634-zaio6zr","Type":"NodeParagraph","Properties":{"id":"20250922201634-zaio6zr","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Qwen."},{"Type":"NodeText","Data":" Qwen是一个开源的大型模型系列，包括Qwen（7B到72B）、Qwen1.5（0.5B到110B）、Qwen2（0.5B到72B）和Qwen2.5（0.5B到72B）。Qwen2.5是Qwen最新的LLM集合，它在高达18T的词元上进行预训练。与Qwen2相比，Qwen2.5在知识保留以及编码和数学能力方面表现出显著的提升。Qwen2.5在指令遵循、长文本生成（超过8K词元）、结构化数据理解和生成（例如，JSON）方面也显示出巨大改进。"}]}]},{"ID":"20250922201634-a33afuc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-a33afuc","updated":"20250922201634"},"Children":[{"ID":"20250922201634-8lxrmpi","Type":"NodeParagraph","Properties":{"id":"20250922201634-8lxrmpi","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GLM."},{"Type":"NodeText","Data":" GLM是一系列在英语和中文方面都具有全面能力的LLM。GLM已升级到其第四代模型GLM-4，参数规模高达9B，拥有出色的对话能力。它在语义、数学、推理、代码和知识等多个角度的评估中取得了优异的性能。"}]}]}]},{"ID":"20250922201634-s2kcwjk","Type":"NodeBlockquote","Properties":{"id":"20250922201634-s2kcwjk","updated":"20250922201641"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922201634-dag8kxy","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922201634-dag8kxy","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922201634-1ncr4te","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922201634-1ncr4te","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-4 Turbo的升级亮点"}]},{"ID":"20250922201634-o8qjs0i","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-o8qjs0i","updated":"20250922201634"},"Children":[{"ID":"20250922201634-095k179","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-095k179","updated":"20250922201634"},"Children":[{"ID":"20250922201634-lll6364","Type":"NodeParagraph","Properties":{"id":"20250922201634-lll6364","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面进化"},{"Type":"NodeText","Data":": GPT-4 Turbo不仅仅是简单的性能提升，而是一次"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全方位的升级"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922201634-vhcfce7","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-vhcfce7","updated":"20250922201634"},"Children":[{"ID":"20250922201634-475rdt4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-475rdt4","updated":"20250922201634"},"Children":[{"ID":"20250922201634-hbh4sax","Type":"NodeParagraph","Properties":{"id":"20250922201634-hbh4sax","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更强 (More Capable)"},{"Type":"NodeText","Data":": 核心能力超越GPT-4。"}]}]},{"ID":"20250922201634-f9ut17y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-f9ut17y","updated":"20250922201634"},"Children":[{"ID":"20250922201634-2culfap","Type":"NodeParagraph","Properties":{"id":"20250922201634-2culfap","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更新 (Extended Knowledge)"},{"Type":"NodeText","Data":": 知识库更新到2023年4月，缓解了时效性问题。"}]}]},{"ID":"20250922201634-fdoi98e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-fdoi98e","updated":"20250922201634"},"Children":[{"ID":"20250922201634-i4s3aw4","Type":"NodeParagraph","Properties":{"id":"20250922201634-i4s3aw4","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更长 (Long Context)"},{"Type":"NodeText","Data":": 上下文窗口扩展到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"128K"},{"Type":"NodeText","Data":"，处理长文档的能力大幅增强。"}]}]},{"ID":"20250922201634-0k78rxt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-0k78rxt","updated":"20250922201634"},"Children":[{"ID":"20250922201634-qwc77a6","Type":"NodeParagraph","Properties":{"id":"20250922201634-qwc77a6","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更便宜 (Cheaper Price)"},{"Type":"NodeText","Data":": 降低了使用成本，推动了更广泛的应用。"}]}]}]}]},{"ID":"20250922201634-wkblqlq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-wkblqlq","updated":"20250922201634"},"Children":[{"ID":"20250922201634-2a4vfx4","Type":"NodeParagraph","Properties":{"id":"20250922201634-2a4vfx4","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生态系统构建"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Assistants API"},{"Type":"NodeText","Data":"的推出是关键一步。它将LLM从一个“模型”变成了一个可以轻松集成的“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"智能助手开发平台"},{"Type":"NodeText","Data":"”，极大地降低了构建LLM应用的门槛，旨在催生一个繁荣的应用生态。"}]}]},{"ID":"20250922201634-vjr5yjl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-vjr5yjl","updated":"20250922201634"},"Children":[{"ID":"20250922201634-75qjuyn","Type":"NodeParagraph","Properties":{"id":"20250922201634-75qjuyn","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"迈向多模态"},{"Type":"NodeText","Data":": 集成DALL·E 3、TTS等功能，使模型具备了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"看、听、说"},{"Type":"NodeText","Data":"的能力，标志着其正在从一个语言模型向一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态交互智能体"},{"Type":"NodeText","Data":"演进。"}]}]}]},{"ID":"20250922201634-od0jhh1","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922201634-od0jhh1","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源LLM的“百家争鸣”"}]},{"ID":"20250922201634-wibyebs","Type":"NodeParagraph","Properties":{"id":"20250922201634-wibyebs","updated":"20250922201634"},"Children":[{"Type":"NodeText","Data":"这部分内容展示了开源社区在追赶顶尖闭源模型方面所做的巨大努力和取得的显著成就，呈现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“百家争鸣”"},{"Type":"NodeText","Data":"的繁荣景象。"}]},{"ID":"20250922201634-hx0a7d8","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-hx0a7d8","updated":"20250922201634"},"Children":[{"ID":"20250922201634-s8x6sl6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-s8x6sl6","updated":"20250922201634"},"Children":[{"ID":"20250922201634-2my1xev","Type":"NodeParagraph","Properties":{"id":"20250922201634-2my1xev","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA系列 (Meta)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922201634-t9hntp8","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-t9hntp8","updated":"20250922201634"},"Children":[{"ID":"20250922201634-11jyoz3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-11jyoz3","updated":"20250922201634"},"Children":[{"ID":"20250922201634-dsdkrx3","Type":"NodeParagraph","Properties":{"id":"20250922201634-dsdkrx3","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源标杆"},{"Type":"NodeText","Data":": LLaMA系列已成为开源LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"事实标准和基石"},{"Type":"NodeText","Data":"。其开放性和高性能催生了庞大的下游生态。"}]}]},{"ID":"20250922201634-ljs3x6u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-ljs3x6u","updated":"20250922201634"},"Children":[{"ID":"20250922201634-gf86o9p","Type":"NodeParagraph","Properties":{"id":"20250922201634-gf86o9p","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能追赶"},{"Type":"NodeText","Data":": 最新的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA-3.1"},{"Type":"NodeText","Data":"在性能上已经能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"媲美"},{"Type":"NodeText","Data":"GPT-4、Claude 3.5等顶级闭源模型，证明了开源路线的巨大潜力。"}]}]},{"ID":"20250922201634-eb077k8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-eb077k8","updated":"20250922201634"},"Children":[{"ID":"20250922201634-e8h1wi5","Type":"NodeParagraph","Properties":{"id":"20250922201634-e8h1wi5","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"资源投入"},{"Type":"NodeText","Data":": 训练LLaMA-3.1使用了超过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"16,000个H100 GPU"},{"Type":"NodeText","Data":"，这表明顶级的开源模型同样需要巨大的计算资源投入。"}]}]}]}]},{"ID":"20250922201634-6ncmizx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-6ncmizx","updated":"20250922201634"},"Children":[{"ID":"20250922201634-92mq61b","Type":"NodeParagraph","Properties":{"id":"20250922201634-92mq61b","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mistral系列 (Mistral AI)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922201634-67dqly3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-67dqly3","updated":"20250922201634"},"Children":[{"ID":"20250922201634-jhp75q0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-jhp75q0","updated":"20250922201634"},"Children":[{"ID":"20250922201634-4dsvpjv","Type":"NodeParagraph","Properties":{"id":"20250922201634-4dsvpjv","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"效率的探索"},{"Type":"NodeText","Data":": Mistral以其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效的模型设计"},{"Type":"NodeText","Data":"而闻名。特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mixtral"},{"Type":"NodeText","Data":"采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稀疏混合专家（SMoE）"},{"Type":"NodeText","Data":"架构，能在保持高性能的同时，显著降低推理成本，为模型的高效部署提供了新思路。"}]}]}]}]},{"ID":"20250922201634-ellnlz4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-ellnlz4","updated":"20250922201634"},"Children":[{"ID":"20250922201634-226d9dl","Type":"NodeParagraph","Properties":{"id":"20250922201634-226d9dl","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Gemma系列 (Google)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922201634-ijw31mu","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-ijw31mu","updated":"20250922201634"},"Children":[{"ID":"20250922201634-gygjla8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-gygjla8","updated":"20250922201634"},"Children":[{"ID":"20250922201634-vw7bl4u","Type":"NodeParagraph","Properties":{"id":"20250922201634-vw7bl4u","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"轻量而强大"},{"Type":"NodeText","Data":": Gemma系列主打"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"轻量级"},{"Type":"NodeText","Data":"，证明了即使是较小规模的模型（2B, 9B），只要训练得当，也能在关键基准上取得优异性能，适合在资源受限的环境下部署。"}]}]}]}]},{"ID":"20250922201634-r0alkc3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-r0alkc3","updated":"20250922201634"},"Children":[{"ID":"20250922201634-uzzx55z","Type":"NodeParagraph","Properties":{"id":"20250922201634-uzzx55z","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Qwen (通义千问) 系列 (Alibaba)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922201634-wvzx2ct","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-wvzx2ct","updated":"20250922201634"},"Children":[{"ID":"20250922201634-5srf5xy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-5srf5xy","updated":"20250922201634"},"Children":[{"ID":"20250922201634-u4pjz62","Type":"NodeParagraph","Properties":{"id":"20250922201634-u4pjz62","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面发展"},{"Type":"NodeText","Data":": Qwen系列模型覆盖了从0.5B到72B的广泛尺寸，并且在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令遵循、长文本、代码、数学"},{"Type":"NodeText","Data":"等多个维度上持续改进，展现了其作为通用模型的全面能力。"}]}]}]}]},{"ID":"20250922201634-popsnol","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-popsnol","updated":"20250922201634"},"Children":[{"ID":"20250922201634-8weggxm","Type":"NodeParagraph","Properties":{"id":"20250922201634-8weggxm","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GLM系列 (智谱AI)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922201634-0o22omz","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-0o22omz","updated":"20250922201634"},"Children":[{"ID":"20250922201634-j47ed9n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-j47ed9n","updated":"20250922201634"},"Children":[{"ID":"20250922201634-3ac3va0","Type":"NodeParagraph","Properties":{"id":"20250922201634-3ac3va0","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"中英双语优势"},{"Type":"NodeText","Data":": GLM系列以其出色的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"中英双语能力"},{"Type":"NodeText","Data":"为特色，并在对话能力上表现突出，满足了特定语言市场的需求。"}]}]}]}]}]}]},{"ID":"20250922201634-8273kzm","Type":"NodeBlockquote","Properties":{"id":"20250922201634-8273kzm","updated":"20250922201641"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922201634-k2n62bb","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922201634-k2n62bb","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922201634-9ohk6pw","Type":"NodeParagraph","Properties":{"id":"20250922201634-9ohk6pw","updated":"20250922201634"},"Children":[{"Type":"NodeText","Data":"第七部分的内容可以分为两大块："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭源模型的持续引领"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源模型的奋起直追"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922201634-7ed5mqt","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922201634-7ed5mqt","updated":"20250922201634"},"Children":[{"ID":"20250922201634-hwwsjfi","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922201634-hwwsjfi","updated":"20250922201634"},"Children":[{"ID":"20250922201634-73qbre2","Type":"NodeParagraph","Properties":{"id":"20250922201634-73qbre2","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭源模型的“生态化”战略"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922201634-v5jtgpy","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-v5jtgpy","updated":"20250922201634"},"Children":[{"ID":"20250922201634-avfu366","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-avfu366","updated":"20250922201634"},"Children":[{"ID":"20250922201634-mvz8hzu","Type":"NodeParagraph","Properties":{"id":"20250922201634-mvz8hzu","updated":"20250922201634"},"Children":[{"Type":"NodeText","Data":"以GPT-4 Turbo和Assistants API为代表，顶尖的闭源模型已经超越了单纯的“模型能力”竞赛，进入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“生态系统构建”"},{"Type":"NodeText","Data":"的新阶段。它们的策略核心是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过API和开发工具，将强大的AI能力赋能给千行百业的开发者，从而构建一个围绕自身模型的应用帝国。"},{"Type":"NodeText","Data":" 这是一种从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术提供者"},{"Type":"NodeText","Data":"向"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平台构建者"},{"Type":"NodeText","Data":"的战略转变。多模态能力的整合进一步巩固了它们的技术护城河。"}]}]}]}]},{"ID":"20250922201634-6usb09u","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922201634-6usb09u","updated":"20250922201634"},"Children":[{"ID":"20250922201634-6r29mrv","Type":"NodeParagraph","Properties":{"id":"20250922201634-6r29mrv","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源模型的“多元化”发展"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922201634-d5wayyu","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-d5wayyu","updated":"20250922201634"},"Children":[{"ID":"20250922201634-rb31cpj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-rb31cpj","updated":"20250922201634"},"Children":[{"ID":"20250922201634-9rygx51","Type":"NodeParagraph","Properties":{"id":"20250922201634-9rygx51","updated":"20250922201634"},"Children":[{"Type":"NodeText","Data":"开源社区则呈现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多元化和差异化"},{"Type":"NodeText","Data":"的竞争格局。"}]}]},{"ID":"20250922201634-dbq0c8d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-dbq0c8d","updated":"20250922201634"},"Children":[{"ID":"20250922201634-ft1k8xf","Type":"NodeParagraph","Properties":{"id":"20250922201634-ft1k8xf","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Meta (LLaMA)"},{"Type":"NodeText","Data":" 扮演着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“规则挑战者”"},{"Type":"NodeText","Data":"的角色，通过提供性能逼近顶尖闭源模型的开源模型，极大地推动了整个领域的创新和普及。"}]}]},{"ID":"20250922201634-2sktbyr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-2sktbyr","updated":"20250922201634"},"Children":[{"ID":"20250922201634-twu3wk7","Type":"NodeParagraph","Properties":{"id":"20250922201634-twu3wk7","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mistral AI"},{"Type":"NodeText","Data":" 则专注于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“效率创新”"},{"Type":"NodeText","Data":"，其SMoE架构为解决LLM高昂的部署成本问题提供了有效的解决方案。"}]}]},{"ID":"20250922201634-2v8v2jy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-2v8v2jy","updated":"20250922201634"},"Children":[{"ID":"20250922201634-dlph8c7","Type":"NodeParagraph","Properties":{"id":"20250922201634-dlph8c7","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Google (Gemma)、阿里巴巴 (Qwen)、智谱AI (GLM)"},{"Type":"NodeText","Data":" 等则从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同尺寸、不同语言、不同能力维度"},{"Type":"NodeText","Data":"切入，满足了市场的多样化需求。\n这种“百家争鸣”的局面极大地促进了技术的快速迭代，并为开发者和研究者提供了丰富的选择。"}]}]}]}]},{"ID":"20250922201634-c3qj4u8","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922201634-c3qj4u8","updated":"20250922201634"},"Children":[{"ID":"20250922201634-34rdvby","Type":"NodeParagraph","Properties":{"id":"20250922201634-34rdvby","updated":"20250922201634"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"共同的挑战与未来"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922201634-ffgdm3b","Type":"NodeList","ListData":{},"Properties":{"id":"20250922201634-ffgdm3b","updated":"20250922201634"},"Children":[{"ID":"20250922201634-qc3cofo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-qc3cofo","updated":"20250922201634"},"Children":[{"ID":"20250922201634-0kqdhmf","Type":"NodeParagraph","Properties":{"id":"20250922201634-0kqdhmf","updated":"20250922201634"},"Children":[{"Type":"NodeText","Data":"无论是闭源还是开源，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幻觉、安全性和对齐"},{"Type":"NodeText","Data":"仍然是所有LLM面临的共同挑战。OpenAI的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"迭代部署"},{"Type":"NodeText","Data":"和安全工具的开发，反映了业界对这些问题的日益重视。"}]}]},{"ID":"20250922201634-mk78xsn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922201634-mk78xsn","updated":"20250922201634"},"Children":[{"ID":"20250922201634-03r702l","Type":"NodeParagraph","Properties":{"id":"20250922201634-03r702l","updated":"20250922201634"},"Children":[{"Type":"NodeText","Data":"从技术趋势看，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长上下文、多模态、高效推理（如SMoE）"},{"Type":"NodeText","Data":"是所有顶尖模型共同追求的方向。"}]}]}]}]}]},{"ID":"20250922201634-d33as8b","Type":"NodeParagraph","Properties":{"id":"20250922201634-d33as8b","updated":"20250922201634"},"Children":[{"Type":"NodeText","Data":"总结而言，第七部分描绘了一幅生动的LLM产业图景："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以OpenAI为代表的闭源巨头正在通过平台化和生态化构建其商业帝国，而以LLaMA为核心的开源力量则通过多元化和差异化的创新奋起直追，共同推动着整个领域以前所未有的速度向前发展。"}]}]},{"ID":"20250922202006-sj33ca9","Type":"NodeParagraph","Properties":{"id":"20250922202006-sj33ca9","updated":"20250924093324"},"Children":[{"Type":"NodeText","Data":"除了基础模型GLM-4-9B外，它还开源了经过人类偏好对齐的模型GLM-4-9B-Chat，以及长上下文对话模型GLM-4-9B-Chat-1M。"}]},{"ID":"20250922202006-iw8su14","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202006-iw8su14","updated":"20250924093324"},"Children":[{"ID":"20250922202005-78kbzrw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-78kbzrw","updated":"20250922202005"},"Children":[{"ID":"20250922202006-a2d2rpf","Type":"NodeParagraph","Properties":{"id":"20250922202006-a2d2rpf","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"百川 (Baichuan)."},{"Type":"NodeText","Data":" 百川是一系列开源的双语LLM，最新版本是百川-2。百川和百川-2都有两种可用的参数大小（7B和13B）。百川支持中文和英文，预训练数据达到1.2万亿词元。此外，百川-2将其预训练数据扩展到2.6万亿词元。百川-2在所有评估基准上都超越了百川，展现了出色的多语言能力，并在法律和医疗等垂直应用领域显示出潜力（例如，JEC-QA和MedQA）。"}]}]}]},{"ID":"20250922202006-nihu49e","Type":"NodeParagraph","Properties":{"id":"20250922202006-nihu49e","updated":"20250924093324"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA Model Family (LLaMA模型家族)."},{"Type":"NodeText","Data":" Meta AI于2023年2月推出了LLaMA模型集合，包含四种大小（7B, 13B, 30B and 65B）。自发布以来，LLaMA吸引了研究界和工业界的广泛关注。LLaMA模型在各种开放基准上取得了非常出色的表现，至今已成为最受欢迎的开放语言模型。大量研究人员通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续预训练"},{"Type":"NodeText","Data":"来扩展LLaMA模型。特别是，指令微调LLaMA已成为开发定制化或专业化模型的主要方法，因为其计算成本相对较低。为了有效地将LLaMA模型应用于非英语语言，通常需要扩展其原始词汇表（主要在英语语料上训练）或用目标语言的指令或数据进行微调。在这些扩展模型中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"斯坦福Alpaca"},{"Type":"NodeText","Data":"是第一个基于LLaMA（7B）微调的开放指令遵循模型。它通过使用"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"text-davinci-003"},{"Type":"NodeText","Data":"​以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自指令"},{"Type":"NodeText","Data":"方式生成的52K条指令遵循演示进行训练。名为Alpaca-52K的指令数据和训练代码在后续工作中被广泛采用，例如Alpaca-LoRA（使用LoRA复现斯坦福Alpaca）、Koala和BELLE。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna"},{"Type":"NodeText","Data":"是另一个受欢迎的LLaMA变体，它在从ShareGPT收集的用户共享对话上进行训练。由于LLaMA模型家族出色的性能和可用性，许多"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态模型"},{"Type":"NodeText","Data":"将其作为基础语言模型，以实现强大的语言理解和生成能力。与其他变体相比，Vicuna在多模态语言模型中更受青睐，这催生了各种流行模型的出现，包括LLaVA、MiniGPT-4、InstructBLIP和PandaGPT。LLaMA的发布极大地推动了LLM的研究进展。为了总结在LLaMA上进行的研究工作，我们在图5中展示了一个简要的演化图。"}]},{"ID":"20250924094043-813z68x","Type":"NodeParagraph","Properties":{"id":"20250924094043-813z68x","updated":"20250924094043"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250924094043-phvni51.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922202006-1zu6cvi","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202006-1zu6cvi","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 5：基于LLaMA进行的研究工作的演化图"}]},{"ID":"20250922202006-a3xb78y","Type":"NodeParagraph","Properties":{"id":"20250922202006-a3xb78y","updated":"20250924093324"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图注："},{"Type":"NodeText","Data":" 由于数量庞大，我们无法在此图中包含所有LLaMA的变体，即使是许多优秀的工作。为了支持增量更新，我们分享了此图的源文件，并欢迎读者通过在我们的GitHub页面上提交拉取请求来包含所需的模型。"}]},{"ID":"20250922202006-yoeitak","Type":"NodeBlockquote","Properties":{"id":"20250922202006-yoeitak","updated":"20250924094157"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202006-3h0hxmc","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202006-3h0hxmc","updated":"20250924094157"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922202006-iikgkqc","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202006-iikgkqc","updated":"20250924094157"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图5解析：LLaMA生态系统的“繁衍”"}]},{"ID":"20250922202006-ee2b8yh","Type":"NodeParagraph","Properties":{"id":"20250922202006-ee2b8yh","updated":"20250922202006"},"Children":[{"Type":"NodeText","Data":"这张图生动地展示了以原始"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA"},{"Type":"NodeText","Data":"模型为“根”，如何通过不同的技术路径“繁衍”出一个庞大而多样化的模型生态系统。"}]},{"ID":"20250922202006-96ycvzw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202006-96ycvzw","updated":"20250924094157"},"Children":[{"ID":"20250922202005-nidjkyq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-nidjkyq","updated":"20250922202005"},"Children":[{"ID":"20250922202006-o5d7zbf","Type":"NodeParagraph","Properties":{"id":"20250922202006-o5d7zbf","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心模型 (根)"},{"Type":"NodeText","Data":": 左上角的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA"},{"Type":"NodeText","Data":"是所有后续模型的基础。"}]}]},{"ID":"20250922202005-u9mvfkg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-u9mvfkg","updated":"20250922202005"},"Children":[{"ID":"20250922202006-lqjubww","Type":"NodeParagraph","Properties":{"id":"20250922202006-lqjubww","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两条主要演化路径"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202006-2htaqi8","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922202006-2htaqi8","updated":"20250922202006"},"Children":[{"ID":"20250922202005-z8pcdlk","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922202005-z8pcdlk","updated":"20250922202005"},"Children":[{"ID":"20250922202006-guesxq0","Type":"NodeParagraph","Properties":{"id":"20250922202006-guesxq0","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调 (Instruction Tuning)"},{"Type":"NodeText","Data":": 这是最主要的路径，旨在提升模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话和指令遵循能力"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922202006-59mfsed","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202006-59mfsed","updated":"20250922202006"},"Children":[{"ID":"20250922202005-uk7jpyk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-uk7jpyk","updated":"20250922202005"},"Children":[{"ID":"20250922202006-xu1sjeg","Type":"NodeParagraph","Properties":{"id":"20250922202006-xu1sjeg","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca"},{"Type":"NodeText","Data":"是这条路上的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开山之作"},{"Type":"NodeText","Data":"，它通过“自指令”方法生成数据进行微调，并催生了如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca-Lora"},{"Type":"NodeText","Data":"（参数高效版本）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BELLE"},{"Type":"NodeText","Data":"（中文增强）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Ziya"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Koala"},{"Type":"NodeText","Data":"等一系列后续工作。"}]}]},{"ID":"20250922202005-51z5xhc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-51z5xhc","updated":"20250922202005"},"Children":[{"ID":"20250922202006-hayfo5f","Type":"NodeParagraph","Properties":{"id":"20250922202006-hayfo5f","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna"},{"Type":"NodeText","Data":"是另一个重要的分支，它使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"真实的用户对话数据 (ShareGPT)"},{"Type":"NodeText","Data":" 进行训练，使其对话质量更高，因此在后续的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态"},{"Type":"NodeText","Data":"模型中被广泛用作语言基座。"}]}]}]}]},{"ID":"20250922202005-t3e7ieg","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922202005-t3e7ieg","updated":"20250922202005"},"Children":[{"ID":"20250922202006-68v6ukv","Type":"NodeParagraph","Properties":{"id":"20250922202006-68v6ukv","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续预训练 (Continue pre-training)"},{"Type":"NodeText","Data":": 这条路径旨在增强模型在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特定语言或领域"},{"Type":"NodeText","Data":"的能力。"}]},{"ID":"20250922202006-8lhvb4e","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202006-8lhvb4e","updated":"20250922202006"},"Children":[{"ID":"20250922202005-b7m3ywk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-b7m3ywk","updated":"20250922202005"},"Children":[{"ID":"20250922202006-4u1xjiw","Type":"NodeParagraph","Properties":{"id":"20250922202006-4u1xjiw","updated":"20250922202006"},"Children":[{"Type":"NodeText","Data":"例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Open-Chinese-LLaMA"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Linly-Chinese-LLaMA"},{"Type":"NodeText","Data":"通过加入大量中文数据进行持续预训练，来提升模型的中文能力。"}]}]},{"ID":"20250922202005-e5aqy2x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-e5aqy2x","updated":"20250922202005"},"Children":[{"ID":"20250922202006-kug7iwt","Type":"NodeParagraph","Properties":{"id":"20250922202006-kug7iwt","updated":"20250922202006"},"Children":[{"Type":"NodeText","Data":"一些模型（如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BenTsao"},{"Type":"NodeText","Data":"）则专注于特定领域（如医疗），通过领域数据进行持续预训练。"}]}]}]}]}]}]},{"ID":"20250922202005-gneo823","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-gneo823","updated":"20250924094157"},"Children":[{"ID":"20250922202006-0uosvdn","Type":"NodeParagraph","Properties":{"id":"20250922202006-0uosvdn","updated":"20250924094157"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态AI的融合"},{"Type":"NodeText","Data":": 图的右侧展示了LLaMA生态的另一个重要方向——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与视觉等多模态能力的结合"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922202006-wawyz9p","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202006-wawyz9p","updated":"20250922202006"},"Children":[{"ID":"20250922202005-uxzk9lw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-uxzk9lw","updated":"20250922202005"},"Children":[{"ID":"20250922202006-vkvvb0p","Type":"NodeParagraph","Properties":{"id":"20250922202006-vkvvb0p","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaVA"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"InstructBLIP"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MiniGPT-4"},{"Type":"NodeText","Data":"等模型将视觉编码器与LLaMA（特别是Vicuna）相结合，使其具备了理解图像并进行对话的能力。这代表了LLM向多模态演进的重要趋势。"}]}]}]}]},{"ID":"20250922202005-7e4fhzv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-7e4fhzv","updated":"20250922202005"},"Children":[{"ID":"20250922202006-0biq7dv","Type":"NodeParagraph","Properties":{"id":"20250922202006-0biq7dv","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域专业化"},{"Type":"NodeText","Data":": 图下方的标签（数学、金融、医学、法律等）表明，LLaMA生态正朝着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"垂直领域专业化"},{"Type":"NodeText","Data":"的方向发展，产生了如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Lawyer LLaMA"},{"Type":"NodeText","Data":"（法律）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatMed"},{"Type":"NodeText","Data":"（医疗）等专业模型。"}]}]}]},{"ID":"20250922202006-jefew39","Type":"NodeParagraph","Properties":{"id":"20250922202006-jefew39","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张图谱清晰地揭示了LLaMA作为开源基石的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"催化作用"},{"Type":"NodeText","Data":"。它不仅激发了在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用对话能力"},{"Type":"NodeText","Data":"上的创新（Alpaca, Vicuna），还推动了在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特定语言"},{"Type":"NodeText","Data":"（中文）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"垂直领域"},{"Type":"NodeText","Data":"（法律、医疗）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态"},{"Type":"NodeText","Data":"（视觉）等多个维度的探索。整个生态系统的发展呈现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“从通用到专用，从单模态到多模态”"},{"Type":"NodeText","Data":"的清晰趋势。"}]}]},{"ID":"20250922202006-zoj3pro","Type":"NodeParagraph","Properties":{"id":"20250922202006-zoj3pro","updated":"20250924093324"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Public API of LLMs (LLM的公共API)."},{"Type":"NodeText","Data":" 除了直接使用模型副本外，API为普通用户提供了一种更便捷的方式来使用LLM，而无需在本地运行模型。作为使用LLM的代表性接口，GPT系列模型的API已被学术界和工业界广泛使用。OpenAI为GPT-3系列模型提供了七个主要接口："},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"ada"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"babbage"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"curie"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"davinci"},{"Type":"NodeText","Data":"​（GPT-3系列中最强大的版本）、"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"text-ada-001"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"text-babbage-001"},{"Type":"NodeText","Data":"​, 和 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"text-curie-001"},{"Type":"NodeText","Data":"​。其中，前四个接口可以在OpenAI的主机服务器上进一步微调。特别是，"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"babbage"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"curie"},{"Type":"NodeText","Data":"​, 和 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"davinci"},{"Type":"NodeText","Data":"​ 分别对应于GPT-3（1B）、GPT-3（6.7B）和GPT-3（175B）模型。此外，还有两个与Codex相关的API，名为"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"code-cushman-001"},{"Type":"NodeText","Data":"​（Codex（12B）的一个强大且多语言的版本）和"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"code-davinci-002"},{"Type":"NodeText","Data":"​。此外，GPT-3.5系列包括一个基础模型"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"code-davinci-002"},{"Type":"NodeText","Data":"​和三个增强版本，即"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"text-davinci-002"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"text-davinci-003"},{"Type":"NodeText","Data":"​, 和"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-3.5-turbo"},{"Type":"NodeText","Data":"​。作为更强大的替代品，今年OpenAI发布了GPT-4系列的模型接口，包括"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-4"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-4-32k"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-4-1106-preview"},{"Type":"NodeText","Data":"​（即GPT-4 Turbo）和"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-4-vision-preview"},{"Type":"NodeText","Data":"​（即带视觉功能的GPT-4 Turbo，一个多模态模型）。值得注意的是，OpenAI一直在维护和升级这些模型接口（"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-3.5-turbo"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-4"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-4-32k"},{"Type":"NodeText","Data":"​），所以API名称实际上会指向最新版本。目前，ChatGPT可以由GPT-3.5或GPT-4模型驱动。总的来说，人们可以根据具体的应用场景和响应要求选择合适的模型接口。详细用法可以在他们的项目网站上找到。"}]},{"ID":"20250922202006-1ts6rwn","Type":"NodeBlockquote","Properties":{"id":"20250922202006-1ts6rwn","updated":"20250924093324"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202006-yimbnco","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202006-yimbnco","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922202006-ce4jcrz","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202006-ce4jcrz","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"API：连接AI能力与现实世界的桥梁"}]},{"ID":"20250922202006-9ji38tx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202006-9ji38tx","updated":"20250922202006"},"Children":[{"ID":"20250922202005-xywnmjj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-xywnmjj","updated":"20250922202005"},"Children":[{"ID":"20250922202006-i6wx2wv","Type":"NodeParagraph","Properties":{"id":"20250922202006-i6wx2wv","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"降低使用门槛"},{"Type":"NodeText","Data":": API是让"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非AI专家"},{"Type":"NodeText","Data":"也能使用顶尖LLM能力的关键。用户无需关心复杂的模型部署和硬件维护，只需通过简单的编程接口调用，就能将强大的AI功能集成到自己的应用中。"}]}]},{"ID":"20250922202005-ypg9d0h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-ypg9d0h","updated":"20250922202005"},"Children":[{"ID":"20250922202006-do2p4ev","Type":"NodeParagraph","Properties":{"id":"20250922202006-do2p4ev","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型即服务 (Model-as-a-Service, MaaS)"},{"Type":"NodeText","Data":": OpenAI的API策略是“模型即服务”理念的典型实践。他们将不同能力、不同成本的模型（从最便宜的"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"ada"},{"Type":"NodeText","Data":"​到最强大的"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-4-turbo"},{"Type":"NodeText","Data":"​）打包成服务，供用户按需选用。"}]}]},{"ID":"20250922202005-igvszcz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-igvszcz","updated":"20250922202005"},"Children":[{"ID":"20250922202006-tmynf08","Type":"NodeParagraph","Properties":{"id":"20250922202006-tmynf08","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"版本迭代的透明化"},{"Type":"NodeText","Data":": 作者指出了一个重要细节：API名称（如"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-4"},{"Type":"NodeText","Data":"​）通常会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动指向最新的稳定版本"},{"Type":"NodeText","Data":"。这意味着开发者可以持续享受到模型升级带来的好处，而无需修改代码。"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-4-1106-preview"},{"Type":"NodeText","Data":"​这样的“预览”版本则为希望尝鲜新功能的用户提供了通道。"}]}]},{"ID":"20250922202005-y2by6st","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-y2by6st","updated":"20250922202005"},"Children":[{"ID":"20250922202006-6b7oia1","Type":"NodeParagraph","Properties":{"id":"20250922202006-6b7oia1","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力的多样化"},{"Type":"NodeText","Data":": API不仅提供了不同规模的文本模型，还提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专门针对代码（Codex系列）和多模态（"},{"Type":"NodeTextMark","TextMarkType":"strong code","TextMarkTextContent":"gpt-4-vision-preview"},{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"）"},{"Type":"NodeText","Data":"的接口，满足了多样化的开发需求。"}]}]},{"ID":"20250922202005-lwo3bi3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-lwo3bi3","updated":"20250922202005"},"Children":[{"ID":"20250922202006-xnqihzi","Type":"NodeParagraph","Properties":{"id":"20250922202006-xnqihzi","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从模型到产品"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"gpt-3.5-turbo"},{"Type":"NodeText","Data":"​是专门为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT产品"},{"Type":"NodeText","Data":"优化的模型，这表明API提供的不仅是原始的模型能力，也包括经过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"产品级优化"},{"Type":"NodeText","Data":"的服务。"}]}]}]}]},{"ID":"20250922202006-rwvoze5","Type":"NodeBlockquote","Properties":{"id":"20250922202006-rwvoze5","updated":"20250924093324"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202006-zhksc1w","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202006-zhksc1w","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922202006-fh9c6t9","Type":"NodeParagraph","Properties":{"id":"20250922202006-fh9c6t9","updated":"20250922202006"},"Children":[{"Type":"NodeText","Data":"第八部分的核心是展示了大型语言模型（特别是开源模型）如何从一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“基础模型”"},{"Type":"NodeText","Data":"演变为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"繁荣、庞大且多样化的“生态系统”"},{"Type":"NodeText","Data":"，以及API在其中扮演的关键角色。"}]},{"ID":"20250922202006-202xhi7","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922202006-202xhi7","updated":"20250922202006"},"Children":[{"ID":"20250922202005-jma6mxy","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922202005-jma6mxy","updated":"20250922202005"},"Children":[{"ID":"20250922202006-pmhi41i","Type":"NodeParagraph","Properties":{"id":"20250922202006-pmhi41i","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA的“iPhone时刻”"},{"Type":"NodeText","Data":": LLaMA的发布，可以被类比为智能手机领域的“iPhone时刻”。它提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高性能、开放的硬件平台（基础模型）"},{"Type":"NodeText","Data":"，激发了全球开发者社区的巨大创造力，从而催生了一个类似"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“App Store”的生态系统"},{"Type":"NodeText","Data":"（如图5所示的各种衍生模型）。"}]}]},{"ID":"20250922202005-6qxm2cs","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922202005-6qxm2cs","updated":"20250922202005"},"Children":[{"ID":"20250922202006-1uvet70","Type":"NodeParagraph","Properties":{"id":"20250922202006-1uvet70","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生态演进的两大驱动力"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202006-ih0t6tc","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202006-ih0t6tc","updated":"20250922202006"},"Children":[{"ID":"20250922202005-y3s2dnj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-y3s2dnj","updated":"20250922202005"},"Children":[{"ID":"20250922202006-ipzkbwn","Type":"NodeParagraph","Properties":{"id":"20250922202006-ipzkbwn","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调 (Instruction Tuning)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“软件”层面的创新"},{"Type":"NodeText","Data":"。社区通过不同的数据（合成指令、真实对话）和方法（全参数微调、LoRA），开发出各种“App”（如Alpaca, Vicuna），极大地提升了模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话和交互能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922202005-albl6qt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-albl6qt","updated":"20250922202005"},"Children":[{"ID":"20250922202006-fm6hovh","Type":"NodeParagraph","Properties":{"id":"20250922202006-fm6hovh","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续预训练 (Continue Pre-training)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“硬件”层面的定制"},{"Type":"NodeText","Data":"。通过在特定语言（如中文）或特定领域（如法律、医疗）的数据上进行再训练，相当于为基础模型定制了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“专用芯片”"},{"Type":"NodeText","Data":"，使其在特定场景下表现更出色。"}]}]}]}]},{"ID":"20250922202005-rw3u3in","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922202005-rw3u3in","updated":"20250922202005"},"Children":[{"ID":"20250922202006-1hulao8","Type":"NodeParagraph","Properties":{"id":"20250922202006-1hulao8","updated":"20250922202006"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"API的“云服务”模式"},{"Type":"NodeText","Data":": 如果说开源模型生态是让开发者可以“自己动手，丰衣足食”，那么以OpenAI为代表的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"API服务"},{"Type":"NodeText","Data":"则提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“开箱即用”的云服务"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922202006-pp5o1pq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202006-pp5o1pq","updated":"20250922202006"},"Children":[{"ID":"20250922202005-5kmajik","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-5kmajik","updated":"20250922202005"},"Children":[{"ID":"20250922202006-mij0rf8","Type":"NodeParagraph","Properties":{"id":"20250922202006-mij0rf8","updated":"20250922202006"},"Children":[{"Type":"NodeText","Data":"它将最前沿的AI能力（包括代码、多模态、经过产品优化的模型）以一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高度抽象、易于集成"},{"Type":"NodeText","Data":"的方式提供给所有开发者。"}]}]},{"ID":"20250922202005-uwfnvl9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202005-uwfnvl9","updated":"20250922202005"},"Children":[{"ID":"20250922202006-vq28s6c","Type":"NodeParagraph","Properties":{"id":"20250922202006-vq28s6c","updated":"20250922202006"},"Children":[{"Type":"NodeText","Data":"这种模式极大地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加速了AI技术的商业化和普及"},{"Type":"NodeText","Data":"，使得即使是小团队也能在其应用中集成世界顶级的AI能力。"}]}]}]}]}]},{"ID":"20250922202006-nn7km76","Type":"NodeParagraph","Properties":{"id":"20250922202006-nn7km76","updated":"20250922202006"},"Children":[{"Type":"NodeText","Data":"总结而言，第八部分从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源社区的 grassroots innovation (草根创新)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"商业公司的 platform-as-a-service (平台即服务)"},{"Type":"NodeText","Data":" 两个视角，共同描绘了LLM技术如何以前所未有的速度进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"传播、演化和应用"},{"Type":"NodeText","Data":"的宏大图景。LLaMA模型家族的演化图谱和OpenAI的API矩阵，分别是这两种发展模式最生动的写照。"}]}]},{"ID":"20250922202303-75u3nw6","Type":"NodeTable","TableAligns":[1,1,1,1],"Properties":{"colgroup":"|||","id":"20250922202303-75u3nw6","updated":"20250924094714"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Corpora"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Size"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Source"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Latest Update Time"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BookCorpus"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5GB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Books"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dec-2015"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Gutenberg"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Books"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dec-2021"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"C4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"800GB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CommonCrawl"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Apr-2019"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CC-Stories-R"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"31GB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CommonCrawl"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Sep-2019"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CC-NEWS"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78GB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CommonCrawl"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Feb-2019"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"REALNEWs"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"120GB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CommonCrawl"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Apr-2019"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"OpenWebText"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"38GB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Reddit links"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Mar-2023"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pushift.io"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2TB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Reddit links"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Mar-2023"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Wikipedia"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"21GB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Wikipedia"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Mar-2023"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BigQuery"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Codes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Mar-2023"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"the Pile"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"800GB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Other"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dec-2020"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ROOTS"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.6TB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Other"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Jun-2022"}]}]}]},{"ID":"20250922202303-nq9ikk0","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202303-nq9ikk0","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 2：常用数据源统计"}]},{"ID":"20250922202303-l223e5k","Type":"NodeBlockquote","Properties":{"id":"20250922202303-l223e5k","updated":"20250924094714"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202303-fpmg7me","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202303-fpmg7me","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922202303-do8j44z","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202303-do8j44z","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表2解析：LLM的“精神食粮”"}]},{"ID":"20250922202303-iq4o8u3","Type":"NodeParagraph","Properties":{"id":"20250922202303-iq4o8u3","updated":"20250922202303"},"Children":[{"Type":"NodeText","Data":"这张表格列出了用于预训练大型语言模型的一些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心数据集"},{"Type":"NodeText","Data":"，可以看作是LLM的“精神食粮”。"}]},{"ID":"20250922202303-ooc7lnj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202303-ooc7lnj","updated":"20250922202303"},"Children":[{"ID":"20250922202303-oovpiwh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-oovpiwh","updated":"20250922202303"},"Children":[{"ID":"20250922202303-dsgf0lj","Type":"NodeParagraph","Properties":{"id":"20250922202303-dsgf0lj","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据来源的多样性"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202303-du914tw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202303-du914tw","updated":"20250922202303"},"Children":[{"ID":"20250922202303-24w19d3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-24w19d3","updated":"20250922202303"},"Children":[{"ID":"20250922202303-pszs09c","Type":"NodeParagraph","Properties":{"id":"20250922202303-pszs09c","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"书籍 (Books)"},{"Type":"NodeText","Data":": BookCorpus 和 Gutenberg 是高质量文本的代表，提供了丰富的词汇、语法和世界知识。"}]}]},{"ID":"20250922202303-pp4ule7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-pp4ule7","updated":"20250922202303"},"Children":[{"ID":"20250922202303-0c7o182","Type":"NodeParagraph","Properties":{"id":"20250922202303-0c7o182","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"网页抓取 (CommonCrawl)"},{"Type":"NodeText","Data":": C4, CC-Stories等是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大"},{"Type":"NodeText","Data":"的数据来源，包含了互联网上包罗万象的信息，是模型学习通用知识的基础。但其质量参差不齐，需要大量清洗。"}]}]},{"ID":"20250922202303-docu5iz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-docu5iz","updated":"20250922202303"},"Children":[{"ID":"20250922202303-dbfnoks","Type":"NodeParagraph","Properties":{"id":"20250922202303-dbfnoks","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"社交媒体 (Reddit links)"},{"Type":"NodeText","Data":": OpenWebText 和 Pushift.io 提供了更具"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话性、口语化"},{"Type":"NodeText","Data":"的文本，有助于模型学习交互和交流。"}]}]},{"ID":"20250922202303-d7172zo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-d7172zo","updated":"20250922202303"},"Children":[{"ID":"20250922202303-f12j86x","Type":"NodeParagraph","Properties":{"id":"20250922202303-f12j86x","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"百科全书 (Wikipedia)"},{"Type":"NodeText","Data":": 维基百科是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高质量、结构化"},{"Type":"NodeText","Data":"事实知识的宝库。"}]}]},{"ID":"20250922202303-b2en2zi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-b2en2zi","updated":"20250922202303"},"Children":[{"ID":"20250922202303-8qicvjb","Type":"NodeParagraph","Properties":{"id":"20250922202303-8qicvjb","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码 (Codes)"},{"Type":"NodeText","Data":": BigQuery等代码数据集是模型学习"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逻辑和推理能力"},{"Type":"NodeText","Data":"的关键。"}]}]},{"ID":"20250922202303-597vudi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-597vudi","updated":"20250922202303"},"Children":[{"ID":"20250922202303-y3q9c4u","Type":"NodeParagraph","Properties":{"id":"20250922202303-y3q9c4u","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合数据集 (Other)"},{"Type":"NodeText","Data":": The Pile 和 ROOTS 是精心策划的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据拼盘”"},{"Type":"NodeText","Data":"，它们混合了来自多种来源的高质量数据，旨在为模型提供一个更均衡、更多样化的“营养餐”。"}]}]}]}]},{"ID":"20250922202303-nge2yu0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-nge2yu0","updated":"20250922202303"},"Children":[{"ID":"20250922202303-5q26ns5","Type":"NodeParagraph","Properties":{"id":"20250922202303-5q26ns5","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据规模的庞大"},{"Type":"NodeText","Data":": 数据集的规模从GB级到TB级不等，特别是像CommonCrawl这样PB级的数据源，凸显了训练LLM需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"海量数据"},{"Type":"NodeText","Data":"的特点。"}]}]},{"ID":"20250922202303-sapewdh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-sapewdh","updated":"20250922202303"},"Children":[{"ID":"20250922202303-2sdrpf1","Type":"NodeParagraph","Properties":{"id":"20250922202303-2sdrpf1","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"时效性问题"},{"Type":"NodeText","Data":": “Latest Update Time”这一列很重要，它揭示了许多常用数据集存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识截止日期"},{"Type":"NodeText","Data":"的问题，这也是为什么基于这些数据训练的模型无法回答最新事件的原因。"}]}]}]},{"ID":"20250922202303-tk25oie","Type":"NodeParagraph","Properties":{"id":"20250922202303-tk25oie","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格直观地展示了构建一个强大LLM所需的数据基础是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"庞大、多样且高质量"},{"Type":"NodeText","Data":"的。不同来源的数据扮演着不同的角色，共同塑造了模型的语言能力、知识储备和推理能力。"}]}]},{"ID":"20250922202303-oo2xwib","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202303-oo2xwib","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.2 Commonly Used Corpora for Pre-training (常用的预训练语料库)"}]},{"ID":"20250922202303-0e8y90v","Type":"NodeParagraph","Properties":{"id":"20250922202303-0e8y90v","updated":"20250924094714"},"Children":[{"Type":"NodeText","Data":"与早期的PLM相比，包含更多参数的LLM需要更高容量的、覆盖内容范围更广的训练数据。为了满足这一需求，已有越来越多的可访问训练数据集被发布用于研究。在本节中，我们将简要总结几种广泛用于训练LLM的语料库。根据其内容类型，我们将这些语料库分为五组：网页、书籍、维基百科、代码和其他。"}]},{"ID":"20250922202303-qbaidm2","Type":"NodeParagraph","Properties":{"id":"20250922202303-qbaidm2","updated":"20250924094714"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Web pages (网页)."},{"Type":"NodeText","Data":" 网页是训练语言模型的主要数据来源。"}]},{"ID":"20250922202303-r3fdldi","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202303-r3fdldi","updated":"20250924094714"},"Children":[{"ID":"20250922202303-686flar","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-686flar","updated":"20250922202303"},"Children":[{"ID":"20250922202303-7j0etjo","Type":"NodeParagraph","Properties":{"id":"20250922202303-7j0etjo","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CommonCrawl."},{"Type":"NodeText","Data":" CommonCrawl 是最大的开源网络爬取数据库之一，包含PB级的数据量，已被广泛用作现有LLM的训练数据。由于整个数据集非常庞大，现有研究主要提取其在特定时期内或根据特定需求（例如，提取数学文本）的网页子集。然而，由于网页数据中普遍存在噪声和低质量信息，在使用前有必要进行数据预处理。一个常用的清洗CommonCrawl的工具包是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CC-Net"},{"Type":"NodeText","Data":"，由Facebook开发，并已用于处理像RedPama-Data这样的数据集。"}]}]},{"ID":"20250922202303-8ouh9fc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-8ouh9fc","updated":"20250922202303"},"Children":[{"ID":"20250922202303-yp48c7m","Type":"NodeParagraph","Properties":{"id":"20250922202303-yp48c7m","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"C4."},{"Type":"NodeText","Data":" Colossal Clean Crawled Corpus（C4）包括五个变体，即en（806G）、en.noclean（6T）、realnewslike（36G）、webtextlike（17G）和multilingual（38T）。en版本已被用于预训练T5、LaMDA、Gopher和UL2。多语言C4，也称为mC4，已被用于mT5。"}]}]},{"ID":"20250922202303-e8g81wu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-e8g81wu","updated":"20250922202303"},"Children":[{"ID":"20250922202303-jrtwinu","Type":"NodeParagraph","Properties":{"id":"20250922202303-jrtwinu","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RedPajama-Data."},{"Type":"NodeText","Data":" RedPajama-Data 是一个公开可用的综合性网络数据集，包含来自Common Crawl的1000亿份文档。它已使用CCNet工具进行清洗、过滤和去重，产生了大约30T的词元，可在Hugging Face上下载。RedPajama-Data是一个多语言数据集，包括五种语言：英语、法语、西班牙语、德语和意大利语。此外，它提供了超过40个质量标签，使得根据特定标准过滤或重新加权数据集成为可能。该数据集持续更新和维护，所有数据处理脚本都在GitHub上开源以便使用。"}]}]},{"ID":"20250922202303-vy1awi4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-vy1awi4","updated":"20250922202303"},"Children":[{"ID":"20250922202303-mzoxbts","Type":"NodeParagraph","Properties":{"id":"20250922202303-mzoxbts","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RefinedWeb."},{"Type":"NodeText","Data":" RefinedWeb 是一个通过对来自Common Crawl的数据进行严格筛选和去重而获得的网页数据集，涵盖了从2008年到2023年6月的所有Common Crawl网页记录，总计约5T词元。其开源部分包含600B词元，数据大小约500GB。解压后，它需要2.8TB的本地存储空间，并可在Hugging Face上下载。该数据集是开源大型语言模型Falcon的主要训练数据集。"}]}]},{"ID":"20250922202303-4olg813","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-4olg813","updated":"20250922202303"},"Children":[{"ID":"20250922202303-htvbkg4","Type":"NodeParagraph","Properties":{"id":"20250922202303-htvbkg4","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WebText."},{"Type":"NodeText","Data":" WebText 是一个著名的语料库，由来自Reddit的高赞链接组成，这是一个社交媒体平台，用户可以提交链接和文本帖子，但它并未公开。作为替代，有一个易于访问的开源替代品，名为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"OpenWebText"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922202303-jqbiy9n","Type":"NodeParagraph","Properties":{"id":"20250922202303-jqbiy9n","updated":"20250924094714"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Books \u0026amp; Academic Data (书籍与学术数据)."},{"Type":"NodeText","Data":" 书籍和学术数据包含了丰富的世界知识和语言信息，是模型学习的高质量语料库。"}]},{"ID":"20250922202303-g800z27","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202303-g800z27","updated":"20250924094714"},"Children":[{"ID":"20250922202303-ucf736x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-ucf736x","updated":"20250922202303"},"Children":[{"ID":"20250922202303-lulxwvp","Type":"NodeParagraph","Properties":{"id":"20250922202303-lulxwvp","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Book Data."},{"Type":"NodeText","Data":" BookCorpus 是之前小规模模型（例如，GPT和GPT-2）中常用的数据集，包含超过11,000本书，涵盖了广泛的主题和类型（例如，小说和传记）。另一个大规模的图书语料库是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"古登堡计划（Project Gutenberg）"},{"Type":"NodeText","Data":"，包含超过70,000本包括小说在内的文学书籍，"}]}]}]},{"ID":"20250922202303-jg5cpom","Type":"NodeBlockquote","Properties":{"id":"20250922202303-jg5cpom","updated":"20250924094714"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202303-tlrzbup","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202303-tlrzbup","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922202303-bttp5dd","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202303-bttp5dd","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM训练数据的“金字塔”"}]},{"ID":"20250922202303-vrkd2zz","Type":"NodeParagraph","Properties":{"id":"20250922202303-vrkd2zz","updated":"20250922202303"},"Children":[{"Type":"NodeText","Data":"这部分内容详细介绍了LLM的“食物来源”，可以看作一个金字塔结构："}]},{"ID":"20250922202303-imvgr8a","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202303-imvgr8a","updated":"20250922202303"},"Children":[{"ID":"20250922202303-nfgcpph","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-nfgcpph","updated":"20250922202303"},"Children":[{"ID":"20250922202303-x14ob2x","Type":"NodeParagraph","Properties":{"id":"20250922202303-x14ob2x","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"塔基 - 海量原始数据 (CommonCrawl)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最基础、最庞大"},{"Type":"NodeText","Data":"的数据源。它就像是未加工的矿石，蕴含着互联网上几乎所有的信息，为模型提供了广度。但它也充满了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"噪声和杂质"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922202303-43b1sqs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-43b1sqs","updated":"20250922202303"},"Children":[{"ID":"20250922202303-1knaegu","Type":"NodeParagraph","Properties":{"id":"20250922202303-1knaegu","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"塔身 - 清洗与筛选 (C4, RedPajama, RefinedWeb)"},{"Type":"NodeText","Data":": 这一层是对原始矿石的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“粗加工”"},{"Type":"NodeText","Data":"。像CC-Net这样的工具就是“洗矿机”，它们通过一系列规则和模型，从CommonCrawl中筛选出相对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"干净、高质量"},{"Type":"NodeText","Data":"的文本，形成了C4等数据集。RedPajama和RefinedWeb是这一方向上更新、更精细的努力，它们不仅清洗数据，还打上了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量标签"},{"Type":"NodeText","Data":"，为后续的精细化训练提供了可能。Falcon模型使用RefinedWeb，说明高质量的网页数据本身就能训练出强大的模型。"}]}]},{"ID":"20250922202303-eenfhbs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-eenfhbs","updated":"20250922202303"},"Children":[{"ID":"20250922202303-aegp74i","Type":"NodeParagraph","Properties":{"id":"20250922202303-aegp74i","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"塔尖 - 高质量精选数据 (WebText, Books, Academic Data)"},{"Type":"NodeText","Data":": 这一层是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“精加工”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“营养补充剂”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922202303-h1avvw7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-h1avvw7","updated":"20250922202303"},"Children":[{"ID":"20250922202303-shaimcm","Type":"NodeParagraph","Properties":{"id":"20250922202303-shaimcm","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WebText/OpenWebText"},{"Type":"NodeText","Data":": 来自Reddit高赞链接，代表了经过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类社区隐式筛选"},{"Type":"NodeText","Data":"的高质量、有趣的内容。"}]}]},{"ID":"20250922202303-xagzz4h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-xagzz4h","updated":"20250922202303"},"Children":[{"ID":"20250922202303-il0ygc9","Type":"NodeParagraph","Properties":{"id":"20250922202303-il0ygc9","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"书籍 (BookCorpus, Gutenberg)"},{"Type":"NodeText","Data":": 提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构完整、语法规范、逻辑严谨"},{"Type":"NodeText","Data":"的长文本，对于模型学习语言的深层结构和世界知识至关重要。"}]}]}]},{"ID":"20250922202303-a8k8tq0","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202303-a8k8tq0","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键趋势与洞见"}]},{"ID":"20250922202303-ooktaf7","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202303-ooktaf7","updated":"20250922202303"},"Children":[{"ID":"20250922202303-gexfgys","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-gexfgys","updated":"20250922202303"},"Children":[{"ID":"20250922202303-ry0hg4p","Type":"NodeParagraph","Properties":{"id":"20250922202303-ry0hg4p","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据清洗是核心竞争力"},{"Type":"NodeText","Data":": 从原始的CommonCrawl到精炼的RefinedWeb，可以看出，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"获取和处理高质量数据的能力，正成为训练顶尖LLM的核心竞争力之一"},{"Type":"NodeText","Data":"。简单地堆砌数据已不足够，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据的“质”和“量”同等重要"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922202303-ia1upab","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-ia1upab","updated":"20250922202303"},"Children":[{"ID":"20250922202303-5076n77","Type":"NodeParagraph","Properties":{"id":"20250922202303-5076n77","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放与复现"},{"Type":"NodeText","Data":": RedPajama等项目不仅开放数据，还开放"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据处理脚本"},{"Type":"NodeText","Data":"，这极大地促进了研究的透明度和可复现性，是开源精神的重要体现。"}]}]},{"ID":"20250922202303-clclans","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-clclans","updated":"20250922202303"},"Children":[{"ID":"20250922202303-23kxmir","Type":"NodeParagraph","Properties":{"id":"20250922202303-23kxmir","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据驱动模型特性"},{"Type":"NodeText","Data":": 不同的数据集会塑造模型不同的特性。例如，大量对话数据有助于提升模型的交互能力，而书籍和学术数据则有助于提升其知识深度和严谨性。"}]}]}]}]},{"ID":"20250922202303-e8wj1ya","Type":"NodeBlockquote","Properties":{"id":"20250922202303-e8wj1ya","updated":"20250924094714"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202303-ux500yq","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202303-ux500yq","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922202303-xuukwgw","Type":"NodeParagraph","Properties":{"id":"20250922202303-xuukwgw","updated":"20250922202303"},"Children":[{"Type":"NodeText","Data":"第九部分深入探讨了大型语言模型（LLM）的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据基础"},{"Type":"NodeText","Data":"，即其赖以生存和学习的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练语料库"},{"Type":"NodeText","Data":"。这一部分的核心思想是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个强大的LLM背后，必然有一个庞大、多样且经过精心处理的数据集。"}]},{"ID":"20250922202303-0jf7h0o","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922202303-0jf7h0o","updated":"20250922202303"},"Children":[{"ID":"20250922202303-t3ugwly","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922202303-t3ugwly","updated":"20250922202303"},"Children":[{"ID":"20250922202303-qlun5qr","Type":"NodeParagraph","Properties":{"id":"20250922202303-qlun5qr","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据来源的“广度”与“深度”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202303-qbe0km9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202303-qbe0km9","updated":"20250922202303"},"Children":[{"ID":"20250922202303-rczcwni","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-rczcwni","updated":"20250922202303"},"Children":[{"ID":"20250922202303-5hzfq53","Type":"NodeParagraph","Properties":{"id":"20250922202303-5hzfq53","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"广度"},{"Type":"NodeText","Data":": 主要由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CommonCrawl"},{"Type":"NodeText","Data":"等网页抓取数据提供，它为模型带来了互联网级别的广博见闻，是模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用能力"},{"Type":"NodeText","Data":"的基础。"}]}]},{"ID":"20250922202303-x6jqcwr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-x6jqcwr","updated":"20250922202303"},"Children":[{"ID":"20250922202303-a3bwc35","Type":"NodeParagraph","Properties":{"id":"20250922202303-a3bwc35","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度与质量"},{"Type":"NodeText","Data":": 由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"书籍（BookCorpus）、学术文献、维基百科"},{"Type":"NodeText","Data":"等高质量文本提供。这些数据语法规范、逻辑严谨、事实性强，是模型学习"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度知识、复杂推理和语言规范"},{"Type":"NodeText","Data":"的“教科书”。"}]}]},{"ID":"20250922202303-jfmvdda","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-jfmvdda","updated":"20250922202303"},"Children":[{"ID":"20250922202303-ztxvyug","Type":"NodeParagraph","Properties":{"id":"20250922202303-ztxvyug","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交互性与时效性"},{"Type":"NodeText","Data":": 由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Reddit链接（OpenWebText）"},{"Type":"NodeText","Data":"等社交媒体内容提供，这部分数据更具口语化和对话性，有助于模型学习如何与人"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然地交流"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922202303-m13cquw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-m13cquw","updated":"20250922202303"},"Children":[{"ID":"20250922202303-ugrrcwk","Type":"NodeParagraph","Properties":{"id":"20250922202303-ugrrcwk","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逻辑与结构"},{"Type":"NodeText","Data":": 由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码（BigQuery）"},{"Type":"NodeText","Data":"提供，这是模型学习"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严密逻辑、算法思维和结构化表达"},{"Type":"NodeText","Data":"的关键训练材料。"}]}]}]}]},{"ID":"20250922202303-ip61sx1","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922202303-ip61sx1","updated":"20250922202303"},"Children":[{"ID":"20250922202303-4gn39fo","Type":"NodeParagraph","Properties":{"id":"20250922202303-4gn39fo","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据工程”的核心地位"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202303-k8503ep","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202303-k8503ep","updated":"20250922202303"},"Children":[{"ID":"20250922202303-9vpyo4k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-9vpyo4k","updated":"20250922202303"},"Children":[{"ID":"20250922202303-wzjz7za","Type":"NodeParagraph","Properties":{"id":"20250922202303-wzjz7za","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从原始到精炼"},{"Type":"NodeText","Data":": 文章清晰地展示了一个从“原始数据”到“精炼数据”的加工链条。直接使用原始的CommonCrawl是远远不够的，必须通过像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CC-Net"},{"Type":"NodeText","Data":"这样的工具进行大量的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清洗、去重和质量过滤"},{"Type":"NodeText","Data":"，才能得到像C4、RefinedWeb这样真正可用的高质量数据集。"}]}]},{"ID":"20250922202303-0gvckp1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-0gvckp1","updated":"20250922202303"},"Children":[{"ID":"20250922202303-aipovr0","Type":"NodeParagraph","Properties":{"id":"20250922202303-aipovr0","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据配方”的重要性"},{"Type":"NodeText","Data":": 像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"The Pile"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ROOTS"},{"Type":"NodeText","Data":"这样的“混合数据集”的出现，标志着“数据工程”进入了一个新阶段。研究者们不再是简单地堆砌数据，而是像配制“营养餐”一样，精心"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"调配不同来源、不同类型数据的比例"},{"Type":"NodeText","Data":"，以期训练出能力更均衡、更全面的模型。"}]}]}]}]},{"ID":"20250922202303-7ja5u7f","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922202303-7ja5u7f","updated":"20250922202303"},"Children":[{"ID":"20250922202303-y17z6fn","Type":"NodeParagraph","Properties":{"id":"20250922202303-y17z6fn","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放与共享的趋势"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202303-yj3m3t2","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202303-yj3m3t2","updated":"20250922202303"},"Children":[{"ID":"20250922202303-si3km3y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202303-si3km3y","updated":"20250922202303"},"Children":[{"ID":"20250922202303-qviz674","Type":"NodeParagraph","Properties":{"id":"20250922202303-qviz674","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RedPajama"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RefinedWeb"},{"Type":"NodeText","Data":"等项目的出现，以及Hugging Face等平台的普及，使得大规模、高质量的预训练数据集变得越来越"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放和易于获取"},{"Type":"NodeText","Data":"。更重要的是，连同数据处理的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码和流程"},{"Type":"NodeText","Data":"也一并开源，这极大地降低了研究门槛，加速了整个领域的创新。"}]}]}]}]}]},{"ID":"20250922202303-o43s50g","Type":"NodeParagraph","Properties":{"id":"20250922202303-o43s50g","updated":"20250922202303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第九部分揭示了LLM成功的“秘密”之一就在于其背后庞大而复杂的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据供应链”"},{"Type":"NodeText","Data":"。打造一个SOTA级别的LLM，不仅是算法和模型的竞争，更是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据获取能力、数据处理工程能力和数据组织与配比智慧"},{"Type":"NodeText","Data":"的综合体现。“数据决定上限，算法逼近上限”的原则在这里得到了充分的体现。"}]}]},{"ID":"20250922202449-v9zsemo","Type":"NodeParagraph","Properties":{"id":"20250922202449-v9zsemo","updated":"20250924095820"},"Children":[{"Type":"NodeText","Data":"论文、诗歌、戏剧、历史、科学、哲学以及其他公共领域的作品。它目前是最大的开源图书收藏之一，被用于训练MT-NLG和LLaMA。至于GPT-3中使用的Books1和Books2，它们比BookCorpus大得多，但至今尚未公开发布。"}]},{"ID":"20250922202449-4n7f9lg","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-4n7f9lg","updated":"20250924095820"},"Children":[{"ID":"20250922202449-06mgdwg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-06mgdwg","updated":"20250922202449"},"Children":[{"ID":"20250922202449-nxolhvu","Type":"NodeParagraph","Properties":{"id":"20250922202449-nxolhvu","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学术数据 (Academic Data)."},{"Type":"NodeText","Data":" 除了图书数据，科学出版物数据（如论文）对于模型的预训练也很重要。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"arXiv数据集"},{"Type":"NodeText","Data":"是一个包含170万篇学术论文的语料库，涵盖了物理、数学和计算机科学等领域的广泛论文。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"S2ORC"},{"Type":"NodeText","Data":"是一个由Semantic Scholar收集的包含1.36亿篇学术论文的语料库。它还发布了一个衍生数据集peS2o，其中包含约420亿个词元。"}]}]}]},{"ID":"20250922202449-s470dgw","Type":"NodeParagraph","Properties":{"id":"20250922202449-s470dgw","updated":"20250924095820"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Wikipedia (维基百科)."},{"Type":"NodeText","Data":" 维基百科是一个在线百科全书，包含大量关于不同主题的高质量文章。这些文章大多以说明性的写作风格构成（并附有参考文献），涵盖了广泛的语言和领域。通常，在大多数LLM（例如，GPT-3、LaMDA和LLaMA）中广泛使用的是仅经过英语过滤的维基百科版本。维基百科支持多种语言，因此也可以用于多语言设置。"}]},{"ID":"20250922202449-kbe0muf","Type":"NodeParagraph","Properties":{"id":"20250922202449-kbe0muf","updated":"20250924095820"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Code (代码)."},{"Type":"NodeText","Data":" 为了收集代码数据，现有的工作主要从互联网上爬取开源许可的代码。两个主要来源是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"公共代码仓库"},{"Type":"NodeText","Data":"（如GitHub）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码相关的问答平台"},{"Type":"NodeText","Data":"（如StackOverflow）。谷歌公开发布了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BigQuery数据集"},{"Type":"NodeText","Data":"，其中包含了大量各种编程语言的开源许可代码片段，是一个代表性的代码数据集。CodeGen利用了BIGQUERY，即BigQuery数据集的一个子集，来训练CodeGen的多语言版本（CodeGen-Multi）。此外，Hugging Face收集并发布了一个名为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"The Stack"},{"Type":"NodeText","Data":"的代码数据集，涵盖了超过30种编程语言。The Stack持续更新，其v1.2版本已扩展到358种编程语言。基于此数据集，BigCode进一步处理并发布了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"StarCoder"},{"Type":"NodeText","Data":"，它也是StarCoder模型的预训练数据。"}]},{"ID":"20250922202449-iea4cvo","Type":"NodeParagraph","Properties":{"id":"20250922202449-iea4cvo","updated":"20250924095820"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mixed Data (混合数据)."},{"Type":"NodeText","Data":" 除了上述特定类型的数据集，不同类型的数据也被组合起来以方便研究人员使用。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"The Pile"},{"Type":"NodeText","Data":"是一个大规模、多样化且开源的文本数据集，由来自多种来源的超过800GB的数据组成，包括书籍、网站、代码、科学论文和社交媒体平台。它由22个多样化的高质量子集构成。The Pile数据集被广泛用于不同参数规模的模型中，如GPT-J（6B）、CodeGen（16B）和Megatron-Turing NLG（530B）。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ROOTS"},{"Type":"NodeText","Data":"由各种较小的数据集组成（总计1.61TB的文本），涵盖59种不同的语言（包括自然语言和编程语言），并已被用于训练BLOOM。另一个混合数据集是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Dolma"},{"Type":"NodeText","Data":"，它包括来自Common Crawl的网络文本、来自Semantic Scholar的学术论文、来自GitHub的代码、来自Reddit的书籍和社交媒体，以及维基百科数据。Dolma包含约3T词元的约200TB原始文本，并已用于训练OLMo。"}]},{"ID":"20250922202449-8wwchs8","Type":"NodeParagraph","Properties":{"id":"20250922202449-8wwchs8","updated":"20250924095820"},"Children":[{"Type":"NodeText","Data":"在实践中，预训练LLM通常需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合不同数据源"},{"Type":"NodeText","Data":"（见图6），而不是单一语料库。因此，现有研究通常混合几个现成的数据集（例如，C4、OpenWebText和the Pile），然后进行进一步处理以获得预训练语料库。此外，为了训练能适应特定应用的LLM，从相关来源（例如，维基百科和BigQuery）提取数据以丰富预训练数据中的相应信息也很重要。"}]},{"ID":"20250922202449-bcgpdcx","Type":"NodeTable","TableAligns":[1,1,1,1],"Properties":{"colgroup":"|||","id":"20250922202449-bcgpdcx","updated":"20250924095820"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Categories"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Collections"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Time"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"#Examples"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Task"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Nat. Inst."}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Apr-2021"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"193K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"FLAN"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Sep-2021"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.4M"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"P3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Oct-2021"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"12.1M"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Super Nat. Inst."}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Apr-2022"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5M"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MVPCorpus"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Jun-2022"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41M"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"xP3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Nov-2022"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"81M"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"OIG"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Mar-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"43M"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Chat"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HH-RLHF"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Apr-2022"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"160K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HC3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Jan-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"87K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ShareGPT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Mar-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"90K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dolly"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Apr-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"15K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"OpenAssistant"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Apr-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"161K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Synthetic"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Self-Instruct"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dec-2022"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"82K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Alpaca"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Mar-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"52K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Guanaco"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Mar-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"535K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Baize"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Apr-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"158K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BELLE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Apr-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.5M"}]}]}]},{"ID":"20250922202449-7qxbwi7","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202449-7qxbwi7","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 3：可用于指令微调的数据集详细列表"}]},{"ID":"20250922202449-bizxpdt","Type":"NodeBlockquote","Properties":{"id":"20250922202449-bizxpdt","updated":"20250924095820"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202449-vvb55kx","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202449-vvb55kx","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922202449-jnse2oo","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202449-jnse2oo","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表3解析：LLM的“教科书”与“练习册”"}]},{"ID":"20250922202449-2qzzzzi","Type":"NodeParagraph","Properties":{"id":"20250922202449-2qzzzzi","updated":"20250922202449"},"Children":[{"Type":"NodeText","Data":"这张表格分类列出了用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"的数据集，它们是教会LLM如何“听懂人话、按指令办事”的关键教材。"}]},{"ID":"20250922202449-t78locb","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-t78locb","updated":"20250922202449"},"Children":[{"ID":"20250922202449-v6z2dbm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-v6z2dbm","updated":"20250922202449"},"Children":[{"ID":"20250922202449-vsb66mw","Type":"NodeParagraph","Properties":{"id":"20250922202449-vsb66mw","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大类“教材”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-d8cdy8q","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922202449-d8cdy8q","updated":"20250922202449"},"Children":[{"ID":"20250922202449-8a1em7c","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922202449-8a1em7c","updated":"20250922202449"},"Children":[{"ID":"20250922202449-35fhiep","Type":"NodeParagraph","Properties":{"id":"20250922202449-35fhiep","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务型 (Task)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-ydeq3xf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-ydeq3xf","updated":"20250922202449"},"Children":[{"ID":"20250922202449-t5a3naf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-t5a3naf","updated":"20250922202449"},"Children":[{"ID":"20250922202449-xdtffc7","Type":"NodeParagraph","Properties":{"id":"20250922202449-xdtffc7","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"来源"},{"Type":"NodeText","Data":": 主要来自"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"传统的NLP任务数据集"},{"Type":"NodeText","Data":"（如翻译、摘要、问答）。"}]}]},{"ID":"20250922202449-0a7qrnc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-0a7qrnc","updated":"20250922202449"},"Children":[{"ID":"20250922202449-l5kr7a7","Type":"NodeParagraph","Properties":{"id":"20250922202449-l5kr7a7","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构化、目标明确"},{"Type":"NodeText","Data":"，数据量可以非常大（如FLAN, P3）。"}]}]},{"ID":"20250922202449-7ix29iv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-7ix29iv","updated":"20250922202449"},"Children":[{"ID":"20250922202449-2ez1yog","Type":"NodeParagraph","Properties":{"id":"20250922202449-2ez1yog","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"作用"},{"Type":"NodeText","Data":": 教会模型解决"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学术界定义的、有标准答案"},{"Type":"NodeText","Data":"的各种NLP任务，是模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础能力"},{"Type":"NodeText","Data":"的来源。"}]}]}]}]},{"ID":"20250922202449-79yxhpg","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922202449-79yxhpg","updated":"20250922202449"},"Children":[{"ID":"20250922202449-nqlwji9","Type":"NodeParagraph","Properties":{"id":"20250922202449-nqlwji9","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"聊天型 (Chat)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-2l0xhne","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-2l0xhne","updated":"20250922202449"},"Children":[{"ID":"20250922202449-ann7su5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-ann7su5","updated":"20250922202449"},"Children":[{"ID":"20250922202449-raj0oe4","Type":"NodeParagraph","Properties":{"id":"20250922202449-raj0oe4","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"来源"},{"Type":"NodeText","Data":": 来自"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"真实的人机对话"},{"Type":"NodeText","Data":"（如ShareGPT, OpenAssistant）或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类模拟的对话"},{"Type":"NodeText","Data":"（如HH-RLHF, Dolly）。"}]}]},{"ID":"20250922202449-v34bgwg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-v34bgwg","updated":"20250922202449"},"Children":[{"ID":"20250922202449-lo28xp9","Type":"NodeParagraph","Properties":{"id":"20250922202449-lo28xp9","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放式、非结构化、更贴近真实世界"},{"Type":"NodeText","Data":"的交流。"}]}]},{"ID":"20250922202449-52u0hv4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-52u0hv4","updated":"20250922202449"},"Children":[{"ID":"20250922202449-k9e7e6n","Type":"NodeParagraph","Properties":{"id":"20250922202449-k9e7e6n","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"作用"},{"Type":"NodeText","Data":": 教会模型如何进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然的、多轮的、有帮助的对话"},{"Type":"NodeText","Data":"，是打造ChatGPT这类对话式模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922202449-0xzha46","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922202449-0xzha46","updated":"20250922202449"},"Children":[{"ID":"20250922202449-v3mykls","Type":"NodeParagraph","Properties":{"id":"20250922202449-v3mykls","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成型 (Synthetic)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-ia03uj3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-ia03uj3","updated":"20250922202449"},"Children":[{"ID":"20250922202449-d0ldtba","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-d0ldtba","updated":"20250922202449"},"Children":[{"ID":"20250922202449-13h1cr1","Type":"NodeParagraph","Properties":{"id":"20250922202449-13h1cr1","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"来源"},{"Type":"NodeText","Data":": 利用一个强大的“教师”模型（如GPT-4）来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动生成"},{"Type":"NodeText","Data":"大量的指令和回答。"}]}]},{"ID":"20250922202449-bvs75wi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-bvs75wi","updated":"20250922202449"},"Children":[{"ID":"20250922202449-gqudep4","Type":"NodeParagraph","Properties":{"id":"20250922202449-gqudep4","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代表"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Instruct"},{"Type":"NodeText","Data":"是开创性的方法，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca"},{"Type":"NodeText","Data":"是其最著名的应用。"}]}]},{"ID":"20250922202449-ve60xzw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-ve60xzw","updated":"20250922202449"},"Children":[{"ID":"20250922202449-kjejemy","Type":"NodeParagraph","Properties":{"id":"20250922202449-kjejemy","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成本低、可扩展性强"},{"Type":"NodeText","Data":"，可以快速生成海量数据。"}]}]},{"ID":"20250922202449-kv2h2th","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-kv2h2th","updated":"20250922202449"},"Children":[{"ID":"20250922202449-31bij3f","Type":"NodeParagraph","Properties":{"id":"20250922202449-31bij3f","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"作用"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极大地降低了指令微调的门槛"},{"Type":"NodeText","Data":"，使得在开源模型上复现ChatGPT-like能力成为可能。"}]}]}]}]}]}]},{"ID":"20250922202449-cjlvn7p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-cjlvn7p","updated":"20250922202449"},"Children":[{"ID":"20250922202449-5vf4pz5","Type":"NodeParagraph","Properties":{"id":"20250922202449-5vf4pz5","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"发展趋势"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-03zp0gx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-03zp0gx","updated":"20250922202449"},"Children":[{"ID":"20250922202449-d9docim","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-d9docim","updated":"20250922202449"},"Children":[{"ID":"20250922202449-dp9eaeo","Type":"NodeParagraph","Properties":{"id":"20250922202449-dp9eaeo","updated":"20250922202449"},"Children":[{"Type":"NodeText","Data":"从时间上看，数据集的发布从早期的任务型，发展到后来的聊天型，再到最近火爆的合成型，反映了研究焦点从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“解决NLP任务”"},{"Type":"NodeText","Data":"向"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“打造通用对话助手”"},{"Type":"NodeText","Data":"的转变。"}]}]},{"ID":"20250922202449-5223hvm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-5223hvm","updated":"20250922202449"},"Children":[{"ID":"20250922202449-tvraed8","Type":"NodeParagraph","Properties":{"id":"20250922202449-tvraed8","updated":"20250922202449"},"Children":[{"Type":"NodeText","Data":"合成数据集（如BELLE的1.5M）的规模越来越大，说明"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过“蒸馏”强大模型来训练开源模型"},{"Type":"NodeText","Data":"已成为一条主流技术路线。"}]}]}]}]}]}]},{"ID":"20250922202449-vn861q4","Type":"NodeTable","TableAligns":[1,1,1],"Properties":{"colgroup":"||","id":"20250922202449-vn861q4","updated":"20250924095820"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dataset"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Release Time"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"#Examples"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Summarize from Feedback"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Sep-2020"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"193K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SHP"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Oct-2021"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"385K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WebGPT Comparisons"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dec-2021"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"19K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Stack Exchange Preferences"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dec-2021"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10M"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HH-RLHF"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Apr-2022"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"169K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Sandbox Alignment Data"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"May-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"169K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CValues"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Jul-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"145K"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PKU-SafeRLHF"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Oct-2023"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"330K"}]}]}]},{"ID":"20250922202449-12gea6b","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202449-12gea6b","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 4：可用于对齐的数据集列表"}]},{"ID":"20250922202449-n2ioske","Type":"NodeBlockquote","Properties":{"id":"20250922202449-n2ioske","updated":"20250924095820"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202449-1lh39d8","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202449-1lh39d8","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922202449-lj1p9mr","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202449-lj1p9mr","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表4解析：为LLM校准“价值观”"}]},{"ID":"20250922202449-5qrmjgr","Type":"NodeParagraph","Properties":{"id":"20250922202449-5qrmjgr","updated":"20250922202449"},"Children":[{"Type":"NodeText","Data":"这张表格列出的是用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐（Alignment）"},{"Type":"NodeText","Data":"微调的数据集，它们是教会LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"何为“好”、何为“坏”"},{"Type":"NodeText","Data":"，使其行为符合人类价值观和偏好的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"道德准则"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922202449-llr08lv","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-llr08lv","updated":"20250922202449"},"Children":[{"ID":"20250922202449-sc02sl4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-sc02sl4","updated":"20250922202449"},"Children":[{"ID":"20250922202449-wa7xutd","Type":"NodeParagraph","Properties":{"id":"20250922202449-wa7xutd","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心形式"},{"Type":"NodeText","Data":": 这些数据集的核心不再是“指令-正确答案”，而是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“指令-多个回答-人类偏好排序”"},{"Type":"NodeText","Data":"。例如，对于一个问题，模型可能给出A、B两个回答，人类标注者会指出“A比B更好”。"}]}]}]}]},{"ID":"20250922202449-wpv02t1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-wpv02t1","updated":"20250924095820"},"Children":[{"ID":"20250922202449-itdpplh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-itdpplh","updated":"20250922202449"},"Children":[{"ID":"20250922202449-p9y9oxq","Type":"NodeParagraph","Properties":{"id":"20250922202449-p9y9oxq","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐的维度"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-1rkxjtf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-1rkxjtf","updated":"20250922202449"},"Children":[{"ID":"20250922202449-unmryb3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-unmryb3","updated":"20250922202449"},"Children":[{"ID":"20250922202449-b8mjzxj","Type":"NodeParagraph","Properties":{"id":"20250922202449-b8mjzxj","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性 (Helpfulness)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-mfbm52y","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-mfbm52y","updated":"20250922202449"},"Children":[{"ID":"20250922202449-i8rfqu6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-i8rfqu6","updated":"20250922202449"},"Children":[{"ID":"20250922202449-1kn0bqs","Type":"NodeParagraph","Properties":{"id":"20250922202449-1kn0bqs","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Summarize from Feedback"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SHP (Stanford Human Preferences)"},{"Type":"NodeText","Data":" 都专注于收集人类对于回答"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性"},{"Type":"NodeText","Data":"的偏好。SHP的数据量非常大（385K），来源是Reddit，更贴近真实世界的偏好。"}]}]},{"ID":"20250922202449-pkovaa5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-pkovaa5","updated":"20250922202449"},"Children":[{"ID":"20250922202449-fwm4lq3","Type":"NodeParagraph","Properties":{"id":"20250922202449-fwm4lq3","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Stack Exchange Preferences"},{"Type":"NodeText","Data":" 则是一个规模巨大（10M）的、来自专业问答社区的偏好数据集，代表了在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业领域"},{"Type":"NodeText","Data":"何为“好答案”的标准。"}]}]}]}]},{"ID":"20250922202449-9ze3bm6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-9ze3bm6","updated":"20250922202449"},"Children":[{"ID":"20250922202449-2ug5car","Type":"NodeParagraph","Properties":{"id":"20250922202449-2ug5car","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"诚实性/无害性 (Honesty/Harmlessness)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-ncnj8jc","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-ncnj8jc","updated":"20250922202449"},"Children":[{"ID":"20250922202449-zcygkzh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-zcygkzh","updated":"20250922202449"},"Children":[{"ID":"20250922202449-hwz95ee","Type":"NodeParagraph","Properties":{"id":"20250922202449-hwz95ee","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HH-RLHF (Helpful and Harmless - Reinforcement Learning from Human Feedback)"},{"Type":"NodeText","Data":" 是Anthropic公司发布的一个里程碑式的数据集，它同时包含了对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“有用性”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“无害性”"},{"Type":"NodeText","Data":"的偏好标注，是训练Claude这类安全模型的关键。"}]}]},{"ID":"20250922202449-chm91mo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-chm91mo","updated":"20250922202449"},"Children":[{"ID":"20250922202449-8swsvxp","Type":"NodeParagraph","Properties":{"id":"20250922202449-8swsvxp","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PKU-SafeRLHF"},{"Type":"NodeText","Data":" 是一个规模很大的（330K）中文安全对齐数据集，专注于此方向。"}]}]}]}]},{"ID":"20250922202449-hncfvx7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-hncfvx7","updated":"20250922202449"},"Children":[{"ID":"20250922202449-h8wew9n","Type":"NodeParagraph","Properties":{"id":"20250922202449-h8wew9n","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合与模拟"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-p60hrx4","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-p60hrx4","updated":"20250922202449"},"Children":[{"ID":"20250922202449-mf4mndh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-mf4mndh","updated":"20250922202449"},"Children":[{"ID":"20250922202449-ayot0tg","Type":"NodeParagraph","Properties":{"id":"20250922202449-ayot0tg","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Sandbox Alignment Data"},{"Type":"NodeText","Data":" 探索了一种新颖的模式，让LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在模拟社会环境中相互交互和提供反馈"},{"Type":"NodeText","Data":"，而不是依赖人类标注，这为自动化对齐数据收集提供了新思路。"}]}]}]}]}]}]},{"ID":"20250922202449-i740z6x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-i740z6x","updated":"20250922202449"},"Children":[{"ID":"20250922202449-ezsfdmz","Type":"NodeParagraph","Properties":{"id":"20250922202449-ezsfdmz","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"作用"},{"Type":"NodeText","Data":": 这些数据集是训练"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型（Reward Model）"},{"Type":"NodeText","Data":"的基石。在RLHF流程中，奖励模型需要学习预测人类会给哪个回答打高分，从而为强化学习提供指导信号。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可以说，没有这些偏好数据集，就没有可靠的RLHF，也就没有像ChatGPT或Claude这样既有用又安全的模型。"}]}]}]},{"ID":"20250922202449-tzj7dqo","Type":"NodeThematicBreak","Properties":{"id":"20250922202449-tzj7dqo","updated":"20250924095820"}},{"ID":"20250922202449-06wht25","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202449-06wht25","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.3 Commonly Used Datasets for Fine-tuning (常用的微调数据集)"}]},{"ID":"20250922202449-lc0gjk6","Type":"NodeParagraph","Properties":{"id":"20250922202449-lc0gjk6","updated":"20250924095820"},"Children":[{"Type":"NodeText","Data":"预训练之后，需要进一步微调LLM以增强模型能力，这通常涉及两个主要步骤，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"（监督式微调）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调"},{"Type":"NodeText","Data":"。在本节中，我们主要讨论这两种微调方法的相关可用数据集，更多算法细节可以在第5节中找到。"}]},{"ID":"20250922202449-putx58g","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922202449-putx58g","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.3.1 Instruction Tuning Datasets (指令微调数据集)"}]},{"ID":"20250922202449-do5ksy8","Type":"NodeParagraph","Properties":{"id":"20250922202449-do5ksy8","updated":"20250924095820"},"Children":[{"Type":"NodeText","Data":"预训练之后，指令微调（又称监督式微调）是增强或解锁LLM特定能力（例如，指令遵循）的重要方法。"}]},{"ID":"20250922202449-pfgirl6","Type":"NodeBlockquote","Properties":{"id":"20250922202449-pfgirl6","updated":"20250924095820"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202449-ar5l4j9","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202449-ar5l4j9","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922202449-lwzdpyf","Type":"NodeParagraph","Properties":{"id":"20250922202449-lwzdpyf","updated":"20250922202449"},"Children":[{"Type":"NodeText","Data":"这部分内容是对接下来将要详细介绍的“微调数据集”的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"引子和概述"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922202449-jbg1sy3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-jbg1sy3","updated":"20250922202449"},"Children":[{"ID":"20250922202449-j7wy20n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-j7wy20n","updated":"20250922202449"},"Children":[{"ID":"20250922202449-ozabmuc","Type":"NodeParagraph","Properties":{"id":"20250922202449-ozabmuc","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"明确微调的两个阶段"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-y8hf6gp","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922202449-y8hf6gp","updated":"20250922202449"},"Children":[{"ID":"20250922202449-6ks883w","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922202449-6ks883w","updated":"20250922202449"},"Children":[{"ID":"20250922202449-49ueb0v","Type":"NodeParagraph","Properties":{"id":"20250922202449-49ueb0v","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调 (Instruction Tuning)"},{"Type":"NodeText","Data":": 这一阶段的目标是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“教能力”"},{"Type":"NodeText","Data":"。通过大量的“指令-回答”对，让模型学会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理解和执行各种任务"},{"Type":"NodeText","Data":"，解锁其作为通用任务解决器的潜力。这更侧重于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“能不能做”"},{"Type":"NodeText","Data":"的问题。"}]}]},{"ID":"20250922202449-vj5wopz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922202449-vj5wopz","updated":"20250922202449"},"Children":[{"ID":"20250922202449-wqt4ppu","Type":"NodeParagraph","Properties":{"id":"20250922202449-wqt4ppu","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调 (Alignment Tuning)"},{"Type":"NodeText","Data":": 这一阶段的目标是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“教价值观”"},{"Type":"NodeText","Data":"。通过人类偏好数据，让模型学会生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更有帮助、更诚实、更无害"},{"Type":"NodeText","Data":"的回答。这更侧重于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“该不该做”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“该怎么做”"},{"Type":"NodeText","Data":"的问题。"}]}]}]}]},{"ID":"20250922202449-72iyx06","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-72iyx06","updated":"20250922202449"},"Children":[{"ID":"20250922202449-zuik3cg","Type":"NodeParagraph","Properties":{"id":"20250922202449-zuik3cg","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"承上启下"},{"Type":"NodeText","Data":": 这段话清晰地将讨论的焦点从“预训练数据”（模型的通识教育）转移到了“微调数据”（模型的专业和品德教育），并为后续详细介绍这两类“教材”（表3和表4中的数据集）做好了铺垫。"}]}]}]}]},{"ID":"20250922202449-jaxbnnl","Type":"NodeBlockquote","Properties":{"id":"20250922202449-jaxbnnl","updated":"20250924095820"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202449-49vcu2u","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202449-49vcu2u","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922202449-d04rfrv","Type":"NodeParagraph","Properties":{"id":"20250922202449-d04rfrv","updated":"20250922202449"},"Children":[{"Type":"NodeText","Data":"第十部分深入探讨了LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“教育体系”"},{"Type":"NodeText","Data":"，从“通识教育”到“专业教育”再到“品德教育”，全面展示了塑造一个强大、可用且安全的LLM所需的数据资源。"}]},{"ID":"20250922202449-e2n07zs","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922202449-e2n07zs","updated":"20250922202449"},"Children":[{"ID":"20250922202449-spjzwaw","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922202449-spjzwaw","updated":"20250922202449"},"Children":[{"ID":"20250922202449-1xz8mv4","Type":"NodeParagraph","Properties":{"id":"20250922202449-1xz8mv4","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三级教育体系"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-u935vj8","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-u935vj8","updated":"20250922202449"},"Children":[{"ID":"20250922202449-1cy139g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-1cy139g","updated":"20250922202449"},"Children":[{"ID":"20250922202449-h6odlbh","Type":"NodeParagraph","Properties":{"id":"20250922202449-h6odlbh","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第一级：通识教育 (Pre-training Data)"},{"Type":"NodeText","Data":": 这是模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础教育"},{"Type":"NodeText","Data":"阶段，对应的是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表2"},{"Type":"NodeText","Data":"中的海量、多样化的语料库（网页、书籍、代码等）。其目标是让模型掌握语言的规律，并尽可能多地吸收世界知识，形成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"广泛的通识基础"},{"Type":"NodeText","Data":"。这个阶段决定了模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"潜力上限"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922202449-ntifhg3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-ntifhg3","updated":"20250922202449"},"Children":[{"ID":"20250922202449-4rdqbri","Type":"NodeParagraph","Properties":{"id":"20250922202449-4rdqbri","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二级：专业/技能教育 (Instruction Tuning Data)"},{"Type":"NodeText","Data":": 这是模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高等教育和职业培训"},{"Type":"NodeText","Data":"阶段，对应的是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表3"},{"Type":"NodeText","Data":"中的指令微调数据集（任务型、聊天型、合成型）。其目标是教会模型如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用其知识"},{"Type":"NodeText","Data":"来解决具体问题、遵循指令、进行流畅对话。这个阶段是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解锁模型潜力、使其变得“有用”"},{"Type":"NodeText","Data":"的关键。"}]}]},{"ID":"20250922202449-5zlsyne","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-5zlsyne","updated":"20250922202449"},"Children":[{"ID":"20250922202449-h4p2ml4","Type":"NodeParagraph","Properties":{"id":"20250922202449-h4p2ml4","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三级：品德/价值观教育 (Alignment Tuning Data)"},{"Type":"NodeText","Data":": 这是模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“思想品德”教育"},{"Type":"NodeText","Data":"，对应的是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表4"},{"Type":"NodeText","Data":"中的对齐微调数据集（人类偏好数据）。其目标是为模型建立一套行为准则，使其回答"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符合人类的价值观（有用、诚实、无害）"},{"Type":"NodeText","Data":"。这个阶段是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确保模型“安全、可靠”"},{"Type":"NodeText","Data":"的最后一道屏障。"}]}]}]}]},{"ID":"20250922202449-7q5p70v","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922202449-7q5p70v","updated":"20250922202449"},"Children":[{"ID":"20250922202449-1xtv3bw","Type":"NodeParagraph","Properties":{"id":"20250922202449-1xtv3bw","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据工程的演进"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202449-turkw08","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202449-turkw08","updated":"20250922202449"},"Children":[{"ID":"20250922202449-ve1uylp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-ve1uylp","updated":"20250922202449"},"Children":[{"ID":"20250922202449-08k6kfv","Type":"NodeParagraph","Properties":{"id":"20250922202449-08k6kfv","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“有什么用什么”到“按需制造”"},{"Type":"NodeText","Data":": 如果说预训练数据在很大程度上是“收集和清洗”，那么微调数据，特别是指令和对齐数据，则更多地体现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“设计和制造”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922202449-o79lczn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202449-o79lczn","updated":"20250922202449"},"Children":[{"ID":"20250922202449-h6rvesd","Type":"NodeParagraph","Properties":{"id":"20250922202449-h6rvesd","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成数据的兴起"},{"Type":"NodeText","Data":": 以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Instruct (Alpaca)"},{"Type":"NodeText","Data":"为代表的合成数据技术，以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Sandbox (模拟环境)"},{"Type":"NodeText","Data":"的探索，标志着数据工程进入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自动化生成”"},{"Type":"NodeText","Data":"的新阶段。这极大地降低了数据获取成本，加速了整个领域的迭代。"}]}]}]}]},{"ID":"20250922202449-okdgfjd","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922202449-okdgfjd","updated":"20250922202449"},"Children":[{"ID":"20250922202449-0kbdswm","Type":"NodeParagraph","Properties":{"id":"20250922202449-0kbdswm","updated":"20250922202449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据是塑造AI的核心"},{"Type":"NodeText","Data":": 整个部分通过对三类不同功能的数据集的详细介绍，反复强调了一个核心观点："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我们用什么样的数据去“喂养”和“教导”AI，最终就会得到什么样能力的、具有何种行为模式的AI"},{"Type":"NodeText","Data":"。数据不仅仅是燃料，更是塑造AI智能、能力乃至“品性”的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模具"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922202449-gca2v82","Type":"NodeParagraph","Properties":{"id":"20250922202449-gca2v82","updated":"20250922202449"},"Children":[{"Type":"NodeText","Data":"总结而言，第十部分通过对三类核心数据集（预训练、指令微调、对齐微调）的系统性梳理，为我们构建了一个理解LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“成长之路”"},{"Type":"NodeText","Data":"的完整框架。它清晰地展示了一个LLM是如何从一个博学的“通才”（预训练），通过“专业技能培训”（指令微调）和“价值观塑造”（对齐微调），最终成长为一个既强大又能被社会接受的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“专家”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“助手”"},{"Type":"NodeText","Data":"的。"}]}]},{"ID":"20250922202622-6tl31sn","Type":"NodeParagraph","Properties":{"id":"20250922202622-6tl31sn","updated":"20250924101359"},"Children":[{"Type":"NodeText","Data":"在本部分中，我们介绍几种广泛使用的指令微调数据集，并根据格式化指令实例的构建方法，将它们分为三种主要类型，即NLP任务数据集、日常聊天数据集和合成数据集。我们在表3中展示了它们的详细信息。"}]},{"ID":"20250922202622-6kpmykp","Type":"NodeParagraph","Properties":{"id":"20250922202622-6kpmykp","updated":"20250924101359"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"NLP Task Datasets (NLP任务数据集)."},{"Type":"NodeText","Data":" 这类数据集是基于收集到的NLP任务数据集（例如，文本分类和摘要），并配以相应的自然语言任务描述来格式化的。在这个类别中，P3和FLAN是两种广泛用于指令微tuning的数据集。"}]},{"ID":"20250922202622-ntqhr7v","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202622-ntqhr7v","updated":"20250924101359"},"Children":[{"ID":"20250922202622-uuwlrjp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-uuwlrjp","updated":"20250922202622"},"Children":[{"ID":"20250922202622-n7autjj","Type":"NodeParagraph","Properties":{"id":"20250922202622-n7autjj","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"P3."},{"Type":"NodeText","Data":" P3由170个英语NLP数据集和2,052个英语提示模板组成，其中每个数据示例的输入和输出都已使用特定的提示模板进行格式化，以构成训练实例。"}]}]},{"ID":"20250922202622-sazk329","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-sazk329","updated":"20250922202622"},"Children":[{"ID":"20250922202622-q0fy5rw","Type":"NodeParagraph","Properties":{"id":"20250922202622-q0fy5rw","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FLAN."},{"Type":"NodeText","Data":" FLAN在其原始版本中包含62个广泛使用的NLP基准。最近，FLAN-v2也已提出，它通过混合额外的指令数据集来扩展FLAN，包括Muffin、NIV2、T0-SF和CoT。Muffin包含来自原始FLAN的62个任务以及额外的26个任务，包括对话和代码合成任务。T0-SF是从T0中提取的，同时确保与Muffin没有重叠。NIV2指的是Natural-Instructions v2数据集，而CoT是九个推理任务及其相应的思维链提示和输出的组合。"}]}]}]},{"ID":"20250922202622-4s6h3lx","Type":"NodeParagraph","Properties":{"id":"20250922202622-4s6h3lx","updated":"20250924101359"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Daily Chat Datasets (日常聊天数据集)."},{"Type":"NodeText","Data":" 这类数据集是基于真实用户对话构建的，其中查询由人类提出，响应主要由人类标注员或LLM（例如，ChatGPT, GPT-4）生成。对话类型包括开放式生成、问答、头脑风暴和聊天。在这个类别中，ShareGPT、OpenAssistant和Dolly是三种常用的LLM微调数据集。"}]},{"ID":"20250922202622-l9qknlu","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202622-l9qknlu","updated":"20250924101359"},"Children":[{"ID":"20250922202622-ck1u8ff","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-ck1u8ff","updated":"20250922202622"},"Children":[{"ID":"20250922202622-p4vrbbw","Type":"NodeParagraph","Properties":{"id":"20250922202622-p4vrbbw","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ShareGPT."},{"Type":"NodeText","Data":" ShareGPT是从一个数据收集平台收集的，用户可以通过ShareGPT API上传他们与ChatGPT或GPT-4的对话。目前，该数据集包含大约90,000次对话，包括来自人类的真实指令或查询以及来自ChatGPT的响应。"}]}]},{"ID":"20250922202622-io9d2am","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-io9d2am","updated":"20250922202622"},"Children":[{"ID":"20250922202622-k3uie1k","Type":"NodeParagraph","Properties":{"id":"20250922202622-k3uie1k","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"OpenAssistant."},{"Type":"NodeText","Data":" OpenAssistant是一个多语言语料库，包含66,497棵人类与AI助手之间的真实世界对话树。每棵对话树由多个节点组成，每个节点代表对话中一个角色生成的信息。它涵盖35种语言，并包括461,292个手动标注的响应质量评级。"}]}]},{"ID":"20250922202622-zhb0a43","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-zhb0a43","updated":"20250922202622"},"Children":[{"ID":"20250922202622-cxomv89","Type":"NodeParagraph","Properties":{"id":"20250922202622-cxomv89","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Dolly."},{"Type":"NodeText","Data":" Dolly是一个英语数据集，包含15,000个人类生成的（提示-响应对）数据实例，来自Databricks。该数据集涵盖了InstructGPT论文中概述的七个领域，包括头脑风暴、分类、闭卷质量保证、生成、信息提取、开卷质量保证和摘要。"}]}]}]},{"ID":"20250922202622-7jmpgcu","Type":"NodeParagraph","Properties":{"id":"20250922202622-7jmpgcu","updated":"20250924101359"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Synthetic Datasets (合成数据集)."},{"Type":"NodeText","Data":" 这类数据集通常是通过指示LLM，基于预定义的指导规则或方法来构建的。在这个类别中，Self-Instruct 52K、Alpaca和Baize是三种常用的LLM合成数据集。"}]},{"ID":"20250922202622-a2vcsu0","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202622-a2vcsu0","updated":"20250924101359"},"Children":[{"ID":"20250922202622-nowtmn5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-nowtmn5","updated":"20250922202622"},"Children":[{"ID":"20250922202622-paia602","Type":"NodeParagraph","Properties":{"id":"20250922202622-paia602","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Instruct-52K."},{"Type":"NodeText","Data":" Self-Instruct-52K是通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"self-instruct"},{"Type":"NodeText","Data":"方法生成的指令数据集，包含82,000个实例和52,000条指令。具体来说，作者构建了175个种子实例，然后迭代地提示LLM，以随机选择的8条指令作为参考来合成额外的指令。随后，LLM被进一步指示根据合成的指令生成实例输入及其对应的输出，最终获得Self-Instruct-52K数据集。"}]}]},{"ID":"20250922202622-7eib1ir","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-7eib1ir","updated":"20250922202622"},"Children":[{"ID":"20250922202622-vz0uc27","Type":"NodeParagraph","Properties":{"id":"20250922202622-vz0uc27","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca."},{"Type":"NodeText","Data":" Alpaca也是一个基于self-instruct方法的合成数据集。它利用"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"text-davinci-003"},{"Type":"NodeText","Data":"​模型，在来自Self-Instruct-52K的175个种子数据集上，获得了52,000条新的指令以及相应的输入和输出。此外，最终数据集中60%的示例是没有输入部分的纯指令。"}]}]},{"ID":"20250922202622-iwe583s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-iwe583s","updated":"20250922202622"},"Children":[{"ID":"20250922202622-ltd0sh6","Type":"NodeParagraph","Properties":{"id":"20250922202622-ltd0sh6","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Baize."},{"Type":"NodeText","Data":" Baize是一个使用ChatGPT构建的英语多轮对话语料库，包含111.5K个实例。为了创建Baize，提出了一种名为“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"self-chat"},{"Type":"NodeText","Data":"”的方法，其中ChatGPT轮流扮演用户和AI助手的角色，以对话形式生成信息。"}]}]}]},{"ID":"20250922202622-hebj5v7","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922202622-hebj5v7","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.3.2 Alignment Datasets (对齐数据集)"}]},{"ID":"20250922202622-wdtg6x9","Type":"NodeParagraph","Properties":{"id":"20250922202622-wdtg6x9","updated":"20250924101359"},"Children":[{"Type":"NodeText","Data":"除了指令微调，构建高质量的数据集以使LLM与人类价值观和偏好（例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性、诚实性和无害性"},{"Type":"NodeText","Data":"）对齐也很重要。在本节中，我们介绍几种广泛用于对齐微调的数据集，包括HH-RLHF、SHP、PKU-SafeRLHF、Stack Exchange Preferences和Sandbox Alignment Data。我们在表4中展示了它们的详细信息。"}]},{"ID":"20250922202622-4vgs4rq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202622-4vgs4rq","updated":"20250924101359"},"Children":[{"ID":"20250922202622-9ca5cpa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-9ca5cpa","updated":"20250922202622"},"Children":[{"ID":"20250922202622-vgc4ql6","Type":"NodeParagraph","Properties":{"id":"20250922202622-vgc4ql6","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HH-RLHF."},{"Type":"NodeText","Data":" HH-RLHF包含约169K个实例，可分为两部分，分别关注LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无害性"},{"Type":"NodeText","Data":"。每个实例都是众包工作者与聊天模型之间的开放式对话，内容涉及寻求帮助、建议或任务完成。聊天模型为每个用户查询提供两个响应，更有用或更有害的响应将被选择作为标注。"}]}]},{"ID":"20250922202622-ada41uk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-ada41uk","updated":"20250922202622"},"Children":[{"ID":"20250922202622-1lssbbp","Type":"NodeParagraph","Properties":{"id":"20250922202622-1lssbbp","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SHP."},{"Type":"NodeText","Data":" SHP关注响应的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性"},{"Type":"NodeText","Data":"。它包含了超过385K个关于18个不同主题领域的响应/指令的集体人类偏好，涵盖从烹饪到法律咨询等话题。每个实例都是一个包含问题或指令的Reddit帖子，以及一对顶级评论，其中一个被Reddit用户认为更可取，另一个则被认为不太有用。与HH-RLHF不同，SHP中的数据由自然发生且人类撰写的响应组成。"}]}]},{"ID":"20250922202622-wedtm7j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-wedtm7j","updated":"20250922202622"},"Children":[{"ID":"20250922202622-qd3c9rp","Type":"NodeParagraph","Properties":{"id":"20250922202622-qd3c9rp","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PKU-SafeRLHF."},{"Type":"NodeText","Data":" PKU-SafeRLHF包含超过330K个专家比较数据实例，专注于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无害性"},{"Type":"NodeText","Data":"。数据集中的每个实例都包括一个问题和两个响应，并附有每个响应的安全标签以及根据有用性和无害性对两个响应的两个偏好标注。响应的无害性表示其在所有14个伤害类别中被分类为风险中性，而响应的有用性则根据其解决问题的有效性进行评估。"}]}]}]},{"ID":"20250922202622-7oo8nbp","Type":"NodeBlockquote","Properties":{"id":"20250922202622-7oo8nbp","updated":"20250924101755"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202622-pzo0guj","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202622-pzo0guj","updated":"20250924101755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922202622-rkn16po","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202622-rkn16po","updated":"20250924101755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调数据集的“原材料”"}]},{"ID":"20250922202622-4nx927r","Type":"NodeParagraph","Properties":{"id":"20250922202622-4nx927r","updated":"20250922202622"},"Children":[{"Type":"NodeText","Data":"这部分详细介绍了三类指令微调数据集的构建方法和代表。"}]},{"ID":"20250922202622-prsfbj9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202622-prsfbj9","updated":"20250924101755"},"Children":[{"ID":"20250922202622-o34vyrz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-o34vyrz","updated":"20250922202622"},"Children":[{"ID":"20250922202622-fj5lvsu","Type":"NodeParagraph","Properties":{"id":"20250922202622-fj5lvsu","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"NLP任务数据集 (如FLAN)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“学院派”"},{"Type":"NodeText","Data":"的教材。它们将传统的NLP任务（如分类、摘要）包装成自然语言指令，系统性地教模型解决学术界定义的各种问题。CoT数据集的加入，专门用于训练模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922202622-f1kk23n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-f1kk23n","updated":"20250922202622"},"Children":[{"ID":"20250922202622-hv3k7u9","Type":"NodeParagraph","Properties":{"id":"20250922202622-hv3k7u9","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"日常聊天数据集 (如ShareGPT, OpenAssistant)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“社会实践”"},{"Type":"NodeText","Data":"的教材。它们来源于真实的人机对话，内容更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放、多样、口语化"},{"Type":"NodeText","Data":"，教会模型如何像一个真正的助手一样与人交流。OpenAssistant还引入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量评级"},{"Type":"NodeText","Data":"，为数据增加了更丰富的监督信号。"}]}]},{"ID":"20250922202622-4wosax6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-4wosax6","updated":"20250924101755"},"Children":[{"ID":"20250922202622-mwctw61","Type":"NodeParagraph","Properties":{"id":"20250922202622-mwctw61","updated":"20250924101755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成数据集 (如Alpaca, Baize)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自动化批量生产”"},{"Type":"NodeText","Data":"的教材。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Instruct"},{"Type":"NodeText","Data":"（让大模型自己出题、自己作答）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Chat"},{"Type":"NodeText","Data":"（让大模型自己和自己聊天）等方法，可以低成本、大规模地生成训练数据。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"democratizing (普及化)"},{"Type":"NodeText","Data":" LLM微调技术的关键，使得资源有限的研究者也能训练出强大的对话模型。"}]}]}]},{"ID":"20250922202622-xkdy8ys","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202622-xkdy8ys","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐数据集的“道德准则”"}]},{"ID":"20250922202622-kb7bica","Type":"NodeParagraph","Properties":{"id":"20250922202622-kb7bica","updated":"20250922202622"},"Children":[{"Type":"NodeText","Data":"这部分则聚焦于为LLM校准“价值观”的对齐数据集。"}]},{"ID":"20250922202622-0ukddxy","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202622-0ukddxy","updated":"20250922202622"},"Children":[{"ID":"20250922202622-vn5sutb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-vn5sutb","updated":"20250922202622"},"Children":[{"ID":"20250922202622-pb5o41o","Type":"NodeParagraph","Properties":{"id":"20250922202622-pb5o41o","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心方法论"},{"Type":"NodeText","Data":": 对齐的核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"比较和偏好"},{"Type":"NodeText","Data":"。不再是提供“标准答案”，而是提供“哪个答案更好”的信号。"}]}]},{"ID":"20250922202622-q4ikhvf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-q4ikhvf","updated":"20250922202622"},"Children":[{"ID":"20250922202622-g80l8td","Type":"NodeParagraph","Properties":{"id":"20250922202622-g80l8td","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐的维度"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202622-mwqg9jh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202622-mwqg9jh","updated":"20250922202622"},"Children":[{"ID":"20250922202622-d0oi6cq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-d0oi6cq","updated":"20250922202622"},"Children":[{"ID":"20250922202622-cn6xc08","Type":"NodeParagraph","Properties":{"id":"20250922202622-cn6xc08","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性 (Helpfulness)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SHP"},{"Type":"NodeText","Data":"数据集利用Reddit社区的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“点赞”机制"},{"Type":"NodeText","Data":"作为天然的人类偏好信号，是一种非常聪明的真实数据利用方式。"}]}]},{"ID":"20250922202622-5ox04gu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-5ox04gu","updated":"20250922202622"},"Children":[{"ID":"20250922202622-lsbghwz","Type":"NodeParagraph","Properties":{"id":"20250922202622-lsbghwz","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无害性 (Harmlessness)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HH-RLHF"},{"Type":"NodeText","Data":"是这一领域的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开创性工作"},{"Type":"NodeText","Data":"，它明确地将“无害”作为一个独立的对齐维度，并收集了大量的对比数据。这是训练出像Claude这样以安全著称的模型的基石。"}]}]},{"ID":"20250922202622-3smxgx9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-3smxgx9","updated":"20250922202622"},"Children":[{"ID":"20250922202622-z0xo776","Type":"NodeParagraph","Properties":{"id":"20250922202622-z0xo776","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业与安全并重"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PKU-SafeRLHF"},{"Type":"NodeText","Data":"则提供了由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专家"},{"Type":"NodeText","Data":"标注的、同时考虑有用性和无害性的高质量数据集，为训练更可靠、更专业的对齐模型提供了宝贵资源。"}]}]}]}]}]}]},{"ID":"20250922202622-hb60ndg","Type":"NodeBlockquote","Properties":{"id":"20250922202622-hb60ndg","updated":"20250924101359"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202622-jqnbwrs","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202622-jqnbwrs","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922202622-ds3jlsv","Type":"NodeParagraph","Properties":{"id":"20250922202622-ds3jlsv","updated":"20250922202622"},"Children":[{"Type":"NodeText","Data":"第十一部分是全篇综述中关于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据资源”"},{"Type":"NodeText","Data":"的章节的核心，它系统地梳理了微调阶段——特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调"},{"Type":"NodeText","Data":"——所依赖的关键数据集。这一部分的核心思想是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM的强大能力和安全行为，是通过不同类型、不同来源的“教材”精心“教导”出来的。"}]},{"ID":"20250922202622-h3b4r7v","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922202622-h3b4r7v","updated":"20250922202622"},"Children":[{"ID":"20250922202622-i59287p","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922202622-i59287p","updated":"20250922202622"},"Children":[{"ID":"20250922202622-lj7zcmu","Type":"NodeParagraph","Properties":{"id":"20250922202622-lj7zcmu","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“能做什么”到“应该怎么做”的教育路径"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202622-88ofrt7","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202622-88ofrt7","updated":"20250922202622"},"Children":[{"ID":"20250922202622-sgyum8q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-sgyum8q","updated":"20250922202622"},"Children":[{"ID":"20250922202622-g2ibish","Type":"NodeParagraph","Properties":{"id":"20250922202622-g2ibish","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调数据集 (表3)"},{"Type":"NodeText","Data":" 解决了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“能做什么”"},{"Type":"NodeText","Data":"的问题。它们是模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“技能培训手册”"},{"Type":"NodeText","Data":"，通过任务型、聊天型和合成型的数据，教会LLM理解指令、进行对话、解决问题。这一步的目标是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大化模型的能力和有用性"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922202622-x4pnpi5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-x4pnpi5","updated":"20250922202622"},"Children":[{"ID":"20250922202622-86oseug","Type":"NodeParagraph","Properties":{"id":"20250922202622-86oseug","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调数据集 (表4)"},{"Type":"NodeText","Data":" 解决了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“应该怎么做”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“不应该做什么”"},{"Type":"NodeText","Data":"的问题。它们是模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“道德与行为准则”"},{"Type":"NodeText","Data":"，通过人类对响应的偏好排序，教会LLM什么是“好”的回答（有用、诚实）和什么是“坏”的回答（有害、有偏见）。这一步的目标是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"约束模型的能力，使其符合人类社会的价值观"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922202622-g4iu7qh","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922202622-g4iu7qh","updated":"20250922202622"},"Children":[{"ID":"20250922202622-1dhpd8z","Type":"NodeParagraph","Properties":{"id":"20250922202622-1dhpd8z","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据收集方法的演进与创新"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202622-3azsggm","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202622-3azsggm","updated":"20250922202622"},"Children":[{"ID":"20250922202622-zsrsb90","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202622-zsrsb90","updated":"20250922202622"},"Children":[{"ID":"20250922202622-4567j3k","Type":"NodeParagraph","Properties":{"id":"20250922202622-4567j3k","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从人类密集到AI辅助"},{"Type":"NodeText","Data":": 数据集的构建过程本身也体现了技术的进步。早期的数据集（如Dolly）严重依赖"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类手动编写"},{"Type":"NodeText","Data":"。后来，研究者们开始利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"社区智慧"},{"Type":"NodeText","Data":"（如ShareGPT, SHP）。而最新的趋势是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用LLM自身的能力"},{"Type":"NodeText","Data":"来大规模生成数据，无论是生成指令（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Instruct"},{"Type":"NodeText","Data":"）、模拟对话（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Chat"},{"Type":"NodeText","Data":"），还是在模拟环境中进行交互（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Sandbox Alignment Data"},{"Type":"NodeText","Data":"），都极大地提高了数据生产的效率。"}]}]}]}]},{"ID":"20250922202622-m1v08ex","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922202622-m1v08ex","updated":"20250922202622"},"Children":[{"ID":"20250922202622-s6de4g2","Type":"NodeParagraph","Properties":{"id":"20250922202622-s6de4g2","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源社区的推动作用"},{"Type":"NodeText","Data":": 这一部分列出的绝大多数数据集都是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源"},{"Type":"NodeText","Data":"的。正是这些公开的数据集，极大地推动了开源LLM的快速发展，使得社区能够复现、改进并超越早期的闭源模型，形成了如今百花齐放的局面。"}]}]}]},{"ID":"20250922202622-6i4ozjw","Type":"NodeParagraph","Properties":{"id":"20250922202622-6i4ozjw","updated":"20250922202622"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第十一部分为我们描绘了一幅清晰的LLM“教育蓝图”。它告诉我们，一个成熟的LLM，不仅要经过预训练的“通识教育”，还必须接受指令微调的“专业技能训练”和对齐微调的“思想品德教育”。而支撑这一整套教育体系的，是社区在数据收集和构建方法上的不懈创新与开放共享精神。"}]}]},{"ID":"20250922202918-npjki59","Type":"NodeParagraph","Properties":{"id":"20250922202918-npjki59","updated":"20250924101940"},"Children":[{"Type":"NodeText","Data":"4.2节介绍常用的模型架构，最后在4.3节介绍训练技术，以稳定高效地优化LLM。"}]},{"ID":"20250922202918-v3yp6r7","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202918-v3yp6r7","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.1 Data Collection and Preparation (数据收集与准备)"}]},{"ID":"20250922202918-rgmjbp8","Type":"NodeParagraph","Properties":{"id":"20250922202918-rgmjbp8","updated":"20250924101940"},"Children":[{"Type":"NodeText","Data":"与小规模语言模型相比，LLM对高质量的预训练数据有更强的需求，其模型能力在很大程度上依赖于预训练语料库及其预处理方式。在本部分中，我们讨论预训练数据的收集和处理，包括数据源、预处理方法，以及关于预训练数据如何影响LLM性能的重要分析。"}]},{"ID":"20250922202918-9vl3b7f","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922202918-9vl3b7f","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.1.1 Data Source (数据源)"}]},{"ID":"20250922202918-cgwr9jc","Type":"NodeParagraph","Properties":{"id":"20250922202918-cgwr9jc","updated":"20250924101940"},"Children":[{"Type":"NodeText","Data":"要开发一个有能力的LLM，关键是收集大量来自不同来源的自然语言语料库。现有的LLM主要利用多样化的公开文本数据集的混合体作为预训练语料库。图6显示了多个代表性LLM的预训练数据来源分布。"}]},{"ID":"20250922202918-6cuwuuk","Type":"NodeParagraph","Properties":{"id":"20250922202918-6cuwuuk","updated":"20250924101940"},"Children":[{"Type":"NodeText","Data":"预训练语料库的来源可以大致分为两类："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用数据"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业数据"},{"Type":"NodeText","Data":"。通用数据，如网页、书籍和对话文本，因其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模大、多样化且易于获取"},{"Type":"NodeText","Data":"而被大多数LLM 所使用，这可以增强LLM的语言建模和泛化能力。鉴于LLM展现出的令人印象深刻的泛化能力，也有研究将其预训练语料库扩展到更专业的数据集，如多语言数据、科学数据和代码，从而赋予LLM特定的任务解决能力。接下来，我们将描述这两种类型的预训练数据源及其对LLM的影响。关于常用语料库的详细介绍，可以参考3.2节。"}]},{"ID":"20250922202918-0iirj13","Type":"NodeParagraph","Properties":{"id":"20250922202918-0iirj13","updated":"20250924101940"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"General Text Data (通用文本数据)."},{"Type":"NodeText","Data":" 正如图6所示，绝大多数LLM采用通用的预训练数据，如网页、书籍和对话文本，这些数据提供了关于各种主题的丰富文本来源。接下来，我们简要总结三种重要的通用数据。"}]},{"ID":"20250922202918-lokbmp6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-lokbmp6","updated":"20250924101940"},"Children":[{"ID":"20250922202918-3c9hqa5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-3c9hqa5","updated":"20250922202918"},"Children":[{"ID":"20250922202918-u259srg","Type":"NodeParagraph","Properties":{"id":"20250922202918-u259srg","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Webpages (网页)."},{"Type":"NodeText","Data":" 由于互联网的普及，各种类型的数据被创造出来，这使得LLM能够获得多样的语言知识并增强其泛化能力。为了方便使用这些数据资源，先前的工作中从网络上爬取了大量数据，例如CommonCrawl。然而，爬取的网络数据往往同时包含高质量文本（如维基百科）和低质量文本（如垃圾邮件），因此为了提高数据质量，进行过滤和处理非常重要。"}]}]},{"ID":"20250922202918-g4x49tf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-g4x49tf","updated":"20250922202918"},"Children":[{"ID":"20250922202918-papa3er","Type":"NodeParagraph","Properties":{"id":"20250922202918-papa3er","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Conversation text (对话文本)."},{"Type":"NodeText","Data":" 对话数据可以增强LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话能力"},{"Type":"NodeText","Data":"，并可能提升其在一系列问答任务上的性能。研究人员可以利用公共对话语料库的子集（例如，PushShift.io Reddit语料库）或从在线社交媒体收集对话数据。由于在线对话数据通常涉及多方参与者的讨论，一种有效的处理方式是将对话转换为树状结构，其中每个话语都链接到它所回应的话语。通过这种方式，多方对话树可以被分解为多个子对话，这些子对话可以被收集到预训练语料库中。此外，一个潜在的风险是，在LLM中过度整合对话数据可能会产生副作用：陈述性指令和直接疑问句被错误地感知为对话的开始，从而导致指令效力的下降。"}]}]},{"ID":"20250922202918-e8mt9jj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-e8mt9jj","updated":"20250922202918"},"Children":[{"ID":"20250922202918-5rk7wqb","Type":"NodeParagraph","Properties":{"id":"20250922202918-5rk7wqb","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Books (书籍)."},{"Type":"NodeText","Data":" 与其他语料库相比，书籍提供了重要的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正式长文本"},{"Type":"NodeText","Data":"来源，这可能有助于LLM学习语言知识、建模长期依赖关系以及生成叙事性和连贯的文本。为了获得开源的图书数据，现有研究通常采用Pile数据集中可用的Books3和Bookcorpus2数据集。"}]}]}]},{"ID":"20250924102316-th84j9z","Type":"NodeParagraph","Properties":{"id":"20250924102316-th84j9z","updated":"20250924102316"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250924102316-1oul4jn.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922202918-yc5h6kp","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202918-yc5h6kp","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 6：现有LLM预训练数据中各种数据源的比例"}]},{"ID":"20250922202918-783s8yo","Type":"NodeBlockquote","Properties":{"id":"20250922202918-783s8yo","updated":"20250924101940"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202918-z2ekc94","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202918-z2ekc94","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922202918-qh80y5w","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202918-qh80y5w","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图6解析：LLM们的“食谱”构成"}]},{"ID":"20250922202918-pb7mkt3","Type":"NodeParagraph","Properties":{"id":"20250922202918-pb7mkt3","updated":"20250922202918"},"Children":[{"Type":"NodeText","Data":"这张饼图集合直观地展示了不同大型语言模型在预训练时所使用的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据来源及其比例"},{"Type":"NodeText","Data":"，就像是展示了每个模型的“营养配餐食谱”。"}]},{"ID":"20250922202918-1eacqpi","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-1eacqpi","updated":"20250922202918"},"Children":[{"ID":"20250922202918-mq3u79m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-mq3u79m","updated":"20250922202918"},"Children":[{"ID":"20250922202918-a6abi8y","Type":"NodeParagraph","Properties":{"id":"20250922202918-a6abi8y","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用数据是主食"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202918-bs8ebf4","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-bs8ebf4","updated":"20250922202918"},"Children":[{"ID":"20250922202918-43whsz7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-43whsz7","updated":"20250922202918"},"Children":[{"ID":"20250922202918-8fb7w5j","Type":"NodeParagraph","Properties":{"id":"20250922202918-8fb7w5j","updated":"20250922202918"},"Children":[{"Type":"NodeText","Data":"绝大多数模型的“食谱”中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"网页数据 (Webpages, 主要是C4)"},{"Type":"NodeText","Data":" 占据了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"绝对主导"},{"Type":"NodeText","Data":"的地位（蓝色部分）。例如，T5 (11B) 几乎100%使用C4数据，而PaLM (540B)、Gopher (280B)等模型的网页数据占比也超过了50%。这说明，互联网上的海量、多样化的文本是模型学习通用世界知识的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础和主食"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922202918-1j6cxd1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-1j6cxd1","updated":"20250922202918"},"Children":[{"ID":"20250922202918-xwnliwp","Type":"NodeParagraph","Properties":{"id":"20250922202918-xwnliwp","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同模型的“偏好”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202918-3x5e3fp","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-3x5e3fp","updated":"20250922202918"},"Children":[{"ID":"20250922202918-8a3vzi3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-8a3vzi3","updated":"20250922202918"},"Children":[{"ID":"20250922202918-8ym3fah","Type":"NodeParagraph","Properties":{"id":"20250922202918-8ym3fah","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PaLM (540B) vs. LLaMA (65B)"},{"Type":"NodeText","Data":": PaLM在其食谱中加入了相当比例的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"书籍 (Books \u0026amp; News)"},{"Type":"NodeText","Data":" 和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话数据 (Conversation data)"},{"Type":"NodeText","Data":"，这可能有助于其在叙事和对话任务上的表现。而LLaMA的“食谱”则"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极其纯粹"},{"Type":"NodeText","Data":"，几乎完全由网页数据构成，这表明高质量、大规模的网页数据本身就足以训练出强大的模型。"}]}]},{"ID":"20250922202918-76q2e4v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-76q2e4v","updated":"20250922202918"},"Children":[{"ID":"20250922202918-ykhqcje","Type":"NodeParagraph","Properties":{"id":"20250922202918-ykhqcje","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专才模型 (Specialist Models)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CodeGen (16B)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"StarCoder 2 (15B)"},{"Type":"NodeText","Data":" 的“食谱”则非常特殊，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码 (Code)"},{"Type":"NodeText","Data":" 数据（紫色部分）占据了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"绝对主导"},{"Type":"NodeText","Data":"。这清晰地表明，它们是被专门设计用来理解和生成代码的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“专才”"},{"Type":"NodeText","Data":"模型。"}]}]},{"ID":"20250922202918-dtz3t8b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-dtz3t8b","updated":"20250922202918"},"Children":[{"ID":"20250922202918-22s9rcs","Type":"NodeParagraph","Properties":{"id":"20250922202918-22s9rcs","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多才多艺的模型 (Versatile Models)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Galactica (120B)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Yi (34B)"},{"Type":"NodeText","Data":" 的“食谱”则更加"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"均衡"},{"Type":"NodeText","Data":"，除了网页数据，还包含了大量的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学数据 (Scientific data)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码"},{"Type":"NodeText","Data":"。这使得它们在科学文献理解和代码生成等领域可能具有更强的能力。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MT-NLG (530B)"},{"Type":"NodeText","Data":" 的“食谱”则像一个“大杂烩”，混合了多种来源的数据，体现了其构建一个综合性模型的意图。"}]}]}]}]},{"ID":"20250922202918-ucc98i1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-ucc98i1","updated":"20250922202918"},"Children":[{"ID":"20250922202918-zzf80sz","Type":"NodeParagraph","Properties":{"id":"20250922202918-zzf80sz","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据的演进"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202918-qak9wlt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-qak9wlt","updated":"20250922202918"},"Children":[{"ID":"20250922202918-zejfdsx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-zejfdsx","updated":"20250922202918"},"Children":[{"ID":"20250922202918-dfhfwk3","Type":"NodeParagraph","Properties":{"id":"20250922202918-dfhfwk3","updated":"20250922202918"},"Children":[{"Type":"NodeText","Data":"早期的T5模型数据来源相对单一。而后来的模型，如PaLM、Gopher，开始有意识地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合多种数据源"},{"Type":"NodeText","Data":"，如书籍、新闻和对话，以期获得更全面的能力。"}]}]},{"ID":"20250922202918-x7lf7ac","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-x7lf7ac","updated":"20250922202918"},"Children":[{"ID":"20250922202918-132u8ha","Type":"NodeParagraph","Properties":{"id":"20250922202918-132u8ha","updated":"20250922202918"},"Children":[{"Type":"NodeText","Data":"LLaMA的成功又似乎表明，只要网页数据的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量足够高、规模足够大"},{"Type":"NodeText","Data":"，单一数据源也能取得很好的效果。"}]}]}]}]}]},{"ID":"20250922202918-odlcqrc","Type":"NodeParagraph","Properties":{"id":"20250922202918-odlcqrc","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张图谱揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“你喂给模型什么，它就擅长什么”"},{"Type":"NodeText","Data":"这一基本原则。不同的数据配比，会塑造出能力倾向各异的模型。预训练数据的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"选择和配比"},{"Type":"NodeText","Data":"本身，就是一门深刻的学问，直接决定了最终模型的“基因”和“特长”。"}]}]},{"ID":"20250922202918-vy7zvpb","Type":"NodeParagraph","Properties":{"id":"20250922202918-vy7zvpb","updated":"20250924101940"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Specialized Text Data (专业文本数据)."},{"Type":"NodeText","Data":" 专业数据集有助于提升LLM在下游任务上的特定能力。接下来，我们介绍三种专业数据。"}]},{"ID":"20250922202918-23mhxz2","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-23mhxz2","updated":"20250924101940"},"Children":[{"ID":"20250922202918-akdm6s1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-akdm6s1","updated":"20250922202918"},"Children":[{"ID":"20250922202918-9cp42kg","Type":"NodeParagraph","Properties":{"id":"20250922202918-9cp42kg","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Multilingual text (多语言文本)."},{"Type":"NodeText","Data":" 除了目标语言的文本，整合多语言语料库可以增强语言理解和生成的多语言能力。例如，BLOOM和PaLM分别在其预训练语料库中整理了覆盖46种和122种语言的多语言数据。FLM则以几乎相等的比例混合了中文和英文语料库。这些模型在多语言任务（如翻译、多语言摘要和多语言问答）上表现出色，并取得了与在目标语言语料库上微调的最新模型相当或更优的性能。"}]}]},{"ID":"20250922202918-k9mbg5v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-k9mbg5v","updated":"20250922202918"},"Children":[{"ID":"20250922202918-izdjwya","Type":"NodeParagraph","Properties":{"id":"20250922202918-izdjwya","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Scientific text (科学文本)."},{"Type":"NodeText","Data":" 人类对科学的探索见证了科学出版物的不断增长。为了增强LLM对科学知识的理解，将科学语料库纳入模型预训练是非常有用的。通过在大量科学文本上进行预训练，LLM可以在科学和推理任务上取得令人印象深刻的性能。为了构建科学语料库，现有的努力主要收集arXiv论文、科学教科书、数学网页和其他相关的科学资源。由于科学领域数据的复杂性，如数学符号和蛋白质序列，通常需要特定的分词和预处理技术来将这些不同格式的数据转换为语言模型可以处理的统一形式。"}]}]},{"ID":"20250922202918-uwx4opr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-uwx4opr","updated":"20250922202918"},"Children":[{"ID":"20250922202918-5kk5kdr","Type":"NodeParagraph","Properties":{"id":"20250922202918-5kk5kdr","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Code (代码)."},{"Type":"NodeText","Data":" 程序合成在研究界得到了广泛研究，特别是使用在代码上训练的PLM。然而，让这些PLM（例如，GPT-J）生成高质量和准确的程序仍然具有挑战性。最近的研究发现，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"庞大的代码语料库"},{"Type":"NodeText","Data":"上训练LLM可以显著提升合成程序的质量。生成的程序可以成功通过专家设计的单元测试用例或解决竞争性编程问题。通常，有两种类型的代码语料库被用于预训练LLM。第一种来源是编程问答社区，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Stack Exchange"},{"Type":"NodeText","Data":"。第二种来源是公共软件仓库，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GitHub"},{"Type":"NodeText","Data":"，从中收集代码数据（包括注释和文档字符串）加以利用。与自然语言文本相比，代码是编程语言的格式，对应于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长距离依赖"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确的执行逻辑"},{"Type":"NodeText","Data":"。最近的一项研究还推测，在代码上训练可能是复杂推理能力（例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链能力"},{"Type":"NodeText","Data":"）的一个来源。此外，已经证明将推理任务格式化为代码可以帮助LLM生成更准确的结果。"}]}]}]},{"ID":"20250922202918-tq5tisb","Type":"NodeBlockquote","Properties":{"id":"20250922202918-tq5tisb","updated":"20250924101940"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202918-0rrb8l4","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202918-0rrb8l4","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922202918-x4pa42w","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202918-x4pa42w","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用数据 vs. 专业数据：通才与专才的培养"}]},{"ID":"20250922202918-0uceu1m","Type":"NodeParagraph","Properties":{"id":"20250922202918-0uceu1m","updated":"20250922202918"},"Children":[{"Type":"NodeText","Data":"这部分内容的核心是将LLM的训练数据分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业"},{"Type":"NodeText","Data":"两大类，这可以类比为对一个学生的“通识教育”和“专业教育”。"}]},{"ID":"20250922202918-yvmkks5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-yvmkks5","updated":"20250922202918"},"Children":[{"ID":"20250922202918-bajxhij","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-bajxhij","updated":"20250922202918"},"Children":[{"ID":"20250922202918-ks1zdmx","Type":"NodeParagraph","Properties":{"id":"20250922202918-ks1zdmx","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用文本数据 (General Text Data)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202918-m8vz2jy","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-m8vz2jy","updated":"20250922202918"},"Children":[{"ID":"20250922202918-7blac5c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-7blac5c","updated":"20250922202918"},"Children":[{"ID":"20250922202918-lwh4rl0","Type":"NodeParagraph","Properties":{"id":"20250922202918-lwh4rl0","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"角色"},{"Type":"NodeText","Data":": 这是LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通识教育”"},{"Type":"NodeText","Data":"材料，构成了其知识和能力的基础。"}]}]},{"ID":"20250922202918-i9cnry1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-i9cnry1","updated":"20250922202918"},"Children":[{"ID":"20250922202918-i9g2gb6","Type":"NodeParagraph","Properties":{"id":"20250922202918-i9g2gb6","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大来源"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202918-kchribg","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922202918-kchribg","updated":"20250922202918"},"Children":[{"ID":"20250922202918-9nl39tf","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922202918-9nl39tf","updated":"20250922202918"},"Children":[{"ID":"20250922202918-ywk9yvv","Type":"NodeParagraph","Properties":{"id":"20250922202918-ywk9yvv","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"网页 (Webpages)"},{"Type":"NodeText","Data":": 提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"广度"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"，是模型世界知识的主要来源。但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量控制"},{"Type":"NodeText","Data":"是关键挑战。"}]}]},{"ID":"20250922202918-4at1r12","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922202918-4at1r12","updated":"20250922202918"},"Children":[{"ID":"20250922202918-2a50d90","Type":"NodeParagraph","Properties":{"id":"20250922202918-2a50d90","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话文本 (Conversation text)"},{"Type":"NodeText","Data":": 教授模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交互和对话"},{"Type":"NodeText","Data":"的能力，使其更具“社交智能”。但需要注意，过多的对话数据可能影响其执行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严谨指令"},{"Type":"NodeText","Data":"的能力。"}]}]},{"ID":"20250922202918-xqb0zta","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922202918-xqb0zta","updated":"20250922202918"},"Children":[{"ID":"20250922202918-syjduob","Type":"NodeParagraph","Properties":{"id":"20250922202918-syjduob","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"书籍 (Books)"},{"Type":"NodeText","Data":": 提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连贯性"},{"Type":"NodeText","Data":"，对于模型学习"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长程依赖"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正式语言"},{"Type":"NodeText","Data":"至关重要。"}]}]}]}]}]}]},{"ID":"20250922202918-hy9o6u7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-hy9o6u7","updated":"20250922202918"},"Children":[{"ID":"20250922202918-723f5dk","Type":"NodeParagraph","Properties":{"id":"20250922202918-723f5dk","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业文本数据 (Specialized Text Data)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202918-f4as8op","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-f4as8op","updated":"20250922202918"},"Children":[{"ID":"20250922202918-64p1fj3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-64p1fj3","updated":"20250922202918"},"Children":[{"ID":"20250922202918-x2mqqo9","Type":"NodeParagraph","Properties":{"id":"20250922202918-x2mqqo9","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"角色"},{"Type":"NodeText","Data":": 这是LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“专业教育”"},{"Type":"NodeText","Data":"材料，旨在培养其在特定领域的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“专长”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922202918-6a54fww","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-6a54fww","updated":"20250922202918"},"Children":[{"ID":"20250922202918-p7hifxi","Type":"NodeParagraph","Properties":{"id":"20250922202918-p7hifxi","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大专业方向"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202918-inm0gyt","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922202918-inm0gyt","updated":"20250922202918"},"Children":[{"ID":"20250922202918-d4l8iiy","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922202918-d4l8iiy","updated":"20250922202918"},"Children":[{"ID":"20250922202918-ib4mckc","Type":"NodeParagraph","Properties":{"id":"20250922202918-ib4mckc","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多语言文本 (Multilingual text)"},{"Type":"NodeText","Data":": 培养模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“翻译官”"},{"Type":"NodeText","Data":"能力。BLOOM和PaLM是这方面的代表。"}]}]},{"ID":"20250922202918-19obmzn","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922202918-19obmzn","updated":"20250922202918"},"Children":[{"ID":"20250922202918-dgewial","Type":"NodeParagraph","Properties":{"id":"20250922202918-dgewial","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学文本 (Scientific text)"},{"Type":"NodeText","Data":": 培养模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“科学家”"},{"Type":"NodeText","Data":"能力，使其能够理解复杂的科学概念、公式和推理。处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特殊符号"},{"Type":"NodeText","Data":"（如数学公式）是其技术难点。"}]}]},{"ID":"20250922202918-c0hg1y5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922202918-c0hg1y5","updated":"20250922202918"},"Children":[{"ID":"20250922202918-t680a99","Type":"NodeParagraph","Properties":{"id":"20250922202918-t680a99","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码 (Code)"},{"Type":"NodeText","Data":": 培养模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“程序员”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“逻辑学家”"},{"Type":"NodeText","Data":"能力。代码是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构化、逻辑严密"},{"Type":"NodeText","Data":"的语言，训练代码不仅能让模型会编程，更重要的是，能极大地提升其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逻辑推理"},{"Type":"NodeText","Data":"能力，甚至是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"能力的基础来源。"}]}]}]}]}]}]}]},{"ID":"20250922202918-u45di54","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922202918-u45di54","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心洞见"}]},{"ID":"20250922202918-0whjh66","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-0whjh66","updated":"20250922202918"},"Children":[{"ID":"20250922202918-y7uvvsd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-y7uvvsd","updated":"20250922202918"},"Children":[{"ID":"20250922202918-k620gvi","Type":"NodeParagraph","Properties":{"id":"20250922202918-k620gvi","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据决定能力"},{"Type":"NodeText","Data":": 这一节再次印证了“You are what you eat”的道理。喂给模型什么样的数据，它就会展现出什么样的能力。想要一个会写诗的通才，就多喂些书籍和网页；想要一个会编程的专才，就必须大量喂养代码数据。"}]}]},{"ID":"20250922202918-qky73ki","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-qky73ki","updated":"20250922202918"},"Children":[{"ID":"20250922202918-u65x89p","Type":"NodeParagraph","Properties":{"id":"20250922202918-u65x89p","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码的双重价值"},{"Type":"NodeText","Data":": 代码数据对于LLM的价值是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"双重的"},{"Type":"NodeText","Data":"。它既是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技能"},{"Type":"NodeText","Data":"（编程），更是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"底层能力"},{"Type":"NodeText","Data":"（逻辑推理）。这解释了为什么基于代码训练的模型（如Codex）在数学和逻辑问题上表现得更好。"}]}]}]}]},{"ID":"20250922202918-0am9dwf","Type":"NodeBlockquote","Properties":{"id":"20250922202918-0am9dwf","updated":"20250924101940"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922202918-d2a4u1s","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922202918-d2a4u1s","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922202918-2dxd8vu","Type":"NodeParagraph","Properties":{"id":"20250922202918-2dxd8vu","updated":"20250922202918"},"Children":[{"Type":"NodeText","Data":"第十三部分是“预训练”章节的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基石"},{"Type":"NodeText","Data":"，它详细地剖析了大型语言模型（LLM）的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“食物”——即预训练数据"},{"Type":"NodeText","Data":"。这一部分的核心思想是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练数据的来源、构成和特性，从根本上决定了LLM最终的能力图谱和行为模式。"}]},{"ID":"20250922202918-ipti1s8","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922202918-ipti1s8","updated":"20250922202918"},"Children":[{"ID":"20250922202918-hdagh2i","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922202918-hdagh2i","updated":"20250922202918"},"Children":[{"ID":"20250922202918-swa4a3u","Type":"NodeParagraph","Properties":{"id":"20250922202918-swa4a3u","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据构成的“金字塔模型”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202918-oquz3e4","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-oquz3e4","updated":"20250922202918"},"Children":[{"ID":"20250922202918-ejrqacx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-ejrqacx","updated":"20250922202918"},"Children":[{"ID":"20250922202918-356lj3s","Type":"NodeParagraph","Properties":{"id":"20250922202918-356lj3s","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"塔基（广度与通用性）"},{"Type":"NodeText","Data":": 由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用文本数据"},{"Type":"NodeText","Data":"（网页、书籍、对话）构成。这是LLM能力的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础"},{"Type":"NodeText","Data":"，为其提供了广博的世界知识、基础语言能力和交互模式。绝大多数LLM都建立在这个坚实的塔基之上，如图6所示。"}]}]},{"ID":"20250922202918-kxvieg4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-kxvieg4","updated":"20250922202918"},"Children":[{"ID":"20250922202918-56xdc9b","Type":"NodeParagraph","Properties":{"id":"20250922202918-56xdc9b","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"塔尖（深度与专业性）"},{"Type":"NodeText","Data":": 由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业文本数据"},{"Type":"NodeText","Data":"（多语言、科学、代码）构成。这是为了培养LLM在特定领域的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“专长”"},{"Type":"NodeText","Data":"。通过“喂养”这些专业数据，可以让模型从一个“通才”转变为在翻译、科学研究或编程等领域的“专家”。"}]}]}]}]},{"ID":"20250922202918-u1yyak6","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922202918-u1yyak6","updated":"20250922202918"},"Children":[{"ID":"20250922202918-5mfo4wf","Type":"NodeParagraph","Properties":{"id":"20250922202918-5mfo4wf","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“代码”作为“元能力”的特殊地位"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202918-ihzhboz","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-ihzhboz","updated":"20250922202918"},"Children":[{"ID":"20250922202918-8uac6ug","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-8uac6ug","updated":"20250922202918"},"Children":[{"ID":"20250922202918-9eqnl0q","Type":"NodeParagraph","Properties":{"id":"20250922202918-9eqnl0q","updated":"20250922202918"},"Children":[{"Type":"NodeText","Data":"文章特别强调了代码数据的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特殊重要性"},{"Type":"NodeText","Data":"。训练代码不仅仅是为了让LLM学会编程这一项技能，更重要的是，代码本身所蕴含的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严密逻辑、长距离依赖和结构化思想"},{"Type":"NodeText","Data":"，被认为是提升LLM整体"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逻辑推理能力"},{"Type":"NodeText","Data":"，甚至是催生"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"等高级能力的关键来源。这可以看作是对LLM智能来源的一个深刻洞察。"}]}]}]}]},{"ID":"20250922202918-utk3fsw","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922202918-utk3fsw","updated":"20250922202918"},"Children":[{"ID":"20250922202918-ndm9kik","Type":"NodeParagraph","Properties":{"id":"20250922202918-ndm9kik","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据工程的艺术与科学"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922202918-210on4f","Type":"NodeList","ListData":{},"Properties":{"id":"20250922202918-210on4f","updated":"20250922202918"},"Children":[{"ID":"20250922202918-m33ypfm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-m33ypfm","updated":"20250922202918"},"Children":[{"ID":"20250922202918-ueagsrv","Type":"NodeParagraph","Properties":{"id":"20250922202918-ueagsrv","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据源的选择和配比是一门艺术"},{"Type":"NodeText","Data":"。如图6所示，不同的模型有不同的“食谱”，这反映了模型设计者对其能力定位的考量。是追求全面的“六边形战士”，还是某个领域的“单项冠军”，很大程度上取决于数据配方。"}]}]},{"ID":"20250922202918-w59yptw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922202918-w59yptw","updated":"20250922202918"},"Children":[{"ID":"20250922202918-1t4beyy","Type":"NodeParagraph","Properties":{"id":"20250922202918-1t4beyy","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据处理是一门科学"},{"Type":"NodeText","Data":"。文章强调了对原始数据（特别是网络数据）进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清洗、过滤和预处理"},{"Type":"NodeText","Data":"的至关重要性，以及处理特殊格式数据（如数学符号、代码）所需的技术挑战。"}]}]}]}]}]},{"ID":"20250922202918-r9kgwos","Type":"NodeParagraph","Properties":{"id":"20250922202918-r9kgwos","updated":"20250922202918"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第十三部分通过对数据源的系统性分类和介绍，为我们揭示了LLM能力形成的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“原料”基础"},{"Type":"NodeText","Data":"。它清晰地表明，一个成功的LLM，其背后必然是一套经过精心设计和处理的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据鸡尾酒”"},{"Type":"NodeText","Data":"，其中通用数据提供了广阔的基底，而专业数据则赋予了其独特的风味和特长。理解这一点，对于理解不同LLM之间的能力差异以及如何构建更强大的LLM至关重要。"}]}]},{"ID":"20250922203108-zvheqy2","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922203108-zvheqy2","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.1.2 Data Preprocessing (数据预处理)"}]},{"ID":"20250922203108-4cl3y3u","Type":"NodeParagraph","Properties":{"id":"20250922203108-4cl3y3u","updated":"20250924104303"},"Children":[{"Type":"NodeText","Data":"在收集了大量文本数据之后，对数据进行预处理以构建预训练语料库至关重要，特别是要去除"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"噪声、冗余、无关和潜在有毒"},{"Type":"NodeText","Data":"的数据，这些都可能极大地影响LLM的能力和性能。为了方便数据处理，最近的一项研究提出了一个名为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Data-Juicer"},{"Type":"NodeText","Data":"的有用数据处理系统，它提供了超过50种处理操作符和工具。在本部分中，我们回顾了用于提高所收集数据质量的详细数据预处理策略。LLM预训练数据的典型预处理流程已在图7中说明。"}]},{"ID":"20250922203108-tlsn174","Type":"NodeParagraph","Properties":{"id":"20250922203108-tlsn174","updated":"20250924104303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Filtering and Selection (过滤与选择)."},{"Type":"NodeText","Data":" 为了从收集的语料库中去除低质量数据，现有的工作通常采用两种方法，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于分类器的方法"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于启发式规则的方法"},{"Type":"NodeText","Data":"。前者训练一个基于高质量文本的选择分类器，并利用它来识别和过滤掉低质量数据。通常，这些方法使用以下正例来训练一个二元分类器：精心策划的数据（例如，维基百科页面）、高质量的合成数据，或两者的结合。它们将候选数据作为负例进行抽样，并预测衡量每个数据示例质量的分数。然而，一些研究发现，基于分类器的方法可能会导致无意中删除方言、口语和社会方言中的高质量文本，这可能导致预训练语料库的偏见，并减少语料库的多样性。作为第二种方法，一些研究，如BLOOM和Gopher，采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于启发式规则"},{"Type":"NodeText","Data":"的方法，通过一套精心设计的规则来消除低质量文本，可以总结如下："}]},{"ID":"20250922203108-jye8qfj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-jye8qfj","updated":"20250924104303"},"Children":[{"ID":"20250922203108-72ysnjs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-72ysnjs","updated":"20250922203108"},"Children":[{"ID":"20250922203108-wws5bxa","Type":"NodeParagraph","Properties":{"id":"20250922203108-wws5bxa","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于语言的过滤。"},{"Type":"NodeText","Data":" 如果一个LLM主要用于某些特定语言的任务，那么其他语言的文本可以被过滤掉。"}]}]},{"ID":"20250922203108-47pokoa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-47pokoa","updated":"20250922203108"},"Children":[{"ID":"20250922203108-0lgg2bv","Type":"NodeParagraph","Properties":{"id":"20250922203108-0lgg2bv","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于度量的过滤。"},{"Type":"NodeText","Data":" 可以利用关于生成文本的评估指标，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"困惑度（perplexity）"},{"Type":"NodeText","Data":"，来检测和移除不自然的句子。"}]}]},{"ID":"20250922203108-sldbtvt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-sldbtvt","updated":"20250922203108"},"Children":[{"ID":"20250922203108-koru6hz","Type":"NodeParagraph","Properties":{"id":"20250922203108-koru6hz","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于统计的过滤。"},{"Type":"NodeText","Data":" 语料库的统计特征，例如标点符号分布、符号与词的比例以及句子长度，可以被用来衡量文本质量并过滤低质量数据。"}]}]},{"ID":"20250922203108-hefur6h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-hefur6h","updated":"20250922203108"},"Children":[{"ID":"20250922203108-r8y9z0z","Type":"NodeParagraph","Properties":{"id":"20250922203108-r8y9z0z","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于关键词的过滤。"},{"Type":"NodeText","Data":" 基于特定的关键词集，可以识别并移除文本中的噪声或无用元素，如HTML标签、超链接、样板文件和冒犯性词语。"}]}]}]},{"ID":"20250922203108-l74u6ci","Type":"NodeParagraph","Properties":{"id":"20250922203108-l74u6ci","updated":"20250924104303"},"Children":[{"Type":"NodeText","Data":"除了上述方法，LLM（特别是相对较小的模型）也可以用于数据选择，可以通过计算困惑度或直接提示LLM来衡量样本的重要性。然而，使用LLM进行大规模数据选择不可避免地会带来巨大的计算开销。"}]},{"ID":"20250924104654-vgvspeb","Type":"NodeParagraph","Properties":{"id":"20250924104654-vgvspeb","updated":"20250924104654"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250924104654-y4cijqv.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922203108-hwyw5v1","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203108-hwyw5v1","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 7：预训练大型语言模型的典型数据预处理流程图"}]},{"ID":"20250922203108-340mw82","Type":"NodeBlockquote","Properties":{"id":"20250922203108-340mw82","updated":"20250924104303"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203108-ed47qc3","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203108-ed47qc3","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922203108-q7l9nxs","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203108-q7l9nxs","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图7解析：LLM数据的“净化流水线”"}]},{"ID":"20250922203108-st6y8qb","Type":"NodeParagraph","Properties":{"id":"20250922203108-st6y8qb","updated":"20250922203108"},"Children":[{"Type":"NodeText","Data":"这张图生动地展示了原始的、混杂的数据（Raw Corpus）是如何经过一系列"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“净化”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“格式化”"},{"Type":"NodeText","Data":"步骤，最终变成可供LLM“食用”的干净、规整的数据（Ready to pre-train!）的。"}]},{"ID":"20250922203108-6yvsxr6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-6yvsxr6","updated":"20250922203108"},"Children":[{"ID":"20250922203108-ptjofu8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-ptjofu8","updated":"20250922203108"},"Children":[{"ID":"20250922203108-ie5u100","Type":"NodeParagraph","Properties":{"id":"20250922203108-ie5u100","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"步骤一：过滤与选择 (Filtering \u0026amp; Selection)"}]},{"ID":"20250922203108-8o8xmyy","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-8o8xmyy","updated":"20250922203108"},"Children":[{"ID":"20250922203108-zb5ujs5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-zb5ujs5","updated":"20250922203108"},"Children":[{"ID":"20250922203108-gbbttnv","Type":"NodeParagraph","Properties":{"id":"20250922203108-gbbttnv","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"去粗取精"},{"Type":"NodeText","Data":"。这是数据清洗的第一步，旨在剔除明显的低质量文本。"}]}]},{"ID":"20250922203108-6ybpt7v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-6ybpt7v","updated":"20250922203108"},"Children":[{"ID":"20250922203108-c5uel78","Type":"NodeParagraph","Properties":{"id":"20250922203108-c5uel78","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": 通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言、度量（如困惑度）、统计特征、关键词"},{"Type":"NodeText","Data":"等多种启发式规则，对数据进行初步筛选。图中示例 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Alice is writing a paper about LLMs. #$^\u0026amp;"},{"Type":"NodeText","Data":"​ 变成了 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Alice is writing a paper about LLMs."},{"Type":"NodeText","Data":"​，就是去除了无意义的符号。"}]}]}]}]},{"ID":"20250922203108-wderwth","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-wderwth","updated":"20250922203108"},"Children":[{"ID":"20250922203108-iue0mdl","Type":"NodeParagraph","Properties":{"id":"20250922203108-iue0mdl","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"步骤二：去重 (De-duplication)"}]},{"ID":"20250922203108-ukcnplx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-ukcnplx","updated":"20250922203108"},"Children":[{"ID":"20250922203108-jjlftkb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-jjlftkb","updated":"20250922203108"},"Children":[{"ID":"20250922203108-e27mx06","Type":"NodeParagraph","Properties":{"id":"20250922203108-e27mx06","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"保证多样性"},{"Type":"NodeText","Data":"。去除重复或高度相似的内容，避免模型在重复数据上过拟合，从而影响其泛化能力。"}]}]},{"ID":"20250922203108-a9ijp3q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-a9ijp3q","updated":"20250922203108"},"Children":[{"ID":"20250922203108-2jbb0ln","Type":"NodeParagraph","Properties":{"id":"20250922203108-2jbb0ln","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"粒度"},{"Type":"NodeText","Data":": 去重可以在不同层级进行，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"句子级、文档级和数据集级"},{"Type":"NodeText","Data":"。图中示例 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Alice is writing a paper about LLMs. Alice is writing a paper about LLMs."},{"Type":"NodeText","Data":"​ 被合并为一条，就是文档级的去重。"}]}]}]}]},{"ID":"20250922203108-nokmnfi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-nokmnfi","updated":"20250922203108"},"Children":[{"ID":"20250922203108-yn7wvut","Type":"NodeParagraph","Properties":{"id":"20250922203108-yn7wvut","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"步骤三：隐私保护 (Privacy Reduction)"}]},{"ID":"20250922203108-8druohj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-8druohj","updated":"20250922203108"},"Children":[{"ID":"20250922203108-q4v8q9n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-q4v8q9n","updated":"20250922203108"},"Children":[{"ID":"20250922203108-9qjfr7y","Type":"NodeParagraph","Properties":{"id":"20250922203108-9qjfr7y","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确保安全与合规"},{"Type":"NodeText","Data":"。识别并移除文本中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"个人可识别信息（PII）"},{"Type":"NodeText","Data":"，如姓名、地址、电话号码等。"}]}]},{"ID":"20250922203108-8dxiol4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-8dxiol4","updated":"20250922203108"},"Children":[{"ID":"20250922203108-1wr82cb","Type":"NodeParagraph","Properties":{"id":"20250922203108-1wr82cb","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": 通过规则或模型检测PII，并进行脱敏处理。图中示例 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Alice is writing a paper about LLMs."},{"Type":"NodeText","Data":"​ 中的 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Alice"},{"Type":"NodeText","Data":"​ 被替换成了 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[Somebody]"},{"Type":"NodeText","Data":"​。"}]}]}]}]},{"ID":"20250922203108-wglryt6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-wglryt6","updated":"20250922203108"},"Children":[{"ID":"20250922203108-jphqqh5","Type":"NodeParagraph","Properties":{"id":"20250922203108-jphqqh5","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"步骤四：分词 (Tokenization)"}]},{"ID":"20250922203108-3o5opia","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-3o5opia","updated":"20250922203108"},"Children":[{"ID":"20250922203108-8fdd451","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-8fdd451","updated":"20250922203108"},"Children":[{"ID":"20250922203108-vp84jtk","Type":"NodeParagraph","Properties":{"id":"20250922203108-vp84jtk","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"格式化输入"},{"Type":"NodeText","Data":"。将连续的文本字符串切分成模型能够理解的最小单元——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词元（Token）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203108-9m248kq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-9m248kq","updated":"20250922203108"},"Children":[{"ID":"20250922203108-jobyes2","Type":"NodeParagraph","Properties":{"id":"20250922203108-jobyes2","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": 现代LLM普遍采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"子词（Subword）"},{"Type":"NodeText","Data":"分词算法，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SentencePiece"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Byte-level BPE"},{"Type":"NodeText","Data":"，它们能有效处理未登录词（OOV）和多语言文本。图中示例 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[Somebody] is writing a paper about LLMs."},{"Type":"NodeText","Data":"​ 被编码成了一串数字ID "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"32, 145, 66, ..."},{"Type":"NodeText","Data":"​。"}]}]}]}]},{"ID":"20250922203108-f1blfbx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-f1blfbx","updated":"20250922203108"},"Children":[{"ID":"20250922203108-yj20f0s","Type":"NodeParagraph","Properties":{"id":"20250922203108-yj20f0s","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最终产出"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203108-d5fwhyr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-d5fwhyr","updated":"20250922203108"},"Children":[{"ID":"20250922203108-4istj9b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-4istj9b","updated":"20250922203108"},"Children":[{"ID":"20250922203108-6jbbkmj","Type":"NodeParagraph","Properties":{"id":"20250922203108-6jbbkmj","updated":"20250922203108"},"Children":[{"Type":"NodeText","Data":"经过这条流水线处理后，原始的、庞杂的文本数据就变成了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"干净、多样、安全且格式统一"},{"Type":"NodeText","Data":"的词元序列，可以直接输入到模型中进行预训练。"}]}]}]}]}]},{"ID":"20250922203108-bx9gd7b","Type":"NodeParagraph","Properties":{"id":"20250922203108-bx9gd7b","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张图揭示了高质量的预训练数据"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"来之不易"},{"Type":"NodeText","Data":"。它背后是一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂、严谨且多步骤"},{"Type":"NodeText","Data":"的数据工程流程。这条“净化流水线”的效率和质量，直接决定了最终训练出的LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能、稳定性和安全性"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203108-hfcdyde","Type":"NodeParagraph","Properties":{"id":"20250922203108-hfcdyde","updated":"20250924104303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"De-duplication (去重)."},{"Type":"NodeText","Data":" 现有的工作已经发现，语料库中的重复数据会降低语言模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"，可能导致训练过程变得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不稳定"},{"Type":"NodeText","Data":"，从而影响模型性能。因此，对预训练语料库进行去重是必要的。具体来说，去重可以在不同的粒度上执行，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"句子级、文档级和数据集级"},{"Type":"NodeText","Data":"。首先，应移除包含重复词语和短语的低质量句子，因为它们可能在语言建模中引入重复模式。在文档层面，现有研究主要依赖于文档间表面特征（例如，词语和n-gram的重叠率）的重叠比例来检测和移除包含相似内容的重复文档。此外，为避免"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据集污染"},{"Type":"NodeText","Data":"问题，防止训练集和评估集之间的重叠也至关重要，需要从训练集中移除可能重复的文本。已有研究表明，三个级别的去重对于提升LLM的训练效果都很有用，应联合使用。"}]},{"ID":"20250922203108-ktz9dk4","Type":"NodeParagraph","Properties":{"id":"20250922203108-ktz9dk4","updated":"20250924104303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Privacy Reduction (隐私保护)."},{"Type":"NodeText","Data":" 因此，从预训练语料库中移除"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"个人可识别信息（PII）"},{"Type":"NodeText","Data":"是必要的。一种直接有效的方法是采用基于规则的方法，如关键词匹配，来检测并移除PII，如姓名、地址和电话号码。此外，研究人员还发现，LLM在隐私攻击下的脆弱性可归因于预训练语料库中存在重复的PII数据。因此，去重在某种程度上也可以降低隐私风险。"}]},{"ID":"20250922203108-ea7trhu","Type":"NodeParagraph","Properties":{"id":"20250922203108-ea7trhu","updated":"20250924104303"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Tokenization (分词)."},{"Type":"NodeText","Data":" 分词也是数据预处理的一个关键步骤。它旨在将原始文本分割成单个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词元（token）"},{"Type":"NodeText","Data":"的序列，这些序列随后被用作LLM的输入。在传统的NLP研究中（例如，使用条件随机场的序列标注），基于词的分词是主要方法，这更符合人类的语言认知。然而，基于词的分词在某些语言中（例如，中文分词）对于相同输入可能产生不同的分割结果，会生成一个包含许多低频词的巨大词汇表，并且还存在“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词汇表外（out-of-vocabulary）"},{"Type":"NodeText","Data":"”问题。因此，一些神经网络模型采用字符作为最小单位来推导词语表示（例如，ELMo中的CNN词编码器）。最近，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"子词（subword）分词器"},{"Type":"NodeText","Data":"已在基于Transformer的语言模型中被广泛使用，典型地包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"字节对编码（Byte-Pair Encoding, BPE）分词"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WordPiece分词"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Unigram分词"},{"Type":"NodeText","Data":"。HuggingFace维护了一个关于分词器的优秀在线NLP课程，附有运行示例，我们向初学者推荐该课程。接下来，我们简要描述这三种代表性的分词方法。"}]},{"ID":"20250922203108-oel5yqz","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-oel5yqz","updated":"20250924104303"},"Children":[{"ID":"20250922203108-bfl438w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-bfl438w","updated":"20250922203108"},"Children":[{"ID":"20250922203108-y5q0pxm","Type":"NodeParagraph","Properties":{"id":"20250922203108-y5q0pxm","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Byte-Pair Encoding (BPE) tokenization."},{"Type":"NodeText","Data":" BPE最初是作为一种通用的数据压缩算法在1994年提出的，后来被应用于NLP的分词。它从一组基本符号（例如，字母表和边界字符）开始，并迭代地将语料库中频繁出现的连续两个词元的对合并为新的词元（称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合并"},{"Type":"NodeText","Data":"）。对于每次合并，选择标准基于两个连续词元的共现频率：选择频率最高的对。合并过程持续进行，直到达到预定义的词汇表大小。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"字节级BPE（Byte-level BPE）"},{"Type":"NodeText","Data":"已被用于提高多语言语料库（例如，包含非ASCII字符的文本）的分词质量，它将字节作为合并的基本符号。采用这种分词方法的代表性语言模型包括GPT-2、BART和LLaMA。"}]}]},{"ID":"20250922203108-ivd8gc6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-ivd8gc6","updated":"20250922203108"},"Children":[{"ID":"20250922203108-ezoq1cn","Type":"NodeParagraph","Properties":{"id":"20250922203108-ezoq1cn","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WordPiece tokenization."},{"Type":"NodeText","Data":" WordPiece是谷歌内部的一种子词分词算法。它最初由谷歌在开发语音搜索系统时提出。然后，它在2016年的神经机器翻译系统中使用，并于2018年被用作BERT的词语分词器。WordPiece与BPE有着非常相似的思想，即迭代地合并连续的词元，但采用了略有不同的合并选择标准。为了进行合并，它首先训练一个语言模型，并用它来为所有可能的对打分。然后，在每次合并时，它选择能最大程度增加训练数据"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"似然"},{"Type":"NodeText","Data":"的对。由于谷歌尚未发布WordPiece算法的官方实现，HuggingFace在其在线NLP课程中给出了一个更直观的选择度量：通过将共现次数除以训练语料库中两个词元出现次数的乘积来为一对词元打分。"}]}]},{"ID":"20250922203108-i6ihqa7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-i6ihqa7","updated":"20250922203108"},"Children":[{"ID":"20250922203108-essicnk","Type":"NodeParagraph","Properties":{"id":"20250922203108-essicnk","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Unigram tokenization."},{"Type":"NodeText","Data":" 与BPE和WordPiece不同，Unigram分词从一个足够大的、包含语料库所有可能子串或子词元的集合开始，并迭代地移除当前词汇表中的词元，直到达到预期的词汇表大小。作为选择标准，它通过假设某个词元从当前词汇表中移除来计算训练语料库似然的收益增量。这一步是基于一个训练好的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一元语言模型（unigram language model）"},{"Type":"NodeText","Data":"进行的。为了估计这个一元语言模型，它采用了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"期望最大化（EM）算法"},{"Type":"NodeText","Data":"：在每次迭代中，它首先基于旧的语言模型找到当前最优的词语分词方式，然后重新估计一元文法的概率以更新语言模型。在此过程中，使用动态规划算法（即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"维特比算法"},{"Type":"NodeText","Data":"）来高效地找到给定语言模型下词语的最优分解方式。"}]}]}]},{"ID":"20250922203108-srfr4bb","Type":"NodeBlockquote","Properties":{"id":"20250922203108-srfr4bb","updated":"20250924104303"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203108-sy7onyt","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203108-sy7onyt","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922203108-c6eptzi","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203108-c6eptzi","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据预处理的核心目标与方法"}]},{"ID":"20250922203108-9fi6gr4","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-9fi6gr4","updated":"20250922203108"},"Children":[{"ID":"20250922203108-xw0ps1p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-xw0ps1p","updated":"20250922203108"},"Children":[{"ID":"20250922203108-6gwkkav","Type":"NodeParagraph","Properties":{"id":"20250922203108-6gwkkav","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过滤与选择"},{"Type":"NodeText","Data":": 这是数据清洗的第一道防线，目的是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“去伪存真”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203108-p7w716q","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-p7w716q","updated":"20250922203108"},"Children":[{"ID":"20250922203108-71rql2z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-71rql2z","updated":"20250922203108"},"Children":[{"ID":"20250922203108-l3qlyol","Type":"NodeParagraph","Properties":{"id":"20250922203108-l3qlyol","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于分类器"},{"Type":"NodeText","Data":": 像训练一个“垃圾邮件过滤器”一样，训练一个模型来判断文本质量。优点是可能更智能，缺点是可能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“错杀好人”"},{"Type":"NodeText","Data":"，比如把有价值的方言或口语当成低质量文本过滤掉，引入偏见。"}]}]},{"ID":"20250922203108-q4wbt26","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-q4wbt26","updated":"20250922203108"},"Children":[{"ID":"20250922203108-n8p84z7","Type":"NodeParagraph","Properties":{"id":"20250922203108-n8p84z7","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于启发式规则"},{"Type":"NodeText","Data":": 简单、粗暴、但有效。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言、困惑度、统计特征、关键词"},{"Type":"NodeText","Data":"等一系列硬性规则进行筛选。这是目前更主流、更可控的方法。"}]}]}]}]},{"ID":"20250922203108-6e27fg8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-6e27fg8","updated":"20250922203108"},"Children":[{"ID":"20250922203108-vo78vb7","Type":"NodeParagraph","Properties":{"id":"20250922203108-vo78vb7","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"去重 (De-duplication)"},{"Type":"NodeText","Data":": 这是保证模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“博学而不偏执”"},{"Type":"NodeText","Data":"的关键。"}]},{"ID":"20250922203108-il0jwsh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-il0jwsh","updated":"20250922203108"},"Children":[{"ID":"20250922203108-hgenfcw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-hgenfcw","updated":"20250922203108"},"Children":[{"ID":"20250922203108-ifjstwx","Type":"NodeParagraph","Properties":{"id":"20250922203108-ifjstwx","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心原因"},{"Type":"NodeText","Data":": 重复数据会让模型在训练时“走捷径”，反复学习相同的内容，导致"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过拟合"},{"Type":"NodeText","Data":"，降低"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化能力"},{"Type":"NodeText","Data":"，并使训练过程"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不稳定"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203108-gq7ys8f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-gq7ys8f","updated":"20250922203108"},"Children":[{"ID":"20250922203108-05bwohm","Type":"NodeParagraph","Properties":{"id":"20250922203108-05bwohm","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多层次去重"},{"Type":"NodeText","Data":": 必须在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"句子、文档、数据集"},{"Type":"NodeText","Data":"三个层面进行，并且要特别注意防止"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练集与测试集的“数据污染”"},{"Type":"NodeText","Data":"，这是保证模型评估公平性的前提。"}]}]}]}]},{"ID":"20250922203108-7d8636f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-7d8636f","updated":"20250922203108"},"Children":[{"ID":"20250922203108-0i2co70","Type":"NodeParagraph","Properties":{"id":"20250922203108-0i2co70","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐私保护 (Privacy Reduction)"},{"Type":"NodeText","Data":": 这是LLM走向现实应用必须遵守的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“法律和道德底线”"},{"Type":"NodeText","Data":"。移除PII不仅是合规要求，也能降低模型被用于隐私攻击的风险。"}]}]}]},{"ID":"20250922203108-z9icqwr","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203108-z9icqwr","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分词 (Tokenization)：将语言转化为数学"}]},{"ID":"20250922203108-0cbfj4g","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-0cbfj4g","updated":"20250922203108"},"Children":[{"ID":"20250922203108-yz8by9u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-yz8by9u","updated":"20250922203108"},"Children":[{"ID":"20250922203108-zq58s9g","Type":"NodeParagraph","Properties":{"id":"20250922203108-zq58s9g","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心任务"},{"Type":"NodeText","Data":": 分词是将人类的自然语言（一串字符）转化为计算机能够处理的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学表示（一串数字ID）"},{"Type":"NodeText","Data":"的桥梁。"}]}]},{"ID":"20250922203108-d8wtal5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-d8wtal5","updated":"20250922203108"},"Children":[{"ID":"20250922203108-h1vvm83","Type":"NodeParagraph","Properties":{"id":"20250922203108-h1vvm83","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“词”到“子词”的革命"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203108-jgcpjn2","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-jgcpjn2","updated":"20250922203108"},"Children":[{"ID":"20250922203108-srds9f0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-srds9f0","updated":"20250922203108"},"Children":[{"ID":"20250922203108-z8tp5o9","Type":"NodeParagraph","Properties":{"id":"20250922203108-z8tp5o9","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"传统词分词"},{"Type":"NodeText","Data":": 缺点是词汇表巨大，且无法处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"新词（OOV问题）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203108-thnfn8l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-thnfn8l","updated":"20250922203108"},"Children":[{"ID":"20250922203108-4ipnbqx","Type":"NodeParagraph","Properties":{"id":"20250922203108-4ipnbqx","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"子词分词"},{"Type":"NodeText","Data":": 是现代NLP的基石。它将词拆分为更有意义的子单元（如"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"tokenization"},{"Type":"NodeText","Data":"​ -\u003e "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"token"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"ization"},{"Type":"NodeText","Data":"​）。这极大地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缩小了词汇表"},{"Type":"NodeText","Data":"，并且能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优雅地处理任何新词"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922203108-i5qfi2z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-i5qfi2z","updated":"20250922203108"},"Children":[{"ID":"20250922203108-gacgmfm","Type":"NodeParagraph","Properties":{"id":"20250922203108-gacgmfm","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大主流子词算法"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203108-n3tcdqg","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203108-n3tcdqg","updated":"20250922203108"},"Children":[{"ID":"20250922203108-hzx6my5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203108-hzx6my5","updated":"20250922203108"},"Children":[{"ID":"20250922203108-4urdsvi","Type":"NodeParagraph","Properties":{"id":"20250922203108-4urdsvi","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BPE (Byte-Pair Encoding)"},{"Type":"NodeText","Data":": 一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自底向上”"},{"Type":"NodeText","Data":"的合并策略。从单个字符开始，不断合并最高频的相邻对，直到达到词汇表大小。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"字节级BPE"},{"Type":"NodeText","Data":"则能处理任何语言的任何字符，是目前最通用的方法之一。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT系列和LLaMA"},{"Type":"NodeText","Data":"都使用它。"}]}]},{"ID":"20250922203108-uu2jvs2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203108-uu2jvs2","updated":"20250922203108"},"Children":[{"ID":"20250922203108-cbu4hoa","Type":"NodeParagraph","Properties":{"id":"20250922203108-cbu4hoa","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WordPiece"},{"Type":"NodeText","Data":": 与BPE类似，但合并标准是选择能使整个语料库的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“语言模型似然”最大化"},{"Type":"NodeText","Data":"的合并。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BERT"},{"Type":"NodeText","Data":"使用它。"}]}]},{"ID":"20250922203108-ibhdfou","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203108-ibhdfou","updated":"20250922203108"},"Children":[{"ID":"20250922203108-7khdkiv","Type":"NodeParagraph","Properties":{"id":"20250922203108-7khdkiv","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Unigram"},{"Type":"NodeText","Data":": 一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自顶向下”"},{"Type":"NodeText","Data":"的裁剪策略。从一个巨大的子词集合开始，不断裁剪掉那些对整体似然“贡献最小”的子词，直到达到词汇表大小。"}]}]}]}]}]}]},{"ID":"20250922203108-rsgcfh8","Type":"NodeBlockquote","Properties":{"id":"20250922203108-rsgcfh8","updated":"20250924104303"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203108-clrgfj7","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203108-clrgfj7","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922203108-z5vosnn","Type":"NodeParagraph","Properties":{"id":"20250922203108-z5vosnn","updated":"20250922203108"},"Children":[{"Type":"NodeText","Data":"第十四部分深入探讨了大型语言模型预训练的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“幕后工程”——数据预处理"},{"Type":"NodeText","Data":"。它清晰地揭示了，我们所看到的强大LLM背后，是一套极其复杂、严谨且对最终模型性能起着决定性作用的数据处理流水线。"}]},{"ID":"20250922203108-noj39km","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203108-noj39km","updated":"20250922203108"},"Children":[{"ID":"20250922203108-zzfmjbj","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203108-zzfmjbj","updated":"20250922203108"},"Children":[{"ID":"20250922203108-qxb0zmd","Type":"NodeParagraph","Properties":{"id":"20250922203108-qxb0zmd","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预处理的“三大战役”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203108-pgk2tjh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-pgk2tjh","updated":"20250922203108"},"Children":[{"ID":"20250922203108-sd89btf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-sd89btf","updated":"20250922203108"},"Children":[{"ID":"20250922203108-b0nkp6m","Type":"NodeParagraph","Properties":{"id":"20250922203108-b0nkp6m","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"净化战役（过滤与去重）"},{"Type":"NodeText","Data":": 这是为了保证输入数据的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“质量”"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“多样性”"},{"Type":"NodeText","Data":"。过滤旨在剔除噪声和低价值内容，而去重则旨在避免模型“死记硬背”，保证其泛化能力。这一步的成败，直接关系到模型能否学到真实、多样的世界知识，而不是一堆互联网上的“垃圾”和重复信息。"}]}]},{"ID":"20250922203108-owgkc34","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-owgkc34","updated":"20250922203108"},"Children":[{"ID":"20250922203108-waupesz","Type":"NodeParagraph","Properties":{"id":"20250922203108-waupesz","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"安全战役（隐私保护）"},{"Type":"NodeText","Data":": 这是模型走向实际应用的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“合规性”"},{"Type":"NodeText","Data":"保障。主动移除PII是负责任的AI开发的必要环节，也是规避法律和道德风险的关键。"}]}]},{"ID":"20250922203108-sbovkg1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-sbovkg1","updated":"20250922203108"},"Children":[{"ID":"20250922203108-8gsw2wm","Type":"NodeParagraph","Properties":{"id":"20250922203108-8gsw2wm","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"格式化战役（分词）"},{"Type":"NodeText","Data":": 这是连接"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“人类语言”"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“机器数学”"},{"Type":"NodeText","Data":"的桥梁。从词到子词的演进，是NLP领域的一项关键技术突破。现代的BPE、WordPiece等子词分词方法，使得模型能够以一种高效且通用的方式处理海量、多样的文本数据，是Transformer架构能够成功应用的基础之一。"}]}]}]}]},{"ID":"20250922203108-cmfde34","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203108-cmfde34","updated":"20250922203108"},"Children":[{"ID":"20250922203108-m77xhv4","Type":"NodeParagraph","Properties":{"id":"20250922203108-m77xhv4","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据工程的系统性与复杂性"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203108-ky01ffe","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-ky01ffe","updated":"20250922203108"},"Children":[{"ID":"20250922203108-22mroqa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-22mroqa","updated":"20250922203108"},"Children":[{"ID":"20250922203108-0itzwhg","Type":"NodeParagraph","Properties":{"id":"20250922203108-0itzwhg","updated":"20250922203108"},"Children":[{"Type":"NodeText","Data":"图7所展示的流水线，清晰地表明数据预处理是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"环环相扣的系统工程"},{"Type":"NodeText","Data":"。每一步都有其明确的目标和方法，并且前一步的输出会直接影响后一步的效果。例如，糟糕的过滤会增加去重的难度；不彻底的去重则可能加剧隐私泄露的风险。"}]}]},{"ID":"20250922203108-1ongucl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-1ongucl","updated":"20250922203108"},"Children":[{"ID":"20250922203108-z0g8siz","Type":"NodeParagraph","Properties":{"id":"20250922203108-z0g8siz","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Data-Juicer"},{"Type":"NodeText","Data":"等专用工具的出现，也标志着数据预处理本身正在成为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专门的研究领域和工程学科"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922203108-y3vixja","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203108-y3vixja","updated":"20250922203108"},"Children":[{"ID":"20250922203108-cn4e8y2","Type":"NodeParagraph","Properties":{"id":"20250922203108-cn4e8y2","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“数据”到“信息”的转化"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203108-iytn31w","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203108-iytn31w","updated":"20250922203108"},"Children":[{"ID":"20250922203108-8283vmd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203108-8283vmd","updated":"20250922203108"},"Children":[{"ID":"20250922203108-1m8vp5j","Type":"NodeParagraph","Properties":{"id":"20250922203108-1m8vp5j","updated":"20250922203108"},"Children":[{"Type":"NodeText","Data":"整个预处理过程，本质上是一个将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"原始、无序的数据（Raw Data）"},{"Type":"NodeText","Data":"，提炼为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"干净、安全、结构化的信息（Information）"},{"Type":"NodeText","Data":"的过程。只有经过这个提炼过程，数据才能真正成为LLM可以有效学习的“养料”。"}]}]}]}]}]},{"ID":"20250922203108-2p3mugq","Type":"NodeParagraph","Properties":{"id":"20250922203108-2p3mugq","updated":"20250922203108"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第十四部分的核心信息是，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据预处理远非简单的“洗数据”"},{"Type":"NodeText","Data":"，而是一门深刻的学问，一套复杂的工程。它是LLM训练成功与否的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“隐形守护者”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“质量守门员”"},{"Type":"NodeText","Data":"。一个在高质量、干净、多样化的数据上训练出来的模型，其性能、稳定性和安全性，将远远超过一个在未经处理的原始数据上训练的模型，即使后者的数据量更大。这深刻体现了在AI领域，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据的“质”往往比“量”更重要"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203300-m3xx7mr","Type":"NodeParagraph","Properties":{"id":"20250922203300-m3xx7mr","updated":"20250924111354"},"Children":[{"Type":"NodeText","Data":"代表性的采用这种分词方法的模型包括T5和mBART。"}]},{"ID":"20250922203300-co79lzx","Type":"NodeParagraph","Properties":{"id":"20250922203300-co79lzx","updated":"20250924111354"},"Children":[{"Type":"NodeText","Data":"虽然利用现有的分词器是权宜之计（例如，OPT和GPT-3利用了GPT-2的分词器），但使用一个专门为预训练语料库设计的分词器可能会带来很大的好处，特别是对于包含不同领域、语言和格式的语料库。因此，最近的LLM通常使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SentencePiece库"},{"Type":"NodeText","Data":"为预训练语料库专门训练定制的分词器，该库包含了字节级BPE和Unigram分词。需要注意的是，BPE中的规范化技术，如NFKC，可能会降低分词性能。在扩展现有LLM时（即，持续预训练或指令微调），我们也应该意识到使用定制分词器可能带来的潜在副作用。例如，LLaMA基于主要由英文文本组成的预训练语料库训练BPE分词器，其派生的词汇表在处理非英语数据时可能能力较弱，例如，生成中文文本时需要更长的推理延迟。"}]},{"ID":"20250922203300-a932z10","Type":"NodeParagraph","Properties":{"id":"20250922203300-a932z10","updated":"20250924111354"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Discussion on Effect of Data Quality (关于数据质量影响的讨论)."},{"Type":"NodeText","Data":" 对于预训练，预训练数据的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量"},{"Type":"NodeText","Data":"对LLM的模型能力至关重要。现有的工作已经表明，在低质量语料库（如噪声、有毒和重复数据）上进行预训练，会极大地损害模型的性能。最近的研究，如T5、GLaM和Gopher，已经调查了数据质量对LLM能力的影响。通过比较在过滤和未过滤语料库上训练的模型的性能，他们得出了相似的结论，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在清洗过的数据上预训练LLM可以提升模型性能"},{"Type":"NodeText","Data":"。更具体地说，数据的重复可能会导致“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"双重下降"},{"Type":"NodeText","Data":"”（指性能先下降后改善的现象），甚至可能压垮整个训练过程。此外，已有研究表明，重复数据会降低LLM从上下文中复制的能力，这可能进一步影响LLM使用上下文学习的泛化能力。因此，正如中所建议的，利用质量过滤、有毒内容过滤和去重等预处理方法来仔细清洗预训练语料库，以提高训练过程的稳定性并避免影响模型性能，是至关重要的。"}]},{"ID":"20250924111741-cbg95eq","Type":"NodeParagraph","Properties":{"id":"20250924111741-cbg95eq","updated":"20250924111741"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250924111741-e2bjbbk.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922203300-9gzr38p","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203300-9gzr38p","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 8：LLM预训练的数据调度示意图"}]},{"ID":"20250922203300-2f1bsda","Type":"NodeBlockquote","Properties":{"id":"20250922203300-2f1bsda","updated":"20250924111354"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203300-dz6e007","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203300-dz6e007","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922203300-cdes7pk","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203300-cdes7pk","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图8解析：LLM训练的“课程表”"}]},{"ID":"20250922203300-muglc6e","Type":"NodeParagraph","Properties":{"id":"20250922203300-muglc6e","updated":"20250922203300"},"Children":[{"Type":"NodeText","Data":"这张图形象地展示了数据调度（Data Scheduling）的两个核心概念："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据混合（Data Mixture）"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据课程（Data Curriculum）"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203300-7d23t6b","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203300-7d23t6b","updated":"20250922203300"},"Children":[{"ID":"20250922203300-rzryv4g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-rzryv4g","updated":"20250922203300"},"Children":[{"ID":"20250922203300-8vrtftx","Type":"NodeParagraph","Properties":{"id":"20250922203300-8vrtftx","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据混合 (Data Mixture)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203300-imu3uqi","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203300-imu3uqi","updated":"20250922203300"},"Children":[{"ID":"20250922203300-gzg0itb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-gzg0itb","updated":"20250922203300"},"Children":[{"ID":"20250922203300-zzdnb5e","Type":"NodeParagraph","Properties":{"id":"20250922203300-zzdnb5e","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"是什么"},{"Type":"NodeText","Data":": 指在整个预训练过程中，不同来源的数据（如网页、代码、书籍等，图中用不同颜色的柱子表示）所占的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"固定比例"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203300-olg2utj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-olg2utj","updated":"20250922203300"},"Children":[{"ID":"20250922203300-tciu5ko","Type":"NodeParagraph","Properties":{"id":"20250922203300-tciu5ko","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何体现"},{"Type":"NodeText","Data":": 图左侧的“Data Mixture”部分，显示了由四种不同数据源按照一定比例混合而成的训练数据。这个比例在整个训练过程中通常是保持不变的。"}]}]},{"ID":"20250922203300-u2eex0n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-u2eex0n","updated":"20250922203300"},"Children":[{"ID":"20250922203300-v80eo1h","Type":"NodeParagraph","Properties":{"id":"20250922203300-v80eo1h","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"作用"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"决定了模型的“基因”和基础能力构成"},{"Type":"NodeText","Data":"。例如，增加代码数据的比例，会使模型更擅长编程和逻辑推理。"}]}]}]}]},{"ID":"20250922203300-ugqc25l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-ugqc25l","updated":"20250922203300"},"Children":[{"ID":"20250922203300-9wndb4w","Type":"NodeParagraph","Properties":{"id":"20250922203300-9wndb4w","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据课程 (Data Curriculum)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203300-ekvd22b","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203300-ekvd22b","updated":"20250922203300"},"Children":[{"ID":"20250922203300-rogdzku","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-rogdzku","updated":"20250922203300"},"Children":[{"ID":"20250922203300-nptbi7d","Type":"NodeParagraph","Properties":{"id":"20250922203300-nptbi7d","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"是什么"},{"Type":"NodeText","Data":": 指在训练的不同阶段，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动态地调整"},{"Type":"NodeText","Data":"不同数据源的混合比例。这就像是为模型安排一个从易到难、从通用到专业的“课程表”。"}]}]},{"ID":"20250922203300-pfmgqxq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-pfmgqxq","updated":"20250922203300"},"Children":[{"ID":"20250922203300-7uitog0","Type":"NodeParagraph","Properties":{"id":"20250922203300-7uitog0","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何体现"},{"Type":"NodeText","Data":": 图右侧的“Data Curriculum”部分，展示了从阶段1（Stage 1）到阶段n（Stage n），数据混合的比例发生了变化。例如，可能在早期阶段（Stage 1）更多地使用通用网页数据（蓝色柱子最高），而在后期阶段（Stage n）则增加专业数据（如绿色和黄色柱子变高）的比例。"}]}]},{"ID":"20250922203300-62s7ktz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-62s7ktz","updated":"20250922203300"},"Children":[{"ID":"20250922203300-70tvkfw","Type":"NodeParagraph","Properties":{"id":"20250922203300-70tvkfw","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"作用"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有针对性地、分阶段地培养模型的特定能力"},{"Type":"NodeText","Data":"。例如，先用通用数据打好语言基础，再用代码数据强化推理能力，最后用对话数据提升交互能力。"}]}]}]}]}]},{"ID":"20250922203300-dx9ms29","Type":"NodeParagraph","Properties":{"id":"20250922203300-dx9ms29","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张图揭示了现代LLM训练中一个更高级的数据策略。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据混合”是静态的“配方”"},{"Type":"NodeText","Data":"，它决定了模型的“天生资质”；而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据课程”则是动态的“培养计划”"},{"Type":"NodeText","Data":"，它指导模型在不同成长阶段学习不同的知识，从而更高效地成长为能力全面的“专家”。"}]}]},{"ID":"20250922203300-mb9xbyc","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922203300-mb9xbyc","updated":"20250924145426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.1.3 Data Scheduling (数据调度)"}]},{"ID":"20250922203300-z0saung","Type":"NodeParagraph","Properties":{"id":"20250922203300-z0saung","updated":"20250924111354"},"Children":[{"Type":"NodeText","Data":"在数据预处理之后，设计合适的策略来调度这些多源数据以预训练一个有能力的LLM至关重要。通常，数据调度应密切关注两个关键方面："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每种数据源的比例（数据混合）"},{"Type":"NodeText","Data":"，以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每种数据源被用于训练的顺序（数据课程）"},{"Type":"NodeText","Data":"。接下来，我们将详细讨论这两个方面。数据调度的示意图已在图8中呈现。"}]},{"ID":"20250922203300-3ybljce","Type":"NodeParagraph","Properties":{"id":"20250922203300-3ybljce","updated":"20250924111354"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Data Mixture (数据混合)."},{"Type":"NodeText","Data":" 由于每种数据源都与LLM某些能力的发展密切相关（参考4.1节的讨论），因此设置一个合适的分布来混合这些数据非常重要。数据混合通常在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全局层面"},{"Type":"NodeText","Data":"设置（即整个预训练数据的分布），也可以在不同训练阶段"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"局部地设置"},{"Type":"NodeText","Data":"为不同的比例。在预训练期间，会根据混合比例从不同来源选择数据样本：权重较大的数据源将会有更多的数据被采样。通常，现有的LLM如LLaMA可能会对每个来源的全部数据采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上采样或下采样"},{"Type":"NodeText","Data":"来创建特定的数据混合作为预训练数据。如图6所示，现有的LLM使用不同的数据混合来构建预训练数据。作为一个代表性模型，LLaMA的预训练数据主要由网页（超过80%）组成，同时还有来自GitHub和StackExchange的6.5%的重代码数据、4.5%的书籍数据和2.5%的来自arXiv的科学数据，这已成为训练通用LLM的重要参考。此外，特殊的数据混合可用于促进不同的目的。例如，Falcon在纯网页上训练，而CodeGen则大幅增加了代码数据的数量。在实践中，数据混合通常是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"凭经验确定"},{"Type":"NodeText","Data":"的，我们总结了几种寻找有效数据混合的常见策略如下："}]},{"ID":"20250922203300-ksrm1ts","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203300-ksrm1ts","updated":"20250924111354"},"Children":[{"ID":"20250922203300-cc8l71x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-cc8l71x","updated":"20250922203300"},"Children":[{"ID":"20250922203300-f802fo0","Type":"NodeParagraph","Properties":{"id":"20250922203300-f802fo0","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增加数据源的多样性 (Increasing the diversity of data sources)."},{"Type":"NodeText","Data":" 最近的研究通过经验表明，在某个领域的过多数据上训练会降低LLM在其他领域上的泛化能力。相反，增加数据源的异质性（例如，包括多样化的数据源）对于提升LLM的下游性能至关重要。为了进一步检验不同数据源的效果，一些研究通过逐一移除每个数据源并用专门策划的数据集预训练LLM来进行消融实验。结果表明，丢弃具有高异质性的数据源（例如，网页）对LLM能力的影响比丢弃具有低异质性的数据源（例如，学术语料库）更为严重。"}]}]},{"ID":"20250922203300-phdl7fi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-phdl7fi","updated":"20250922203300"},"Children":[{"ID":"20250922203300-7kinz2y","Type":"NodeParagraph","Properties":{"id":"20250922203300-7kinz2y","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化数据混合 (Optimizing data mixtures)."},{"Type":"NodeText","Data":" 除了手动设置数据混合，一些研究也提出了优化数据混合以改善模型预训练的方法。给定目标下游任务，可以选择在特征空间中具有更高"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"邻近度"},{"Type":"NodeText","Data":"的预训练数据，或者那些对下游任务性能提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"积极影响"},{"Type":"NodeText","Data":"的数据。此外，为了减少对目标任务的依赖，DoReMi首先使用给定的初始领域权重训练一个小型的参考模型，然后训练另一个小型的代理模型，对那些可能性差异最大的领域进行加权。最后，将代理模型学到的领域权重应用于训练一个更大的LLM。以一种更简单的方式，可以训练几个具有不同数据混合的小型语言模型，并选择能带来最理想性能的数据混合。然而，这种方法的一个假设是，在以类似方式训练时，小型模型的模型能力或行为会与大型模型相似，但这在实践中可能并不总是成立。"}]}]},{"ID":"20250922203300-ba3nteg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-ba3nteg","updated":"20250922203300"},"Children":[{"ID":"20250922203300-uec3824","Type":"NodeParagraph","Properties":{"id":"20250922203300-uec3824","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专注于目标能力 (Specializing the targeted abilities)."},{"Type":"NodeText","Data":" LLM的模型能力在很大程度上依赖于数据选择和混合，可以通过提升特定数据源的比例来增强某些模型能力。例如，通过在更多的数学文本和代码数据上训练，可以特别增强数学推理和编码能力。此外，在LAMBADA数据集上的实验结果表明，增加书籍数据的比例可以提升模型捕捉文本中长期依赖关系的能力，而增加C4数据集的比例则能在C4验证集上带来性能提升。通常，识别数据源和模型能力之间更深层的关系是很重要的。为了增强LLM中如数学和编码等特定技能，或为了开发专门的LLM，一个实用的方法是采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多阶段训练方法"},{"Type":"NodeText","Data":"，例如，通用和技能特定的数据可以在两个连续的阶段进行调度。这种在多个阶段上对不同来源或比例的数据进行训练的方法也被称为“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据课程"},{"Type":"NodeText","Data":"”，下文将对此进行介绍。"}]}]}]},{"ID":"20250922203300-qcrhbom","Type":"NodeBlockquote","Properties":{"id":"20250922203300-qcrhbom","updated":"20250924111354"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203300-70zhr74","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203300-70zhr74","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922203300-qb7vewq","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203300-qb7vewq","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据质量的重要性"}]},{"ID":"20250922203300-t1dktl5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203300-t1dktl5","updated":"20250922203300"},"Children":[{"ID":"20250922203300-m6mgich","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-m6mgich","updated":"20250922203300"},"Children":[{"ID":"20250922203300-g6xoxq8","Type":"NodeParagraph","Properties":{"id":"20250922203300-g6xoxq8","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“垃圾进，垃圾出”"},{"Type":"NodeText","Data":": 这是本节的核心观点。使用低质量（噪声、有毒、重复）的数据进行预训练，会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严重损害"},{"Type":"NodeText","Data":"模型的性能、稳定性和泛化能力。"}]}]},{"ID":"20250922203300-luqrede","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-luqrede","updated":"20250922203300"},"Children":[{"ID":"20250922203300-hfcs72j","Type":"NodeParagraph","Properties":{"id":"20250922203300-hfcs72j","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重复数据的“毒性”"},{"Type":"NodeText","Data":": 特别强调了重复数据的危害。它不仅可能导致训练崩溃，还会削弱模型一项非常重要的能力——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (ICL)"},{"Type":"NodeText","Data":"。因为ICL需要模型从新颖的上下文中学习，而重复数据训练出的模型更倾向于“死记硬背”而非“灵活学习”。"}]}]},{"ID":"20250922203300-xf62wxu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-xf62wxu","updated":"20250922203300"},"Children":[{"ID":"20250922203300-rk7vu0d","Type":"NodeParagraph","Properties":{"id":"20250922203300-rk7vu0d","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清洗是必须的"},{"Type":"NodeText","Data":": 结论非常明确——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精心的、多步骤的数据清洗是预训练成功的必要条件"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922203300-anhjosw","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203300-anhjosw","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据混合：LLM的“营养配方”"}]},{"ID":"20250922203300-6fdy6l1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203300-6fdy6l1","updated":"20250922203300"},"Children":[{"ID":"20250922203300-c7h8cl6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-c7h8cl6","updated":"20250922203300"},"Children":[{"ID":"20250922203300-6fh7qp4","Type":"NodeParagraph","Properties":{"id":"20250922203300-6fh7qp4","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"什么是数据混合"},{"Type":"NodeText","Data":": 如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确定不同来源数据（网页、代码、书籍等）的比例"},{"Type":"NodeText","Data":"。这个“配方”直接决定了模型最终的能力构成。"}]}]},{"ID":"20250922203300-koxbzkj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-koxbzkj","updated":"20250922203300"},"Children":[{"ID":"20250922203300-58zkdsy","Type":"NodeParagraph","Properties":{"id":"20250922203300-58zkdsy","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何确定“配方”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203300-jmqxb1a","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203300-jmqxb1a","updated":"20250922203300"},"Children":[{"ID":"20250922203300-rrawwj5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203300-rrawwj5","updated":"20250922203300"},"Children":[{"ID":"20250922203300-kt2rra5","Type":"NodeParagraph","Properties":{"id":"20250922203300-kt2rra5","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"凭经验 (Empirically)"},{"Type":"NodeText","Data":": 这是目前的主流做法。例如，LLaMA的数据配方（网页为主，辅以代码、书籍、科学文献）已成为一个被广泛参考的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“黄金配方”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203300-m8pue6u","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203300-m8pue6u","updated":"20250922203300"},"Children":[{"ID":"20250922203300-d73vk40","Type":"NodeParagraph","Properties":{"id":"20250922203300-d73vk40","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增加多样性"},{"Type":"NodeText","Data":": 一个重要的原则是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"尽可能增加数据来源的多样性"},{"Type":"NodeText","Data":"。只在单一领域的数据上训练，会损害模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203300-454irph","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203300-454irph","updated":"20250922203300"},"Children":[{"ID":"20250922203300-niv3c0l","Type":"NodeParagraph","Properties":{"id":"20250922203300-niv3c0l","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动化优化"},{"Type":"NodeText","Data":": 这是一个前沿方向。通过训练"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“代理模型（proxy model）”"},{"Type":"NodeText","Data":"在小模型上试验不同的数据混合比例，找到最优配方，再应用到大模型的训练中。但这存在一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“小模型能否代表大模型”"},{"Type":"NodeText","Data":"的根本性假设问题。"}]}]},{"ID":"20250922203300-e2x8t70","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922203300-e2x8t70","updated":"20250922203300"},"Children":[{"ID":"20250922203300-c71xox2","Type":"NodeParagraph","Properties":{"id":"20250922203300-c71xox2","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"按需定制"},{"Type":"NodeText","Data":": 为了强化特定能力（如编码），最直接的方法就是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增加相应数据（代码）的比例"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922203300-gi9eotf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-gi9eotf","updated":"20250922203300"},"Children":[{"ID":"20250922203300-vepp5of","Type":"NodeParagraph","Properties":{"id":"20250922203300-vepp5of","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“混合”到“课程”"},{"Type":"NodeText","Data":": 当数据混合策略从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"静态（整个训练过程比例固定）"},{"Type":"NodeText","Data":"变为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动态（不同阶段比例可调）"},{"Type":"NodeText","Data":"时，就演变成了更高级的策略——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据课程 (Data Curriculum)"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922203300-tzfps4q","Type":"NodeBlockquote","Properties":{"id":"20250922203300-tzfps4q","updated":"20250924111354"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203300-jhmasqh","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203300-jhmasqh","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922203300-3xthkov","Type":"NodeParagraph","Properties":{"id":"20250922203300-3xthkov","updated":"20250922203300"},"Children":[{"Type":"NodeText","Data":"第十五部分深入探讨了数据准备的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“软件”层面"},{"Type":"NodeText","Data":"——即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略和质量控制"},{"Type":"NodeText","Data":"。如果说前几部分主要讲的是“用什么数据”，那么这一部分则聚焦于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何用好这些数据”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203300-hdjcxwo","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203300-hdjcxwo","updated":"20250922203300"},"Children":[{"ID":"20250922203300-bunra6y","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203300-bunra6y","updated":"20250922203300"},"Children":[{"ID":"20250922203300-mp17tzp","Type":"NodeParagraph","Properties":{"id":"20250922203300-mp17tzp","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量是第一原则"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203300-f52uv4x","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203300-f52uv4x","updated":"20250922203300"},"Children":[{"ID":"20250922203300-6fckatc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-6fckatc","updated":"20250922203300"},"Children":[{"ID":"20250922203300-fs4khiw","Type":"NodeParagraph","Properties":{"id":"20250922203300-fs4khiw","updated":"20250922203300"},"Children":[{"Type":"NodeText","Data":"文章的核心论点是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据质量至上"},{"Type":"NodeText","Data":"。通过对现有研究的总结，它雄辩地证明了低质量、重复的数据对LLM是“有毒的”。这不仅会影响最终性能，甚至可能导致训练过程的彻底失败。这为LLM的开发实践划定了一条清晰的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"红线"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922203300-qxyypoh","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203300-qxyypoh","updated":"20250922203300"},"Children":[{"ID":"20250922203300-gfs3wj2","Type":"NodeParagraph","Properties":{"id":"20250922203300-gfs3wj2","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据混合：从经验到科学的探索"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203300-r7chjzj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203300-r7chjzj","updated":"20250922203300"},"Children":[{"ID":"20250922203300-7r1vs50","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-7r1vs50","updated":"20250922203300"},"Children":[{"ID":"20250922203300-524v8oi","Type":"NodeParagraph","Properties":{"id":"20250922203300-524v8oi","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据混合"},{"Type":"NodeText","Data":"被呈现为一门"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“炼金术”"},{"Type":"NodeText","Data":"，目前仍高度依赖经验和参考成功的“配方”（如LLaMA）。"}]}]},{"ID":"20250922203300-nbrfajd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-nbrfajd","updated":"20250922203300"},"Children":[{"ID":"20250922203300-5y34ahn","Type":"NodeParagraph","Properties":{"id":"20250922203300-5y34ahn","updated":"20250922203300"},"Children":[{"Type":"NodeText","Data":"但文章也指出了其走向"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“科学”"},{"Type":"NodeText","Data":"的路径："}]},{"ID":"20250922203300-3327wyf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203300-3327wyf","updated":"20250922203300"},"Children":[{"ID":"20250922203300-jx3r1g1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-jx3r1g1","updated":"20250922203300"},"Children":[{"ID":"20250922203300-c8mdwiw","Type":"NodeParagraph","Properties":{"id":"20250922203300-c8mdwiw","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以多样性为指导原则"},{"Type":"NodeText","Data":": 增加数据源的异质性被证明是提升泛化能力的关键。"}]}]},{"ID":"20250922203300-r59dedf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-r59dedf","updated":"20250922203300"},"Children":[{"ID":"20250922203300-ccvr49n","Type":"NodeParagraph","Properties":{"id":"20250922203300-ccvr49n","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以目标为导向进行优化"},{"Type":"NodeText","Data":": 探索通过自动化方法（如代理模型）来寻找针对特定下游任务的最优数据混合比例。"}]}]}]}]},{"ID":"20250922203300-tpl7dza","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-tpl7dza","updated":"20250922203300"},"Children":[{"ID":"20250922203300-wpshyqp","Type":"NodeParagraph","Properties":{"id":"20250922203300-wpshyqp","updated":"20250922203300"},"Children":[{"Type":"NodeText","Data":"这揭示了数据工程正在从一个粗放的“数据堆砌”阶段，向一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精细化、目标导向"},{"Type":"NodeText","Data":"的“数据调配”阶段演进。"}]}]}]}]},{"ID":"20250922203300-4pxfuf2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203300-4pxfuf2","updated":"20250922203300"},"Children":[{"ID":"20250922203300-c7gsifg","Type":"NodeParagraph","Properties":{"id":"20250922203300-c7gsifg","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从静态到动态：数据课程的引入"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203300-kfv530k","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203300-kfv530k","updated":"20250922203300"},"Children":[{"ID":"20250922203300-mlg4eep","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-mlg4eep","updated":"20250922203300"},"Children":[{"ID":"20250922203300-x0d9map","Type":"NodeParagraph","Properties":{"id":"20250922203300-x0d9map","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据课程 (Data Curriculum)"},{"Type":"NodeText","Data":"的概念是本部分的一个亮点。它将机器学习的训练过程类比为人类的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“教育过程”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203300-12rk2zn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203300-12rk2zn","updated":"20250922203300"},"Children":[{"ID":"20250922203300-ga2cr0z","Type":"NodeParagraph","Properties":{"id":"20250922203300-ga2cr0z","updated":"20250922203300"},"Children":[{"Type":"NodeText","Data":"这种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分阶段、动态调整"},{"Type":"NodeText","Data":"数据配比的策略，使得模型的培养更加高效和有针对性。它允许我们在训练初期用通用数据打下坚实的基础，在后期则可以根据需要，强化模型在特定领域的专业技能。这是一种更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"智能化、更精细化"},{"Type":"NodeText","Data":"的数据利用策略。"}]}]}]}]}]},{"ID":"20250922203300-m53kjx9","Type":"NodeParagraph","Properties":{"id":"20250922203300-m53kjx9","updated":"20250922203300"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第十五部分完成了从“数据收集”到“数据使用策略”的完整闭环。它强调了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据质量的决定性作用"},{"Type":"NodeText","Data":"，并系统地介绍了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据混合（静态配方）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据课程（动态培养计划）"},{"Type":"NodeText","Data":"这两个核心的数据调度策略。通过阅读这一部分，读者可以深刻理解，成功的LLM预训练不仅需要海量的数据，更需要一套关于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何清洗、筛选、组合和调度"},{"Type":"NodeText","Data":"这些数据的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学方法论"},{"Type":"NodeText","Data":"。这正是数据工程在LLM时代的核心价值所在。"}]}]},{"ID":"20250922203406-6lsxlsf","Type":"NodeParagraph","Properties":{"id":"20250922203406-6lsxlsf","updated":"20250924151206"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Data Curriculum (数据课程)."},{"Type":"NodeText","Data":" 在准备好数据混合之后，安排特定数据呈现给LLM进行预训练的顺序非常重要。已有研究表明，在某些情况下，为了学习某项技能，按照一个技能集序列（例如，基础技能 → 目标技能）学习，其效果优于直接从一个仅专注于目标技能的语料库中学习。遵循"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"课程学习"},{"Type":"NodeText","Data":"的思想，数据课程被提出并广泛用于模型预训练。它旨在以特定的顺序组织LLM预训练数据的不同部分，例如，从简单/通用的例子开始，然后逐步引入更具挑战性/更专业的例子。更广泛地说，它可以指在预训练期间对不同来源的数据比例进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自适应调整"},{"Type":"NodeText","Data":"。关于数据课程的现有工作主要集中在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续预训练"},{"Type":"NodeText","Data":"上，例如专门的编码LLM（如CodeLLaMA）或长上下文LLM（如LongLLaMA）。然而，在文献中仍然缺乏关于通用LLM（如LLaMA）数据课程的更详细报告。为了确定数据课程，一个实用的方法是基于专门构建的评估基准来监控LLM关键能力的发展，然后在预训练期间自适应地调整数据混合。接下来，我们以三种常见的能力为例，介绍数据课程的概念如何在持续预训练中应用。"}]},{"ID":"20250922203406-g8oa4qt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203406-g8oa4qt","updated":"20250924151206"},"Children":[{"ID":"20250922203406-qwjye0e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-qwjye0e","updated":"20250922203406"},"Children":[{"ID":"20250922203406-89bxwls","Type":"NodeParagraph","Properties":{"id":"20250922203406-89bxwls","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Coding (编码)."},{"Type":"NodeText","Data":" 为了提升LLM的编码能力，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CodeLLaMA"},{"Type":"NodeText","Data":"基于LLaMA 2开发而来（2T通用词元 → 500B重代码词元），旨在提升代码生成能力并保留自然语言理解能力。CodeLLaMA还提供了一个进一步专注于特定编程语言的版本，即CodeLLaMA-Python（2T通用词元 → 500B重代码词元 → 100B重Python词元）。"}]}]},{"ID":"20250922203406-73sfgdb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-73sfgdb","updated":"20250922203406"},"Children":[{"ID":"20250922203406-ywyt6al","Type":"NodeParagraph","Properties":{"id":"20250922203406-ywyt6al","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mathematics (数学)."},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Llemma"},{"Type":"NodeText","Data":"被提出来增强通用LLM的数学能力。它基于CodeLLaMA开发。尽管CodeLLaMA主要关注编码能力，但实验表明它在其基础模型LLaMA 2的数学基准上表现更好。基于CodeLLaMA，Llemma在包含科学论文、含有数学文本的网页数据和代码的混合数据上进行持续训练（2T通用词元 → 500B重代码词元 → 50∼200B重数学词元）。请注意，Llemma的预训练数据也包含5%的通用领域数据作为一种正则化形式。"}]}]},{"ID":"20250922203406-i9fuv6y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-i9fuv6y","updated":"20250922203406"},"Children":[{"ID":"20250922203406-725306j","Type":"NodeParagraph","Properties":{"id":"20250922203406-725306j","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Long context (长上下文)."},{"Type":"NodeText","Data":" 长上下文建模是LLM的一项重要能力，许多研究已经探索了通过持续训练来扩展LLM的上下文窗口。通过修改基于RoPE的LLM的位置嵌入（即，位置插值），CodeLLaMA进一步扩展了LLaMA 2的上下文窗口（2.5T词元与4K上下文窗口 → 20B词元与16K上下文窗口）。LongLLaMA也借助外部记忆和独特的训练目标实现了更长的上下文窗口（1T词元与2K上下文窗口 → 10B词元与8K上下文窗口）。"}]}]}]},{"ID":"20250922203406-6argkkz","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922203406-6argkkz","updated":"20250924151206"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.1.4 Summary of Data Preparation (数据准备总结)"}]},{"ID":"20250922203406-f0msjem","Type":"NodeParagraph","Properties":{"id":"20250922203406-f0msjem","updated":"20250924151206"},"Children":[{"Type":"NodeText","Data":"在本部分中，我们总结了为LLM准备预训练数据的通用流程和要点，具体分为以下三个方面。"}]},{"ID":"20250922203406-ha024f7","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203406-ha024f7","updated":"20250924151206"},"Children":[{"ID":"20250922203406-31dop4x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-31dop4x","updated":"20250922203406"},"Children":[{"ID":"20250922203406-de2pli2","Type":"NodeParagraph","Properties":{"id":"20250922203406-de2pli2","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Data collection (数据收集)."},{"Type":"NodeText","Data":" 建议在预训练数据中包含"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样化"},{"Type":"NodeText","Data":"的数据源。尽管Falcon表明仅凭网页就可以训练出强大的LLM，但更典型的方法是也整合各种高质量的文本，如代码、书籍、科学论文等。如果一个LLM专注于某项特定技能，相应数据源的比例应相应增加。例如，Gopher和Chinchilla训练时使用了大约40%的书籍数据。PaLM和LaMDA使用了大约50%的对话数据。"}]}]},{"ID":"20250922203406-htlx71g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-htlx71g","updated":"20250922203406"},"Children":[{"ID":"20250922203406-i22fst5","Type":"NodeParagraph","Properties":{"id":"20250922203406-i22fst5","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Data cleaning (数据清洗)."},{"Type":"NodeText","Data":" 数据收集后，清洗原始语料库以尽可能提升其质量至关重要。首先，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"去重"},{"Type":"NodeText","Data":"在现有工作中被普遍使用。其次，应在不同粒度（例如，文档、段落或句子）上移除低质量文本、有毒内容和带有隐私问题的数据。在实践中，启发式和基于分类器的方法都可以用于质量和毒性过滤（例如，CCNet、fastText和Data-Juicer）。第三，对于清洗过的数据，可以进一步统一或指定预训练数据的格式，并通过使用SentencePiece等库在过滤和去重后的语料库上训练分词器来进行分词。"}]}]},{"ID":"20250922203406-c3359jq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-c3359jq","updated":"20250922203406"},"Children":[{"ID":"20250922203406-ppm6651","Type":"NodeParagraph","Properties":{"id":"20250922203406-ppm6651","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Data scheduling (数据调度)."},{"Type":"NodeText","Data":" 对于预处理过的数据，下一步是确定数据混合和特定顺序"}]}]}]},{"ID":"20250922203406-t6txug6","Type":"NodeBlockquote","Properties":{"id":"20250922203406-t6txug6","updated":"20250924151206"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203406-nshvob7","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203406-nshvob7","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922203406-2bncgjj","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203406-2bncgjj","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据课程：LLM的“因材施教”"}]},{"ID":"20250922203406-isk0p1o","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203406-isk0p1o","updated":"20250922203406"},"Children":[{"ID":"20250922203406-aovplyg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-aovplyg","updated":"20250922203406"},"Children":[{"ID":"20250922203406-35nsoty","Type":"NodeParagraph","Properties":{"id":"20250922203406-35nsoty","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": 数据课程（Data Curriculum）借鉴了人类教育中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“课程学习（Curriculum Learning）”"},{"Type":"NodeText","Data":"理念，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"先易后难、循序渐进"},{"Type":"NodeText","Data":"。它不再是简单地将所有数据混合在一起“一锅炖”，而是为模型的学习规划了一条"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有序的路径"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203406-prwp4ut","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-prwp4ut","updated":"20250922203406"},"Children":[{"ID":"20250922203406-cv35yio","Type":"NodeParagraph","Properties":{"id":"20250922203406-cv35yio","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用场景"},{"Type":"NodeText","Data":": 目前主要应用在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续预训练（Continual Pre-training）"},{"Type":"NodeText","Data":"阶段，即在一个已经训练好的通用模型基础上，进一步培养其特定能力。"}]}]},{"ID":"20250922203406-u1sutnx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-u1sutnx","updated":"20250922203406"},"Children":[{"ID":"20250922203406-gg2u8zv","Type":"NodeParagraph","Properties":{"id":"20250922203406-gg2u8zv","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三个典型案例"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203406-336kyz5","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203406-336kyz5","updated":"20250922203406"},"Children":[{"ID":"20250922203406-gdi35jb","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203406-gdi35jb","updated":"20250922203406"},"Children":[{"ID":"20250922203406-wl04xsl","Type":"NodeParagraph","Properties":{"id":"20250922203406-wl04xsl","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码能力 (Coding)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CodeLLaMA"},{"Type":"NodeText","Data":"的训练过程是一个经典的数据课程。它首先在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用语料"},{"Type":"NodeText","Data":"上学习基础（LLaMA 2），然后进入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“代码专业”"},{"Type":"NodeText","Data":"（500B重代码词元），甚至还可以选择"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“Python方向”"},{"Type":"NodeText","Data":"进行深造（100B重Python词元）。这是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通用 → 专业 → 更专业”"},{"Type":"NodeText","Data":"的清晰路径。"}]}]},{"ID":"20250922203406-yr23g68","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203406-yr23g68","updated":"20250922203406"},"Children":[{"ID":"20250922203406-7we02gx","Type":"NodeParagraph","Properties":{"id":"20250922203406-7we02gx","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学能力 (Mathematics)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Llemma"},{"Type":"NodeText","Data":"的培养路径类似，它在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CodeLLaMA"},{"Type":"NodeText","Data":"（已具备一定逻辑能力）的基础上，进一步“主修”"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学密集型数据"},{"Type":"NodeText","Data":"。值得注意的是，其课程中还保留了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5%的通用数据"},{"Type":"NodeText","Data":"，这起到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“正则化”"},{"Type":"NodeText","Data":"的作用，防止模型在专业学习中“偏科”，忘记了通用的语言能力。"}]}]},{"ID":"20250922203406-1bjqsyv","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203406-1bjqsyv","updated":"20250922203406"},"Children":[{"ID":"20250922203406-ey1bbn6","Type":"NodeParagraph","Properties":{"id":"20250922203406-ey1bbn6","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长上下文能力 (Long Context)"},{"Type":"NodeText","Data":": 同样采用持续训练的方式，在更多、更长的数据上进行训练，并配合"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"位置嵌入的调整"},{"Type":"NodeText","Data":"，来逐步扩展模型的上下文窗口。"}]}]}]}]}]},{"ID":"20250922203406-8eenfbs","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203406-8eenfbs","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据准备的“三步走”总结"}]},{"ID":"20250922203406-skah4a9","Type":"NodeParagraph","Properties":{"id":"20250922203406-skah4a9","updated":"20250922203406"},"Children":[{"Type":"NodeText","Data":"这部分内容是对整个4.1节的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高度概括和总结"},{"Type":"NodeText","Data":"，为数据准备工作提供了一个清晰的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“操作手册”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203406-x9528r9","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203406-x9528r9","updated":"20250922203406"},"Children":[{"ID":"20250922203406-53btqdj","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203406-53btqdj","updated":"20250922203406"},"Children":[{"ID":"20250922203406-p85gzob","Type":"NodeParagraph","Properties":{"id":"20250922203406-p85gzob","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据收集 (Collection)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203406-k9i51db","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203406-k9i51db","updated":"20250922203406"},"Children":[{"ID":"20250922203406-y389i52","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-y389i52","updated":"20250922203406"},"Children":[{"ID":"20250922203406-20uwjgh","Type":"NodeParagraph","Properties":{"id":"20250922203406-20uwjgh","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"原则"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性是关键"},{"Type":"NodeText","Data":"。即使网页数据很重要，也应该尽可能多地混合代码、书籍等高质量数据源。"}]}]},{"ID":"20250922203406-vr6duhz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-vr6duhz","updated":"20250922203406"},"Children":[{"ID":"20250922203406-63ws4e1","Type":"NodeParagraph","Properties":{"id":"20250922203406-63ws4e1","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定制化"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"按需配比"},{"Type":"NodeText","Data":"。要培养什么能力，就增加相应数据的比例。"}]}]}]}]},{"ID":"20250922203406-namni21","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203406-namni21","updated":"20250922203406"},"Children":[{"ID":"20250922203406-capnhyn","Type":"NodeParagraph","Properties":{"id":"20250922203406-capnhyn","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据清洗 (Cleaning)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203406-c239t18","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203406-c239t18","updated":"20250922203406"},"Children":[{"ID":"20250922203406-mkjnasb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-mkjnasb","updated":"20250922203406"},"Children":[{"ID":"20250922203406-wtz4fl8","Type":"NodeParagraph","Properties":{"id":"20250922203406-wtz4fl8","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心步骤"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"去重"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量过滤"},{"Type":"NodeText","Data":"（去除低质量和有毒内容）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"格式统一"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练分词器"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203406-0ckm7pv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-0ckm7pv","updated":"20250922203406"},"Children":[{"ID":"20250922203406-2av7tjd","Type":"NodeParagraph","Properties":{"id":"20250922203406-2av7tjd","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重要性"},{"Type":"NodeText","Data":": 这一步是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"保证模型质量的基石"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922203406-sjjta1m","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203406-sjjta1m","updated":"20250922203406"},"Children":[{"ID":"20250922203406-9x94388","Type":"NodeParagraph","Properties":{"id":"20250922203406-9x94388","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据调度 (Scheduling)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203406-oyytj39","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203406-oyytj39","updated":"20250922203406"},"Children":[{"ID":"20250922203406-b6o43g8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-b6o43g8","updated":"20250922203406"},"Children":[{"ID":"20250922203406-g26s3se","Type":"NodeParagraph","Properties":{"id":"20250922203406-g26s3se","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心任务"},{"Type":"NodeText","Data":": 确定"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“吃什么” (数据混合)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“怎么吃” (数据课程)"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203406-mjpa7fc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-mjpa7fc","updated":"20250922203406"},"Children":[{"ID":"20250922203406-6mva3s9","Type":"NodeParagraph","Properties":{"id":"20250922203406-6mva3s9","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": 目前仍以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"经验为主"},{"Type":"NodeText","Data":"，通过在小模型上进行实验来探索最佳方案，并动态监控大模型在训练过程中的能力变化来调整策略。"}]}]}]}]}]}]},{"ID":"20250922203406-rn362ak","Type":"NodeBlockquote","Properties":{"id":"20250922203406-rn362ak","updated":"20250924151206"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203406-d413ril","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203406-d413ril","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922203406-1khgud0","Type":"NodeParagraph","Properties":{"id":"20250922203406-1khgud0","updated":"20250922203406"},"Children":[{"Type":"NodeText","Data":"第十六部分深入探讨了数据调度的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级策略——数据课程（Data Curriculum）"},{"Type":"NodeText","Data":"，并对整个数据准备阶段进行了全面的总结。它标志着LLM的数据工程正在从静态的“数据混合”向"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动态的、智能化的“数据调度”"},{"Type":"NodeText","Data":"演进。"}]},{"ID":"20250922203406-bo3xrr9","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203406-bo3xrr9","updated":"20250922203406"},"Children":[{"ID":"20250922203406-j36i3nk","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203406-j36i3nk","updated":"20250922203406"},"Children":[{"ID":"20250922203406-qygjw3x","Type":"NodeParagraph","Properties":{"id":"20250922203406-qygjw3x","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“混合喂养”到“定制课程”的飞跃"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203406-gcvq0gs","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203406-gcvq0gs","updated":"20250922203406"},"Children":[{"ID":"20250922203406-vppc9bk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-vppc9bk","updated":"20250922203406"},"Children":[{"ID":"20250922203406-rzttnof","Type":"NodeParagraph","Properties":{"id":"20250922203406-rzttnof","updated":"20250922203406"},"Children":[{"Type":"NodeText","Data":"如果说"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据混合"},{"Type":"NodeText","Data":"是为LLM提供一份"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“营养均衡的配方奶粉”"},{"Type":"NodeText","Data":"，那么"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据课程"},{"Type":"NodeText","Data":"就是为其量身定制一套从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“幼儿园”到“博士”的完整“教育大纲”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203406-cu6sc2l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-cu6sc2l","updated":"20250922203406"},"Children":[{"ID":"20250922203406-vluq8zq","Type":"NodeParagraph","Properties":{"id":"20250922203406-vluq8zq","updated":"20250922203406"},"Children":[{"Type":"NodeText","Data":"这种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"循序渐进、从通用到专业"},{"Type":"NodeText","Data":"的学习路径，更符合认知规律，能够更高效地培养LLM在特定领域的深度能力。CodeLLaMA和Llemma的训练范式是这一思想的最佳实践证明。"}]}]}]}]},{"ID":"20250922203406-zcb9uxj","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203406-zcb9uxj","updated":"20250922203406"},"Children":[{"ID":"20250922203406-99u7tiq","Type":"NodeParagraph","Properties":{"id":"20250922203406-99u7tiq","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据准备的“三位一体”框架"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203406-0qcyrxd","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203406-0qcyrxd","updated":"20250922203406"},"Children":[{"ID":"20250922203406-xrm0rvo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-xrm0rvo","updated":"20250922203406"},"Children":[{"ID":"20250922203406-fc749yr","Type":"NodeParagraph","Properties":{"id":"20250922203406-fc749yr","updated":"20250922203406"},"Children":[{"Type":"NodeText","Data":"总结部分提出的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“收集-清洗-调度”"},{"Type":"NodeText","Data":"三步走框架，高度概括了数据准备的核心流程。"}]}]},{"ID":"20250922203406-127qz68","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-127qz68","updated":"20250922203406"},"Children":[{"ID":"20250922203406-t3cs8m4","Type":"NodeParagraph","Properties":{"id":"20250922203406-t3cs8m4","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"收集 (Collection)"},{"Type":"NodeText","Data":" 决定了知识的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"广度"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203406-di7u5ol","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-di7u5ol","updated":"20250922203406"},"Children":[{"ID":"20250922203406-2adnfe0","Type":"NodeParagraph","Properties":{"id":"20250922203406-2adnfe0","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清洗 (Cleaning)"},{"Type":"NodeText","Data":" 保证了知识的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203406-fqdm88q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-fqdm88q","updated":"20250922203406"},"Children":[{"ID":"20250922203406-6dnzpjm","Type":"NodeParagraph","Properties":{"id":"20250922203406-6dnzpjm","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"调度 (Scheduling)"},{"Type":"NodeText","Data":" 优化了知识的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习效率和最终效果"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203406-kq4sdso","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-kq4sdso","updated":"20250922203406"},"Children":[{"ID":"20250922203406-owoolsb","Type":"NodeParagraph","Properties":{"id":"20250922203406-owoolsb","updated":"20250922203406"},"Children":[{"Type":"NodeText","Data":"这三者相辅相成，共同构成了LLM成功预训练的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据基座"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922203406-u4h6qa0","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203406-u4h6qa0","updated":"20250922203406"},"Children":[{"ID":"20250922203406-l70vco8","Type":"NodeParagraph","Properties":{"id":"20250922203406-l70vco8","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实践的艺术性与挑战"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203406-u80zabr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203406-u80zabr","updated":"20250922203406"},"Children":[{"ID":"20250922203406-irvkqe2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-irvkqe2","updated":"20250922203406"},"Children":[{"ID":"20250922203406-lq3uuor","Type":"NodeParagraph","Properties":{"id":"20250922203406-lq3uuor","updated":"20250922203406"},"Children":[{"Type":"NodeText","Data":"文章坦诚地指出，尽管我们有了“数据课程”这样的高级理念，但在实践中，如何设计最优的课程仍然是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高度依赖经验"},{"Type":"NodeText","Data":"的难题。"}]}]},{"ID":"20250922203406-ezxf64a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203406-ezxf64a","updated":"20250922203406"},"Children":[{"ID":"20250922203406-5axkp4d","Type":"NodeParagraph","Properties":{"id":"20250922203406-5axkp4d","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何监控能力发展”"},{"Type":"NodeText","Data":"并"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“动态调整数据混合”"},{"Type":"NodeText","Data":"是其中的核心挑战。这需要一整套完善的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估基准"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练监控体系"},{"Type":"NodeText","Data":"，也预示了未来数据工程的一个重要研究方向。"}]}]}]}]}]},{"ID":"20250922203406-cxtxx66","Type":"NodeParagraph","Properties":{"id":"20250922203406-cxtxx66","updated":"20250922203406"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第十六部分的核心贡献在于，它不仅总结了数据准备的“做什么”（收集和清洗），更重要的是，深入探讨了“如何做”（调度）。特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据课程”"},{"Type":"NodeText","Data":"概念的引入，揭示了LLM训练背后日益增长的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略性和智能化"},{"Type":"NodeText","Data":"。它告诉我们，训练顶尖的LLM，不仅是一场关于计算和数据的“军备竞赛”，更是一场关于如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学地“教育”这些庞大模型"},{"Type":"NodeText","Data":"的智慧较量。"}]}]},{"ID":"20250922203543-4xgfd2m","Type":"NodeParagraph","Properties":{"id":"20250922203543-4xgfd2m","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"的数据用于LLM预训练。确定这两种设置，一个实用的方法是首先用多个候选计划训练几个小型语言模型，然后从中选择一个好的计划。总的来说，找到一个合适的数据课程更为困难。在实践中，可以监控中间模型检查点在特定评估基准上的性能，并在预训练期间动态调整数据混合和分布。在此过程中，探索数据源和模型能力之间的潜在关系，以指导数据课程的设计，也是很有用的。"}]},{"ID":"20250922203543-ud0g1wf","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203543-ud0g1wf","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.2 Architecture (架构)"}]},{"ID":"20250922203543-kpelupc","Type":"NodeParagraph","Properties":{"id":"20250922203543-kpelupc","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"在本节中，我们回顾LLM的架构设计，即主流架构、预训练目标和详细配置。表5展示了几个代表性LLM的模型卡，其中包含公开的细节。"}]},{"ID":"20250922203543-itr6i9f","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922203543-itr6i9f","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.2.1 Typical Architectures (典型架构)"}]},{"ID":"20250922203543-m79kmj7","Type":"NodeParagraph","Properties":{"id":"20250922203543-m79kmj7","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"由于其出色的并行性和能力，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Transformer架构"},{"Type":"NodeText","Data":"已成为开发各种LLM事实上的骨干，使得将语言模型扩展到数千甚至数万亿参数成为可能。总的来说，现有LLM的主流架构可以大致分为三种主要类型，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器架构、因果解码器架构和前缀解码器架构"},{"Type":"NodeText","Data":"，如图9所示。"}]},{"ID":"20250922203543-czdz88w","Type":"NodeParagraph","Properties":{"id":"20250922203543-czdz88w","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Encoder-decoder Architecture (编码器-解码器架构)."},{"Type":"NodeText","Data":" 原始的Transformer模型是建立在编码器-解码器架构之上的，它由两个Transformer块堆栈分别作为编码器和解码器组成。编码器采用堆叠的多头自注意力层来编码输入序列，以生成其潜在表示，而解码器则对这些表示执行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交叉注意力"},{"Type":"NodeText","Data":"，并自回归地生成目标序列。编码器-解码器PLM（例如，T5和BART）已在各种NLP任务上显示出有效性。到目前为止，只有少数LLM是基于编码器-解码器架构构建的，例如Flan-T5。我们将在4.2.5节中对架构选择进行详细讨论。"}]},{"ID":"20250922203543-e6p9hcl","Type":"NodeParagraph","Properties":{"id":"20250922203543-e6p9hcl","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Causal Decoder Architecture (因果解码器架构)."},{"Type":"NodeText","Data":" 因果解码器架构采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单向注意力掩码"},{"Type":"NodeText","Data":"，以确保每个输入词元只能关注其过去的词元和自身。输入和输出词元通过解码器以相同的方式进行处理。作为该架构的代表性语言模型，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT系列模型"},{"Type":"NodeText","Data":"是基于因果解码器架构开发的。特别是，GPT-3已成功证明了该架构的有效性，并展现出惊人的上下文学习能力。有趣的是，GPT-1和GPT-2并未表现出像GPT-3中那样卓越的能力，这似乎表明"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩展"},{"Type":"NodeText","Data":"在提升该模型架构的模型能力方面起着重要作用。到目前为止，因果解码器已被各种现有的LLM广泛采用为架构，例如OPT、BLOOM和Gopher。请注意，下文讨论的因果解码器和前缀解码器都属于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器（decoder-only）"},{"Type":"NodeText","Data":"架构。在现有文献中，除非另有说明，当提到“仅解码器架构”时，主要指的是因果解码器架构。"}]},{"ID":"20250922203543-5ibw8l2","Type":"NodeParagraph","Properties":{"id":"20250922203543-5ibw8l2","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Prefix Decoder Architecture (前缀解码器架构)."},{"Type":"NodeText","Data":" 前缀解码器架构（又称非因果解码器）修改了因果解码器的掩码机制，使其能够在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀词元"},{"Type":"NodeText","Data":"上执行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"双向注意力"},{"Type":"NodeText","Data":"，而在生成的词元上仅执行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单向注意力"},{"Type":"NodeText","Data":"。通过这种方式，与编码器-解码器架构类似，前缀解码器可以双向编码前缀序列，并自回归地逐一预测输出词元，其中编码和解码共享相同的参数。与从头开始预训练相比，一个实用的建议是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续训练因果解码器"},{"Type":"NodeText","Data":"，然后将它们转换为前缀解码器以加速收敛，例如，U-PaLM是从PaLM派生而来的。现有的基于前缀解码器的代表性LLM包括GLM-130B和U-PaLM。"}]},{"ID":"20250922203543-ifv5bsv","Type":"NodeParagraph","Properties":{"id":"20250922203543-ifv5bsv","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mixture-of-Experts (混合专家模型)."},{"Type":"NodeText","Data":" 对于上述三种类型的架构，我们可以通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合专家（MoE）"},{"Type":"NodeText","Data":"扩展进一步扩展它们，其中每个输入的神经网络权重的一个子集被"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稀疏地激活"},{"Type":"NodeText","Data":"，例如，Switch Transformer和GLaM。MoE的主要优点是它是一种在保持恒定计算成本的同时扩展模型参数的灵活方式。已有研究表明，通过增加专家数量或总参数大小，可以观察到显著的性能提升。尽管有这些优点，训练大型MoE模型可能会因路由操作的复杂、硬切换特性而遭受不稳定问题。为了增强基于MoE的语言模型的训练稳定性，已经引入了一些技术，例如在路由模块中选择性地使用高精度张量，或使用较小范围初始化模型。最近，广泛流传的猜测是GPT-4是基于MoE架构开发的，但没有官方证实。"}]},{"ID":"20250922203543-szqvkpc","Type":"NodeParagraph","Properties":{"id":"20250922203543-szqvkpc","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Emergent Architectures (新兴架构)."},{"Type":"NodeText","Data":" 传统的Transformer架构通常在序列长度方面具有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"二次计算复杂度"},{"Type":"NodeText","Data":"，导致在处理长输入时处理成本高昂。为了提高效率，最近的研究旨在设计新的语言建模架构，大多数基于参数化的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"状态空间模型（SSM）"},{"Type":"NodeText","Data":"，这可以被看作是RNN和CNN的结合。一方面，SSM可以像RNN一样递归地生成输出，这意味着它们在解码时只需要参考前一个状态。这使得解码过程更有效，因为它消除了像传统Transformer那样需要重新访问所有先前状态的需要。另一方面，这些模型具有通过卷积计算像Transformer一样并行编码整个序列的能力。因此，它们可以受益于GPU的并行性，使用并行扫描、FFT和分块递归等技术。尽管SSM的计算效率很高，但它们的性能仍然落后于Transformer。因此，已经提出了SSM的几种变体，包括Mamba、RetNet、RWKV、"}]},{"ID":"20250922203543-pzqd8hf","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1,1,1,1,1],"Properties":{"colgroup":"||||||||||","id":"20250922203543-pzqd8hf","updated":"20250924151212"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Model"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Category"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Size"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Normalization"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PE"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Activation"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Bias"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"#L"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"#H"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"d_model"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MCL"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT3"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"175B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre LayerNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Learned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GeLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"✓"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"12288"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PanGU- α"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"207B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre LayerNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Learned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GeLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"✓"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"128"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"16384"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1024"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"OPT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"175B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre LayerNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Learned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ReLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"✓"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"12288"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PaLM"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"540B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre LayerNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RoPE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SwiGLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"×"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"118"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"18432"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BLOOM"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"176B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre LayerNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ALiBi"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GeLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"✓"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"112"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14336"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MT-NLG"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"530B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"105"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"128"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"20480"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Gopher"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"280B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre RMSNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Relative"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"128"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"16384"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Chinchilla"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre RMSNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Relative"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8192"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Galactica"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"120B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre LayerNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Learned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GeLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"×"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10240"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LaMDA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"137B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Relative"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GeGLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"128"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8192"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Jurassic-1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"178B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre LayerNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Learned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GeLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"✓"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"76"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"13824"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LLaMA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"65B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre RMSNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RoPE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SwiGLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"×"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8192"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LLaMA 2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre RMSNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RoPE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SwiGLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"×"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8192"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4096"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Falcon"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Causal decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"40B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre LayerNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RoPE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GeLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"×"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"60"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8192"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GLM-130B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Prefix decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"130B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Post DeepNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RoPE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GeGLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"✓"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"12288"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2048"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Encoder-decoder"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11B"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre RMSNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Relative"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ReLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"×"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"128"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1024"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"512"}]}]}]},{"ID":"20250922203543-z2lqsok","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203543-z2lqsok","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 5：几个选定LLM的模型卡，包含公开的配置细节。"}]},{"ID":"20250922203543-hqyzb52","Type":"NodeParagraph","Properties":{"id":"20250922203543-hqyzb52","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"这里，PE表示位置嵌入，L表示层数，H表示注意力头数，d_model表示隐藏状态的大小，MCL表示训练期间的最大上下文长度。"}]},{"ID":"20250922203543-4rk93ml","Type":"NodeBlockquote","Properties":{"id":"20250922203543-4rk93ml","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203543-oxp3v21","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203543-oxp3v21","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922203543-3naqooh","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203543-3naqooh","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表5解析：LLM的“身份证”"}]},{"ID":"20250922203543-tlsrsfy","Type":"NodeParagraph","Properties":{"id":"20250922203543-tlsrsfy","updated":"20250922203543"},"Children":[{"Type":"NodeText","Data":"这张表格就像是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"各个大型语言模型的“身份证”"},{"Type":"NodeText","Data":"，详细列出了它们的核心技术参数，揭示了主流LLM在架构设计上的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"共性与个性"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203543-tyxgi3h","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203543-tyxgi3h","updated":"20250922203543"},"Children":[{"ID":"20250922203543-mvrcfc5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-mvrcfc5","updated":"20250922203543"},"Children":[{"ID":"20250922203543-xzesagc","Type":"NodeParagraph","Properties":{"id":"20250922203543-xzesagc","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"共性/主流趋势"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203543-wxsvhxi","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203543-wxsvhxi","updated":"20250922203543"},"Children":[{"ID":"20250922203543-fllfgfu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-fllfgfu","updated":"20250922203543"},"Children":[{"ID":"20250922203543-q7ldqld","Type":"NodeParagraph","Properties":{"id":"20250922203543-q7ldqld","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"架构类别 (Category)"},{"Type":"NodeText","Data":": 绝大多数顶尖模型（GPT-3, PaLM, LLaMA等）都采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"因果解码器（Causal decoder）"},{"Type":"NodeText","Data":"架构，即“仅解码器”架构。这表明"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自回归生成"},{"Type":"NodeText","Data":"已成为LLM的主流范式。"}]}]},{"ID":"20250922203543-bmv03e8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-bmv03e8","updated":"20250922203543"},"Children":[{"ID":"20250922203543-y05o35d","Type":"NodeParagraph","Properties":{"id":"20250922203543-y05o35d","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"归一化 (Normalization)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前置层归一化（Pre LayerNorm / Pre RMSNorm）"},{"Type":"NodeText","Data":"是绝对主流。这主要是为了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提升大规模训练的稳定性"},{"Type":"NodeText","Data":"。其中，更新的模型（如Gopher, LLaMA）倾向于使用计算更高效的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RMSNorm"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203543-gan2xt6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-gan2xt6","updated":"20250922203543"},"Children":[{"ID":"20250922203543-h46tu8k","Type":"NodeParagraph","Properties":{"id":"20250922203543-h46tu8k","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"位置嵌入 (PE)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"旋转位置嵌入（RoPE）"},{"Type":"NodeText","Data":"已成为最新SOTA模型（PaLM, LLaMA）的标配。它在处理长序列和外推能力上优于传统的学习式（Learned）或相对（Relative）位置嵌入。"}]}]},{"ID":"20250922203543-m4tx7qv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-m4tx7qv","updated":"20250922203543"},"Children":[{"ID":"20250922203543-sal9vli","Type":"NodeParagraph","Properties":{"id":"20250922203543-sal9vli","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"激活函数 (Activation)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GLU的变体"},{"Type":"NodeText","Data":"（特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SwiGLU"},{"Type":"NodeText","Data":"）正在取代传统的GeLU或ReLU，成为PaLM、LLaMA等新模型的首选，因为它能带来更好的性能。"}]}]}]}]},{"ID":"20250922203543-hogeeb2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-hogeeb2","updated":"20250922203543"},"Children":[{"ID":"20250922203543-ha48jkt","Type":"NodeParagraph","Properties":{"id":"20250922203543-ha48jkt","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"个性/特色设计"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203543-49vbiaj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203543-49vbiaj","updated":"20250922203543"},"Children":[{"ID":"20250922203543-t9666bn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-t9666bn","updated":"20250922203543"},"Children":[{"ID":"20250922203543-qiqph5c","Type":"NodeParagraph","Properties":{"id":"20250922203543-qiqph5c","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GLM-130B"},{"Type":"NodeText","Data":": 在多个方面都显得与众不同。它采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀解码器（Prefix decoder）"},{"Type":"NodeText","Data":"架构，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"后置DeepNorm"},{"Type":"NodeText","Data":"归一化，这是一种独特的稳定深层网络训练的技术。"}]}]},{"ID":"20250922203543-pgb1ljx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-pgb1ljx","updated":"20250922203543"},"Children":[{"ID":"20250922203543-1zut9lu","Type":"NodeParagraph","Properties":{"id":"20250922203543-1zut9lu","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BLOOM"},{"Type":"NodeText","Data":": 采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ALiBi"},{"Type":"NodeText","Data":"位置嵌入，这是一种无需额外参数、通过偏置注意力分数来实现位置信息的方法，对外推能力友好。"}]}]},{"ID":"20250922203543-6tzwrn3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-6tzwrn3","updated":"20250922203543"},"Children":[{"ID":"20250922203543-8bhfea9","Type":"NodeParagraph","Properties":{"id":"20250922203543-8bhfea9","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"偏置项 (Bias)"},{"Type":"NodeText","Data":": 大多数新模型（PaLM, LLaMA, Falcon）都"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"取消了注意力层中的偏置项（Bias=×）"},{"Type":"NodeText","Data":"，这可能是一种简化模型、提升效率和稳定性的设计选择。"}]}]}]}]},{"ID":"20250922203543-tzc51cm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-tzc51cm","updated":"20250922203543"},"Children":[{"ID":"20250922203543-ekz29v9","Type":"NodeParagraph","Properties":{"id":"20250922203543-ekz29v9","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模的震撼"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203543-pafh6cf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203543-pafh6cf","updated":"20250922203543"},"Children":[{"ID":"20250922203543-ycao31y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-ycao31y","updated":"20250922203543"},"Children":[{"ID":"20250922203543-77t1ziw","Type":"NodeParagraph","Properties":{"id":"20250922203543-77t1ziw","updated":"20250922203543"},"Children":[{"Type":"NodeText","Data":"表格清晰地展示了LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“大”"},{"Type":"NodeText","Data":": 参数规模（Size）从11B到540B不等，层数（#L）和隐藏层维度（d_model）都非常巨大。"}]}]}]}]}]},{"ID":"20250922203543-ro2g5gg","Type":"NodeParagraph","Properties":{"id":"20250922203543-ro2g5gg","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格不仅提供了宝贵的模型配置参考，更重要的是，它揭示了LLM架构设计的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术演进路线"},{"Type":"NodeText","Data":"。我们可以看到一条清晰的路径：从早期类似GPT-3的设计，演进到以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RMSNorm + RoPE + SwiGLU + 无偏置"},{"Type":"NodeText","Data":"为代表的、以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA"},{"Type":"NodeText","Data":"为集大成者的现代LLM架构范式。这些看似微小的技术选择，共同构成了SOTA模型高性能和高稳定性的基石。"}]}]},{"ID":"20250922203543-fur5pk4","Type":"NodeBlockquote","Properties":{"id":"20250922203543-fur5pk4","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203543-ahz65za","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203543-ahz65za","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922203543-diiwdeg","Type":"NodeParagraph","Properties":{"id":"20250922203543-diiwdeg","updated":"20250922203543"},"Children":[{"Type":"NodeText","Data":"第十七部分深入到了大型语言模型（LLM）的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“建筑蓝图”——即模型架构"},{"Type":"NodeText","Data":"。它系统地梳理了LLM的主流架构类型和关键的设计选择，揭示了这些“庞然大物”内部的构造原理。"}]},{"ID":"20250922203543-58wb5wg","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203543-58wb5wg","updated":"20250922203543"},"Children":[{"ID":"20250922203543-3ps66un","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203543-3ps66un","updated":"20250922203543"},"Children":[{"ID":"20250922203543-vpnsy2y","Type":"NodeParagraph","Properties":{"id":"20250922203543-vpnsy2y","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"架构的“三足鼎立”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203543-xlywdzq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203543-xlywdzq","updated":"20250922203543"},"Children":[{"ID":"20250922203543-4m64vyp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-4m64vyp","updated":"20250922203543"},"Children":[{"ID":"20250922203543-gmm942y","Type":"NodeParagraph","Properties":{"id":"20250922203543-gmm942y","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器 (Encoder-Decoder)"},{"Type":"NodeText","Data":": 如T5，是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“翻译”"},{"Type":"NodeText","Data":"类任务的经典架构。编码器负责理解输入，解码器负责生成输出。"}]}]},{"ID":"20250922203543-okwlpmb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-okwlpmb","updated":"20250922203543"},"Children":[{"ID":"20250922203543-5mlrt62","Type":"NodeParagraph","Properties":{"id":"20250922203543-5mlrt62","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"因果解码器 (Causal Decoder)"},{"Type":"NodeText","Data":": 如GPT系列，是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“续写”"},{"Type":"NodeText","Data":"的专家。它只能看到前面的内容来预测下一个，天然适合做生成任务，已成为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM的绝对主流"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203543-l6mowi2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-l6mowi2","updated":"20250922203543"},"Children":[{"ID":"20250922203543-id503v6","Type":"NodeParagraph","Properties":{"id":"20250922203543-id503v6","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀解码器 (Prefix Decoder)"},{"Type":"NodeText","Data":": 如GLM，是前两者的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“混合体”"},{"Type":"NodeText","Data":"。它允许对输入前缀进行双向理解（类似编码器），同时保持自回归生成（类似解码器），在某些任务上表现出优势。"}]}]}]}]},{"ID":"20250922203543-1uiad8o","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203543-1uiad8o","updated":"20250922203543"},"Children":[{"ID":"20250922203543-7noajy6","Type":"NodeParagraph","Properties":{"id":"20250922203543-7noajy6","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"效率与性能的权衡：新兴架构的探索"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203543-wcwopes","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203543-wcwopes","updated":"20250922203543"},"Children":[{"ID":"20250922203543-zvy8znq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-zvy8znq","updated":"20250922203543"},"Children":[{"ID":"20250922203543-gumw1in","Type":"NodeParagraph","Properties":{"id":"20250922203543-gumw1in","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MoE (混合专家模型)"},{"Type":"NodeText","Data":": 是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“用空间换时间”"},{"Type":"NodeText","Data":"的策略。通过极大地增加模型参数（更多的“专家”），但在每次计算时只"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稀疏激活"},{"Type":"NodeText","Data":"一小部分，从而在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不增加计算量"},{"Type":"NodeText","Data":"的情况下提升模型容量。GPT-4被广泛猜测使用了此架构。"}]}]},{"ID":"20250922203543-opeav3t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-opeav3t","updated":"20250922203543"},"Children":[{"ID":"20250922203543-itqkqlv","Type":"NodeParagraph","Properties":{"id":"20250922203543-itqkqlv","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SSM (状态空间模型)"},{"Type":"NodeText","Data":": 如Mamba，是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Transformer二次复杂度瓶颈"},{"Type":"NodeText","Data":"的挑战。它试图结合RNN（高效推理）和CNN（并行训练）的优点，在处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超长序列"},{"Type":"NodeText","Data":"时展现出巨大潜力，是未来架构演进的重要方向。"}]}]}]}]},{"ID":"20250922203543-udh6q87","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203543-udh6q87","updated":"20250922203543"},"Children":[{"ID":"20250922203543-0xtxl1c","Type":"NodeParagraph","Properties":{"id":"20250922203543-0xtxl1c","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"设计细节决定成败"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203543-vswzb1w","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203543-vswzb1w","updated":"20250922203543"},"Children":[{"ID":"20250922203543-nwwr2xb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-nwwr2xb","updated":"20250922203543"},"Children":[{"ID":"20250922203543-j4l2kvh","Type":"NodeParagraph","Properties":{"id":"20250922203543-j4l2kvh","updated":"20250922203543"},"Children":[{"Type":"NodeText","Data":"表5及其相关的讨论揭示了，除了宏观的架构选型，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微观的设计细节"},{"Type":"NodeText","Data":"（归一化、位置嵌入、激活函数等）对模型的性能和训练稳定性至关重要。"}]}]},{"ID":"20250922203543-rd0nlor","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203543-rd0nlor","updated":"20250922203543"},"Children":[{"ID":"20250922203543-tgc89fx","Type":"NodeParagraph","Properties":{"id":"20250922203543-tgc89fx","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术演进的趋势"},{"Type":"NodeText","Data":"清晰可见："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pre-RMSNorm"},{"Type":"NodeText","Data":"为了稳定性，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RoPE"},{"Type":"NodeText","Data":"为了更好的长程和外推能力，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SwiGLU"},{"Type":"NodeText","Data":"为了更高的性能。这些已成为现代高性能LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“标准配置”"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922203543-8bheqq1","Type":"NodeParagraph","Properties":{"id":"20250922203543-8bheqq1","updated":"20250922203543"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第十七部分为我们提供了一份详尽的LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“架构说明书”"},{"Type":"NodeText","Data":"。它不仅让我们了解了不同LLM在宏观架构上的选择差异，更通过对具体配置的分析（表5），揭示了隐藏在这些庞然大物背后的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精巧设计和技术演进"},{"Type":"NodeText","Data":"。它告诉我们，一个成功的LLM，不仅要选对大的方向（如采用因果解码器），更要在每一个技术细节上精益求精，才能在激烈的竞争中脱颖而出。"}]}]},{"ID":"20250922203804-g8z2l8r","Type":"NodeParagraph","Properties":{"id":"20250922203804-g8z2l8r","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"和Hyena。"}]},{"ID":"20250922203804-p9r91ol","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-p9r91ol","updated":"20250924151212"},"Children":[{"ID":"20250922203804-ezttma8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-ezttma8","updated":"20250922203804"},"Children":[{"ID":"20250922203804-r3plupt","Type":"NodeParagraph","Properties":{"id":"20250922203804-r3plupt","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mamba."},{"Type":"NodeText","Data":" Mamba旨在在状态更新期间"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"选择性地过滤或记住信息"},{"Type":"NodeText","Data":"。它将SSM层的原始固定参数替换为输入的函数，根据当前输入选择性地过滤掉前一状态的信息和当前输入的信息。与传统的SSM相比，Mamba展现了改进的文本建模能力。"}]}]},{"ID":"20250922203804-vetk2i3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-vetk2i3","updated":"20250922203804"},"Children":[{"ID":"20250922203804-dm2abu4","Type":"NodeParagraph","Properties":{"id":"20250922203804-dm2abu4","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RWKV."},{"Type":"NodeText","Data":" RWKV结合了Transformer和RNN的优点。它采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"时间混合模块"},{"Type":"NodeText","Data":"，即带门控的RNN，和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通道混合模块"},{"Type":"NodeText","Data":"，即特殊的前馈神经网络。在这些模块中，使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词元移位"},{"Type":"NodeText","Data":"（token shift），即当前词元和前一个词元的线性组合，来代替词元表示作为输入。"}]}]},{"ID":"20250922203804-ni8r0md","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-ni8r0md","updated":"20250922203804"},"Children":[{"ID":"20250922203804-uo1aqic","Type":"NodeParagraph","Properties":{"id":"20250922203804-uo1aqic","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RetNet."},{"Type":"NodeText","Data":" RetNet提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多尺度保持（multi-scale retention, MSR）"},{"Type":"NodeText","Data":"来替代Transformer中的注意力模块。与线性注意力类似，在MSR模块中，输入首先被映射为查询、键和值，然后键和值的乘积被用来更新状态。接着，查询被用来将状态投影到输出。与传统的SSM类似，RetNet同时保持了并行和循环的计算能力。"}]}]},{"ID":"20250922203804-dlb34dw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-dlb34dw","updated":"20250922203804"},"Children":[{"ID":"20250922203804-qwkw6hi","Type":"NodeParagraph","Properties":{"id":"20250922203804-qwkw6hi","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Hyena."},{"Type":"NodeText","Data":" Hyena采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长卷积"},{"Type":"NodeText","Data":"来替代"}]}]}]},{"ID":"20250924140528-hew9cvj","Type":"NodeParagraph","Properties":{"id":"20250924140528-hew9cvj","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250924140527-sapcxrq.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922203804-5fn6xv1","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203804-5fn6xv1","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 9：三种主流架构中注意力模式的比较。"}]},{"ID":"20250922203804-mqm3kur","Type":"NodeParagraph","Properties":{"id":"20250922203804-mqm3kur","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"这里，蓝色、绿色、黄色和灰色的圆角矩形分别表示前缀词元之间的注意力、前缀与目标词元之间的注意力、目标词元之间的注意力以及被掩码的注意力。"}]},{"ID":"20250922203804-773cou8","Type":"NodeBlockquote","Properties":{"id":"20250922203804-773cou8","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203804-v59ztj2","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203804-v59ztj2","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922203804-ocdqola","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203804-ocdqola","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图9解析：LLM架构的“视野”差异"}]},{"ID":"20250922203804-cvgzr8q","Type":"NodeParagraph","Properties":{"id":"20250922203804-cvgzr8q","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"这张图非常直观地展示了三种主流Transformer架构在处理信息时"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“看”的方式（即注意力模式）"},{"Type":"NodeText","Data":"的根本不同。矩阵中的每个方格代表一个词元对之间的注意力关系，深色表示可以关注，浅色（灰色）表示被掩码（Masked），即不可见。"}]},{"ID":"20250922203804-r3xl98e","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-r3xl98e","updated":"20250922203804"},"Children":[{"ID":"20250922203804-t62o1rc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-t62o1rc","updated":"20250922203804"},"Children":[{"ID":"20250922203804-ljk0jys","Type":"NodeParagraph","Properties":{"id":"20250922203804-ljk0jys","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"因果解码器 (Causal Decoder)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-p2mx95k","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-p2mx95k","updated":"20250922203804"},"Children":[{"ID":"20250922203804-4wsvg3a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-4wsvg3a","updated":"20250922203804"},"Children":[{"ID":"20250922203804-6vwxjzr","Type":"NodeParagraph","Properties":{"id":"20250922203804-6vwxjzr","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视野"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严格的“向后看”"},{"Type":"NodeText","Data":"。每个词元（无论是输入还是输出）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只能关注它自己以及它前面的所有词元"},{"Type":"NodeText","Data":"。这形成了一个严格的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"下三角矩阵"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203804-30xtxru","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-30xtxru","updated":"20250922203804"},"Children":[{"ID":"20250922203804-q0jxk9c","Type":"NodeParagraph","Properties":{"id":"20250922203804-q0jxk9c","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类比"},{"Type":"NodeText","Data":": 就像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"按顺序阅读一本书"},{"Type":"NodeText","Data":"，你只能看到已经读过的内容。"}]}]},{"ID":"20250922203804-y1jaf3t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-y1jaf3t","updated":"20250922203804"},"Children":[{"ID":"20250922203804-mqnxexp","Type":"NodeParagraph","Properties":{"id":"20250922203804-mqnxexp","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用"},{"Type":"NodeText","Data":": 天然适合"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自回归生成"},{"Type":"NodeText","Data":"任务，如文本续写，是GPT系列模型的核心。"}]}]}]}]},{"ID":"20250922203804-068lhg1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-068lhg1","updated":"20250922203804"},"Children":[{"ID":"20250922203804-65w0kc1","Type":"NodeParagraph","Properties":{"id":"20250922203804-65w0kc1","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀解码器 (Prefix Decoder)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-1ejz7wr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-1ejz7wr","updated":"20250922203804"},"Children":[{"ID":"20250922203804-kngwjjs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-kngwjjs","updated":"20250922203804"},"Children":[{"ID":"20250922203804-oonpb3q","Type":"NodeParagraph","Properties":{"id":"20250922203804-oonpb3q","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视野"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“前缀”部分全知，“生成”部分向后看"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203804-n241eoz","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-n241eoz","updated":"20250922203804"},"Children":[{"ID":"20250922203804-p63l2ob","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-p63l2ob","updated":"20250922203804"},"Children":[{"ID":"20250922203804-zy4rdrc","Type":"NodeParagraph","Properties":{"id":"20250922203804-zy4rdrc","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"对于作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文/前缀（Prefix）"},{"Type":"NodeText","Data":"的部分（图中的蓝色区域），所有词元之间可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相互看到"},{"Type":"NodeText","Data":"，形成一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全连接的双向注意力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203804-dw7unhh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-dw7unhh","updated":"20250922203804"},"Children":[{"ID":"20250922203804-q1asy5f","Type":"NodeParagraph","Properties":{"id":"20250922203804-q1asy5f","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"对于需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成的目标（Target）"},{"Type":"NodeText","Data":"部分（图中的黄色区域），仍然遵循"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严格的“向后看”"},{"Type":"NodeText","Data":"规则。"}]}]},{"ID":"20250922203804-pi8ohms","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-pi8ohms","updated":"20250922203804"},"Children":[{"ID":"20250922203804-2xf5rp3","Type":"NodeParagraph","Properties":{"id":"20250922203804-2xf5rp3","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"目标部分的词元可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"回头看"},{"Type":"NodeText","Data":"整个前缀部分（图中的绿色区域）。"}]}]}]}]},{"ID":"20250922203804-qop8ap1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-qop8ap1","updated":"20250922203804"},"Children":[{"ID":"20250922203804-c6kyjcc","Type":"NodeParagraph","Properties":{"id":"20250922203804-c6kyjcc","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类比"},{"Type":"NodeText","Data":": 就像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"做阅读理解题"},{"Type":"NodeText","Data":"，你可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反复、完整地阅读问题和背景材料（前缀）"},{"Type":"NodeText","Data":"，但在写答案时，你仍然是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个词一个词地顺序写（生成）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203804-49f4bqq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-49f4bqq","updated":"20250922203804"},"Children":[{"ID":"20250922203804-muiizz2","Type":"NodeParagraph","Properties":{"id":"20250922203804-muiizz2","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用"},{"Type":"NodeText","Data":": 适合需要对输入上下文有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深入、双向理解"},{"Type":"NodeText","Data":"的生成任务，如GLM模型。"}]}]}]}]},{"ID":"20250922203804-0jq0ehu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-0jq0ehu","updated":"20250922203804"},"Children":[{"ID":"20250922203804-p8s0051","Type":"NodeParagraph","Properties":{"id":"20250922203804-p8s0051","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器 (Encoder-Decoder)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-zc6i10i","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-zc6i10i","updated":"20250922203804"},"Children":[{"ID":"20250922203804-b5dtlev","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-b5dtlev","updated":"20250922203804"},"Children":[{"ID":"20250922203804-yhuj4g7","Type":"NodeParagraph","Properties":{"id":"20250922203804-yhuj4g7","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视野"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“分工明确”的复合视野"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203804-0dd7gur","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-0dd7gur","updated":"20250922203804"},"Children":[{"ID":"20250922203804-y96hd0l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-y96hd0l","updated":"20250922203804"},"Children":[{"ID":"20250922203804-j7pog9z","Type":"NodeParagraph","Properties":{"id":"20250922203804-j7pog9z","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器 (Encoder)"},{"Type":"NodeText","Data":": 负责处理输入序列，其内部是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完全的双向注意力"},{"Type":"NodeText","Data":"（左下角的方块），所有输入词元可以相互看到，以形成对输入的深刻理解。"}]}]},{"ID":"20250922203804-hpzabet","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-hpzabet","updated":"20250922203804"},"Children":[{"ID":"20250922203804-2udchu6","Type":"NodeParagraph","Properties":{"id":"20250922203804-2udchu6","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码器 (Decoder)"},{"Type":"NodeText","Data":": 负责生成输出序列。其内部的自注意力仍然是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"因果的（“向后看”）"},{"Type":"NodeText","Data":"（右上角的方块）。但最关键的是，解码器的每个词元都可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“回头看”编码器输出的所有信息"},{"Type":"NodeText","Data":"（通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交叉注意力 Cross-Attention"},{"Type":"NodeText","Data":"，图中未显式标出但体现在解码器能访问编码器结果上）。"}]}]}]}]},{"ID":"20250922203804-xsuz7bn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-xsuz7bn","updated":"20250922203804"},"Children":[{"ID":"20250922203804-5y57vrm","Type":"NodeParagraph","Properties":{"id":"20250922203804-5y57vrm","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类比"},{"Type":"NodeText","Data":": 就像一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"翻译家"},{"Type":"NodeText","Data":"，他首先"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完整、反复地阅读并理解原文（编码器）"},{"Type":"NodeText","Data":"，然后在下笔翻译时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一边构思译文（解码器自注意力），一边不断地回顾原文的各个部分（交叉注意力）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203804-qd4l63h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-qd4l63h","updated":"20250922203804"},"Children":[{"ID":"20250922203804-gfraro9","Type":"NodeParagraph","Properties":{"id":"20250922203804-gfraro9","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"序列到序列（Seq2Seq）"},{"Type":"NodeText","Data":"任务的经典架构，如机器翻译（T5, BART）。"}]}]}]}]}]},{"ID":"20250922203804-84s84k9","Type":"NodeParagraph","Properties":{"id":"20250922203804-84s84k9","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张图用一种优雅的方式揭示了不同架构处理信息流的本质区别，其核心在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"注意力掩码（Attention Mask）"},{"Type":"NodeText","Data":"的设计。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"因果解码器是纯粹的生成模型，编码器-解码器是理解与生成的结合体，而前缀解码器则是两者的巧妙折中。"}]}]},{"ID":"20250922203804-zk8whgn","Type":"NodeTable","TableAligns":[1,1,1],"Properties":{"colgroup":"||","id":"20250922203804-zk8whgn","updated":"20250924151212"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Model"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Decoding Complexity"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Training Complexity"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Transformer"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(H(T+H))"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(TH(T+H))"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SSM"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(H(N^2+H))"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(TH(\\log T + N^2+H))"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Mamba"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(H(N^2+H))"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(TH(N^2+H))"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RWKV"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(H^2)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(TH^2)"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RetNet"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(H^2)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(TH^2)"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Hyena"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(MH(T+H))"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"O(TMH(\\log T + H))"}]}]}]},{"ID":"20250922203804-h2alojd","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203804-h2alojd","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 6：不同模型的并行性和复杂度比较。"}]},{"ID":"20250922203804-7ae22hc","Type":"NodeParagraph","Properties":{"id":"20250922203804-7ae22hc","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"T表示序列长度，H表示输入表示的维度，N表示SSM中压缩后的维度，M表示每个Hyena模块中的层数。"}]},{"ID":"20250922203804-undiee1","Type":"NodeBlockquote","Properties":{"id":"20250922203804-undiee1","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203804-m284ua0","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203804-m284ua0","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922203804-409p81e","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203804-409p81e","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表6解析：效率革命——超越Transformer的探索"}]},{"ID":"20250922203804-3xdkdxr","Type":"NodeParagraph","Properties":{"id":"20250922203804-3xdkdxr","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"这张表格对比了Transformer及其新兴替代架构在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理（解码）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练"},{"Type":"NodeText","Data":"时的计算复杂度，核心是围绕如何解决Transformer在处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长序列（T很大时）"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能瓶颈"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203804-fmuwzm1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-fmuwzm1","updated":"20250922203804"},"Children":[{"ID":"20250922203804-ln9wvhe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-ln9wvhe","updated":"20250922203804"},"Children":[{"ID":"20250922203804-c1wwfrv","Type":"NodeParagraph","Properties":{"id":"20250922203804-c1wwfrv","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心问题 - Transformer的瓶颈"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-1pmyr47","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-1pmyr47","updated":"20250922203804"},"Children":[{"ID":"20250922203804-7fen1wd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-7fen1wd","updated":"20250922203804"},"Children":[{"ID":"20250922203804-s1ls4in","Type":"NodeParagraph","Properties":{"id":"20250922203804-s1ls4in","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"无论是解码还是训练，Transformer的复杂度都与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"序列长度T的平方（"},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"T^2"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"）"},{"Type":"NodeText","Data":"有关（隐藏在"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"H(T+H)"},{"Type":"NodeText","Data":"项中，当T很大时，T项占主导）。这就是所谓的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“二次复杂度”"},{"Type":"NodeText","Data":"问题。当序列变得很长时（如处理一整本书），计算量和内存会爆炸性增长，使其变得不切实际。"}]}]}]}]},{"ID":"20250922203804-mwx3j2t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-mwx3j2t","updated":"20250922203804"},"Children":[{"ID":"20250922203804-8dd556x","Type":"NodeParagraph","Properties":{"id":"20250922203804-8dd556x","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解决方案 - 新兴架构的崛起"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-uteb83l","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-uteb83l","updated":"20250922203804"},"Children":[{"ID":"20250922203804-nlavmj4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-nlavmj4","updated":"20250922203804"},"Children":[{"ID":"20250922203804-vu7jdb8","Type":"NodeParagraph","Properties":{"id":"20250922203804-vu7jdb8","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SSM (状态空间模型) / Mamba"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-s8b3m4h","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-s8b3m4h","updated":"20250922203804"},"Children":[{"ID":"20250922203804-nyxs7e2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-nyxs7e2","updated":"20250922203804"},"Children":[{"ID":"20250922203804-vuw97i4","Type":"NodeParagraph","Properties":{"id":"20250922203804-vuw97i4","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练优势"},{"Type":"NodeText","Data":": 它们的训练复杂度与"},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"T \\log T"},{"Type":"NodeText","Data":"相关，远优于Transformer的"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"T^2"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203804-6dofhfq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-6dofhfq","updated":"20250922203804"},"Children":[{"ID":"20250922203804-ihduccx","Type":"NodeParagraph","Properties":{"id":"20250922203804-ihduccx","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码优势"},{"Type":"NodeText","Data":": 它们的解码复杂度"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与序列长度T无关"},{"Type":"NodeText","Data":"！这就像RNN一样，只需要前一个状态就可以计算当前状态，实现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常数时间"},{"Type":"NodeText","Data":"的解码。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命性的"},{"Type":"NodeText","Data":"，对于需要快速生成长文本的场景（如对话）至关重要。"}]}]}]}]},{"ID":"20250922203804-dcrovvz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-dcrovvz","updated":"20250922203804"},"Children":[{"ID":"20250922203804-46jkq50","Type":"NodeParagraph","Properties":{"id":"20250922203804-46jkq50","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RWKV / RetNet"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-66nk4nx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-66nk4nx","updated":"20250922203804"},"Children":[{"ID":"20250922203804-uzkphri","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-uzkphri","updated":"20250922203804"},"Children":[{"ID":"20250922203804-6jfzyru","Type":"NodeParagraph","Properties":{"id":"20250922203804-6jfzyru","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练优势"},{"Type":"NodeText","Data":": 训练复杂度为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"线性（"},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"O(T)"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"）"},{"Type":"NodeText","Data":"，非常高效。"}]}]},{"ID":"20250922203804-26mwsp5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-26mwsp5","updated":"20250922203804"},"Children":[{"ID":"20250922203804-tnt5tp4","Type":"NodeParagraph","Properties":{"id":"20250922203804-tnt5tp4","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码优势"},{"Type":"NodeText","Data":": 解码复杂度也"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与序列长度T无关"},{"Type":"NodeText","Data":"，同样具有RNN式的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效推理"},{"Type":"NodeText","Data":"特性。"}]}]}]}]},{"ID":"20250922203804-2xz832z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-2xz832z","updated":"20250922203804"},"Children":[{"ID":"20250922203804-g065ngx","Type":"NodeParagraph","Properties":{"id":"20250922203804-g065ngx","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Hyena"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-y3anjwm","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-y3anjwm","updated":"20250922203804"},"Children":[{"ID":"20250922203804-wggwdmt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-wggwdmt","updated":"20250922203804"},"Children":[{"ID":"20250922203804-fpnwpr6","Type":"NodeParagraph","Properties":{"id":"20250922203804-fpnwpr6","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长卷积"},{"Type":"NodeText","Data":"实现，其训练复杂度也优于Transformer，与"},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"T \\log T"},{"Type":"NodeText","Data":"相关。"}]}]}]}]}]}]},{"ID":"20250922203804-taugdzs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-taugdzs","updated":"20250922203804"},"Children":[{"ID":"20250922203804-ll8kw44","Type":"NodeParagraph","Properties":{"id":"20250922203804-ll8kw44","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键启示"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-rm3itpi","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-rm3itpi","updated":"20250922203804"},"Children":[{"ID":"20250922203804-9qdoqlx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-9qdoqlx","updated":"20250922203804"},"Children":[{"ID":"20250922203804-kc16xxr","Type":"NodeParagraph","Properties":{"id":"20250922203804-kc16xxr","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"所有这些新兴架构的核心目标都是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"打破Transformer的二次复杂度诅咒"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203804-e7coc4h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-e7coc4h","updated":"20250922203804"},"Children":[{"ID":"20250922203804-hkerobs","Type":"NodeParagraph","Properties":{"id":"20250922203804-hkerobs","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"它们普遍借鉴了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RNN（高效解码）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CNN/卷积（并行训练）"},{"Type":"NodeText","Data":"的思想。"}]}]},{"ID":"20250922203804-qnpevjy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-qnpevjy","updated":"20250922203804"},"Children":[{"ID":"20250922203804-6pfu2kg","Type":"NodeParagraph","Properties":{"id":"20250922203804-6pfu2kg","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练"},{"Type":"NodeText","Data":"时，它们实现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"准线性或线性"},{"Type":"NodeText","Data":"的复杂度，使得在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超长序列"},{"Type":"NodeText","Data":"上进行训练成为可能。"}]}]},{"ID":"20250922203804-t8d0y0n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-t8d0y0n","updated":"20250922203804"},"Children":[{"ID":"20250922203804-s3auo1f","Type":"NodeParagraph","Properties":{"id":"20250922203804-s3auo1f","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码（推理）"},{"Type":"NodeText","Data":"时，它们大多实现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与序列长度无关的常数时间复杂度"},{"Type":"NodeText","Data":"，极大地提升了长文本生成的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"速度"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922203804-vw7r50w","Type":"NodeParagraph","Properties":{"id":"20250922203804-vw7r50w","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格揭示了后Transformer时代架构演进的核心方向——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"追求对长序列的更高效率"},{"Type":"NodeText","Data":"。以Mamba、RWKV为代表的新兴架构，通过创新的设计，在保持强大性能的同时，显著降低了计算复杂度，特别是在推理阶段。这预示着未来处理长文档、长对话的模型架构可能会发生"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"范式转移"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203804-f0zukme","Type":"NodeBlockquote","Properties":{"id":"20250922203804-f0zukme","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203804-m0fxf9g","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203804-m0fxf9g","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922203804-n0ghzn5","Type":"NodeParagraph","Properties":{"id":"20250922203804-n0ghzn5","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"第十八部分深入探讨了新兴的、旨在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越传统Transformer架构"},{"Type":"NodeText","Data":"的语言模型，并对这些新架构与Transformer在计算复杂度上进行了量化对比。这一部分的核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“效率革命”"},{"Type":"NodeText","Data":"，即如何解决Transformer在处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长序列"},{"Type":"NodeText","Data":"时面临的性能瓶颈。"}]},{"ID":"20250922203804-z2l1qrt","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203804-z2l1qrt","updated":"20250922203804"},"Children":[{"ID":"20250922203804-3gr75ql","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203804-3gr75ql","updated":"20250922203804"},"Children":[{"ID":"20250922203804-9cu4ypi","Type":"NodeParagraph","Properties":{"id":"20250922203804-9cu4ypi","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题的根源：Transformer的“原罪”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-6aqerd9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-6aqerd9","updated":"20250922203804"},"Children":[{"ID":"20250922203804-2t3dp44","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-2t3dp44","updated":"20250922203804"},"Children":[{"ID":"20250922203804-d2oc2jp","Type":"NodeParagraph","Properties":{"id":"20250922203804-d2oc2jp","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"Transformer的成功源于其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全连接的自注意力机制"},{"Type":"NodeText","Data":"，它允许模型在序列的任何两个位置之间直接建立联系。但这也带来了它的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“原罪”——二次计算复杂度"},{"Type":"NodeText","Data":"。随着序列长度T的增加，计算和内存需求呈"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"T^2"},{"Type":"NodeText","Data":"增长，这使得处理长文档、高清图片或长视频等任务变得极其昂贵和低效。"}]}]}]}]},{"ID":"20250922203804-gzhvkmi","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203804-gzhvkmi","updated":"20250922203804"},"Children":[{"ID":"20250922203804-gd8iitd","Type":"NodeParagraph","Properties":{"id":"20250922203804-gd8iitd","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命的方向：借鉴RNN和CNN"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-cnd4d9t","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-cnd4d9t","updated":"20250922203804"},"Children":[{"ID":"20250922203804-903qx31","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-903qx31","updated":"20250922203804"},"Children":[{"ID":"20250922203804-r4bpwri","Type":"NodeParagraph","Properties":{"id":"20250922203804-r4bpwri","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"新兴架构如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mamba, RWKV, RetNet"},{"Type":"NodeText","Data":"等，它们的设计哲学可以看作是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RNN"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CNN"},{"Type":"NodeText","Data":"优点的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“文艺复兴”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“巧妙融合”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203804-a2rgrfg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-a2rgrfg","updated":"20250922203804"},"Children":[{"ID":"20250922203804-ckof6l6","Type":"NodeParagraph","Properties":{"id":"20250922203804-ckof6l6","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"借鉴RNN"},{"Type":"NodeText","Data":": 它们引入了“状态”或“递归”的概念，使得在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理（解码）"},{"Type":"NodeText","Data":"时，模型只需关注前一个时刻的状态，而无需回顾整个历史序列。这使得解码复杂度从与序列长度相关，骤降为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常数级别"},{"Type":"NodeText","Data":"，极大地加速了长文本的生成。"}]}]},{"ID":"20250922203804-musedqz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-musedqz","updated":"20250922203804"},"Children":[{"ID":"20250922203804-uoixjtz","Type":"NodeParagraph","Properties":{"id":"20250922203804-uoixjtz","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"借鉴CNN/卷积"},{"Type":"NodeText","Data":": 它们通过卷积或并行扫描等操作，保留了类似Transformer的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并行计算能力"},{"Type":"NodeText","Data":"，使得在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练"},{"Type":"NodeText","Data":"时能够充分利用GPU的并行优势，训练复杂度也从二次降为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"准线性或线性"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922203804-ctsfpsh","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203804-ctsfpsh","updated":"20250922203804"},"Children":[{"ID":"20250922203804-ml5nf8z","Type":"NodeParagraph","Properties":{"id":"20250922203804-ml5nf8z","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图与表的互补诠释"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203804-049tob1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203804-049tob1","updated":"20250922203804"},"Children":[{"ID":"20250922203804-r8qmtgv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-r8qmtgv","updated":"20250922203804"},"Children":[{"ID":"20250922203804-m5b6vny","Type":"NodeParagraph","Properties":{"id":"20250922203804-m5b6vny","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"图9从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“信息流”"},{"Type":"NodeText","Data":"的角度，直观地展示了不同"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"宏观架构（因果解码器、前缀解码器、编码器-解码器）"},{"Type":"NodeText","Data":"在“看”数据方式上的不同。"}]}]},{"ID":"20250922203804-n04fwsz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-n04fwsz","updated":"20250922203804"},"Children":[{"ID":"20250922203804-vfpaoz5","Type":"NodeParagraph","Properties":{"id":"20250922203804-vfpaoz5","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"表6则从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“计算成本”"},{"Type":"NodeText","Data":"的角度，量化地对比了不同"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微观架构（Transformer vs. Mamba, RWKV等）"},{"Type":"NodeText","Data":"在处理长序列时的效率差异。"}]}]},{"ID":"20250922203804-kpt37wn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203804-kpt37wn","updated":"20250922203804"},"Children":[{"ID":"20250922203804-pf61ub6","Type":"NodeParagraph","Properties":{"id":"20250922203804-pf61ub6","updated":"20250922203804"},"Children":[{"Type":"NodeText","Data":"两者结合，为我们提供了一个全面的视角：我们不仅可以选择不同的宏观架构来适应不同的任务类型，还可以在此基础上，选择更高效的微观架构来应对长序列的挑战。"}]}]}]}]}]},{"ID":"20250922203804-i9wq2d3","Type":"NodeParagraph","Properties":{"id":"20250922203804-i9wq2d3","updated":"20250922203804"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第十八部分标志着LLM架构研究进入了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“后Transformer时代”"},{"Type":"NodeText","Data":"。虽然Transformer仍然是当前的主流和王者，但其固有的效率瓶颈已经催生了一批极具潜力的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“挑战者”"},{"Type":"NodeText","Data":"。以Mamba为代表的SSM类模型，通过将RNN的高效推理与类Transformer的并行训练能力相结合，为未来构建"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更长、更快、更高效"},{"Type":"NodeText","Data":"的语言模型开辟了全新的、激动人心的可能性。"}]}]},{"ID":"20250922203959-feuowqu","Type":"NodeParagraph","Properties":{"id":"20250922203959-feuowqu","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"注意力模块。在长卷积模块中，基于相对位置的滤波器被用来聚合不同位置的信息到中间表示中，并采用门控函数来进一步将中间表示投影到最终输出。然而，由于长卷积的存在，Hyena不能像RNN那样进行推理，必须显式地访问所有先前的状态。"}]},{"ID":"20250922203959-1ld4jpc","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922203959-1ld4jpc","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.2.2 Detailed Configuration (详细配置)"}]},{"ID":"20250922203959-s4bffj3","Type":"NodeParagraph","Properties":{"id":"20250922203959-s4bffj3","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"自Transformer发布以来，为增强其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练稳定性、性能和计算效率"},{"Type":"NodeText","Data":"，已提出了各种改进。在本部分中，我们将讨论Transformer四个主要部分的相应配置，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"归一化、位置嵌入、激活函数以及注意力和偏置"},{"Type":"NodeText","Data":"。为了使本综述更具自包含性，我们在表7中展示了这些配置的详细公式。"}]},{"ID":"20250922203959-r348qb9","Type":"NodeParagraph","Properties":{"id":"20250922203959-r348qb9","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Normalization Methods (归一化方法)."},{"Type":"NodeText","Data":" 训练不稳定性是预训练LLM的一个挑战性问题。为了缓解这个问题，归一化是一种广泛采用的稳定神经网络训练的策略。在原始的Transformer中，使用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LayerNorm"},{"Type":"NodeText","Data":"。最近，一些先进的归一化技术已被提出作为LayerNorm的替代方案，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RMSNorm"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DeepNorm"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203959-b38r946","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-b38r946","updated":"20250924151212"},"Children":[{"ID":"20250922203959-yj7mxih","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-yj7mxih","updated":"20250922203959"},"Children":[{"ID":"20250922203959-3x05fkz","Type":"NodeParagraph","Properties":{"id":"20250922203959-3x05fkz","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LayerNorm."},{"Type":"NodeText","Data":" 在早期的研究中，BatchNorm是一种常用的归一化方法。然而，它很难处理可变长度的序列数据和小批量数据。因此，引入了LayerNorm来进行层级归一化。具体来说，计算每层所有激活值的均值和方差，以重新中心化和重新缩放激活值。"}]}]},{"ID":"20250922203959-zfdk2kv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-zfdk2kv","updated":"20250922203959"},"Children":[{"ID":"20250922203959-2ibnfcu","Type":"NodeParagraph","Properties":{"id":"20250922203959-2ibnfcu","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RMSNorm."},{"Type":"NodeText","Data":" 为了提高LayerNorm的训练速度，提出了RMSNorm，它仅通过激活值总和的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"均方根（RMS）"},{"Type":"NodeText","Data":"来重新缩放激活值，而不是使用均值和方差。相关研究已证明其在训练速度和Transformer性能上的优越性。采用RMSNorm的代表性模型包括Gopher和Chinchilla。"}]}]},{"ID":"20250922203959-0ltkcdp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-0ltkcdp","updated":"20250922203959"},"Children":[{"ID":"20250922203959-5aeph4g","Type":"NodeParagraph","Properties":{"id":"20250922203959-5aeph4g","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DeepNorm."},{"Type":"NodeText","Data":" DeepNorm由微软提出，用于稳定"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度Transformer"},{"Type":"NodeText","Data":"的训练。通过将DeepNorm作为残差连接，Transformer可以扩展到1,000层，这显示了其在稳定性和良好性能方面的优势。它已被GLM-130B采用。"}]}]}]},{"ID":"20250922203959-x7vw98k","Type":"NodeParagraph","Properties":{"id":"20250922203959-x7vw98k","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Normalization Position (归一化位置)."},{"Type":"NodeText","Data":" 除了归一化方法，归一化位置在LLM中也起着至关重要的作用。通常有三种归一化位置的选择，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"post-LN、pre-LN和sandwich-LN"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203959-7akw7ww","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-7akw7ww","updated":"20250924151212"},"Children":[{"ID":"20250922203959-sscvlkn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-sscvlkn","updated":"20250922203959"},"Children":[{"ID":"20250922203959-wq77lqu","Type":"NodeParagraph","Properties":{"id":"20250922203959-wq77lqu","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Post-LN."},{"Type":"NodeText","Data":" Post-LN用在原始的Transformer中，它被放置在残差块之间。然而，现有的工作发现，使用post-LN训练的Transformer由于输出层附近的大梯度而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"容易变得不稳定"},{"Type":"NodeText","Data":"。因此，除了与其他策略结合使用外（例如，在GLM-130B中将post-LN与pre-LN结合），post-LN很少在现有的LLM中使用。"}]}]},{"ID":"20250922203959-jglw3yy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-jglw3yy","updated":"20250922203959"},"Children":[{"ID":"20250922203959-kee3u0i","Type":"NodeParagraph","Properties":{"id":"20250922203959-kee3u0i","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pre-LN."},{"Type":"NodeText","Data":" 与post-LN不同，pre-LN应用于每个子层之前，并在最终预测前放置一个额外的LN。与post-LN相比，使用pre-LN的Transformer在训练中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更稳定"},{"Type":"NodeText","Data":"。然而，它的性能比使用post-LN的变体差。尽管性能有所下降，但由于其训练稳定性，大多数LLM仍采用pre-LN。然而，一个例外是，在训练超过100B参数的GLM时，pre-LN被发现不稳定。"}]}]},{"ID":"20250922203959-48sl0uv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-48sl0uv","updated":"20250922203959"},"Children":[{"ID":"20250922203959-q2nziz5","Type":"NodeParagraph","Properties":{"id":"20250922203959-q2nziz5","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Sandwich-LN."},{"Type":"NodeText","Data":" 基于pre-LN，Sandwich-LN在残差连接前增加了额外的LN，以避免Transformer层输出中的值爆炸问题。然而，研究发现Sandwich-LN有时无法稳定LLM的训练，并可能导致训练崩溃。"}]}]}]},{"ID":"20250922203959-dlk9rf6","Type":"NodeParagraph","Properties":{"id":"20250922203959-dlk9rf6","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Activation Functions (激活函数)."},{"Type":"NodeText","Data":" 为了获得良好的性能，前馈网络中的激活函数也需要被正确设置。在现有的LLM中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GeLU"},{"Type":"NodeText","Data":"激活函数被广泛使用。特别是在最新的LLM（例如，PaLM和LaMDA）中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GLU"},{"Type":"NodeText","Data":"激活函数的变体也已被利用，尤其是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SwiGLU"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GeGLU"},{"Type":"NodeText","Data":"变体，它们在实践中通常能取得更好的性能。然而，与GeLU相比，它们在前馈网络中需要额外的参数（约50%）。"}]},{"ID":"20250922203959-hci0r3k","Type":"NodeParagraph","Properties":{"id":"20250922203959-hci0r3k","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Position Embeddings (位置嵌入)."},{"Type":"NodeText","Data":" 由于Transformer中的自注意力模块是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排列不变"},{"Type":"NodeText","Data":"的，因此采用位置嵌入（PE）来注入绝对或相对的位置信息以建模序列。"}]},{"ID":"20250922203959-xgqns7o","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-xgqns7o","updated":"20250924151212"},"Children":[{"ID":"20250922203959-3gmut2v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-3gmut2v","updated":"20250922203959"},"Children":[{"ID":"20250922203959-3tz63nu","Type":"NodeParagraph","Properties":{"id":"20250922203959-3tz63nu","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"绝对位置嵌入 (Absolute position embedding)."},{"Type":"NodeText","Data":" 在原始的Transformer中，采用了绝对位置嵌入。在编码器和解码器的底部，绝对位置嵌入被加到输入嵌入上。原始Transformer中提出了两种绝对位置嵌入的变体，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正弦"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习式"},{"Type":"NodeText","Data":"位置嵌入，后者在现有的预训练语言模型中被普遍使用。"}]}]},{"ID":"20250922203959-bry8e0x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-bry8e0x","updated":"20250922203959"},"Children":[{"ID":"20250922203959-c74os6g","Type":"NodeParagraph","Properties":{"id":"20250922203959-c74os6g","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相对位置嵌入 (Relative position embedding)."},{"Type":"NodeText","Data":" 与绝对位置嵌入不同，相对位置嵌入是根据"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"键（key）和查询（query）之间的偏移量"},{"Type":"NodeText","Data":"生成的。一种流行的相对PE变体在Transformer-XL中被引入。键和查询之间注意力分数的计算被修改为引入与相对位置对应的可学习嵌入。T5进一步简化了相对位置嵌入，随后被Gopher采用。具体来说，它在注意力分数上增加了可学习的标量，这些标量是根据查询和键的位置之间的距离计算的。与绝对PE相比，具有相对位置嵌入的Transformer可以泛化到比训练序列更长的序列，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外推（extrapolation）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203959-3piekmk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-3piekmk","updated":"20250922203959"},"Children":[{"ID":"20250922203959-cnk9a6b","Type":"NodeParagraph","Properties":{"id":"20250922203959-cnk9a6b","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"旋转位置嵌入 (Rotary position embedding, RoPE)."},{"Type":"NodeText","Data":" 旋转位置嵌入（RoPE）根据每个键或查询的绝对位置设置特定的旋转矩阵。键和查询之间的分数可以用相对位置信息来计算（表7）。RoPE将查询和键向量中每两个连续的元素对作为一个维度，因此对于一个原始的d长度嵌入，有d/2个维度。对于每个维度"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"i"},{"Type":"NodeText","Data":" ∈ {1, . . . , "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"d"},{"Type":"NodeText","Data":"/2}，所涉及的元素对将根据旋转角度"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"t"},{"Type":"NodeText","Data":" · "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"θᵢ"},{"Type":"NodeText","Data":"进行旋转，其中"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"t"},{"Type":"NodeText","Data":"表示位置索引，"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"θᵢ"},{"Type":"NodeText","Data":"是该维度的基准。遵循正弦位置嵌入，"}]}]}]},{"ID":"20250922203959-ba6lhhg","Type":"NodeBlockquote","Properties":{"id":"20250922203959-ba6lhhg","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203959-khz4jyy","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203959-khz4jyy","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922203959-k0pt6q1","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922203959-k0pt6q1","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"架构的“微观调优”：稳定性与性能的权衡"}]},{"ID":"20250922203959-dtayfta","Type":"NodeParagraph","Properties":{"id":"20250922203959-dtayfta","updated":"20250922203959"},"Children":[{"Type":"NodeText","Data":"这部分内容深入到了Transformer架构内部的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“精装修”"},{"Type":"NodeText","Data":"细节，揭示了看似微小的配置选择如何深刻影响模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练稳定性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最终性能"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922203959-6zbzu6z","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-6zbzu6z","updated":"20250922203959"},"Children":[{"ID":"20250922203959-s1z97yl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-s1z97yl","updated":"20250922203959"},"Children":[{"ID":"20250922203959-1dcohl3","Type":"NodeParagraph","Properties":{"id":"20250922203959-1dcohl3","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"归一化 (Normalization): 平衡梯度，稳定训练"}]},{"ID":"20250922203959-fm82xa2","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-fm82xa2","updated":"20250922203959"},"Children":[{"ID":"20250922203959-ea1dgs0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-ea1dgs0","updated":"20250922203959"},"Children":[{"ID":"20250922203959-d2gdjmx","Type":"NodeParagraph","Properties":{"id":"20250922203959-d2gdjmx","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为什么需要"},{"Type":"NodeText","Data":": 神经网络层数深了之后，梯度容易在反向传播中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"爆炸或消失"},{"Type":"NodeText","Data":"，导致训练不稳定甚至失败。归一化的作用就是将每层的输出拉回到一个稳定的分布上。"}]}]},{"ID":"20250922203959-415t3eb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-415t3eb","updated":"20250922203959"},"Children":[{"ID":"20250922203959-0uvbrew","Type":"NodeParagraph","Properties":{"id":"20250922203959-0uvbrew","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法演进"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203959-pq73run","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-pq73run","updated":"20250922203959"},"Children":[{"ID":"20250922203959-mfqceey","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-mfqceey","updated":"20250922203959"},"Children":[{"ID":"20250922203959-zfa3w6d","Type":"NodeParagraph","Properties":{"id":"20250922203959-zfa3w6d","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LayerNorm"},{"Type":"NodeText","Data":": 经典方法，按层进行归一化。"}]}]},{"ID":"20250922203959-qo4qr49","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-qo4qr49","updated":"20250922203959"},"Children":[{"ID":"20250922203959-ho20usz","Type":"NodeParagraph","Properties":{"id":"20250922203959-ho20usz","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RMSNorm"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LayerNorm的“减配增效”版"},{"Type":"NodeText","Data":"。它去掉了均值中心化的步骤，只进行方差缩放，计算更简单，速度更快，效果却不差，因此成为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"现代LLM（如LLaMA）的新宠"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203959-kcjiygc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-kcjiygc","updated":"20250922203959"},"Children":[{"ID":"20250922203959-ljla0bz","Type":"NodeParagraph","Properties":{"id":"20250922203959-ljla0bz","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DeepNorm"},{"Type":"NodeText","Data":": 专为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"千层以上"},{"Type":"NodeText","Data":"的超深网络设计，是一种更强的稳定技术。"}]}]}]}]},{"ID":"20250922203959-w30kf1t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-w30kf1t","updated":"20250922203959"},"Children":[{"ID":"20250922203959-2q2qr1c","Type":"NodeParagraph","Properties":{"id":"20250922203959-2q2qr1c","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"位置选择"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pre-LN（前置归一化）"},{"Type":"NodeText","Data":"是绝对的主流。虽然性能略逊于Post-LN（后置归一化），但它能极大地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提升训练稳定性"},{"Type":"NodeText","Data":"，对于训练动辄上千亿参数的LLM来说，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“不出错”远比“跑得快”重要"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922203959-cxoqqzd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-cxoqqzd","updated":"20250922203959"},"Children":[{"ID":"20250922203959-2vuf68y","Type":"NodeParagraph","Properties":{"id":"20250922203959-2vuf68y","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"激活函数 (Activation Function): 注入非线性"}]},{"ID":"20250922203959-bhf58rf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-bhf58rf","updated":"20250922203959"},"Children":[{"ID":"20250922203959-q7jpqb2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-q7jpqb2","updated":"20250922203959"},"Children":[{"ID":"20250922203959-8ewmckk","Type":"NodeParagraph","Properties":{"id":"20250922203959-8ewmckk","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为什么需要"},{"Type":"NodeText","Data":": 激活函数为神经网络引入非线性，使其能够拟合复杂的函数。"}]}]},{"ID":"20250922203959-xxieipo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-xxieipo","updated":"20250922203959"},"Children":[{"ID":"20250922203959-q7y5jil","Type":"NodeParagraph","Properties":{"id":"20250922203959-q7y5jil","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法演进"},{"Type":"NodeText","Data":": 从经典的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ReLU"},{"Type":"NodeText","Data":"，到更平滑的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GeLU"},{"Type":"NodeText","Data":"，再到目前SOTA模型（如PaLM, LLaMA）偏爱的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GLU变体（特别是SwiGLU）"},{"Type":"NodeText","Data":"。SwiGLU性能更好，但代价是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数量更大"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922203959-a1xqdhw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-a1xqdhw","updated":"20250922203959"},"Children":[{"ID":"20250922203959-uhrhfl2","Type":"NodeParagraph","Properties":{"id":"20250922203959-uhrhfl2","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"位置嵌入 (Position Embedding, PE): 让模型理解“顺序”"}]},{"ID":"20250922203959-o7al6na","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-o7al6na","updated":"20250922203959"},"Children":[{"ID":"20250922203959-fzgjks8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-fzgjks8","updated":"20250922203959"},"Children":[{"ID":"20250922203959-wqw11bf","Type":"NodeParagraph","Properties":{"id":"20250922203959-wqw11bf","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为什么需要"},{"Type":"NodeText","Data":": Transformer的自注意力机制本身是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无视顺序的"},{"Type":"NodeText","Data":"（“词袋模型”），它需要通过位置嵌入来告诉模型每个词在句子中的位置。"}]}]},{"ID":"20250922203959-csv7u87","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-csv7u87","updated":"20250922203959"},"Children":[{"ID":"20250922203959-xl7tv5x","Type":"NodeParagraph","Properties":{"id":"20250922203959-xl7tv5x","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法演进"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203959-5bbxb7j","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203959-5bbxb7j","updated":"20250922203959"},"Children":[{"ID":"20250922203959-3yldlvt","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203959-3yldlvt","updated":"20250922203959"},"Children":[{"ID":"20250922203959-e0xcj7s","Type":"NodeParagraph","Properties":{"id":"20250922203959-e0xcj7s","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"绝对位置嵌入 (Absolute PE)"},{"Type":"NodeText","Data":": 最简单直接，给每个位置一个固定的、可学习的向量。缺点是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化能力差"},{"Type":"NodeText","Data":"，无法处理比训练时更长的序列。"}]}]},{"ID":"20250922203959-4dixk95","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203959-4dixk95","updated":"20250922203959"},"Children":[{"ID":"20250922203959-mtf674h","Type":"NodeParagraph","Properties":{"id":"20250922203959-mtf674h","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相对位置嵌入 (Relative PE)"},{"Type":"NodeText","Data":": 建模的是词与词之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相对距离"},{"Type":"NodeText","Data":"，而不是绝对位置。这使得模型具备了一定的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“外推”能力"},{"Type":"NodeText","Data":"，即能处理比训练时更长的文本。"}]}]},{"ID":"20250922203959-00km023","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203959-00km023","updated":"20250922203959"},"Children":[{"ID":"20250922203959-8eeiidz","Type":"NodeParagraph","Properties":{"id":"20250922203959-8eeiidz","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"旋转位置嵌入 (RoPE)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目前最先进和最流行"},{"Type":"NodeText","Data":"的方法，被PaLM、LLaMA等广泛采用。它通过一种巧妙的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"向量旋转"},{"Type":"NodeText","Data":"方式，将相对位置信息融入到自注意力计算中，具有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优秀的外推性能"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论优雅性"},{"Type":"NodeText","Data":"。"}]}]}]}]}]}]}]},{"ID":"20250922203959-gtpp82t","Type":"NodeParagraph","Properties":{"id":"20250922203959-gtpp82t","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这一部分揭示了LLM架构设计的核心矛盾："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能与稳定性的权衡"},{"Type":"NodeText","Data":"。Pre-LN的选择牺牲了部分性能以换取稳定性；SwiGLU则牺牲了参数效率以换取更高性能。而RoPE的成功则是在性能、外推能力和理论完备性之间取得了一个绝佳的平衡。这些看似底层的技术细节，共同决定了LLM这座“摩天大楼”能否"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"建得高（性能好）"},{"Type":"NodeText","Data":"，更能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"站得稳（训练稳定）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203959-gehrm92","Type":"NodeBlockquote","Properties":{"id":"20250922203959-gehrm92","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922203959-icgufl6","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922203959-icgufl6","updated":"20250924143121"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922203959-t2vwsvg","Type":"NodeParagraph","Properties":{"id":"20250922203959-t2vwsvg","updated":"20250922203959"},"Children":[{"Type":"NodeText","Data":"第十九部分从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“宏观架构的替代方案”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“微观配置的精细调优”"},{"Type":"NodeText","Data":"两个层面，全面地探讨了LLM的架构设计。它不仅为我们展示了前沿的、旨在突破Transformer瓶颈的新兴架构，还深入剖析了那些决定现代Transformer模型成败的关键技术细节。"}]},{"ID":"20250922203959-4p6ug7a","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922203959-4p6ug7a","updated":"20250924143121"},"Children":[{"ID":"20250922203959-q1s1lpv","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922203959-q1s1lpv","updated":"20250924143121"},"Children":[{"ID":"20250922203959-psqiyy4","Type":"NodeParagraph","Properties":{"id":"20250922203959-psqiyy4","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“革命”与“改良”并存的架构演进"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203959-g6cj44s","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-g6cj44s","updated":"20250924143121"},"Children":[{"ID":"20250922203959-8faewtq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-8faewtq","updated":"20250924143121"},"Children":[{"ID":"20250922203959-sfcpvej","Type":"NodeParagraph","Properties":{"id":"20250922203959-sfcpvej","updated":"20250924143121"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命派 (Emergent Architectures)"},{"Type":"NodeText","Data":": 以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mamba, RWKV, RetNet"},{"Type":"NodeText","Data":"为代表，它们试图从根本上解决Transformer的二次复杂度问题，是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“架构革命”"},{"Type":"NodeText","Data":"的探索者。它们的核心思想是借鉴RNN和CNN的优点，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长序列处理效率"},{"Type":"NodeText","Data":"上实现对Transformer的超越。这代表了架构演进的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"未来方向"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922203959-d65hvpo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-d65hvpo","updated":"20250922203959"},"Children":[{"ID":"20250922203959-v7wou0b","Type":"NodeParagraph","Properties":{"id":"20250922203959-v7wou0b","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改良派 (Detailed Configuration)"},{"Type":"NodeText","Data":": 这一派则致力于在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"现有Transformer框架内"},{"Type":"NodeText","Data":"进行精细的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“改良”"},{"Type":"NodeText","Data":"。通过对归一化方法（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RMSNorm"},{"Type":"NodeText","Data":"）、位置嵌入（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RoPE"},{"Type":"NodeText","Data":"）、激活函数（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SwiGLU"},{"Type":"NodeText","Data":"）等关键组件的不断优化，极大地提升了传统Transformer的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练稳定性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能上限"},{"Type":"NodeText","Data":"。LLaMA系列的成功就是“改良派”路线的集大成者。"}]}]}]}]},{"ID":"20250922203959-ohu77jy","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922203959-ohu77jy","updated":"20250922203959"},"Children":[{"ID":"20250922203959-wuzeooc","Type":"NodeParagraph","Properties":{"id":"20250922203959-wuzeooc","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳定性是第一要务"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203959-06pfwfw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-06pfwfw","updated":"20250922203959"},"Children":[{"ID":"20250922203959-yjq58vl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-yjq58vl","updated":"20250922203959"},"Children":[{"ID":"20250922203959-1rblkyh","Type":"NodeParagraph","Properties":{"id":"20250922203959-1rblkyh","updated":"20250922203959"},"Children":[{"Type":"NodeText","Data":"在讨论微观配置时，一个反复出现的主题是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“训练稳定性”"},{"Type":"NodeText","Data":"。对于耗资巨大的LLM训练而言，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能够稳定地完成训练，其重要性甚至超过了追求极致的性能"},{"Type":"NodeText","Data":"。Pre-LN的选择就是这一原则的最佳体现。"}]}]}]}]},{"ID":"20250922203959-ylrg6b4","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922203959-ylrg6b4","updated":"20250922203959"},"Children":[{"ID":"20250922203959-scb5lya","Type":"NodeParagraph","Properties":{"id":"20250922203959-scb5lya","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"效率与性能的永恒权衡"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203959-fdwyio1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-fdwyio1","updated":"20250922203959"},"Children":[{"ID":"20250922203959-y56nn9w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-y56nn9w","updated":"20250922203959"},"Children":[{"ID":"20250922203959-aodzobi","Type":"NodeParagraph","Properties":{"id":"20250922203959-aodzobi","updated":"20250922203959"},"Children":[{"Type":"NodeText","Data":"无论是宏观架构还是微观配置，都体现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"效率（计算速度、内存占用）"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能（模型准确率、泛化能力）"},{"Type":"NodeText","Data":"之间的权衡。Mamba牺牲了部分Transformer的表达能力以换取线性复杂度的效率；SwiGLU则增加了参数量以换取性能的提升。如何在这个多维空间中找到最佳的“帕累托前沿”，是架构设计的核心艺术。"}]}]}]}]},{"ID":"20250922203959-9md7j84","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922203959-9md7j84","updated":"20250922203959"},"Children":[{"ID":"20250922203959-kwwxm32","Type":"NodeParagraph","Properties":{"id":"20250922203959-kwwxm32","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从理论到实践的落地"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922203959-1j4kbss","Type":"NodeList","ListData":{},"Properties":{"id":"20250922203959-1j4kbss","updated":"20250922203959"},"Children":[{"ID":"20250922203959-k4lxu86","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922203959-k4lxu86","updated":"20250922203959"},"Children":[{"ID":"20250922203959-84ifh2g","Type":"NodeParagraph","Properties":{"id":"20250922203959-84ifh2g","updated":"20250922203959"},"Children":[{"Type":"NodeText","Data":"本部分内容非常具有实践指导意义。表5、表6、图9以及对各种配置的详细讨论，为希望从零开始构建或理解LLM的研究者和工程师提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一份宝贵的“技术手册”"},{"Type":"NodeText","Data":"。它清晰地指出了当前SOTA模型所采用的主流技术栈，以及未来可能的技术演进方向。"}]}]}]}]}]},{"ID":"20250922203959-51pkqxq","Type":"NodeParagraph","Properties":{"id":"20250922203959-51pkqxq","updated":"20250922203959"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第十九部分如同一位建筑师，既向我们展示了未来建筑的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前瞻性设计图纸（新兴架构）"},{"Type":"NodeText","Data":"，也详细讲解了当前摩天大楼（Transformer）能够屹立不倒的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键施工工艺和材料科学（微观配置）"},{"Type":"NodeText","Data":"。它深刻地揭示了LLM的架构设计是一门在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论创新、工程实践、性能与稳定性之间不断权衡与进化的艺术与科学"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922204440-e2qf91s","Type":"NodeParagraph","Properties":{"id":"20250922204440-e2qf91s","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"RoPE将基准"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"θᵢ"},{"Type":"NodeText","Data":"定义为基数"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"b"},{"Type":"NodeText","Data":"（默认设置为10000）的幂："}]},{"ID":"20250922204440-ihpggeh","Type":"NodeParagraph","Properties":{"id":"20250922204440-ihpggeh","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\Theta = \\{\\theta_i = b^{-2(i-1)/d} | i \\in \\{1, 2, ..., d/2\\}\\}"},{"Type":"NodeText","Data":" (4)"}]},{"ID":"20250922204440-ml78e5w","Type":"NodeParagraph","Properties":{"id":"20250922204440-ml78e5w","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"此外，最近的一项研究将每个维度旋转一个周期（2π）所需的距离定义为波长："}]},{"ID":"20250922204440-9c0r8sz","Type":"NodeParagraph","Properties":{"id":"20250922204440-9c0r8sz","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\lambda_i = 2\\pi b^{2(i-1)/d} = 2\\pi/\\theta_i"},{"Type":"NodeText","Data":" (5)"}]},{"ID":"20250922204440-zqzciuy","Type":"NodeParagraph","Properties":{"id":"20250922204440-zqzciuy","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"由于其出色的性能和长期衰减特性，RoPE在最新的LLM中被广泛采用，例如PaLM和LLaMA。基于RoPE，xPos进一步提升了Transformer的平移不变性和长度外推能力。在旋转角度向量的每个维度上，xPos增加了一个特殊的指数衰减，当基准较大时，衰减较小。它可以在距离增加时缓解训练期间的不稳定现象。"}]},{"ID":"20250922204440-e6ms38u","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-e6ms38u","updated":"20250924151212"},"Children":[{"ID":"20250922204440-860e2kf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-860e2kf","updated":"20250922204440"},"Children":[{"ID":"20250922204440-v37ycui","Type":"NodeParagraph","Properties":{"id":"20250922204440-v37ycui","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ALiBi."},{"Type":"NodeText","Data":" ALiBi被提出来改进Transformer的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外推"},{"Type":"NodeText","Data":"能力。与相对位置嵌入类似，它通过一个基于键和查询之间距离的惩罚项来偏置注意力分数。与T5偏置等相对位置嵌入方法不同，ALiBi中的惩罚分数是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预先定义"},{"Type":"NodeText","Data":"的，没有任何可训练的参数。中的实证结果表明，ALiBi在比训练序列更长的序列上具有比几种流行的位置嵌入方法（如正弦PE、RoPE和T5偏置）更好的外推性能。此外，已有研究表明ALiBi还可以提高BLOOM的训练稳定性。"}]}]}]},{"ID":"20250922204440-nwh513r","Type":"NodeParagraph","Properties":{"id":"20250922204440-nwh513r","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Attention (注意力)."},{"Type":"NodeText","Data":" 注意力机制是Transformer的一个关键组成部分。它允许序列中的词元相互交互，并计算输入和输出序列的表示。"}]},{"ID":"20250922204440-4mo3zez","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-4mo3zez","updated":"20250924151212"},"Children":[{"ID":"20250922204440-wcblp96","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-wcblp96","updated":"20250922204440"},"Children":[{"ID":"20250922204440-2u6xblz","Type":"NodeParagraph","Properties":{"id":"20250922204440-2u6xblz","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全注意力 (Full attention)."},{"Type":"NodeText","Data":" 在原始的Transformer中，注意力机制是以成对的方式进行的，考虑了序列中所有词元对之间的关系。它采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缩放点积注意力"},{"Type":"NodeText","Data":"，其中隐藏状态被映射为查询、键和值。此外，Transformer使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多头注意力"},{"Type":"NodeText","Data":"而不是单头注意力，用不同的投影将查询、键和值投影到不同的头中。每个头的输出的拼接被作为最终输出。"}]}]},{"ID":"20250922204440-zxzcupl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-zxzcupl","updated":"20250922204440"},"Children":[{"ID":"20250922204440-g4hf3jw","Type":"NodeParagraph","Properties":{"id":"20250922204440-g4hf3jw","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稀疏注意力 (Sparse attention)."},{"Type":"NodeText","Data":" 全注意力的一个关键挑战是其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"二次计算复杂度"},{"Type":"NodeText","Data":"，这在处理长序列时成为一个负担。因此，提出了各种高效的Transformer变体来降低注意力机制的计算复杂度。例如，在GPT-3中采用了局部带状稀疏注意力（即分解注意力）。每个查询只能根据位置关注词元的一个子集，而不是整个序列。"}]}]},{"ID":"20250922204440-8ji59ox","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-8ji59ox","updated":"20250922204440"},"Children":[{"ID":"20250922204440-6t9qms2","Type":"NodeParagraph","Properties":{"id":"20250922204440-6t9qms2","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多查询/分组查询注意力 (Multi-query/grouped-query attention)."},{"Type":"NodeText","Data":" 多查询注意力指的是一种注意力变体，其中不同的头共享相同的键和值线性变换矩阵。它以牺牲少量模型质量为代价，实现了更高的推理速度。采用多查询注意力的代表性模型包括PaLM和StarCoder。为了在多查询注意力和多头注意力之间取得平衡，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分组查询注意力（GQA）"},{"Type":"NodeText","Data":"被探索。在GQA中，头被分配到不同的组中，属于同一组的头将共享相同的变换矩阵。特别地，GQA已在最近发布的LLaMA 2模型中被采用并进行了实证测试。"}]}]},{"ID":"20250922204440-lfk0ena","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-lfk0ena","updated":"20250922204440"},"Children":[{"ID":"20250922204440-y56ey4g","Type":"NodeParagraph","Properties":{"id":"20250922204440-y56ey4g","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FlashAttention."},{"Type":"NodeText","Data":" 与大多数现有的近似注意力方法以牺牲模型质量来提高计算效率不同，FlashAttention提出从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"IO感知"},{"Type":"NodeText","Data":"的角度来优化GPU上注意力模块的速度和内存消耗。现代GPU上存在不同级别的内存，例如IO快速的SRAM和IO相对较慢的HBM。FlashAttention将输入组织成块，并引入了必要的重计算，以更好地利用快速的SRAM内存。作为CUDA中的一个融合内核实现，FlashAttention已被集成到"}]}]}]},{"ID":"20250922204440-wsmsioc","Type":"NodeTable","TableAligns":[1,1,1],"Properties":{"colgroup":"||","id":"20250922204440-wsmsioc","updated":"20250924151212"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Configuration"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Method"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Equation"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Normalization position"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Post Norm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"Norm(x+Sublayer(x))"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Pre Norm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x+Sublayer(Norm(x))"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Sandwich Norm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x+Norm(Sublayer(Norm(x)))"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Normalization method"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LayerNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\frac{x-\\mu}{\\sigma} \\cdot \\gamma + \\beta"},{"Type":"NodeText","Data":", "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mu = \\frac{1}{d}\\sum_{i=1}^{d}x_i"},{"Type":"NodeText","Data":", "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\sigma = \\sqrt{\\frac{1}{d}\\sum_{i=1}^{d}(x_i-\\mu)^2}"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RMSNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\frac{x}{RMS(x)} \\cdot \\gamma"},{"Type":"NodeText","Data":", "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"RMS(x) = \\sqrt{\\frac{1}{d}\\sum_{i=1}^{d}x_i^2}"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"DeepNorm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"LayerNorm(\\alpha \\cdot x + Sublayer(x))"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Activation function"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ReLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"ReLU(x) = \\max(x, 0)"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GeLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"GeLU(x) = 0.5x \\otimes [1+erf(x/\\sqrt{2})]"},{"Type":"NodeText","Data":", "},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"erf(x) = \\frac{2}{\\sqrt{\\pi}}\\int_0^x e^{-t^2}dt"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Swish"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"Swish(x) = x \\otimes sigmoid(x)"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SwiGLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"SwiGLU(x_1, x_2) = Swish(x_1) \\otimes x_2"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GeGLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"GeGLU(x_1, x_2) = GeLU(x_1) \\otimes x_2"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Position embedding"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Absolute"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_i = x_i + p_i"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Relative"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"A_{ij} = W_q x_i x_j^T W_k^T + r_{i-j}"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RoPE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"A_{ij} = W_q x_i R_{\\Theta, i-j} x_j^T W_k^T = (W_q x_i R_{\\Theta, i})^T (W_k x_j R_{\\Theta, j})"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ALiBi"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"A_{ij} = W_q x_i x_j^T W_k^T - m(i-j)"}]}]}]},{"ID":"20250922204440-r142n21","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922204440-r142n21","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 7：网络配置的详细公式。"}]},{"ID":"20250922204440-k71i518","Type":"NodeParagraph","Properties":{"id":"20250922204440-k71i518","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"这里，Sublayer表示Transformer层中的FFN或自注意力模块，d表示隐藏状态的大小，"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"pᵢ"},{"Type":"NodeText","Data":"表示位置i的位置嵌入，"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"Aᵢⱼ"},{"Type":"NodeText","Data":"表示查询和键之间的注意力分数，"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"rᵢ₋ⱼ"},{"Type":"NodeText","Data":"表示基于查询和键偏移量的可学习标量，"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"R"},{"Type":"NodeTextMark","TextMarkType":"em sub","TextMarkTextContent":"Θ,t"},{"Type":"NodeText","Data":"表示旋转度为t·Θ的旋转矩阵。"}]},{"ID":"20250922204440-0gzb38b","Type":"NodeBlockquote","Properties":{"id":"20250922204440-0gzb38b","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922204440-g7aszbe","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922204440-g7aszbe","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922204440-0femsg4","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922204440-0femsg4","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表7解析：Transformer核心组件的数学原理"}]},{"ID":"20250922204440-5yrsmza","Type":"NodeParagraph","Properties":{"id":"20250922204440-5yrsmza","updated":"20250922204440"},"Children":[{"Type":"NodeText","Data":"这张表格用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学公式"},{"Type":"NodeText","Data":"精确地定义了Transformer架构中几个核心组件的工作原理，是理解模型内部运作的关键。"}]},{"ID":"20250922204440-ux6mzpc","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-ux6mzpc","updated":"20250922204440"},"Children":[{"ID":"20250922204440-jrjq0cy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-jrjq0cy","updated":"20250922204440"},"Children":[{"ID":"20250922204440-8yt0y9b","Type":"NodeParagraph","Properties":{"id":"20250922204440-8yt0y9b","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"归一化位置 (Normalization Position)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204440-ouwdwth","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-ouwdwth","updated":"20250922204440"},"Children":[{"ID":"20250922204440-rtq26pe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-rtq26pe","updated":"20250922204440"},"Children":[{"ID":"20250922204440-g0pp4b1","Type":"NodeParagraph","Properties":{"id":"20250922204440-g0pp4b1","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Post Norm (后置)"},{"Type":"NodeText","Data":": 先计算"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"x + Sublayer(x)"},{"Type":"NodeText","Data":"​，再进行归一化。梯度流不稳定。"}]}]},{"ID":"20250922204440-1l4l8e5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-1l4l8e5","updated":"20250922204440"},"Children":[{"ID":"20250922204440-jj6jq96","Type":"NodeParagraph","Properties":{"id":"20250922204440-jj6jq96","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pre Norm (前置)"},{"Type":"NodeText","Data":": 先对"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"x"},{"Type":"NodeText","Data":"​归一化，再计算"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"x + Sublayer(Norm(x))"},{"Type":"NodeText","Data":"​。梯度流更稳定，是主流选择。"}]}]},{"ID":"20250922204440-7ehgy8n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-7ehgy8n","updated":"20250922204440"},"Children":[{"ID":"20250922204440-shzzd5s","Type":"NodeParagraph","Properties":{"id":"20250922204440-shzzd5s","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Sandwich Norm"},{"Type":"NodeText","Data":": 在Pre Norm的基础上再加一层归一化，试图进一步增强稳定性。"}]}]}]}]},{"ID":"20250922204440-wxlbbda","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-wxlbbda","updated":"20250922204440"},"Children":[{"ID":"20250922204440-hw6f4et","Type":"NodeParagraph","Properties":{"id":"20250922204440-hw6f4et","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"归一化方法 (Normalization Method)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204440-pqgtzhy","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-pqgtzhy","updated":"20250922204440"},"Children":[{"ID":"20250922204440-fcjoh05","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-fcjoh05","updated":"20250922204440"},"Children":[{"ID":"20250922204440-zduzj46","Type":"NodeParagraph","Properties":{"id":"20250922204440-zduzj46","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LayerNorm"},{"Type":"NodeText","Data":": 经典方法，同时使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"均值("},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"\\mu"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":")和标准差("},{"Type":"NodeTextMark","TextMarkType":"strong inline-math","TextMarkInlineMathContent":"\\sigma"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":")"},{"Type":"NodeText","Data":"进行归一化，即“中心化+缩放”。"}]}]},{"ID":"20250922204440-p8p7gwu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-p8p7gwu","updated":"20250922204440"},"Children":[{"ID":"20250922204440-rclodku","Type":"NodeParagraph","Properties":{"id":"20250922204440-rclodku","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RMSNorm"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简化版"},{"Type":"NodeText","Data":"，只使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"均方根(RMS)"},{"Type":"NodeText","Data":"进行归一化，即只“缩放”，不“中心化”，计算更快。"}]}]}]}]},{"ID":"20250922204440-6bc3pok","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-6bc3pok","updated":"20250922204440"},"Children":[{"ID":"20250922204440-w72380t","Type":"NodeParagraph","Properties":{"id":"20250922204440-w72380t","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"激活函数 (Activation Function)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204440-k2puu1q","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-k2puu1q","updated":"20250922204440"},"Children":[{"ID":"20250922204440-vnaed74","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-vnaed74","updated":"20250922204440"},"Children":[{"ID":"20250922204440-clnc19a","Type":"NodeParagraph","Properties":{"id":"20250922204440-clnc19a","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ReLU/GeLU/Swish"},{"Type":"NodeText","Data":": 都是作用于单个输入的非线性函数。"}]}]},{"ID":"20250922204440-5q5l2ng","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-5q5l2ng","updated":"20250922204440"},"Children":[{"ID":"20250922204440-85nybxc","Type":"NodeParagraph","Properties":{"id":"20250922204440-85nybxc","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SwiGLU/GeGLU"},{"Type":"NodeText","Data":": GLU（Gated Linear Unit）的变体。它们将输入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"拆分为两部分"},{"Type":"NodeText","Data":"，一部分经过非线性函数（如Swish或GeLU），另一部分作为“门控”，两者"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逐元素相乘"},{"Type":"NodeText","Data":"。这种门控机制被认为能让网络学习更复杂的交互，从而提升性能。"}]}]}]}]},{"ID":"20250922204440-krm0dgy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-krm0dgy","updated":"20250922204440"},"Children":[{"ID":"20250922204440-rv0jde1","Type":"NodeParagraph","Properties":{"id":"20250922204440-rv0jde1","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"位置嵌入 (Position Embedding)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204440-0ydst50","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-0ydst50","updated":"20250922204440"},"Children":[{"ID":"20250922204440-yfj8f5a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-yfj8f5a","updated":"20250922204440"},"Children":[{"ID":"20250922204440-rn9rpqc","Type":"NodeParagraph","Properties":{"id":"20250922204440-rn9rpqc","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Absolute (绝对)"},{"Type":"NodeText","Data":": 最简单，直接将位置向量"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"pᵢ"},{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加"},{"Type":"NodeText","Data":"到词嵌入"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"xᵢ"},{"Type":"NodeText","Data":"​上。"}]}]},{"ID":"20250922204440-v49ms7n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-v49ms7n","updated":"20250922204440"},"Children":[{"ID":"20250922204440-3odyfaj","Type":"NodeParagraph","Properties":{"id":"20250922204440-3odyfaj","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Relative (相对)"},{"Type":"NodeText","Data":": 在计算注意力分数"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Aᵢⱼ"},{"Type":"NodeText","Data":"​时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加入"},{"Type":"NodeText","Data":"一个只与相对距离"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"i-j"},{"Type":"NodeText","Data":"​相关的可学习标量"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"rᵢ₋ⱼ"},{"Type":"NodeText","Data":"​。"}]}]},{"ID":"20250922204440-zkp1rgh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-zkp1rgh","updated":"20250922204440"},"Children":[{"ID":"20250922204440-s1wfpxl","Type":"NodeParagraph","Properties":{"id":"20250922204440-s1wfpxl","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RoPE (旋转)"},{"Type":"NodeText","Data":": 不直接相加，而是用一个与位置相关的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"旋转矩阵"},{"Type":"NodeTextMark","TextMarkType":"strong code","TextMarkTextContent":"R"},{"Type":"NodeText","Data":"​来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"旋转"},{"Type":"NodeText","Data":"查询和键向量。公式的后半部分表明，旋转后的点积结果，其形式自然地只依赖于相对位置"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"i-j"},{"Type":"NodeText","Data":"​。"}]}]},{"ID":"20250922204440-j32tren","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-j32tren","updated":"20250922204440"},"Children":[{"ID":"20250922204440-grzthh6","Type":"NodeParagraph","Properties":{"id":"20250922204440-grzthh6","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ALiBi"},{"Type":"NodeText","Data":": 与Relative类似，也是在注意力分数上"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"减去"},{"Type":"NodeText","Data":"一个与相对距离"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"i-j"},{"Type":"NodeText","Data":"​相关的预定义惩罚项"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"m(i-j)"},{"Type":"NodeText","Data":"​。"}]}]}]}]}]},{"ID":"20250922204440-l74xo4k","Type":"NodeParagraph","Properties":{"id":"20250922204440-l74xo4k","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格从数学层面揭示了各种技术变体的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本质区别"},{"Type":"NodeText","Data":"。例如，它清晰地展示了RMSNorm是如何简化LayerNorm的，SwiGLU是如何引入门控机制的，以及RoPE是如何通过向量旋转来巧妙地编码相对位置信息的。"}]}]},{"ID":"20250922204440-3m2aqqt","Type":"NodeBlockquote","Properties":{"id":"20250922204440-3m2aqqt","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922204440-7c655q5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922204440-7c655q5","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922204440-9hjwj07","Type":"NodeParagraph","Properties":{"id":"20250922204440-9hjwj07","updated":"20250922204440"},"Children":[{"Type":"NodeText","Data":"第二十部分深入探讨了Transformer架构中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"注意力机制 (Attention)"},{"Type":"NodeText","Data":" 的优化演进，并结合表7中的公式，为整个架构配置的讨论画上了句号。这一部分的核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"效率与性能的再平衡"},{"Type":"NodeText","Data":"，特别是在处理长序列的挑战下。"}]},{"ID":"20250922204440-q2vk4cm","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922204440-q2vk4cm","updated":"20250922204440"},"Children":[{"ID":"20250922204440-uwdiia5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922204440-uwdiia5","updated":"20250922204440"},"Children":[{"ID":"20250922204440-0ze187b","Type":"NodeParagraph","Properties":{"id":"20250922204440-0ze187b","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"位置嵌入的终极对决：RoPE vs. ALiBi"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204440-rvhvjtx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-rvhvjtx","updated":"20250922204440"},"Children":[{"ID":"20250922204440-uosegxg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-uosegxg","updated":"20250922204440"},"Children":[{"ID":"20250922204440-9bhf3en","Type":"NodeParagraph","Properties":{"id":"20250922204440-9bhf3en","updated":"20250922204440"},"Children":[{"Type":"NodeText","Data":"文章继续深化了对位置嵌入的讨论，重点比较了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RoPE (旋转位置嵌入)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ALiBi"},{"Type":"NodeText","Data":"。这两者是当前解决长序列"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外推（extrapolation）"},{"Type":"NodeText","Data":"问题的最主流方案。"}]}]},{"ID":"20250922204440-zbxflm7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-zbxflm7","updated":"20250922204440"},"Children":[{"ID":"20250922204440-zuggrwj","Type":"NodeParagraph","Properties":{"id":"20250922204440-zuggrwj","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RoPE"},{"Type":"NodeText","Data":" 以其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学上的优雅性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强大的性能"},{"Type":"NodeText","Data":"，成为PaLM、LLaMA等顶尖模型的首选。"}]}]},{"ID":"20250922204440-x11qecb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-x11qecb","updated":"20250922204440"},"Children":[{"ID":"20250922204440-i7eqjqe","Type":"NodeParagraph","Properties":{"id":"20250922204440-i7eqjqe","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ALiBi"},{"Type":"NodeText","Data":" 则以其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简单、无需训练参数"},{"Type":"NodeText","Data":"的特性，在BLOOM等模型中展现了优秀的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外推能力"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练稳定性"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922204440-p91tlve","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922204440-p91tlve","updated":"20250922204440"},"Children":[{"ID":"20250922204440-4qfpjry","Type":"NodeParagraph","Properties":{"id":"20250922204440-4qfpjry","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"注意力机制的效率革命"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204440-e317ueg","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-e317ueg","updated":"20250922204440"},"Children":[{"ID":"20250922204440-qa226pf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-qa226pf","updated":"20250922204440"},"Children":[{"ID":"20250922204440-gk4xfgq","Type":"NodeParagraph","Properties":{"id":"20250922204440-gk4xfgq","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题的核心"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全注意力 (Full Attention)"},{"Type":"NodeText","Data":" 的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"二次方计算复杂度"},{"Type":"NodeText","Data":"是Transformer处理长序列的最大瓶颈。"}]}]},{"ID":"20250922204440-kng574a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-kng574a","updated":"20250922204440"},"Children":[{"ID":"20250922204440-83gctdu","Type":"NodeParagraph","Properties":{"id":"20250922204440-83gctdu","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解决方案的演进"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204440-q7344pb","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-q7344pb","updated":"20250922204440"},"Children":[{"ID":"20250922204440-1q79vs9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-1q79vs9","updated":"20250922204440"},"Children":[{"ID":"20250922204440-d0n8ji5","Type":"NodeParagraph","Properties":{"id":"20250922204440-d0n8ji5","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稀疏注意力 (Sparse Attention)"},{"Type":"NodeText","Data":": 早期方案，如GPT-3采用的，通过让每个词元只关注其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"邻近的词元"},{"Type":"NodeText","Data":"，来打破全连接，将复杂度降低。但这会损失全局信息。"}]}]},{"ID":"20250922204440-18ou7sw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-18ou7sw","updated":"20250922204440"},"Children":[{"ID":"20250922204440-bqcq3u8","Type":"NodeParagraph","Properties":{"id":"20250922204440-bqcq3u8","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多查询/分组查询注意力 (MQA/GQA)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理加速"},{"Type":"NodeText","Data":"的利器。通过让多个查询头"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"共享"},{"Type":"NodeText","Data":"同一份键和值，极大地减少了推理时KV缓存的内存占用和读取带宽。GQA是MQA和传统多头注意力（MHA）之间的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"巧妙折中"},{"Type":"NodeText","Data":"，已被"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA 2"},{"Type":"NodeText","Data":"采用，是现代LLM推理优化的关键技术。"}]}]},{"ID":"20250922204440-cdo8nlx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-cdo8nlx","updated":"20250922204440"},"Children":[{"ID":"20250922204440-slfqzlt","Type":"NodeParagraph","Properties":{"id":"20250922204440-slfqzlt","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FlashAttention"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统级优化"},{"Type":"NodeText","Data":"的典范。它不是在算法层面近似注意力，而是从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"底层硬件（GPU内存IO）"},{"Type":"NodeText","Data":"入手，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"融合内核（Fused Kernel）和重计算"},{"Type":"NodeText","Data":"等技术，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不损失任何精度"},{"Type":"NodeText","Data":"的情况下，极大地加速了注意力计算并减少了内存占用。它的出现是LLM发展史上的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重大工程突破"},{"Type":"NodeText","Data":"，已成为训练和推理SOTA模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标配"},{"Type":"NodeText","Data":"。"}]}]}]}]}]}]},{"ID":"20250922204440-ohgcvcg","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922204440-ohgcvcg","updated":"20250922204440"},"Children":[{"ID":"20250922204440-3ctdb4r","Type":"NodeParagraph","Properties":{"id":"20250922204440-3ctdb4r","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"公式背后的设计哲学 (表7)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204440-nvf2ibo","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204440-nvf2ibo","updated":"20250922204440"},"Children":[{"ID":"20250922204440-3tl5ket","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204440-3tl5ket","updated":"20250922204440"},"Children":[{"ID":"20250922204440-oefar5e","Type":"NodeParagraph","Properties":{"id":"20250922204440-oefar5e","updated":"20250922204440"},"Children":[{"Type":"NodeText","Data":"表7不仅仅是公式的罗列，它揭示了Transformer设计的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模块化和可组合性"},{"Type":"NodeText","Data":"。研究人员可以在归一化方法、位置、激活函数、位置嵌入等多个维度上，像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“搭积木”"},{"Type":"NodeText","Data":"一样，自由组合不同的技术方案，以在特定的硬件和任务上，找到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳定性、性能和效率"},{"Type":"NodeText","Data":"的最佳平衡点。"}]}]}]}]}]},{"ID":"20250922204440-ccxjqzn","Type":"NodeParagraph","Properties":{"id":"20250922204440-ccxjqzn","updated":"20250922204440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第二十部分为我们展示了一幅围绕"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“注意力”"},{"Type":"NodeText","Data":"这一核心机制展开的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续创新图景"},{"Type":"NodeText","Data":"。从位置编码的精巧设计（RoPE, ALiBi），到注意力计算本身的效率优化（GQA, FlashAttention），这些技术共同推动了LLM处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更长序列、实现更快推理"},{"Type":"NodeText","Data":"的能力。特别是FlashAttention的出现，雄辩地证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算法与系统协同设计"},{"Type":"NodeText","Data":"在推动AI进步中的巨大威力。"}]}]},{"ID":"20250922204611-0x45tmm","Type":"NodeParagraph","Properties":{"id":"20250922204611-0x45tmm","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"PyTorch、DeepSpeed和Megatron-LM。更新的版本FlashAttention-2进一步优化了GPU线程块和warp的工作划分，与原始的FlashAttention相比，速度提升了大约2倍。"}]},{"ID":"20250922204611-6kbbhak","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-6kbbhak","updated":"20250924151212"},"Children":[{"ID":"20250922204611-ygiyjrq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-ygiyjrq","updated":"20250922204611"},"Children":[{"ID":"20250922204611-0mnm61n","Type":"NodeParagraph","Properties":{"id":"20250922204611-0mnm61n","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PagedAttention."},{"Type":"NodeText","Data":" 已经观察到，当LLM部署在服务器上时，GPU内存主要被缓存的注意力键和值张量（称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"KV缓存"},{"Type":"NodeText","Data":"）占用。主要原因是输入长度通常是可变的，导致"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"碎片化"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过度预留"},{"Type":"NodeText","Data":"问题。受操作系统中经典的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分页技术"},{"Type":"NodeText","Data":"的启发，PagedAttention被提出来提高部署LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内存效率"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"吞吐量"},{"Type":"NodeText","Data":"。具体来说，PagedAttention将每个序列划分为子序列，并将这些子序列的相应KV缓存分配到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非连续的物理块"},{"Type":"NodeText","Data":"中。分页技术提高了GPU的利用率，并实现了并行采样中的高效内存共享。"}]}]}]},{"ID":"20250922204611-wq7v8hg","Type":"NodeParagraph","Properties":{"id":"20250922204611-wq7v8hg","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"综合所有这些讨论，我们总结了现有文献中关于详细配置的建议。为了获得更强的泛化能力和训练稳定性，建议选择"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"pre RMSNorm"},{"Type":"NodeText","Data":"作为层归一化，选择"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SwiGLU"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GeGLU"},{"Type":"NodeText","Data":"作为激活函数。此外，LN可能不应立即在嵌入层之后使用，因为这很可能导致性能下降。至于位置嵌入，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RoPE"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ALiBi"},{"Type":"NodeText","Data":"是更好的选择，因为它们在长序列上表现更好。"}]},{"ID":"20250922204611-d6s3wus","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922204611-d6s3wus","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.2.3 Pre-training Tasks (预训练任务)"}]},{"ID":"20250922204611-1mwkn2k","Type":"NodeParagraph","Properties":{"id":"20250922204611-1mwkn2k","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"预训练起着关键作用，它将大规模语料库中的通用知识编码到海量的模型参数中。对于训练LLM，有两种常用的预训练任务，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言建模"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"去噪自编码"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922204611-6scno8x","Type":"NodeParagraph","Properties":{"id":"20250922204611-6scno8x","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Language Modeling (语言建模)."},{"Type":"NodeText","Data":" 语言建模任务（LM）是预训练仅解码器LLM最常用的目标，例如GPT3和PaLM。给定一个词元序列"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"x"},{"Type":"NodeText","Data":" = {"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"x₁"},{"Type":"NodeText","Data":", . . . , "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"xₙ"},{"Type":"NodeText","Data":"}，LM任务旨在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自回归地"},{"Type":"NodeText","Data":"根据前面的词元"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"x"},{"Type":"NodeText","Data":"来预测目标词元"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"xᵢ"},{"Type":"NodeText","Data":"。一个通用的训练目标是最大化以下似然："}]},{"ID":"20250922204611-f6sncuk","Type":"NodeParagraph","Properties":{"id":"20250922204611-f6sncuk","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L_{LM}(x) = \\sum_{i=1}^n \\log P(x_i|x_{\u003ci})"},{"Type":"NodeText","Data":" (6)"}]},{"ID":"20250922204611-yn6x05b","Type":"NodeParagraph","Properties":{"id":"20250922204611-yn6x05b","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"由于大多数语言任务可以被看作是基于输入的预测问题，这些仅解码器的LLM可能潜在地具有以统一的LM方式隐式学习如何完成这些任务的优势。一些研究还揭示，仅解码器的LLM可以自然地转移到某些任务，通过自回归地预测下一个词元，而无需微调。LM的一个重要变体是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀语言建模"},{"Type":"NodeText","Data":"任务，它是为预训练具有前缀解码器架构的模型而设计的。在随机选择的前缀内的词元将不用于计算前缀语言建模的损失。在预训练期间看到相同数量的词元的情况下，前缀语言建模的性能略差于语言建模，因为序列中涉及模型预训练的词元更少。"}]},{"ID":"20250922204611-ewfg6sc","Type":"NodeTable","TableAligns":[1,1,1,1,1,1],"Properties":{"colgroup":"|||||","id":"20250922204611-ewfg6sc","updated":"20250924151212"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"I am sleepy. I start a pot of..."}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"coffee"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.661"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"strong"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.008"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"soup"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.005"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"water"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.119"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"black"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.008"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"..."}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"..."}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"tea"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.057"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"hot"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.007"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"happy"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.3e-6"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"rice"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.017"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"oat"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.006"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Boh"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.3e-6"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"chai"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.012"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"beans"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.006"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"..."}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"..."}]}]}]},{"ID":"20250922204611-q5oifoh","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922204611-q5oifoh","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 10：对于上下文“I am sleepy. I start a pot of”，下一个词元在词汇表上的降序概率分布。"}]},{"ID":"20250922204611-8gvplkr","Type":"NodeParagraph","Properties":{"id":"20250922204611-8gvplkr","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"为了便于讨论，这个例子是以词为单位而不是子词单位给出的。"}]},{"ID":"20250922204611-oyowdck","Type":"NodeParagraph","Properties":{"id":"20250922204611-oyowdck","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Denoising Autoencoding (去噪自编码)."},{"Type":"NodeText","Data":" 除了传统的LM，去噪自编码任务（DAE）也被广泛用于预训练语言模型。DAE任务的输入x"},{"Type":"NodeBackslash","Data":"span\\","Children":[{"Type":"NodeText","Data":"\\"}]},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"x是"},{"Type":"NodeTextMark","TextMarkType":"sub strong","TextMarkTextContent":"被随机替换了片段的损坏文本"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"。然后，语言模型被训练来**恢复被替换的词元"},{"Type":"NodeText","Data":"x**。形式上，DAE的训练目标表示如下："}]},{"ID":"20250922204611-9j9vs8v","Type":"NodeParagraph","Properties":{"id":"20250922204611-9j9vs8v","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"L_{DAE}(x) = \\log P(\\tilde{x}|x \\setminus \\tilde{x})"},{"Type":"NodeText","Data":" (7)"}]},{"ID":"20250922204611-87shxef","Type":"NodeParagraph","Properties":{"id":"20250922204611-87shxef","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"然而，DAE任务在实现上似乎比LM任务更复杂。因此，它没有被广泛用于预训练大型语言模型。将DAE作为预训练目标的现有LLM包括T5和GLM-130B。这些模型主要被训练以自回归的方式恢复被替换的片段。"}]},{"ID":"20250922204611-i7gkgo2","Type":"NodeParagraph","Properties":{"id":"20250922204611-i7gkgo2","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mixture-of-Denoisers (混合去噪器)."},{"Type":"NodeText","Data":" 混合去噪器（MoD），也称为UL2损失，被引入作为预训练语言模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一目标"},{"Type":"NodeText","Data":"。MoD将LM和DAE目标都视为不同类型的去噪任务，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"S-去噪器"},{"Type":"NodeText","Data":"（LM）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"R-去噪器"},{"Type":"NodeText","Data":"（DAE，短片段和低损坏率）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"X-去噪器"},{"Type":"NodeText","Data":"（DAE，长片段或高损坏率）。在这三种去噪任务中，S-去噪器类似于传统的LM目标（方程（6）），而R-去噪器和X-去噪器类似于DAE目标（方程（7）），但它们在片段长度和损坏文本的比例上有所不同。对于以不同特殊词元（即 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"{[R], [S], [X]}"},{"Type":"NodeText","Data":"​）开始的输入句子，模型将使用相应的去噪器进行优化。MoD已在最新的PaLM 2模型中被应用。"}]},{"ID":"20250922204611-cntlbuw","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922204611-cntlbuw","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.2.4 Decoding Strategy (解码策略)"}]},{"ID":"20250922204611-wwrug2z","Type":"NodeParagraph","Properties":{"id":"20250922204611-wwrug2z","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"在LLM预训练完成后，采用特定的解码策略来从LLM生成适当的输出至关重要。"}]},{"ID":"20250922204611-8jf9p7y","Type":"NodeParagraph","Properties":{"id":"20250922204611-8jf9p7y","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Background (背景)."},{"Type":"NodeText","Data":" 我们从流行的仅解码器架构开始讨论，并介绍自回归解码机制。由于这类LLM是基于语言建模任务（方程6）进行预训练的，一种基本的解码方法是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"贪心搜索"},{"Type":"NodeText","Data":"，它在每一步都根据先前生成的词元预测最可能的词元，形式上建模为："}]},{"ID":"20250922204611-5gfyzrw","Type":"NodeParagraph","Properties":{"id":"20250922204611-5gfyzrw","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_i = \\arg\\max_x P(x|x_{\u003ci})"},{"Type":"NodeText","Data":" (8)"}]},{"ID":"20250922204611-pavzwij","Type":"NodeParagraph","Properties":{"id":"20250922204611-pavzwij","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"其中"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"xᵢ"},{"Type":"NodeText","Data":"是在给定上下文"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"x"},{"Type":"NodeText","Data":"的条件下，在第"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"i"},{"Type":"NodeText","Data":"步生成时具有最高概率的词元。"}]},{"ID":"20250922204611-k3brjxe","Type":"NodeBlockquote","Properties":{"id":"20250922204611-k3brjxe","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922204611-1jzdiz9","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922204611-1jzdiz9","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922204611-jc06sfz","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922204611-jc06sfz","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统优化：榨干硬件性能"}]},{"ID":"20250922204611-cjiy46f","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-cjiy46f","updated":"20250922204611"},"Children":[{"ID":"20250922204611-csthiml","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-csthiml","updated":"20250922204611"},"Children":[{"ID":"20250922204611-4ys01kn","Type":"NodeParagraph","Properties":{"id":"20250922204611-4ys01kn","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PagedAttention"},{"Type":"NodeText","Data":": 这是对vLLM核心技术的介绍。它解决了KV缓存管理中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内存碎片化和浪费"},{"Type":"NodeText","Data":"问题，极大地提升了LLM服务的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"吞吐量"},{"Type":"NodeText","Data":"（即单位时间内能处理的请求数）。可以将其理解为为GPU内存开发的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“虚拟内存”"},{"Type":"NodeText","Data":"技术，是系统工程层面的一大创新。"}]}]}]},{"ID":"20250922204611-w0oufeo","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922204611-w0oufeo","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"架构配置的“最佳实践”"}]},{"ID":"20250922204611-qk2u8np","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-qk2u8np","updated":"20250922204611"},"Children":[{"ID":"20250922204611-uqugoer","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-uqugoer","updated":"20250922204611"},"Children":[{"ID":"20250922204611-5ucpwz9","Type":"NodeParagraph","Properties":{"id":"20250922204611-5ucpwz9","updated":"20250922204611"},"Children":[{"Type":"NodeText","Data":"作者在这里给出了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高度凝练的、可操作的"},{"Type":"NodeText","Data":"现代LLM架构"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“推荐配置”"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pre-RMSNorm（归一化） + SwiGLU（激活函数） + RoPE/ALiBi（位置嵌入）"},{"Type":"NodeText","Data":"。这基本上就是以LLaMA为代表的SOTA开源模型的技术栈，对于希望构建自己的LLM的开发者来说，是极具价值的参考。"}]}]}]},{"ID":"20250922204611-3o9ktuw","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922204611-3o9ktuw","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练任务：LLM学习的“基本功”"}]},{"ID":"20250922204611-0hlouyl","Type":"NodeParagraph","Properties":{"id":"20250922204611-0hlouyl","updated":"20250922204611"},"Children":[{"Type":"NodeText","Data":"LLM在预训练阶段学习的“世界模型”是通过完成特定的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自监督任务"},{"Type":"NodeText","Data":"来实现的。"}]},{"ID":"20250922204611-iom2cis","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-iom2cis","updated":"20250922204611"},"Children":[{"ID":"20250922204611-diu28om","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-diu28om","updated":"20250922204611"},"Children":[{"ID":"20250922204611-83ugtd2","Type":"NodeParagraph","Properties":{"id":"20250922204611-83ugtd2","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言建模 (LM)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204611-298b3hp","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-298b3hp","updated":"20250922204611"},"Children":[{"ID":"20250922204611-vryqo13","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-vryqo13","updated":"20250922204611"},"Children":[{"ID":"20250922204611-ev2cdq7","Type":"NodeParagraph","Properties":{"id":"20250922204611-ev2cdq7","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心任务"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“预测下一个词”"},{"Type":"NodeText","Data":"。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最简单、最主流"},{"Type":"NodeText","Data":"的预训练任务，也是所有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅解码器"},{"Type":"NodeText","Data":"模型（如GPT系列）的基础。"}]}]},{"ID":"20250922204611-jslle5h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-jslle5h","updated":"20250922204611"},"Children":[{"ID":"20250922204611-vzn17rj","Type":"NodeParagraph","Properties":{"id":"20250922204611-vzn17rj","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图10的启示"},{"Type":"NodeText","Data":": 这张图生动地展示了LM的工作原理。在看到"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"I start a pot of"},{"Type":"NodeText","Data":"​之后，模型在其内部的“知识库”中进行概率计算，认为接下来最可能的词是"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"coffee"},{"Type":"NodeText","Data":"​（概率0.661），其次是"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"water"},{"Type":"NodeText","Data":"​（0.119）等。"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"happy"},{"Type":"NodeText","Data":"​和"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Boh"},{"Type":"NodeText","Data":"​这种不合逻辑的词，其概率则极低。这说明模型已经学到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言模式和世界常识"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922204611-dxeqsde","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-dxeqsde","updated":"20250922204611"},"Children":[{"ID":"20250922204611-7w62bmq","Type":"NodeParagraph","Properties":{"id":"20250922204611-7w62bmq","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀LM"},{"Type":"NodeText","Data":": 这是为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀解码器"},{"Type":"NodeText","Data":"（如GLM）定制的变体，它允许对前缀部分进行双向理解。"}]}]}]}]},{"ID":"20250922204611-sx8yis0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-sx8yis0","updated":"20250922204611"},"Children":[{"ID":"20250922204611-44uso3j","Type":"NodeParagraph","Properties":{"id":"20250922204611-44uso3j","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"去噪自编码 (DAE)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204611-5btuthg","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-5btuthg","updated":"20250922204611"},"Children":[{"ID":"20250922204611-lnnas9v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-lnnas9v","updated":"20250922204611"},"Children":[{"ID":"20250922204611-8bop0tw","Type":"NodeParagraph","Properties":{"id":"20250922204611-8bop0tw","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心任务"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“完形填空”"},{"Type":"NodeText","Data":"。将文本的一部分"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“挖掉”（损坏）"},{"Type":"NodeText","Data":"，然后让模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“填回去”（恢复）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922204611-y2qpj6z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-y2qpj6z","updated":"20250922204611"},"Children":[{"ID":"20250922204611-goghype","Type":"NodeParagraph","Properties":{"id":"20250922204611-goghype","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代表"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器"},{"Type":"NodeText","Data":"模型（如T5）和BERT类模型的核心预训练任务。"}]}]}]}]},{"ID":"20250922204611-b6ubulh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-b6ubulh","updated":"20250922204611"},"Children":[{"ID":"20250922204611-np666h0","Type":"NodeParagraph","Properties":{"id":"20250922204611-np666h0","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合去噪器 (MoD / UL2)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204611-qlir9kn","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-qlir9kn","updated":"20250922204611"},"Children":[{"ID":"20250922204611-kt9aa7y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-kt9aa7y","updated":"20250922204611"},"Children":[{"ID":"20250922204611-ql2bsbo","Type":"NodeParagraph","Properties":{"id":"20250922204611-ql2bsbo","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“集大成者”"},{"Type":"NodeText","Data":"。它试图"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一"},{"Type":"NodeText","Data":"LM和DAE这两种任务。通过引入不同的特殊符号，让模型在同一个框架下，既能做“预测下一个词”（S-去噪器），也能做不同难度的“完形填空”（R-去噪器和X-去噪器）。"}]}]},{"ID":"20250922204611-n3d4hbq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-n3d4hbq","updated":"20250922204611"},"Children":[{"ID":"20250922204611-4iqlmlw","Type":"NodeParagraph","Properties":{"id":"20250922204611-4iqlmlw","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"意义"},{"Type":"NodeText","Data":": 这是一种更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面、更灵活"},{"Type":"NodeText","Data":"的预训练范式，旨在让模型同时掌握两种任务的优点。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PaLM 2"},{"Type":"NodeText","Data":"采用了此方法，说明了其有效性。"}]}]}]}]}]},{"ID":"20250922204611-s9hz7hf","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922204611-s9hz7hf","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码策略：如何从概率生成文本"}]},{"ID":"20250922204611-zp9xtnm","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-zp9xtnm","updated":"20250922204611"},"Children":[{"ID":"20250922204611-tfcyfo7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-tfcyfo7","updated":"20250922204611"},"Children":[{"ID":"20250922204611-4gvevzv","Type":"NodeParagraph","Properties":{"id":"20250922204611-4gvevzv","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心问题"},{"Type":"NodeText","Data":": 模型训练完成后，输出的是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"概率分布"},{"Type":"NodeText","Data":"（如图10所示）。如何从这个概率分布中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"选择"},{"Type":"NodeText","Data":"一个词，最终生成一段连贯的文本，就是解码策略要解决的问题。"}]}]},{"ID":"20250922204611-2ccdqeq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-2ccdqeq","updated":"20250922204611"},"Children":[{"ID":"20250922204611-kcccqau","Type":"NodeParagraph","Properties":{"id":"20250922204611-kcccqau","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"贪心搜索 (Greedy Search)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204611-dulosn5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-dulosn5","updated":"20250922204611"},"Children":[{"ID":"20250922204611-uu8nbrp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-uu8nbrp","updated":"20250922204611"},"Children":[{"ID":"20250922204611-q1tqsiq","Type":"NodeParagraph","Properties":{"id":"20250922204611-q1tqsiq","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“只选最好的”"},{"Type":"NodeText","Data":"。在每一步，总是选择概率最高的那个词。"}]}]},{"ID":"20250922204611-yl01c2f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-yl01c2f","updated":"20250922204611"},"Children":[{"ID":"20250922204611-tmmw2fy","Type":"NodeParagraph","Properties":{"id":"20250922204611-tmmw2fy","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":": 简单、确定。"}]}]},{"ID":"20250922204611-je4aq55","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-je4aq55","updated":"20250922204611"},"Children":[{"ID":"20250922204611-2bbp5wu","Type":"NodeParagraph","Properties":{"id":"20250922204611-2bbp5wu","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":": 可能会陷入局部最优，导致生成的文本"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单调、重复、缺乏创造性"},{"Type":"NodeText","Data":"。"}]}]}]}]}]}]},{"ID":"20250922204611-8fuygx2","Type":"NodeBlockquote","Properties":{"id":"20250922204611-8fuygx2","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922204611-5ld7xzj","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922204611-5ld7xzj","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922204611-40gsd4y","Type":"NodeParagraph","Properties":{"id":"20250922204611-40gsd4y","updated":"20250922204611"},"Children":[{"Type":"NodeText","Data":"第二十一部分是连接"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模型构建”"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模型使用”"},{"Type":"NodeText","Data":"的桥梁。它首先总结了系统级优化和架构配置的最佳实践，然后深入探讨了模型在预训练阶段"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“学什么”"},{"Type":"NodeText","Data":"（预训练任务）以及在生成阶段"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“怎么说”"},{"Type":"NodeText","Data":"（解码策略）的根本问题。"}]},{"ID":"20250922204611-7qo208e","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922204611-7qo208e","updated":"20250922204611"},"Children":[{"ID":"20250922204611-6sjd17x","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922204611-6sjd17x","updated":"20250922204611"},"Children":[{"ID":"20250922204611-6mu3gdd","Type":"NodeParagraph","Properties":{"id":"20250922204611-6mu3gdd","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从系统到算法的全面优化"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204611-ur9q6r2","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-ur9q6r2","updated":"20250922204611"},"Children":[{"ID":"20250922204611-qghm22a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-qghm22a","updated":"20250922204611"},"Children":[{"ID":"20250922204611-vvw361i","Type":"NodeParagraph","Properties":{"id":"20250922204611-vvw361i","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PagedAttention"},{"Type":"NodeText","Data":"的介绍，标志着LLM优化已经深入到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"底层系统和内存管理"},{"Type":"NodeText","Data":"的层面，这对于LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模部署和商业化"},{"Type":"NodeText","Data":"至关重要。"}]}]},{"ID":"20250922204611-fgn0y8u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-fgn0y8u","updated":"20250922204611"},"Children":[{"ID":"20250922204611-5zygnbn","Type":"NodeParagraph","Properties":{"id":"20250922204611-5zygnbn","updated":"20250922204611"},"Children":[{"Type":"NodeText","Data":"作者给出的“推荐配置”，则是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算法层面"},{"Type":"NodeText","Data":"经验的高度总结，为社区提供了宝贵的“最佳实践”指南。"}]}]}]}]},{"ID":"20250922204611-yiad1j3","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922204611-yiad1j3","updated":"20250922204611"},"Children":[{"ID":"20250922204611-cczlu38","Type":"NodeParagraph","Properties":{"id":"20250922204611-cczlu38","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练任务的统一趋势"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204611-tzraahe","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-tzraahe","updated":"20250922204611"},"Children":[{"ID":"20250922204611-vlzml6g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-vlzml6g","updated":"20250922204611"},"Children":[{"ID":"20250922204611-4z8dqdg","Type":"NodeParagraph","Properties":{"id":"20250922204611-4z8dqdg","updated":"20250922204611"},"Children":[{"Type":"NodeText","Data":"文章清晰地梳理了三大预训练范式："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自回归的LM"},{"Type":"NodeText","Data":"（预测未来）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自编码的DAE"},{"Type":"NodeText","Data":"（恢复损坏），以及试图"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一两者的MoD/UL2"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922204611-v8dn9gu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-v8dn9gu","updated":"20250922204611"},"Children":[{"ID":"20250922204611-fbbwcxw","Type":"NodeParagraph","Properties":{"id":"20250922204611-fbbwcxw","updated":"20250922204611"},"Children":[{"Type":"NodeText","Data":"MoD/UL2的出现，反映了研究者们试图构建一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更通用、更强大的预训练框架"},{"Type":"NodeText","Data":"的努力。通过让模型在训练时就接触到不同类型的去噪任务，期望其能获得更全面的语言理解和生成能力。"}]}]}]}]},{"ID":"20250922204611-racc9a5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922204611-racc9a5","updated":"20250922204611"},"Children":[{"ID":"20250922204611-bc1pkmd","Type":"NodeParagraph","Properties":{"id":"20250922204611-bc1pkmd","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码策略的起点"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204611-jjl831m","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204611-jjl831m","updated":"20250922204611"},"Children":[{"ID":"20250922204611-36qsiyd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-36qsiyd","updated":"20250922204611"},"Children":[{"ID":"20250922204611-n6uv0eh","Type":"NodeParagraph","Properties":{"id":"20250922204611-n6uv0eh","updated":"20250922204611"},"Children":[{"Type":"NodeText","Data":"本部分介绍了最基础的解码策略——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"贪心搜索"},{"Type":"NodeText","Data":"。虽然它本身并不完美，但它为理解后续更复杂的解码策略（如Beam Search, Top-K/Top-p Sampling）提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简单的起点和参照系"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922204611-92xwz2j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204611-92xwz2j","updated":"20250922204611"},"Children":[{"ID":"20250922204611-fb3m9mc","Type":"NodeParagraph","Properties":{"id":"20250922204611-fb3m9mc","updated":"20250922204611"},"Children":[{"Type":"NodeText","Data":"解码策略的选择，直接决定了模型生成文本的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量、多样性和创造性"},{"Type":"NodeText","Data":"。贪心搜索的确定性使其适用于需要精确答案的任务，但也限制了其在开放式生成中的应用。"}]}]}]}]}]},{"ID":"20250922204611-pw5uisd","Type":"NodeParagraph","Properties":{"id":"20250922204611-pw5uisd","updated":"20250922204611"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第二十一部分为我们描绘了一幅从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬件优化"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算法设计"},{"Type":"NodeText","Data":"，再到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习目标"},{"Type":"NodeText","Data":"，最后到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成策略"},{"Type":"NodeText","Data":"的完整技术图景。它揭示了LLM的强大，不仅在于其庞大的规模和精巧的架构，还在于其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习的基本原理（预训练任务）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表达的方式（解码策略）"},{"Type":"NodeText","Data":"。通过对这些基本问题的探讨，我们能更深刻地理解LLM是如何从一堆数字参数，转变为能够生成流畅、连贯甚至富有创造性文本的“智能体”的。"}]}]},{"ID":"20250922204935-16l81be","Type":"NodeParagraph","Properties":{"id":"20250922204935-16l81be","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"例如，在图10中，当预测句子“I am sleepy. I start a pot of”的下一个词元时，贪心搜索会选择当前步骤概率最高的词元“coffee”。贪心搜索在文本生成任务（例如，机器翻译和文本摘要）中可以取得令人满意的结果，因为在这些任务中，输出高度依赖于输入。然而，在开放式生成任务（例如，故事生成和对话）中，贪心搜索有时会生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"笨拙和重复"},{"Type":"NodeText","Data":"的句子。"}]},{"ID":"20250922204935-0y29l8v","Type":"NodeParagraph","Properties":{"id":"20250922204935-0y29l8v","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"作为另一种解码策略，提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于采样"},{"Type":"NodeText","Data":"的方法，即根据概率分布随机选择下一个词元，以增强生成过程中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"随机性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"："}]},{"ID":"20250922204935-joagm15","Type":"NodeParagraph","Properties":{"id":"20250922204935-joagm15","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"x_i \\sim P(x|x_{\u003ci})"},{"Type":"NodeText","Data":" (9)"}]},{"ID":"20250922204935-waxpb5b","Type":"NodeParagraph","Properties":{"id":"20250922204935-waxpb5b","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"对于图10中的例子，基于采样的方法会以更高的概率采样到“coffee”这个词，同时也保留了选择其余词（如“water”、“tea”、“rice”等）的可能性。"}]},{"ID":"20250922204935-dj6pv5j","Type":"NodeParagraph","Properties":{"id":"20250922204935-dj6pv5j","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"这些解码方法不仅限于仅解码器架构，它们通常也可以以类似的方式应用于编码器-解码器模型和前缀解码器模型。"}]},{"ID":"20250922204935-93ippty","Type":"NodeParagraph","Properties":{"id":"20250922204935-93ippty","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Improvement for Greedy Search (对贪心搜索的改进)."},{"Type":"NodeText","Data":" 在每一步选择概率最高的词元可能会导致忽略一个整体概率更高但局部估计较低的句子。接下来，我们介绍几种缓解这个问题的改进策略。"}]},{"ID":"20250922204935-1zxjn8x","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-1zxjn8x","updated":"20250924151212"},"Children":[{"ID":"20250922204934-ppshebt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-ppshebt","updated":"20250922204934"},"Children":[{"ID":"20250922204935-073ldhy","Type":"NodeParagraph","Properties":{"id":"20250922204935-073ldhy","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"束搜索 (Beam search)."},{"Type":"NodeText","Data":" 束搜索在解码过程的每一步保留"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"n"},{"Type":"NodeText","Data":"个（束大小）概率最高的句子，并最终选择生成概率最高的响应。通常，束大小配置在3到6的范围内。然而，选择更大的束大小可能会导致性能下降。"}]}]},{"ID":"20250922204934-otddkt5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-otddkt5","updated":"20250922204934"},"Children":[{"ID":"20250922204935-z51u1f2","Type":"NodeParagraph","Properties":{"id":"20250922204935-z51u1f2","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长度惩罚 (Length penalty)."},{"Type":"NodeText","Data":" 由于束搜索偏爱较短的句子，施加长度惩罚（又称长度归一化）是一种常用的技术，用于克服这个问题。它根据句子长度对句子概率进行归一化（除以长度的指数幂α）。"}]}]}]},{"ID":"20250922204935-umwbyyv","Type":"NodeParagraph","Properties":{"id":"20250922204935-umwbyyv","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"此外，一些研究人员提议对先前生成的词元或n-gram进行惩罚，以缓解重复生成的问题。此外，可以利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样化束搜索"},{"Type":"NodeText","Data":"来根据相同的输入生成一组多样的输出。"}]},{"ID":"20250922204935-ut2hs4w","Type":"NodeParagraph","Properties":{"id":"20250922204935-ut2hs4w","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Improvement for Random Sampling (对随机采样的改进)."},{"Type":"NodeText","Data":" 基于采样的方法在整个词汇表上对词元进行采样，这可能会根据上下文选择错误或不相关的词元（例如，图10中的“happy”和“Boh”）。为了提高生成质量，已经提出了几种策略来减轻或防止选择概率极低的词。"}]},{"ID":"20250922204935-fzmj57f","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-fzmj57f","updated":"20250924151212"},"Children":[{"ID":"20250922204934-4q5qo1c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-4q5qo1c","updated":"20250922204934"},"Children":[{"ID":"20250922204935-32g2gdi","Type":"NodeParagraph","Properties":{"id":"20250922204935-32g2gdi","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"温度采样 (Temperature sampling)."},{"Type":"NodeText","Data":" 为了调节采样的随机性，一个实用的方法是调整用于计算词汇表上第"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"j"},{"Type":"NodeText","Data":"个词元概率的softmax函数的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"温度系数"},{"Type":"NodeText","Data":"："}]},{"ID":"20250922204935-i89dzzj","Type":"NodeParagraph","Properties":{"id":"20250922204935-i89dzzj","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"P(x_j|x_{\u003ci}) = \\frac{\\exp(l_j/t)}{\\sum_{j'}\\exp(l_{j'}/t)}"},{"Type":"NodeText","Data":" (10)"}]},{"ID":"20250922204935-vgh128q","Type":"NodeParagraph","Properties":{"id":"20250922204935-vgh128q","updated":"20250922204935"},"Children":[{"Type":"NodeText","Data":"其中"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"l"},{"Type":"NodeTextMark","TextMarkType":"em sub","TextMarkTextContent":"j'"},{"Type":"NodeText","Data":"是每个词的logits，"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"t"},{"Type":"NodeText","Data":"是温度系数。降低温度"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"t"},{"Type":"NodeText","Data":"会增加选择高概率词的机会，同时减少选择低概率词的机会。当"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"t"},{"Type":"NodeText","Data":"设置为1时，它变成默认的随机采样；当"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"t"},{"Type":"NodeText","Data":"趋近于0时，它等同于贪心搜索。此外，当"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"t"},{"Type":"NodeText","Data":"趋于无穷大时，它退化为均匀采样。"}]}]},{"ID":"20250922204934-xte3al9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-xte3al9","updated":"20250922204934"},"Children":[{"ID":"20250922204935-cpybj8r","Type":"NodeParagraph","Properties":{"id":"20250922204935-cpybj8r","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Top-k采样 (Top-k sampling)."},{"Type":"NodeText","Data":" 与温度采样不同，top-k采样直接截断概率较低的词元，只从概率最高的"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"k"},{"Type":"NodeText","Data":"个词元中进行采样。例如，在图10中，top-5采样将从“coffee”、“water”、“tea”、“rice”和“chai”这几个词中根据它们重新缩放的概率进行采样。"}]}]},{"ID":"20250922204934-roa13hn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-roa13hn","updated":"20250922204934"},"Children":[{"ID":"20250922204935-zjj5j6i","Type":"NodeParagraph","Properties":{"id":"20250922204935-zjj5j6i","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Top-p采样 (Top-p sampling)."},{"Type":"NodeText","Data":" 由于top-k采样不考虑整体的概率分布，一个固定的"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"k"},{"Type":"NodeText","Data":"值可能不适用于不同的上下文。因此，提出了top-p采样（又称"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心采样, nucleus sampling"},{"Type":"NodeText","Data":"），它从累积概率高于（或等于）"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"p"},{"Type":"NodeText","Data":"的最小集合中进行采样。在实践中，这个最小集合可以通过从按生成概率降序排列的词汇表中逐渐添加词元来构建，直到它们的累积值超过"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"p"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922204935-nk87lat","Type":"NodeParagraph","Properties":{"id":"20250922204935-nk87lat","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"最近，研究人员还探索了其他LLM的采样策略。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"η-采样"},{"Type":"NodeText","Data":"通过引入基于概率分布的动态阈值来进一步改进top-p采样。此外，可以利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比搜索"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"典型采样"},{"Type":"NodeText","Data":"来提高解码过程中生成的连贯性。由于发现大型模型比小型模型倾向于为重要词元分配更高的概率，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比解码"},{"Type":"NodeText","Data":"利用一个较大的LM（例如，OPT-13B）和一个较小的LM（例如，OPT-125M）来测量它们的对数似然差异。随后，基于概率分布的delta值对词元进行采样，从而放大了重要词元的影响。基于这种对比思想，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DoLa"},{"Type":"NodeText","Data":"进一步将其扩展到对比单个LLM不同层之间的logits，因为较高层倾向于为重要词元分配更多权重。"}]},{"ID":"20250922204935-mzri9ry","Type":"NodeParagraph","Properties":{"id":"20250922204935-mzri9ry","updated":"20250924151212"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Practical Settings (实践设置)."},{"Type":"NodeText","Data":" 在实践中，现有的库（例如，Transformers）和LLM的公共API（例如，OpenAI）已支持各种解码策略，以服务于不同的文本生成场景。接下来，我们介绍几个代表性LLM的解码设置："}]},{"ID":"20250922204935-y4r55rc","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-y4r55rc","updated":"20250924151212"},"Children":[{"ID":"20250922204934-942s4p9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-942s4p9","updated":"20250922204934"},"Children":[{"ID":"20250922204935-0dkrafk","Type":"NodeParagraph","Properties":{"id":"20250922204935-0dkrafk","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"T5"},{"Type":"NodeText","Data":" 使用贪心搜索作为默认设置，并在翻译和摘要任务中应用束搜索（束大小为4），长度惩罚为0.6。"}]}]},{"ID":"20250922204934-nqpcbbs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-nqpcbbs","updated":"20250922204934"},"Children":[{"ID":"20250922204935-rndj1ao","Type":"NodeParagraph","Properties":{"id":"20250922204935-rndj1ao","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT-3"},{"Type":"NodeText","Data":" 在所有生成任务中均采用束搜索，束大小为4，长度惩罚为0.6。"}]}]},{"ID":"20250922204934-nv9nq7u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-nv9nq7u","updated":"20250922204934"},"Children":[{"ID":"20250922204935-3u1zpt2","Type":"NodeParagraph","Properties":{"id":"20250922204935-3u1zpt2","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca"},{"Type":"NodeText","Data":" 在开放式生成中采用基于采样的策略，其中top-k（k=50），top-p（p=0.9），温度为0.7。"}]}]},{"ID":"20250922204934-vrjwmt9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-vrjwmt9","updated":"20250922204934"},"Children":[{"ID":"20250922204935-bk3lsas","Type":"NodeParagraph","Properties":{"id":"20250922204935-bk3lsas","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA"},{"Type":"NodeText","Data":" 针对特定任务采用不同的解码策略。例如，它在问答任务中使用贪心搜索，而在代码生成中使用温度设置为0.1（pass@1）和0.8（pass@100）的采样策略。"}]}]},{"ID":"20250922204934-ej6i86i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-ej6i86i","updated":"20250922204934"},"Children":[{"ID":"20250922204935-9wwo8hk","Type":"NodeParagraph","Properties":{"id":"20250922204935-9wwo8hk","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"OpenAI API"},{"Type":"NodeText","Data":" 支持几种基本的解码策略，包括贪心搜索（通过将温度设置为"}]}]}]},{"ID":"20250922204935-o8s2irs","Type":"NodeBlockquote","Properties":{"id":"20250922204935-o8s2irs","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922204935-kio1m5r","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922204935-kio1m5r","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922204935-3781qlx","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922204935-3781qlx","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码策略：从“唯一解”到“无限可能”"}]},{"ID":"20250922204935-i7astz6","Type":"NodeParagraph","Properties":{"id":"20250922204935-i7astz6","updated":"20250922204935"},"Children":[{"Type":"NodeText","Data":"这部分内容的核心是探讨如何从模型输出的概率分布中生成最终文本，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码策略"},{"Type":"NodeText","Data":"。它展现了从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确定性"},{"Type":"NodeText","Data":"生成到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样化"},{"Type":"NodeText","Data":"生成的演进。"}]},{"ID":"20250922204935-sj4aqe1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-sj4aqe1","updated":"20250922204935"},"Children":[{"ID":"20250922204934-axgmghr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-axgmghr","updated":"20250922204934"},"Children":[{"ID":"20250922204935-dpma8x1","Type":"NodeParagraph","Properties":{"id":"20250922204935-dpma8x1","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"贪心搜索 (Greedy Search) 与其改进"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204935-ffn1otz","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-ffn1otz","updated":"20250922204935"},"Children":[{"ID":"20250922204934-eocp36k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-eocp36k","updated":"20250922204934"},"Children":[{"ID":"20250922204935-0ienvtb","Type":"NodeParagraph","Properties":{"id":"20250922204935-0ienvtb","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本质"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确定性"},{"Type":"NodeText","Data":"策略，永远选择局部最优解（概率最高的词）。"}]}]},{"ID":"20250922204934-fbt43uh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-fbt43uh","updated":"20250922204934"},"Children":[{"ID":"20250922204935-n612mr7","Type":"NodeParagraph","Properties":{"id":"20250922204935-n612mr7","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题"},{"Type":"NodeText","Data":": 容易生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重复、单调、缺乏新意"},{"Type":"NodeText","Data":"的文本，且可能错失全局最优的句子。"}]}]},{"ID":"20250922204934-3u6ymln","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-3u6ymln","updated":"20250922204934"},"Children":[{"ID":"20250922204935-p1j25ni","Type":"NodeParagraph","Properties":{"id":"20250922204935-p1j25ni","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改进 - 束搜索 (Beam Search)"},{"Type":"NodeText","Data":": 是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“有限的远见”"},{"Type":"NodeText","Data":"。它在每一步都保留"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"k"},{"Type":"NodeText","Data":"​个最可能的候选路径（句子），而不是只保留一个。这在一定程度上缓解了贪心搜索的短视问题。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长度惩罚"},{"Type":"NodeText","Data":"则是为了修正束搜索偏爱短句的“副作用”。"}]}]}]}]},{"ID":"20250922204934-5kgvo90","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-5kgvo90","updated":"20250922204934"},"Children":[{"ID":"20250922204935-90xtdx6","Type":"NodeParagraph","Properties":{"id":"20250922204935-90xtdx6","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"随机采样 (Random Sampling) 与其改进"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204935-diwxp8a","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-diwxp8a","updated":"20250922204935"},"Children":[{"ID":"20250922204934-g4nne90","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-g4nne90","updated":"20250922204934"},"Children":[{"ID":"20250922204935-xi9p0qt","Type":"NodeParagraph","Properties":{"id":"20250922204935-xi9p0qt","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本质"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"随机性"},{"Type":"NodeText","Data":"策略，根据概率分布随机选择下一个词。"}]}]},{"ID":"20250922204934-dx0kiop","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-dx0kiop","updated":"20250922204934"},"Children":[{"ID":"20250922204935-61q3x8t","Type":"NodeParagraph","Properties":{"id":"20250922204935-61q3x8t","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题"},{"Type":"NodeText","Data":": 完全随机可能导致"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“胡言乱语”"},{"Type":"NodeText","Data":"，选出与上下文毫不相关的词（如"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"happy"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Boh"},{"Type":"NodeText","Data":"​）。"}]}]},{"ID":"20250922204934-1bzxorz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-1bzxorz","updated":"20250922204934"},"Children":[{"ID":"20250922204935-qtklklc","Type":"NodeParagraph","Properties":{"id":"20250922204935-qtklklc","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改进 - “有控制的随机”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204935-mjgchzo","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922204935-mjgchzo","updated":"20250922204935"},"Children":[{"ID":"20250922204934-yiq6plh","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922204934-yiq6plh","updated":"20250922204934"},"Children":[{"ID":"20250922204935-zvcfugs","Type":"NodeParagraph","Properties":{"id":"20250922204935-zvcfugs","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"温度采样 (Temperature Sampling)"},{"Type":"NodeText","Data":": 通过调整"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"温度"},{"Type":"NodeTextMark","TextMarkType":"strong code","TextMarkTextContent":"t"},{"Type":"NodeText","Data":"​来控制概率分布的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“平滑度”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922204935-r5x0ykq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-r5x0ykq","updated":"20250922204935"},"Children":[{"ID":"20250922204934-rnl3oib","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-rnl3oib","updated":"20250922204934"},"Children":[{"ID":"20250922204935-w6rqujj","Type":"NodeParagraph","Properties":{"id":"20250922204935-w6rqujj","updated":"20250922204935"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"t"},{"Type":"NodeText","Data":"​ -\u003e 0: 分布变"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“尖锐”"},{"Type":"NodeText","Data":"，趋近于贪心搜索，更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"保守"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922204934-l5xa3on","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-l5xa3on","updated":"20250922204934"},"Children":[{"ID":"20250922204935-c7solou","Type":"NodeParagraph","Properties":{"id":"20250922204935-c7solou","updated":"20250922204935"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"t"},{"Type":"NodeText","Data":"​ \u003e 1: 分布变"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“平坦”"},{"Type":"NodeText","Data":"，趋近于均匀分布，更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冒险"},{"Type":"NodeText","Data":"、更具"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"创造性"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922204934-rt8wj2z","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922204934-rt8wj2z","updated":"20250922204934"},"Children":[{"ID":"20250922204935-wfbb6vw","Type":"NodeParagraph","Properties":{"id":"20250922204935-wfbb6vw","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Top-k 采样"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简单粗暴地圈定候选范围"},{"Type":"NodeText","Data":"。只在概率最高的"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"k"},{"Type":"NodeText","Data":"​个词中进行随机采样。"}]}]},{"ID":"20250922204934-3fg8o3w","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922204934-3fg8o3w","updated":"20250922204934"},"Children":[{"ID":"20250922204935-4gjxcec","Type":"NodeParagraph","Properties":{"id":"20250922204935-4gjxcec","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Top-p (核心) 采样"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更智能地圈定候选范围"},{"Type":"NodeText","Data":"。它选择一个动态的词集，其累积概率刚好超过阈值"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"p"},{"Type":"NodeText","Data":"​。这比固定的"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"k"},{"Type":"NodeText","Data":"​更灵活，能适应不同上下文下概率分布的“胖瘦”。例如，如果模型非常确定下一个词，候选集可能只有几个词；如果不确定，候选集可能会很大。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Top-p是目前最常用、效果最好的采样策略之一。"}]}]}]}]}]}]},{"ID":"20250922204934-v0mp0c6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-v0mp0c6","updated":"20250922204934"},"Children":[{"ID":"20250922204935-zca1few","Type":"NodeParagraph","Properties":{"id":"20250922204935-zca1few","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前沿探索"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204935-25qrxrs","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-25qrxrs","updated":"20250922204935"},"Children":[{"ID":"20250922204934-gn1hnm6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-gn1hnm6","updated":"20250922204934"},"Children":[{"ID":"20250922204935-qc4zahi","Type":"NodeParagraph","Properties":{"id":"20250922204935-qc4zahi","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比解码/DoLa"},{"Type":"NodeText","Data":": 这是一个非常新颖的想法。它认为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大模型"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高层网络"},{"Type":"NodeText","Data":"更懂"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“事实”"},{"Type":"NodeText","Data":"，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"小模型"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"底层网络"},{"Type":"NodeText","Data":"更懂"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“语法”"},{"Type":"NodeText","Data":"。通过对比两者（或高低层）的logits，可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"放大“事实性”信号"},{"Type":"NodeText","Data":"，减少“胡言乱语”，生成更连贯、更符合事实的内容。"}]}]}]}]}]},{"ID":"20250922204935-ftigq9w","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922204935-ftigq9w","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实践中的选择"}]},{"ID":"20250922204935-co9lgy8","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-co9lgy8","updated":"20250922204935"},"Children":[{"ID":"20250922204934-gswmoyz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-gswmoyz","updated":"20250922204934"},"Children":[{"ID":"20250922204935-egnaokx","Type":"NodeParagraph","Properties":{"id":"20250922204935-egnaokx","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"没有万能的策略"},{"Type":"NodeText","Data":": 不同的模型和任务有不同的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“默认偏好”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922204935-xbayttr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-xbayttr","updated":"20250922204935"},"Children":[{"ID":"20250922204934-f9eoijs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-f9eoijs","updated":"20250922204934"},"Children":[{"ID":"20250922204935-bj8vq1s","Type":"NodeParagraph","Properties":{"id":"20250922204935-bj8vq1s","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"T5/GPT-3"},{"Type":"NodeText","Data":": 在需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确定性"},{"Type":"NodeText","Data":"的传统NLP任务（如翻译）中，偏爱"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"束搜索"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922204934-nqadszi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-nqadszi","updated":"20250922204934"},"Children":[{"ID":"20250922204935-b7cwxnc","Type":"NodeParagraph","Properties":{"id":"20250922204935-b7cwxnc","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca/LLaMA"},{"Type":"NodeText","Data":": 在需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"的开放式任务（如对话、代码生成）中，偏爱"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"采样策略"},{"Type":"NodeText","Data":"（特别是Top-p）。"}]}]},{"ID":"20250922204934-wcyo1v6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-wcyo1v6","updated":"20250922204934"},"Children":[{"ID":"20250922204935-eunf224","Type":"NodeParagraph","Properties":{"id":"20250922204935-eunf224","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"OpenAI API"},{"Type":"NodeText","Data":": 提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"丰富的参数"},{"Type":"NodeText","Data":"，让用户可以根据自己的需求，灵活地调整温度、Top-p等，来控制生成的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确定性"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"创造性"},{"Type":"NodeText","Data":"。"}]}]}]}]}]}]},{"ID":"20250922204935-eh6hcoc","Type":"NodeBlockquote","Properties":{"id":"20250922204935-eh6hcoc","updated":"20250924151212"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922204935-fzakzpp","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922204935-fzakzpp","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922204935-em8c4hi","Type":"NodeParagraph","Properties":{"id":"20250922204935-em8c4hi","updated":"20250922204935"},"Children":[{"Type":"NodeText","Data":"第二十二部分深入探讨了LLM生成文本的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“最后一公里”——解码策略"},{"Type":"NodeText","Data":"。如果说模型训练是“学习知识”，那么解码就是“运用知识进行表达”。这一部分清晰地展示了在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确定性（Fidelity）"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性（Diversity）"},{"Type":"NodeText","Data":"这对核心矛盾之间，研究者们是如何通过各种精巧的算法进行权衡和创新的。"}]},{"ID":"20250922204935-w7lyvdq","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922204935-w7lyvdq","updated":"20250922204935"},"Children":[{"ID":"20250922204934-xclemsg","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922204934-xclemsg","updated":"20250922204934"},"Children":[{"ID":"20250922204935-1bcgo1t","Type":"NodeParagraph","Properties":{"id":"20250922204935-1bcgo1t","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大技术路线的对立与统一"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204935-fka6y3x","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-fka6y3x","updated":"20250922204935"},"Children":[{"ID":"20250922204934-pna5pxm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-pna5pxm","updated":"20250922204934"},"Children":[{"ID":"20250922204935-ffmvf7g","Type":"NodeParagraph","Properties":{"id":"20250922204935-ffmvf7g","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确定性路线 (以贪心/束搜索为代表)"},{"Type":"NodeText","Data":": 追求生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最符合概率模型"},{"Type":"NodeText","Data":"的、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最可信"},{"Type":"NodeText","Data":"的输出。适用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有标准答案"},{"Type":"NodeText","Data":"的任务，如翻译、摘要。"}]}]},{"ID":"20250922204934-8bw4a5r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-8bw4a5r","updated":"20250922204934"},"Children":[{"ID":"20250922204935-quvojg1","Type":"NodeParagraph","Properties":{"id":"20250922204935-quvojg1","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"随机性路线 (以采样为代表)"},{"Type":"NodeText","Data":": 追求生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更多样、更有趣、更具创造性"},{"Type":"NodeText","Data":"的输出。适用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"没有标准答案"},{"Type":"NodeText","Data":"的开放式任务，如对话、故事生成。"}]}]},{"ID":"20250922204934-h9c9dtl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-h9c9dtl","updated":"20250922204934"},"Children":[{"ID":"20250922204935-p9nhh6n","Type":"NodeParagraph","Properties":{"id":"20250922204935-p9nhh6n","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一"},{"Type":"NodeText","Data":": 现代解码策略（如带温度的采样）实际上是在这两条路线之间寻找一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平衡点"},{"Type":"NodeText","Data":"。通过调整参数（如温度"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"t"},{"Type":"NodeText","Data":"​、"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"p"},{"Type":"NodeText","Data":"​值），用户可以自由地控制模型是在“严格遵循事实”还是在“自由发挥创意”。"}]}]}]}]},{"ID":"20250922204934-tmovrk2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922204934-tmovrk2","updated":"20250922204934"},"Children":[{"ID":"20250922204935-b30a5lm","Type":"NodeParagraph","Properties":{"id":"20250922204935-b30a5lm","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“无脑”到“智能”的采样"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204935-wyc0psh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-wyc0psh","updated":"20250922204935"},"Children":[{"ID":"20250922204934-e0ekxif","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-e0ekxif","updated":"20250922204934"},"Children":[{"ID":"20250922204935-utk0x03","Type":"NodeParagraph","Properties":{"id":"20250922204935-utk0x03","updated":"20250922204935"},"Children":[{"Type":"NodeText","Data":"解码策略的演进是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不断变得更“智能”"},{"Type":"NodeText","Data":"的过程。"}]}]},{"ID":"20250922204934-tv9yvfh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-tv9yvfh","updated":"20250922204934"},"Children":[{"ID":"20250922204935-4av3lgi","Type":"NodeParagraph","Properties":{"id":"20250922204935-4av3lgi","updated":"20250922204935"},"Children":[{"Type":"NodeText","Data":"从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完全随机采样"},{"Type":"NodeText","Data":"（可能生成无意义内容），到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Top-k"},{"Type":"NodeText","Data":"（简单截断），再到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Top-p/核心采样"},{"Type":"NodeText","Data":"（动态调整候选集），采样方法变得越来越"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文感知"},{"Type":"NodeText","Data":"，能够在保证基本合理性的前提下最大化多样性。"}]}]}]}]},{"ID":"20250922204934-cs8uueb","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922204934-cs8uueb","updated":"20250922204934"},"Children":[{"ID":"20250922204935-nutb094","Type":"NodeParagraph","Properties":{"id":"20250922204935-nutb094","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前沿思想的涌现"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204935-31xpy69","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-31xpy69","updated":"20250922204935"},"Children":[{"ID":"20250922204934-u242mkw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-u242mkw","updated":"20250922204934"},"Children":[{"ID":"20250922204935-bbzxmax","Type":"NodeParagraph","Properties":{"id":"20250922204935-bbzxmax","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比解码（DoLa）"},{"Type":"NodeText","Data":"的出现，标志着解码策略的思考进入了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"新的维度"},{"Type":"NodeText","Data":"。它不再仅仅关注当前层的概率分布，而是开始"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用模型内部不同层次的信息"},{"Type":"NodeText","Data":"（高层代表“语义”，底层代表“语法”）。这是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“利用模型自身的知识来指导自己生成”"},{"Type":"NodeText","Data":"的深刻思想，为提升生成内容的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"事实性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连贯性"},{"Type":"NodeText","Data":"开辟了新途径。"}]}]}]}]},{"ID":"20250922204934-ozchhhh","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922204934-ozchhhh","updated":"20250922204934"},"Children":[{"ID":"20250922204935-b0gtpic","Type":"NodeParagraph","Properties":{"id":"20250922204935-b0gtpic","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实践的指导意义"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922204935-y8kla8w","Type":"NodeList","ListData":{},"Properties":{"id":"20250922204935-y8kla8w","updated":"20250922204935"},"Children":[{"ID":"20250922204934-f5q7msk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922204934-f5q7msk","updated":"20250922204934"},"Children":[{"ID":"20250922204935-d6avoq2","Type":"NodeParagraph","Properties":{"id":"20250922204935-d6avoq2","updated":"20250922204935"},"Children":[{"Type":"NodeText","Data":"通过列举T5、GPT-3、Alpaca等模型的默认设置，本部分为实践者提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"宝贵的参考"},{"Type":"NodeText","Data":"。它告诉我们，针对不同的任务类型（封闭式 vs. 开放式），应该选择哪种解码策略，以及如何设置关键参数。"}]}]}]}]}]},{"ID":"20250922204935-0t3d0t5","Type":"NodeParagraph","Properties":{"id":"20250922204935-0t3d0t5","updated":"20250922204935"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第二十二部分不仅是一份详尽的解码算法“清单”，更是一篇关于如何在LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“确定性”"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“创造性”"},{"Type":"NodeText","Data":"之间进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"艺术性权衡"},{"Type":"NodeText","Data":"的深刻论述。它揭示了，一个优秀的LLM应用，不仅需要一个强大的模型，还需要一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与之匹配的、精心设计的解码策略"},{"Type":"NodeText","Data":"，才能最终生成满足用户需求的、高质量的文本。"}]}]},{"ID":"20250922205316-qgbdp0o","Type":"NodeParagraph","Properties":{"id":"20250922205316-qgbdp0o","updated":"20250924151212"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922205316-akou5k6","Type":"NodeThematicBreak","Properties":{"id":"20250922205316-akou5k6","updated":"20250924151212"}},{"ID":"20250922205316-q7856rq","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205316-q7856rq","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二十三部分"}]},{"ID":"20250922205316-c01wyx9","Type":"NodeParagraph","Properties":{"id":"20250922205316-c01wyx9","updated":"20250922205320"},"Children":[{"Type":"NodeText","Data":"0）、束搜索（使用"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"best_of"},{"Type":"NodeText","Data":"​设置）、温度采样（使用"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"temperature"},{"Type":"NodeText","Data":"​设置）、核心采样（使用"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"top_p"},{"Type":"NodeText","Data":"​设置）。它还引入了"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"presence_penalty"},{"Type":"NodeText","Data":"​和"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"frequency_penalty"},{"Type":"NodeText","Data":"​参数来控制生成的重复度。根据OpenAI的文档，即使输入和超参数相同，他们的API也可能会产生不同的输出。将温度设置为0可以产生更多确定性的输出，尽管仍有微小的变异可能性。"}]},{"ID":"20250922205316-t4u0l8c","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922205316-t4u0l8c","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.2.5 Summary and Discussion (总结与讨论)"}]},{"ID":"20250922205316-vuzy7x0","Type":"NodeParagraph","Properties":{"id":"20250922205316-vuzy7x0","updated":"20250922205320"},"Children":[{"Type":"NodeText","Data":"架构和预训练任务的选择可能会给LLM带来不同的归纳偏置，从而导致不同的模型能力。在本部分中，我们讨论一个关于LLM架构选择的开放问题。"}]},{"ID":"20250922205316-f7bonu0","Type":"NodeBlockquote","Properties":{"id":"20250922205316-f7bonu0","updated":"20250922205320"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922205316-7vnadqp","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205316-7vnadqp","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为什么“预测下一个词”有效？"}]},{"ID":"20250922205316-iav83bm","Type":"NodeParagraph","Properties":{"id":"20250922205316-iav83bm","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"仅解码器架构的本质是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"准确地预测下一个词"},{"Type":"NodeText","Data":"以重构预训练数据。到目前为止，还没有正式的研究从理论上证明其相对于其他架构的优势。一个有趣的解释来自Ilya Sutskever在Jensen Huang主持的访谈中。访谈的原始记录抄录如下："}]},{"ID":"20250922205316-xzalden","Type":"NodeBlockquote","Properties":{"id":"20250922205316-xzalden","updated":"20250922205316"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922205316-omtrqp4","Type":"NodeParagraph","Properties":{"id":"20250922205316-omtrqp4","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"假设你读一本侦探小说。情节复杂，故事情节曲折，人物众多，事件纷繁，线索神秘，一切都扑朔迷离。然后，假设在书的最后一页，侦探召集了所有人说：“好了，我要揭露罪犯的身份，那个人的名字是”。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预测那个词。"}]},{"ID":"20250922205316-3fxfovr","Type":"NodeParagraph","Properties":{"id":"20250922205316-3fxfovr","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"..."}]},{"ID":"20250922205316-x7kgymq","Type":"NodeParagraph","Properties":{"id":"20250922205316-x7kgymq","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"现在，可能会有很多不同的词。但是，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"要更好地预测那些词，对文本的理解就必须不断加深"},{"Type":"NodeText","Data":"。GPT-4能更好地预测下一个词。"}]}]},{"ID":"20250922205316-n9ie8nf","Type":"NodeParagraph","Properties":{"id":"20250922205316-n9ie8nf","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"a. https://www.nvidia.com/en-us/on-demand/session/gtcspring23-S52092/\nb. https://lifearchitect.ai/ilya/"}]}]},{"ID":"20250922205316-6048u3s","Type":"NodeParagraph","Properties":{"id":"20250922205316-6048u3s","updated":"20250922205320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Architecture Choice (架构选择)."},{"Type":"NodeText","Data":" 在早期的预训练语言模型文献中，有很多关于不同架构效果的讨论。然而，大多数LLM都是基于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"因果解码器"},{"Type":"NodeText","Data":"架构开发的，并且仍然缺乏对其相对于其他替代方案优势的理论分析。接下来，我们简要总结关于这个问题的现有讨论。"}]},{"ID":"20250922205316-ow8kkb6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205316-ow8kkb6","updated":"20250922205320"},"Children":[{"ID":"20250922205315-a4ohhi1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-a4ohhi1","updated":"20250922205315"},"Children":[{"ID":"20250922205316-qt33acy","Type":"NodeParagraph","Properties":{"id":"20250922205316-qt33acy","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"通过使用LM目标进行预训练，因果解码器架构似乎可以获得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优越的零样本和少样本泛化能力"},{"Type":"NodeText","Data":"。现有的研究表明，在没有多任务微调的情况下，因果解码器比其他架构具有更好的零样本性能。GPT-3的成功已经证明，大型因果解码器模型可以成为一个很好的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本学习者"},{"Type":"NodeText","Data":"。此外，第5节中讨论的指令微调和对齐微调已被证明能进一步增强大型因果解码器模型的能力。"}]}]},{"ID":"20250922205315-otbi8b8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-otbi8b8","updated":"20250922205315"},"Children":[{"ID":"20250922205316-y4vujdp","Type":"NodeParagraph","Properties":{"id":"20250922205316-y4vujdp","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"在因果解码器中被广泛观察到。通过扩展模型大小、数据集大小和总计算量，因果解码器的性能可以得到显著提升。因此，通过扩展来增加因果解码器的模型能力已成为一个重要的策略。然而，对编码器-解码器模型的更详细调查仍然缺乏，需要更多努力来研究大规模编码器-解码器模型的性能。"}]}]}]},{"ID":"20250922205316-kqf7uou","Type":"NodeParagraph","Properties":{"id":"20250922205316-kqf7uou","updated":"20250922205320"},"Children":[{"Type":"NodeText","Data":"关于架构和预训练目标的讨论需要更多的研究工作，以分析架构和预训练任务的选择如何影响LLM的能力，特别是对于编码器-解码器架构。尽管仅解码器架构行之有效，但也建议在架构设计上进行更多样化的探索。除了主要的架构，LLM的详细配置也值得关注，这已在4.2.2节中讨论。"}]},{"ID":"20250922205316-89av3m3","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205316-89av3m3","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.3 Model Training (模型训练)"}]},{"ID":"20250922205316-pkhd37m","Type":"NodeParagraph","Properties":{"id":"20250922205316-pkhd37m","updated":"20250922205320"},"Children":[{"Type":"NodeText","Data":"在本部分中，我们回顾训练LLM的重要设置、技术或技巧。"}]},{"ID":"20250922205316-09xvw2c","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922205316-09xvw2c","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.3.1 Optimization Setting (优化设置)"}]},{"ID":"20250922205316-tmy84y6","Type":"NodeParagraph","Properties":{"id":"20250922205316-tmy84y6","updated":"20250922205320"},"Children":[{"Type":"NodeText","Data":"对于LLM的参数优化，我们介绍批量训练、学习率、优化器和训练稳定性的常用设置。"}]},{"ID":"20250922205316-mmgphft","Type":"NodeParagraph","Properties":{"id":"20250922205316-mmgphft","updated":"20250922205320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Batch Training (批量训练)."},{"Type":"NodeText","Data":" 对于语言模型预训练，现有的工作通常将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"批量大小"},{"Type":"NodeText","Data":"设置为一个较大的数值（例如，2,048个样本或400万个词元）以提高训练的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳定性和吞吐量"},{"Type":"NodeText","Data":"。对于像GPT-3和PaLM这样的LLM，他们引入了一种在训练期间"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动态增加批量大小"},{"Type":"NodeText","Data":"的新策略，最终达到百万级别。具体来说，GPT-3的批量大小从3.2万词元逐渐增加到320万词元。实证结果证明，动态的批量大小调度可以有效地稳定LLM的训练过程。"}]},{"ID":"20250922205316-8veyny9","Type":"NodeParagraph","Properties":{"id":"20250922205316-8veyny9","updated":"20250922205320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Learning Rate (学习率)."},{"Type":"NodeText","Data":" 现有的LLM通常在预训练期间采用类似的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"带有预热和衰减策略"},{"Type":"NodeText","Data":"的学习率调度。具体来说，在训练步骤的初始0.1%到0.5%，采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"线性预热"},{"Type":"NodeText","Data":"调度来逐渐增加学习率，直到达到大约在5 × 10⁻⁵到1 × 10⁻⁴范围内的最大值（例如，GPT-3为6 × 10⁻⁵）。然后，在后续步骤中采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"余弦衰减"},{"Type":"NodeText","Data":"策略，逐渐将学习率降低到其最大值的大约10%，直到训练损失收敛。"}]},{"ID":"20250922205316-hepenz0","Type":"NodeParagraph","Properties":{"id":"20250922205316-hepenz0","updated":"20250922205320"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Optimizer (优化器)."},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Adam"},{"Type":"NodeText","Data":"优化器和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AdamW"},{"Type":"NodeText","Data":"优化器被广泛用于训练LLM（例如，GPT-3），它们基于对低阶矩的自适应估计。"}]},{"ID":"20250922205316-gwlx71t","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1,1,1,1],"Properties":{"colgroup":"|||||||||","id":"20250922205316-gwlx71t","updated":"20250922205320"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Model"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Batch Size (#tokens)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Learning Rate"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Warmup"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Decay Method"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Optimizer"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Precision Type"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Weight Decay"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Grad Clip"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dropout"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT3 (175B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32K→3.2M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6 × 10⁻⁵"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"cosine decay to 10%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Adam"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"FP16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PanGu-α (200B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2 × 10⁻⁵"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Adam"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"OPT (175B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.2 × 10⁻⁴"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"manual decay"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AdamW"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"FP16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PaLM (540B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1M→4M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1 × 10⁻²"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"no"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"inverse square root"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Adafactor"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BF16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"lr²"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BLOOM (176B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6 × 10⁻⁵"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"cosine decay to 10%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Adam"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BF16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.0"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MT-NLG (530B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64 K→3.75M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5 × 10⁻⁵"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"cosine decay to 10%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Adam"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BF16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Gopher (280B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3M→6M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4 × 10⁻⁵"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"cosine decay to 10%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Adam"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BF16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Chinchilla (70B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.5M→3M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1 × 10⁻⁴"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"cosine decay to 10%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AdamW"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BF16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Galactica (120B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7 × 10⁻⁶"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"linear decay to 10%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AdamW"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LaMDA (137B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"256K"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BF16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Jurassic-1 (178B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32 K→3.2M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6 × 10⁻⁵"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LLaMA (65B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.5 × 10⁻⁴"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"cosine decay to 10%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AdamW"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LLaMA 2 (70B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.5 × 10⁻⁴"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"cosine decay to 10%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AdamW"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Falcon (40B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.85 × 10⁻⁴"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"cosine decay to 10%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AdamW"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BF16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GLM (130B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.4M→8.25M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8 × 10⁻⁵"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"cosine decay to 10%"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AdamW"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"FP16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T5 (11B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64K"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1 × 10⁻²"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"no"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"inverse square root"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AdaFactor"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ERNIE 3.0 Titan (260B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1 × 10⁻⁴"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Adam"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"FP16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.0"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PanGu-Σ (1.085T)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.5M"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2 × 10⁻⁵"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"yes"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Adam"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"FP16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"-"}]}]}]},{"ID":"20250922205316-zm1kaqk","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205316-zm1kaqk","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 8：几个现有LLM的详细优化设置"}]},{"ID":"20250922205316-p8les2y","Type":"NodeBlockquote","Properties":{"id":"20250922205316-p8les2y","updated":"20250922205320"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922205316-a84ymme","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205316-a84ymme","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922205316-i3hwvuk","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205316-i3hwvuk","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表8解析：LLM训练的“秘方”"}]},{"ID":"20250922205316-ndz0nlc","Type":"NodeParagraph","Properties":{"id":"20250922205316-ndz0nlc","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"这张表格详细列出了多个著名LLM在训练时使用的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化器超参数"},{"Type":"NodeText","Data":"，这些是确保模型能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳定、高效"},{"Type":"NodeText","Data":"地从海量数据中学习的关键“秘方”。"}]},{"ID":"20250922205316-ieyxtat","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205316-ieyxtat","updated":"20250922205316"},"Children":[{"ID":"20250922205315-lfvlumx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-lfvlumx","updated":"20250922205315"},"Children":[{"ID":"20250922205316-y0bljfl","Type":"NodeParagraph","Properties":{"id":"20250922205316-y0bljfl","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"共性/主流“配方”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205316-5md6qgv","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205316-5md6qgv","updated":"20250922205316"},"Children":[{"ID":"20250922205315-jbwdw6w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-jbwdw6w","updated":"20250922205315"},"Children":[{"ID":"20250922205316-mmi0bu3","Type":"NodeParagraph","Properties":{"id":"20250922205316-mmi0bu3","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"批量大小 (Batch Size)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"巨大且动态增长"},{"Type":"NodeText","Data":"。大多数模型的批量大小都达到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"百万级词元"},{"Type":"NodeText","Data":"，并且普遍采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动态增加"},{"Type":"NodeText","Data":"的策略（如GPT3, PaLM, Gopher）。这有助于在训练初期稳定起步，在后期提高训练吞吐量。"}]}]},{"ID":"20250922205315-wzvnlvd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-wzvnlvd","updated":"20250922205315"},"Children":[{"ID":"20250922205316-wlm31w2","Type":"NodeParagraph","Properties":{"id":"20250922205316-wlm31w2","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习率调度 (Learning Rate \u0026amp; Warmup \u0026amp; Decay)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“预热+余弦衰减”"},{"Type":"NodeText","Data":"是绝对的主流范式。"}]},{"ID":"20250922205316-n3cma9a","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205316-n3cma9a","updated":"20250922205316"},"Children":[{"ID":"20250922205315-p6gta69","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-p6gta69","updated":"20250922205315"},"Children":[{"ID":"20250922205316-ys6jju2","Type":"NodeParagraph","Properties":{"id":"20250922205316-ys6jju2","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预热 (Warmup)"},{"Type":"NodeText","Data":": 在训练开始时，使用一个很小的学习率，然后"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"线性增加"},{"Type":"NodeText","Data":"到一个峰值。这可以防止模型在训练初期因梯度过大而“跑飞”。"}]}]},{"ID":"20250922205315-dkx9iyh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-dkx9iyh","updated":"20250922205315"},"Children":[{"ID":"20250922205316-7cg6c6t","Type":"NodeParagraph","Properties":{"id":"20250922205316-7cg6c6t","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"余弦衰减 (Cosine Decay)"},{"Type":"NodeText","Data":": 在达到峰值后，学习率按照余弦曲线"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平滑地下降"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922205315-gkahx2h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-gkahx2h","updated":"20250922205315"},"Children":[{"ID":"20250922205316-359ss0r","Type":"NodeParagraph","Properties":{"id":"20250922205316-359ss0r","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化器 (Optimizer)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Adam"},{"Type":"NodeText","Data":"及其改进版"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AdamW"},{"Type":"NodeText","Data":"是绝大多数模型的选择。它们是自适应学习率的优化器，非常适合处理LLM这样复杂的优化问题。"}]}]},{"ID":"20250922205315-rcplejq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-rcplejq","updated":"20250922205315"},"Children":[{"ID":"20250922205316-rmicdmp","Type":"NodeParagraph","Properties":{"id":"20250922205316-rmicdmp","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"梯度裁剪 (Grad Clip)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"几乎所有模型都将梯度裁剪值设置为1.0"},{"Type":"NodeText","Data":"。这是一个防止梯度爆炸的“保险丝”，是保证训练稳定的关键技巧。"}]}]},{"ID":"20250922205315-6qqiikg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-6qqiikg","updated":"20250922205315"},"Children":[{"ID":"20250922205316-6np9sy3","Type":"NodeParagraph","Properties":{"id":"20250922205316-6np9sy3","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"权重衰减 (Weight Decay)"},{"Type":"NodeText","Data":": 大多设置为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"0.1"},{"Type":"NodeText","Data":"，是一种常用的正则化手段，防止模型过拟合。"}]}]}]}]},{"ID":"20250922205315-cxagoh7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-cxagoh7","updated":"20250922205315"},"Children":[{"ID":"20250922205316-k46bxbg","Type":"NodeParagraph","Properties":{"id":"20250922205316-k46bxbg","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"个性化选择"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205316-e0vwvik","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205316-e0vwvik","updated":"20250922205316"},"Children":[{"ID":"20250922205315-z8ltts5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-z8ltts5","updated":"20250922205315"},"Children":[{"ID":"20250922205316-pxzex40","Type":"NodeParagraph","Properties":{"id":"20250922205316-pxzex40","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PaLM / T5"},{"Type":"NodeText","Data":": 这两个模型采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Adafactor"},{"Type":"NodeText","Data":"优化器和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逆平方根衰减"},{"Type":"NodeText","Data":"的学习率调度。Adafactor是一种内存效率更高的Adam变体，特别适合在TPU等硬件上进行大规模训练。"}]}]},{"ID":"20250922205315-4jf4lsn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-4jf4lsn","updated":"20250922205315"},"Children":[{"ID":"20250922205316-s5eh1j9","Type":"NodeParagraph","Properties":{"id":"20250922205316-s5eh1j9","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精度类型 (Precision Type)"},{"Type":"NodeText","Data":": 大多数模型采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FP16（半精度浮点数）"},{"Type":"NodeText","Data":"进行训练，以节省内存和加速计算。但更新的模型如PaLM和Falcon则采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BF16 (BFloat16)"},{"Type":"NodeText","Data":"，它在保持与FP16相似的内存占用的同时，具有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更大的动态范围"},{"Type":"NodeText","Data":"，能更好地处理训练中可能出现的梯度，从而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提升训练稳定性"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922205316-1rmoy4e","Type":"NodeParagraph","Properties":{"id":"20250922205316-1rmoy4e","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格揭示了，尽管LLM的架构各异，但它们的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练“配方”却高度趋同"},{"Type":"NodeText","Data":"。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“大批量 + 预热与余弦衰减 + AdamW优化器 + 梯度裁剪”"},{"Type":"NodeText","Data":"已成为一套经过实践检验的、稳定可靠的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SOTA训练范式"},{"Type":"NodeText","Data":"。而BF16的使用则代表了硬件和软件协同发展的最新趋势。"}]}]},{"ID":"20250922205316-0vfytwp","Type":"NodeThematicBreak","Properties":{"id":"20250922205316-0vfytwp","updated":"20250922205320"}},{"ID":"20250922205316-tpmsu6v","Type":"NodeBlockquote","Properties":{"id":"20250922205316-tpmsu6v","updated":"20250922205320"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922205316-qesnrzq","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205316-qesnrzq","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922205316-nilek62","Type":"NodeParagraph","Properties":{"id":"20250922205316-nilek62","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"第二十三部分深入探讨了LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练的实践层面"},{"Type":"NodeText","Data":"，从宏观的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"架构选择哲学"},{"Type":"NodeText","Data":"到微观的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化器参数设置"},{"Type":"NodeText","Data":"，为我们揭示了理论与实践如何相互作用，共同塑造了现代LLM。"}]},{"ID":"20250922205316-oaxa1dz","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922205316-oaxa1dz","updated":"20250922205316"},"Children":[{"ID":"20250922205315-mvdlfpb","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922205315-mvdlfpb","updated":"20250922205315"},"Children":[{"ID":"20250922205316-fjas5go","Type":"NodeParagraph","Properties":{"id":"20250922205316-fjas5go","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“预测下一个词”的深刻内涵"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205316-q69g5vz","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205316-q69g5vz","updated":"20250922205316"},"Children":[{"ID":"20250922205315-7opret1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-7opret1","updated":"20250922205315"},"Children":[{"ID":"20250922205316-pax8xgl","Type":"NodeParagraph","Properties":{"id":"20250922205316-pax8xgl","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"Ilya Sutskever关于侦探小说的比喻，是对“为什么简单的‘预测下一个词’任务如此强大”这一核心问题的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个深刻而直观的回答"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205315-rp5ykiy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-rp5ykiy","updated":"20250922205315"},"Children":[{"ID":"20250922205316-z083zpm","Type":"NodeParagraph","Properties":{"id":"20250922205316-z083zpm","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"它揭示了，为了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更准确地"},{"Type":"NodeText","Data":"预测那个关键的词，模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"被迫"},{"Type":"NodeText","Data":"去理解整个故事的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文、人物关系、逻辑链条和因果关系"},{"Type":"NodeText","Data":"。预测本身不是目的，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为了预测而进行的深度理解"},{"Type":"NodeText","Data":"才是模型智能涌现的根源。"}]}]},{"ID":"20250922205315-0ufwc5x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-0ufwc5x","updated":"20250922205315"},"Children":[{"ID":"20250922205316-8llwgtf","Type":"NodeParagraph","Properties":{"id":"20250922205316-8llwgtf","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"这为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"因果解码器架构"},{"Type":"NodeText","Data":"的主导地位提供了强有力的哲学支撑。"}]}]}]}]},{"ID":"20250922205315-yisgc9o","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922205315-yisgc9o","updated":"20250922205315"},"Children":[{"ID":"20250922205316-xdibsso","Type":"NodeParagraph","Properties":{"id":"20250922205316-xdibsso","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"架构选择的“路径依赖”与未来探索"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205316-9mjvcow","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205316-9mjvcow","updated":"20250922205316"},"Children":[{"ID":"20250922205315-vrr45yw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-vrr45yw","updated":"20250922205315"},"Children":[{"ID":"20250922205316-vg5j4hb","Type":"NodeParagraph","Properties":{"id":"20250922205316-vg5j4hb","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"文章指出现有LLM大多基于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"因果解码器"},{"Type":"NodeText","Data":"，这既是其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成功（擅长少样本学习）"},{"Type":"NodeText","Data":"的体现，也可能是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“路径依赖”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205315-934f4ko","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-934f4ko","updated":"20250922205315"},"Children":[{"ID":"20250922205316-vacqie2","Type":"NodeParagraph","Properties":{"id":"20250922205316-vacqie2","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"作者呼吁对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器-解码器"},{"Type":"NodeText","Data":"等其他架构在大规模下的潜力进行更多探索，这体现了科学的审慎和对未来多样化可能性的开放态度。"}]}]}]}]},{"ID":"20250922205315-bzq3dh8","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922205315-bzq3dh8","updated":"20250922205315"},"Children":[{"ID":"20250922205316-smh2gyj","Type":"NodeParagraph","Properties":{"id":"20250922205316-smh2gyj","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练优化的“SOTA秘方”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205316-wv23unq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205316-wv23unq","updated":"20250922205316"},"Children":[{"ID":"20250922205315-k104wt6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-k104wt6","updated":"20250922205315"},"Children":[{"ID":"20250922205316-3isbp1q","Type":"NodeParagraph","Properties":{"id":"20250922205316-3isbp1q","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"“模型训练”这一节，特别是表8，为我们提供了一份极其宝贵的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“LLM训练参数速查手册”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205315-5rw741r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-5rw741r","updated":"20250922205315"},"Children":[{"ID":"20250922205316-i9dirn3","Type":"NodeParagraph","Properties":{"id":"20250922205316-i9dirn3","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动态大批量 (Dynamic Large Batch Size)"},{"Type":"NodeText","Data":": 这是为了在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳定性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"效率"},{"Type":"NodeText","Data":"之间取得平衡。"}]}]},{"ID":"20250922205315-4s65jt7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-4s65jt7","updated":"20250922205315"},"Children":[{"ID":"20250922205316-gtpcy7m","Type":"NodeParagraph","Properties":{"id":"20250922205316-gtpcy7m","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习率预热与衰减 (Warmup \u0026amp; Decay)"},{"Type":"NodeText","Data":": 这是控制优化过程的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“油门”和“刹车”"},{"Type":"NodeText","Data":"，确保训练过程平稳可控。"}]}]},{"ID":"20250922205315-7h3ymay","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-7h3ymay","updated":"20250922205315"},"Children":[{"ID":"20250922205316-5jqopyv","Type":"NodeParagraph","Properties":{"id":"20250922205316-5jqopyv","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AdamW优化器与梯度裁剪"},{"Type":"NodeText","Data":": 这已成为保证训练"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"收敛"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳定"},{"Type":"NodeText","Data":"的“黄金组合”。"}]}]},{"ID":"20250922205315-8yvr8bp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205315-8yvr8bp","updated":"20250922205315"},"Children":[{"ID":"20250922205316-6wd98bc","Type":"NodeParagraph","Properties":{"id":"20250922205316-6wd98bc","updated":"20250922205316"},"Children":[{"Type":"NodeText","Data":"这些看似繁杂的参数设置，共同构成了一套经过无数次实验验证的、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学的训练方法论"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922205316-9nhuq5a","Type":"NodeParagraph","Properties":{"id":"20250922205316-9nhuq5a","updated":"20250922205316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第二十三部分将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论思考"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工程实践"},{"Type":"NodeText","Data":"紧密地结合在一起。它用一个生动的比喻解释了LLM智能的来源，系统地总结了当前训练LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“最佳实践（Best Practices）”"},{"Type":"NodeText","Data":"。它告诉我们，训练一个成功的LLM，既需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深刻的理论洞见"},{"Type":"NodeText","Data":"（理解为什么预测下一个词有效），也需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精细的工程调优"},{"Type":"NodeText","Data":"（如何设置批量大小、学习率等）。这就像驾驶一辆高性能赛车，你既要懂空气动力学，也要会精确地踩油门和刹车。"}]}]},{"ID":"20250922205453-xo3nt53","Type":"NodeParagraph","Properties":{"id":"20250922205453-xo3nt53","updated":"20250922205453"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922205453-wmlod9q","Type":"NodeThematicBreak","Properties":{"id":"20250922205453-wmlod9q","updated":"20250922205453"}},{"ID":"20250922205453-q16bg7j","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205453-q16bg7j","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二十四部分"}]},{"ID":"20250922205453-jbjcvfk","Type":"NodeParagraph","Properties":{"id":"20250922205453-jbjcvfk","updated":"20250922205455"},"Children":[{"Type":"NodeText","Data":"通常，其超参数设置如下："},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"β₁"},{"Type":"NodeText","Data":" = 0.9, "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"β₂"},{"Type":"NodeText","Data":" = 0.95 且 "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"ϵ"},{"Type":"NodeText","Data":" = 10⁻⁸。与此同时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Adafactor"},{"Type":"NodeText","Data":"优化器也已被用于训练LLM（例如，PaLM和T5），它是Adam优化器的一个变体，专门设计用于在训练期间节省GPU内存。Adafactor优化器的超参数设置为："},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"β₁"},{"Type":"NodeText","Data":" = 0.9 且 "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"β₂"},{"Type":"NodeText","Data":" = 1.0 - "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"k"},{"Type":"NodeText","Data":"⁻⁰·⁸，其中"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"k"},{"Type":"NodeText","Data":"表示训练步数。"}]},{"ID":"20250922205453-g8bvo1w","Type":"NodeParagraph","Properties":{"id":"20250922205453-g8bvo1w","updated":"20250922205455"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Stabilizing the Training (稳定训练)."},{"Type":"NodeText","Data":" 在LLM的预训练期间，它经常遭受"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练不稳定性"},{"Type":"NodeText","Data":"问题，这可能导致模型崩溃。为了解决这个问题，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"权重衰减"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"梯度裁剪"},{"Type":"NodeText","Data":"已被广泛使用，其中现有的研究通常将梯度裁剪的阈值设置为1.0，权重衰减率设置为0.1。然而，随着LLM的扩展，训练损失"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"尖峰（spike）"},{"Type":"NodeText","Data":"也更有可能发生，导致训练不稳定。为了缓解这个问题，PaLM和OPT使用一种简单的策略，即从尖峰出现前的早期检查点"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重新启动"},{"Type":"NodeText","Data":"训练过程，并"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"跳过"},{"Type":"NodeText","Data":"可能导致问题的数据。此外，GLM发现嵌入层的异常梯度通常会导致尖峰，并提议"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"收缩嵌入层梯度"},{"Type":"NodeText","Data":"以缓解此问题。"}]},{"ID":"20250922205453-qyq0j70","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922205453-qyq0j70","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4.3.2 Scalable Training Techniques (可扩展训练技术)"}]},{"ID":"20250922205453-8y6fzdx","Type":"NodeParagraph","Properties":{"id":"20250922205453-8y6fzdx","updated":"20250922205455"},"Children":[{"Type":"NodeText","Data":"随着模型和数据规模的增加，在有限的计算资源下高效地训练LLM已成为一个挑战。特别地，需要解决两个主要的技术问题，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提高训练吞吐量"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将更大的模型加载到GPU内存中"},{"Type":"NodeText","Data":"。在本部分中，我们回顾了现有工作中几种广泛用于解决上述挑战的方法，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3D并行"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合精度训练"},{"Type":"NodeText","Data":"，并就如何利用它们进行训练给出一般性建议。"}]},{"ID":"20250922205453-g26jh5i","Type":"NodeParagraph","Properties":{"id":"20250922205453-g26jh5i","updated":"20250922205455"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3D Parallelism (3D并行)."},{"Type":"NodeText","Data":" 3D并行实际上是三种常用并行训练技术的组合，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据并行、流水线并行和张量并行"},{"Type":"NodeText","Data":"。接下来我们介绍这三种并行训练技术。"}]},{"ID":"20250922205453-4m9m2s3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205453-4m9m2s3","updated":"20250922205455"},"Children":[{"ID":"20250922205453-4ynrdpk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-4ynrdpk","updated":"20250922205453"},"Children":[{"ID":"20250922205453-k946guu","Type":"NodeParagraph","Properties":{"id":"20250922205453-k946guu","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据并行 (Data parallelism)."},{"Type":"NodeText","Data":" 数据并行是提高训练吞吐量最基本的方法之一。它在多个GPU上"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复制模型参数和优化器状态"},{"Type":"NodeText","Data":"，然后将整个训练语料库"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分配"},{"Type":"NodeText","Data":"到这些GPU上。通过这种方式，每个GPU只需要处理分配给它的数据，并执行前向和后向传播以获得梯度。不同GPU上计算出的梯度将进一步"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"聚合"},{"Type":"NodeText","Data":"，以获得整个批次的梯度，用于更新所有GPU上的模型。通过这种方式，由于梯度的计算在不同GPU上是独立执行的，数据并行机制具有高度的可扩展性，使得增加GPU数量可以提高训练吞-量。此外，该技术实现简单，大多数现有的流行深度学习库（如TensorFlow和PyTorch）已经实现了数据并行。"}]}]},{"ID":"20250922205453-9xhuy4a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-9xhuy4a","updated":"20250922205453"},"Children":[{"ID":"20250922205453-uagbsja","Type":"NodeParagraph","Properties":{"id":"20250922205453-uagbsja","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"流水线并行 (Pipeline parallelism)."},{"Type":"NodeText","Data":" 流水线并行旨在将LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同层"},{"Type":"NodeText","Data":"分配到多个GPU上。特别是在Transformer模型的情况下，流水线并行将连续的层加载到同一个GPU上，以减少在GPU之间传输计算出的隐藏状态或梯度的成本。然而，流水线并行的简单实现可能会导致GPU利用率较低，因为每个GPU都必须等待前一个GPU完成计算，从而导致不必要的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“气泡”开销"},{"Type":"NodeText","Data":"。为了减少流水线并行中的这些气泡，GPipe和PipeDream提出了填充多个数据批次和异步梯度更新的技术，以提高流水线效率。"}]}]},{"ID":"20250922205453-x725pha","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-x725pha","updated":"20250922205453"},"Children":[{"ID":"20250922205453-tkrsbo2","Type":"NodeParagraph","Properties":{"id":"20250922205453-tkrsbo2","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"张量并行 (Tensor parallelism)."},{"Type":"NodeText","Data":" 张量并行也是一种常用的技术，旨在为多GPU加载"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分解LLM"},{"Type":"NodeText","Data":"。与流水线并行不同，张量并行专注于分解LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"张量（参数矩阵）"},{"Type":"NodeText","Data":"。对于LLM中的矩阵乘法运算Y = XA，参数矩阵A可以"}]}]}]},{"ID":"20250922205453-h3rv78k","Type":"NodeBlockquote","Properties":{"id":"20250922205453-h3rv78k","updated":"20250922205455"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922205453-py0fegu","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205453-py0fegu","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922205453-q23cr8z","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205453-q23cr8z","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型训练：在“不稳定的边缘”稳定前行"}]},{"ID":"20250922205453-0e9gjjj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205453-0e9gjjj","updated":"20250922205453"},"Children":[{"ID":"20250922205453-p33zavq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-p33zavq","updated":"20250922205453"},"Children":[{"ID":"20250922205453-sqz41v5","Type":"NodeParagraph","Properties":{"id":"20250922205453-sqz41v5","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心挑战"},{"Type":"NodeText","Data":": 训练LLM就像在走钢丝，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳定性"},{"Type":"NodeText","Data":"是头等大事。由于模型巨大、数据海量，训练过程极易出现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"损失尖峰（loss spike）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型崩溃（collapse）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205453-4x8brjw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-4x8brjw","updated":"20250922205453"},"Children":[{"ID":"20250922205453-xilnoy3","Type":"NodeParagraph","Properties":{"id":"20250922205453-xilnoy3","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常规“保险丝”"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"权重衰减（Weight Decay）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"梯度裁剪（Gradient Clipping）"},{"Type":"NodeText","Data":"是防止模型跑飞的标准操作。"}]}]},{"ID":"20250922205453-fc1awc8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-fc1awc8","updated":"20250922205453"},"Children":[{"ID":"20250922205453-8ac176b","Type":"NodeParagraph","Properties":{"id":"20250922205453-8ac176b","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“重启大法”"},{"Type":"NodeText","Data":": 面对无法避免的损失尖峰，PaLM和OPT采用了一种简单粗暴但有效的策略："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"读档重来"},{"Type":"NodeText","Data":"。从出问题前的最后一个存档点（checkpoint）重新开始训练，并"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"跳过那批可能引发问题的数据"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205453-l24ttn2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-l24ttn2","updated":"20250922205453"},"Children":[{"ID":"20250922205453-7809oll","Type":"NodeParagraph","Properties":{"id":"20250922205453-7809oll","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“精准打击”"},{"Type":"NodeText","Data":": GLM的发现更进一步，它定位到问题的根源往往在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"嵌入层（Embedding Layer）的梯度异常"},{"Type":"NodeText","Data":"，并提出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精准地缩小这部分梯度"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922205453-ts8xmeq","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205453-ts8xmeq","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可扩展训练：“三个臭皮匠”的3D并行"}]},{"ID":"20250922205453-azn79g7","Type":"NodeParagraph","Properties":{"id":"20250922205453-azn79g7","updated":"20250922205453"},"Children":[{"Type":"NodeText","Data":"当单个GPU无法容纳巨大的LLM时，必须将其“肢解”并分散到整个GPU集群上协同训练。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3D并行"},{"Type":"NodeText","Data":"就是实现这一目标的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心技术体系"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922205453-kjbb5jp","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922205453-kjbb5jp","updated":"20250922205453"},"Children":[{"ID":"20250922205453-5ooww1m","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922205453-5ooww1m","updated":"20250922205453"},"Children":[{"ID":"20250922205453-7aakmwp","Type":"NodeParagraph","Properties":{"id":"20250922205453-7aakmwp","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据并行 (Data Parallelism)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205453-y5qv2bw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205453-y5qv2bw","updated":"20250922205453"},"Children":[{"ID":"20250922205453-hb1cxm8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-hb1cxm8","updated":"20250922205453"},"Children":[{"ID":"20250922205453-7i9escy","Type":"NodeParagraph","Properties":{"id":"20250922205453-7i9escy","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“人手一份，分头干活”"},{"Type":"NodeText","Data":"。每个GPU都拥有一份"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完整的模型副本"},{"Type":"NodeText","Data":"，但只处理一小部分数据。计算完梯度后，大家再"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"汇总"},{"Type":"NodeText","Data":"一下结果（AllReduce），一起更新模型。"}]}]},{"ID":"20250922205453-7kiub6p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-7kiub6p","updated":"20250922205453"},"Children":[{"ID":"20250922205453-ytrfwjc","Type":"NodeParagraph","Properties":{"id":"20250922205453-ytrfwjc","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实现简单，易于扩展"},{"Type":"NodeText","Data":"，能有效提升训练"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"吞吐量"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205453-pyyp06m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-pyyp06m","updated":"20250922205453"},"Children":[{"ID":"20250922205453-t14jp7n","Type":"NodeParagraph","Properties":{"id":"20250922205453-t14jp7n","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内存冗余"},{"Type":"NodeText","Data":"。每个GPU都存一份完整的模型，对于超大模型来说，内存开销巨大。"}]}]}]}]},{"ID":"20250922205453-sk20wt1","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922205453-sk20wt1","updated":"20250922205453"},"Children":[{"ID":"20250922205453-9tymoye","Type":"NodeParagraph","Properties":{"id":"20250922205453-9tymoye","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"流水线并行 (Pipeline Parallelism)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205453-vlumr6i","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205453-vlumr6i","updated":"20250922205453"},"Children":[{"ID":"20250922205453-09c3g10","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-09c3g10","updated":"20250922205453"},"Children":[{"ID":"20250922205453-g7k8spb","Type":"NodeParagraph","Properties":{"id":"20250922205453-g7k8spb","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“流水线作业”"},{"Type":"NodeText","Data":"。将模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同层（Layers）"},{"Type":"NodeText","Data":"切分到不同的GPU上。GPU 1负责1-10层，GPU 2负责11-20层，以此类推，数据像在流水线上一样依次流过。"}]}]},{"ID":"20250922205453-2yup7dz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-2yup7dz","updated":"20250922205453"},"Children":[{"ID":"20250922205453-8w2ndwy","Type":"NodeParagraph","Properties":{"id":"20250922205453-8w2ndwy","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":": 能训练"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"层数非常深"},{"Type":"NodeText","Data":"的模型。"}]}]},{"ID":"20250922205453-7ai2q38","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-7ai2q38","updated":"20250922205453"},"Children":[{"ID":"20250922205453-j4ditth","Type":"NodeParagraph","Properties":{"id":"20250922205453-j4ditth","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“气泡”（Bubbles）问题"},{"Type":"NodeText","Data":"。在流水线的开始和结束阶段，总有GPU在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"空闲等待"},{"Type":"NodeText","Data":"，导致计算资源浪费。GPipe等技术通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微批次（micro-batching）"},{"Type":"NodeText","Data":"来试图填满这些气泡。"}]}]}]}]},{"ID":"20250922205453-2b14c41","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922205453-2b14c41","updated":"20250922205453"},"Children":[{"ID":"20250922205453-ts5pvjq","Type":"NodeParagraph","Properties":{"id":"20250922205453-ts5pvjq","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"张量并行 (Tensor Parallelism)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205453-16vz5fr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205453-16vz5fr","updated":"20250922205453"},"Children":[{"ID":"20250922205453-5aok72w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-5aok72w","updated":"20250922205453"},"Children":[{"ID":"20250922205453-2j8hjwb","Type":"NodeParagraph","Properties":{"id":"20250922205453-2j8hjwb","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“把大卸八块”"},{"Type":"NodeText","Data":"。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最彻底的并行"},{"Type":"NodeText","Data":"。它将模型内部的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单个大矩阵（Tensor）"},{"Type":"NodeText","Data":"进行切分，分配到不同GPU上进行并行计算，然后再合并结果。"}]}]},{"ID":"20250922205453-vkp20pw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-vkp20pw","updated":"20250922205453"},"Children":[{"ID":"20250922205453-dtv7495","Type":"NodeParagraph","Properties":{"id":"20250922205453-dtv7495","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":": 能训练"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单个层本身就巨大无比"},{"Type":"NodeText","Data":"的模型，是训练万亿参数模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"必备技术"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205453-o189jzz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-o189jzz","updated":"20250922205453"},"Children":[{"ID":"20250922205453-tmife9y","Type":"NodeParagraph","Properties":{"id":"20250922205453-tmife9y","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通信开销巨大"},{"Type":"NodeText","Data":"，对GPU之间的高速互联（如NVLink）要求极高。Megatron-LM是该技术的开创者和代表。"}]}]}]}]}]},{"ID":"20250922205453-415273z","Type":"NodeParagraph","Properties":{"id":"20250922205453-415273z","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3D并行的本质"},{"Type":"NodeText","Data":": 实践中，这三种并行方式通常"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"组合使用"},{"Type":"NodeText","Data":"，以发挥各自的优势，共同应对训练超大规模模型的挑战。"}]}]},{"ID":"20250922205453-9ydaa73","Type":"NodeThematicBreak","Properties":{"id":"20250922205453-9ydaa73","updated":"20250922205455"}},{"ID":"20250922205453-zias673","Type":"NodeBlockquote","Properties":{"id":"20250922205453-zias673","updated":"20250922205455"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922205453-dut0ptl","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205453-dut0ptl","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922205453-b43qsp8","Type":"NodeParagraph","Properties":{"id":"20250922205453-b43qsp8","updated":"20250922205453"},"Children":[{"Type":"NodeText","Data":"第二十四部分深入探讨了大规模语言模型训练中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大核心工程挑战"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练稳定性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可扩展性"},{"Type":"NodeText","Data":"，并系统地介绍了应对这些挑战的主流技术。"}]},{"ID":"20250922205453-eprml9c","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922205453-eprml9c","updated":"20250922205453"},"Children":[{"ID":"20250922205453-3a216xk","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922205453-3a216xk","updated":"20250922205453"},"Children":[{"ID":"20250922205453-tnoesd0","Type":"NodeParagraph","Properties":{"id":"20250922205453-tnoesd0","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳定是压倒一切的前提"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205453-3hvts8n","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205453-3hvts8n","updated":"20250922205453"},"Children":[{"ID":"20250922205453-lz24rdr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-lz24rdr","updated":"20250922205453"},"Children":[{"ID":"20250922205453-cw18i2l","Type":"NodeParagraph","Properties":{"id":"20250922205453-cw18i2l","updated":"20250922205453"},"Children":[{"Type":"NodeText","Data":"文章通过对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"损失尖峰"},{"Type":"NodeText","Data":"等不稳定现象的讨论，强调了在LLM训练这个“极限运动”中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“不出事”比“跑得快”更重要"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205453-od5gto7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-od5gto7","updated":"20250922205453"},"Children":[{"ID":"20250922205453-n28oksw","Type":"NodeParagraph","Properties":{"id":"20250922205453-n28oksw","updated":"20250922205453"},"Children":[{"Type":"NodeText","Data":"从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用防御（权重衰减、梯度裁剪）"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"紧急预案（重启大法）"},{"Type":"NodeText","Data":"，再到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精准定位（嵌入层梯度收缩）"},{"Type":"NodeText","Data":"，我们看到了一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"层次化、多维度的稳定性保障体系"},{"Type":"NodeText","Data":"。这反映了LLM训练工程的高度成熟。"}]}]}]}]},{"ID":"20250922205453-2q97j5m","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922205453-2q97j5m","updated":"20250922205453"},"Children":[{"ID":"20250922205453-rtkhwts","Type":"NodeParagraph","Properties":{"id":"20250922205453-rtkhwts","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3D并行：驯服“巨兽”的缰绳"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205453-bknyws5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205453-bknyws5","updated":"20250922205453"},"Children":[{"ID":"20250922205453-wbeqm19","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-wbeqm19","updated":"20250922205453"},"Children":[{"ID":"20250922205453-ygzqytf","Type":"NodeParagraph","Properties":{"id":"20250922205453-ygzqytf","updated":"20250922205453"},"Children":[{"Type":"NodeText","Data":"3D并行（数据、流水线、张量）是解决"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模型太大，GPU装不下”"},{"Type":"NodeText","Data":"这一根本矛盾的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统性解决方案"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205453-csdguct","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-csdguct","updated":"20250922205453"},"Children":[{"ID":"20250922205453-d2edeet","Type":"NodeParagraph","Properties":{"id":"20250922205453-d2edeet","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据并行"},{"Type":"NodeText","Data":"解决了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据太多，训练太慢”"},{"Type":"NodeText","Data":"的问题，核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提升吞吐量"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205453-52tckaa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-52tckaa","updated":"20250922205453"},"Children":[{"ID":"20250922205453-duokf5v","Type":"NodeParagraph","Properties":{"id":"20250922205453-duokf5v","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"流水线并行"},{"Type":"NodeText","Data":"解决了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模型太深，单卡装不下”"},{"Type":"NodeText","Data":"的问题，核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"按层切分"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205453-kvb3oq8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-kvb3oq8","updated":"20250922205453"},"Children":[{"ID":"20250922205453-q1s4lgd","Type":"NodeParagraph","Properties":{"id":"20250922205453-q1s4lgd","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"张量并行"},{"Type":"NodeText","Data":"解决了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“单层太大，单卡装不下”"},{"Type":"NodeText","Data":"的问题，核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"按矩阵切分"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205453-2lhvec5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-2lhvec5","updated":"20250922205453"},"Children":[{"ID":"20250922205453-f3449un","Type":"NodeParagraph","Properties":{"id":"20250922205453-f3449un","updated":"20250922205453"},"Children":[{"Type":"NodeText","Data":"这三种并行策略各有侧重，互为补充。在训练SOTA级别的LLM时，往往需要将它们"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精巧地组合"},{"Type":"NodeText","Data":"起来，以在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计算、通信和内存"},{"Type":"NodeText","Data":"这三个维度上达到最佳平衡。这本身就是一门复杂的系统工程艺术。"}]}]}]}]},{"ID":"20250922205453-5lkgjum","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922205453-5lkgjum","updated":"20250922205453"},"Children":[{"ID":"20250922205453-58i0rv9","Type":"NodeParagraph","Properties":{"id":"20250922205453-58i0rv9","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从算法到系统的转变"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205453-kj9y4lg","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205453-kj9y4lg","updated":"20250922205453"},"Children":[{"ID":"20250922205453-umt464q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-umt464q","updated":"20250922205453"},"Children":[{"ID":"20250922205453-h68pnlk","Type":"NodeParagraph","Properties":{"id":"20250922205453-h68pnlk","updated":"20250922205453"},"Children":[{"Type":"NodeText","Data":"这一部分的内容充分体现了LLM研究已经从纯粹的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算法设计"},{"Type":"NodeText","Data":"，深入到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模分布式系统工程"},{"Type":"NodeText","Data":"的领域。"}]}]},{"ID":"20250922205453-dr8duq1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205453-dr8duq1","updated":"20250922205453"},"Children":[{"ID":"20250922205453-hygvkf8","Type":"NodeParagraph","Properties":{"id":"20250922205453-hygvkf8","updated":"20250922205453"},"Children":[{"Type":"NodeText","Data":"GPipe、Megatron-LM等技术的出现，标志着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统设计"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型算法"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度融合"},{"Type":"NodeText","Data":"。没有这些先进的并行训练框架，万亿参数模型的训练根本无从谈起。"}]}]}]}]}]},{"ID":"20250922205453-ruqnpks","Type":"NodeParagraph","Properties":{"id":"20250922205453-ruqnpks","updated":"20250922205453"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第二十四部分为我们揭示了LLM训练光鲜外表下的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“硬核”工程内幕"},{"Type":"NodeText","Data":"。它告诉我们，训练一个LL-M，不仅仅是设计一个巧妙的神经网络架构，更是一场与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不稳定性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬件限制"},{"Type":"NodeText","Data":"的艰苦斗争。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3D并行技术"},{"Type":"NodeText","Data":"就是在这场斗争中被磨砺出的最锋利的武器，它使得我们能够驾驭这些前所未有的计算“巨兽”，推动AI能力的边界不断向前拓展。"}]}]},{"ID":"20250922205643-4fz4kez","Type":"NodeParagraph","Properties":{"id":"20250922205643-4fz4kez","updated":"20250922205643"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922205643-9s71h72","Type":"NodeThematicBreak","Properties":{"id":"20250922205643-9s71h72","updated":"20250922205643"}},{"ID":"20250922205643-f1noyn4","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205643-f1noyn4","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二十五部分"}]},{"ID":"20250922205643-m7frynj","Type":"NodeParagraph","Properties":{"id":"20250922205643-m7frynj","updated":"20250922205648"},"Children":[{"Type":"NodeText","Data":"按列被分割成两个子矩阵A₁和A₂，可以表示为Y = "},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"["}]},{"Type":"NodeText","Data":"XA₁, XA₂"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"]"}]},{"Type":"NodeText","Data":"。通过将矩阵A₁和A₂放置在不同的GPU上，矩阵乘法运算将在两个GPU上并行调用，最终结果可以通过跨GPU通信组合两个GPU的输出来获得。目前，张量并行已在几个开源库中得到支持，例如Megatron-LM，并且可以扩展到更高维的张量。此外，Colossal-AI已经实现了对更高维张量的张量并行，并特别针对序列数据提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"序列并行"},{"Type":"NodeText","Data":"，它可以进一步分解Transformer模型的注意力操作。"}]},{"ID":"20250922205643-rgavb15","Type":"NodeParagraph","Properties":{"id":"20250922205643-rgavb15","updated":"20250922205648"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mixed Precision Training (混合精度训练)."},{"Type":"NodeText","Data":" 在之前的PLM（例如，BERT）中，32位浮点数（也称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FP32"},{"Type":"NodeText","Data":"）已主要用于预训练。近年来，为了预训练极大的语言模型，一些研究已开始利用16位浮点数（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FP16"},{"Type":"NodeText","Data":"），这减少了内存使用和通信开销。此外，由于流行的NVIDIA GPU（例如，A100）的FP16计算单元数量是FP32的两倍，FP16的计算效率可以进一步提高。然而，现有的工作发现FP16可能导致计算"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精度损失"},{"Type":"NodeText","Data":"，从而影响最终的模型性能。为了缓解这个问题，一种名为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大脑浮点数（Brain Floating Point, BF16）"},{"Type":"NodeText","Data":"的替代方案已被用于训练，它比FP16分配了更多的指数位和更少的有效位。对于预训练，BF16在表示精度上通常比FP16表现更好。"}]},{"ID":"20250922205643-lchh8ph","Type":"NodeParagraph","Properties":{"id":"20250922205643-lchh8ph","updated":"20250922205648"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Overall Training Suggestion (总体训练建议)."},{"Type":"NodeText","Data":" 在实践中，上述训练技术，特别是3D并行，通常被"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"联合使用"},{"Type":"NodeText","Data":"以提高训练吞吐量和大型模型的加载能力。例如，研究人员结合了8路数据并行、4路张量并行和12路流水线并行，从而能够在384个A100 GPU上训练BLOOM。目前，像DeepSpeed、Colossal-AI和Alpa这样的开源库可以很好地支持这三种并行训练方法。为了减少内存冗余，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ZeRO、FSDP和激活重计算"},{"Type":"NodeText","Data":"等技术也可以用于训练LLM，这些技术已经集成到DeepSpeed、PyTorch和Megatron-LM中。此外，像BF16这样的混合精度训练技术也可以被利用来提高训练效率和减少GPU内存使用，但这需要硬件的必要支持（例如，A100 GPU）。因为训练大型模型是一个时间密集型的过程，在早期阶段"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预测模型性能"},{"Type":"NodeText","Data":"并"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检测异常问题"},{"Type":"NodeText","Data":"将非常有用。为此，GPT-4最近引入了一种名为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测扩展"},{"Type":"NodeText","Data":"的新机制，该机制建立在一个深度学习栈上，能够用小得多的模型预测大模型的性能，这对于开发LLM可能非常有用。在实践中，人们可以进一步利用主流深度学习框架的支持技术。例如，PyTorch支持数据并行训练算法FSDP（即完全分片数据并行），如果需要，它允许将部分训练计算"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"卸载"},{"Type":"NodeText","Data":"到CPU。"}]},{"ID":"20250922205643-187cv6m","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205643-187cv6m","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5 POST-TRAINING OF LLMS (LLM的后期训练)"}]},{"ID":"20250922205643-sg8avrh","Type":"NodeParagraph","Properties":{"id":"20250922205643-sg8avrh","updated":"20250922205648"},"Children":[{"Type":"NodeText","Data":"预训练后，LLM可以获得解决各种任务的通用能力。然而，越来越多的研究表明，LLM的能力可以根据特定目标被进一步"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"适配"},{"Type":"NodeText","Data":"。在本节中，我们介绍两种适配预训练LLM的主要方法，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调"},{"Type":"NodeText","Data":"。前者主要旨在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增强（或解锁）"},{"Type":"NodeText","Data":"LLM的能力，而后者旨在使LLM的行为与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类价值观或偏好"},{"Type":"NodeText","Data":"对齐。此外，我们还将讨论在资源受限设置下用于模型适配的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效微调"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"量化"},{"Type":"NodeText","Data":"。接下来，我们将详细介绍这四个部分。"}]},{"ID":"20250922205643-g3eivi2","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205643-g3eivi2","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.1 Instruction Tuning (指令微调)"}]},{"ID":"20250922205643-31a7edc","Type":"NodeParagraph","Properties":{"id":"20250922205643-31a7edc","updated":"20250922205648"},"Children":[{"Type":"NodeText","Data":"本质上，指令微调是一种在以自然语言形式组织的格式化实例集合上"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调"},{"Type":"NodeText","Data":"预训练LLM的方法，它与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"监督式微调"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多任务提示训练"},{"Type":"NodeText","Data":"高度相关。为了执行指令微调，我们首先需要收集或构建指令格式化的实例。然后，我们采用这些格式化的实例以监督学习的方式（例如，使用序列到序列损失进行训练）来微调LLM。指令微调后，LLM可以展现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化到未见任务"},{"Type":"NodeText","Data":"的卓越能力，甚至在多语言环境中也是如此。"}]},{"ID":"20250922205643-o0k0a7i","Type":"NodeParagraph","Properties":{"id":"20250922205643-o0k0a7i","updated":"20250922205648"},"Children":[{"Type":"NodeText","Data":"最近的一篇综述对指令微调的研究进行了系统性的概述。与该综述相比，我们主要关注指令微调对LLM的影响，并为实例收集和微调提供详细的指导或策略。此外，我们还讨论了使用指令微调来满足用户真实需求，这已在现有LLM中被广泛应用，例如InstructGPT和GPT-4。"}]},{"ID":"20250922205643-qdqatar","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922205643-qdqatar","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.1.1 Formatted Instance Construction (格式化实例的构建)"}]},{"ID":"20250922205643-4cn1z5d","Type":"NodeParagraph","Properties":{"id":"20250922205643-4cn1z5d","updated":"20250922205648"},"Children":[{"Type":"NodeText","Data":"通常，一个指令格式化的实例由一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述（称为指令）、一个可选的输入、相应的输出以及少量演示（可选）"},{"Type":"NodeText","Data":"组成。作为重要的公共资源，现有研究已经发布了大量以自然语言格式化的标记数据（见3.3.1节中表3的可用资源列表）。接下来，我们介绍四种构建格式化实例的主要方法（见图11中的示意图），然后讨论实例构建的几个关键因素。"}]},{"ID":"20250922205643-ehtw103","Type":"NodeParagraph","Properties":{"id":"20250922205643-ehtw103","updated":"20250922205648"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Formatting NLP Task Datasets (格式化NLP任务数据集)."},{"Type":"NodeText","Data":" 在指令微调被提出之前，一些早期的研究收集了来自不同传统NLP任务（例如，文本摘要、文本分类和翻译）的实例，以创建监督式多任务训练数据集。作为指令微调实例的一个主要来源，用自然语言任务描述来格式化这些多任务训练数据集是很方便的。具体来说，最近的工作用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类编写的任务描述"},{"Type":"NodeText","Data":"来增强标记数据集，这些描述通过解释任务目标来指导LLM理解任务。例如，在图11(a)中，为问答任务中的每个例子添加了任务描述“请回答这个问题”。指令微调后，"}]},{"ID":"20250922205643-i106ppg","Type":"NodeParagraph","Properties":{"id":"20250922205643-i106ppg","updated":"20250922205648"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915170020-gvyz5n1.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922205643-8kwdhvg","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205643-8kwdhvg","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 11：实例格式化及三种构建指令格式化实例方法的示意图。"}]},{"ID":"20250922205643-8zsak9l","Type":"NodeBlockquote","Properties":{"id":"20250922205643-8zsak9l","updated":"20250922205648"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922205643-jpuzvb6","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205643-jpuzvb6","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922205643-2b4byd8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205643-2b4byd8","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图11解析：指令微调数据的“三种来源”"}]},{"ID":"20250922205643-s1ngfm5","Type":"NodeParagraph","Properties":{"id":"20250922205643-s1ngfm5","updated":"20250922205643"},"Children":[{"Type":"NodeText","Data":"这张图生动地展示了用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"的数据是如何被构建出来的，揭示了三种主流的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“教材”编写方法"},{"Type":"NodeText","Data":"。所有方法的最终目标都是产出一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“实例池（Instance Pool）”"},{"Type":"NodeText","Data":"，其中包含了大量的“指令-输入-输出”三元组。"}]},{"ID":"20250922205643-ifm6tvr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205643-ifm6tvr","updated":"20250922205643"},"Children":[{"ID":"20250922205643-80nbbhp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-80nbbhp","updated":"20250922205643"},"Children":[{"ID":"20250922205643-958ctqp","Type":"NodeParagraph","Properties":{"id":"20250922205643-958ctqp","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(a) 格式化任务数据集 (Formatting Task Datasets)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205643-okx29tw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205643-okx29tw","updated":"20250922205643"},"Children":[{"ID":"20250922205643-dwhmel3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-dwhmel3","updated":"20250922205643"},"Children":[{"ID":"20250922205643-6b19502","Type":"NodeParagraph","Properties":{"id":"20250922205643-6b19502","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"原料"},{"Type":"NodeText","Data":": 传统的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"NLP数据集"},{"Type":"NodeText","Data":"（如情感分类、问答）。"}]}]},{"ID":"20250922205643-x2vgmtu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-x2vgmtu","updated":"20250922205643"},"Children":[{"ID":"20250922205643-ezn4ub2","Type":"NodeParagraph","Properties":{"id":"20250922205643-ezn4ub2","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加工方法"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“包装”"},{"Type":"NodeText","Data":"。为原始的数据对（如“问题-答案”）套上一个用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然语言编写的“任务描述”"},{"Type":"NodeText","Data":"（如“请回答这个问题：”）。有时还会加入几个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“演示（Demonstrations）”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205643-pw8vurs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-pw8vurs","updated":"20250922205643"},"Children":[{"ID":"20250922205643-02a4l5w","Type":"NodeParagraph","Properties":{"id":"20250922205643-02a4l5w","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构化、数据量大、易于批量处理"},{"Type":"NodeText","Data":"。这是早期指令微调数据的主要来源。"}]}]}]}]},{"ID":"20250922205643-1ro95gu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-1ro95gu","updated":"20250922205643"},"Children":[{"ID":"20250922205643-5tf4g3b","Type":"NodeParagraph","Properties":{"id":"20250922205643-5tf4g3b","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(b) 格式化日常聊天数据 (Formatting Daily Chat Data)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205643-a4u8jhj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205643-a4u8jhj","updated":"20250922205643"},"Children":[{"ID":"20250922205643-cfa4vji","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-cfa4vji","updated":"20250922205643"},"Children":[{"ID":"20250922205643-boxmrff","Type":"NodeParagraph","Properties":{"id":"20250922205643-boxmrff","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"原料"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"真实的用户查询"},{"Type":"NodeText","Data":"（来自API调用）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类编写的高质量回答"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205643-mvrsj8c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-mvrsj8c","updated":"20250922205643"},"Children":[{"ID":"20250922205643-43lajmt","Type":"NodeParagraph","Properties":{"id":"20250922205643-43lajmt","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加工方法"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“收集与配对”"},{"Type":"NodeText","Data":"。直接将用户的真实问题作为“任务描述/输入”，将人类专家的回答作为“输出”。"}]}]},{"ID":"20250922205643-dq095c8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-dq095c8","updated":"20250922205643"},"Children":[{"ID":"20250922205643-ox3bmsx","Type":"NodeParagraph","Properties":{"id":"20250922205643-ox3bmsx","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更贴近真实世界、更具多样性、质量更高"},{"Type":"NodeText","Data":"。这是训练出像InstructGPT/ChatGPT这样强大对话模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922205643-kwdj1tx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-kwdj1tx","updated":"20250922205643"},"Children":[{"ID":"20250922205643-un18zjs","Type":"NodeParagraph","Properties":{"id":"20250922205643-un18zjs","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(c) 格式化合成数据 (Formatting Synthetic Data)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205643-x2iz347","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205643-x2iz347","updated":"20250922205643"},"Children":[{"ID":"20250922205643-pgf12b6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-pgf12b6","updated":"20250922205643"},"Children":[{"ID":"20250922205643-coeq0ld","Type":"NodeParagraph","Properties":{"id":"20250922205643-coeq0ld","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"原料"},{"Type":"NodeText","Data":": 少量"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“种子实例（Seed Instances）”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205643-dianucx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-dianucx","updated":"20250922205643"},"Children":[{"ID":"20250922205643-1s0ki9p","Type":"NodeParagraph","Properties":{"id":"20250922205643-1s0ki9p","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加工方法"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自力更生”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922205643-d8tnbjj","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922205643-d8tnbjj","updated":"20250922205643"},"Children":[{"ID":"20250922205643-mz7onrs","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922205643-mz7onrs","updated":"20250922205643"},"Children":[{"ID":"20250922205643-9wznbju","Type":"NodeParagraph","Properties":{"id":"20250922205643-9wznbju","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令生成"},{"Type":"NodeText","Data":": 让一个强大的LLM（“教师模型”）以种子为示例，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"创造"},{"Type":"NodeText","Data":"出成千上万条新的、多样的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205643-90dad7w","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922205643-90dad7w","updated":"20250922205643"},"Children":[{"ID":"20250922205643-ypsfltf","Type":"NodeParagraph","Properties":{"id":"20250922205643-ypsfltf","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实例生成"},{"Type":"NodeText","Data":": 再让这个LLM根据新生成的指令，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编造"},{"Type":"NodeText","Data":"出对应的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“输入-输出”"},{"Type":"NodeText","Data":"对。"}]}]},{"ID":"20250922205643-aeq01ae","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922205643-aeq01ae","updated":"20250922205643"},"Children":[{"ID":"20250922205643-iq096na","Type":"NodeParagraph","Properties":{"id":"20250922205643-iq096na","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过滤"},{"Type":"NodeText","Data":": 对生成的数据进行质量和多样性"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过滤"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922205643-7o5k7fr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-7o5k7fr","updated":"20250922205643"},"Children":[{"ID":"20250922205643-i323g3m","Type":"NodeParagraph","Properties":{"id":"20250922205643-i323g3m","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成本极低、可扩展性极强"},{"Type":"NodeText","Data":"。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca"},{"Type":"NodeText","Data":"等项目成功的核心技术，极大地推动了开源LLM的指令微tuning普及。"}]}]}]}]}]},{"ID":"20250922205643-e9c0nbb","Type":"NodeParagraph","Properties":{"id":"20250922205643-e9c0nbb","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张图揭示了指令微调数据来源的演进路径：从最初"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“改造”"},{"Type":"NodeText","Data":"现有的学术数据集，到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“采撷”"},{"Type":"NodeText","Data":"昂贵但高质量的真实人类数据，再到最终利用AI自身能力"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自动化、规模化生产”"},{"Type":"NodeText","Data":"合成数据。这一演进极大地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"降低了数据获取的成本和门槛"},{"Type":"NodeText","Data":"，是近年来LLM技术能够快速普及的关键因素之一。"}]}]},{"ID":"20250922205643-j4rsirp","Type":"NodeThematicBreak","Properties":{"id":"20250922205643-j4rsirp","updated":"20250922205648"}},{"ID":"20250922205643-gy02jjq","Type":"NodeBlockquote","Properties":{"id":"20250922205643-gy02jjq","updated":"20250922205648"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922205643-qq21enf","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205643-qq21enf","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922205643-gnh1l0f","Type":"NodeParagraph","Properties":{"id":"20250922205643-gnh1l0f","updated":"20250922205643"},"Children":[{"Type":"NodeText","Data":"第二十五部分是承上启下的关键，它首先"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"终结了关于“如何训练”的讨论"},{"Type":"NodeText","Data":"，给出了系统性的、可操作的建议；然后"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开启了关于“训练好之后做什么”的新篇章"},{"Type":"NodeText","Data":"——即模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"后期训练（Post-training）"},{"Type":"NodeText","Data":"，并重点聚焦于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922205643-aypdugb","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922205643-aypdugb","updated":"20250922205643"},"Children":[{"ID":"20250922205643-cpaox0g","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922205643-cpaox0g","updated":"20250922205643"},"Children":[{"ID":"20250922205643-7l32ifd","Type":"NodeParagraph","Properties":{"id":"20250922205643-7l32ifd","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练技术的“毕业总结”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205643-uj8u6p6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205643-uj8u6p6","updated":"20250922205643"},"Children":[{"ID":"20250922205643-affk8t6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-affk8t6","updated":"20250922205643"},"Children":[{"ID":"20250922205643-a3ldtbd","Type":"NodeParagraph","Properties":{"id":"20250922205643-a3ldtbd","updated":"20250922205643"},"Children":[{"Type":"NodeText","Data":"文章对可扩展训练技术进行了全面总结。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3D并行"},{"Type":"NodeText","Data":"是解决"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型大小"},{"Type":"NodeText","Data":"问题的宏观策略，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合精度训练（特别是BF16）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内存优化技术（ZeRO, FSDP, 激活重计算）"},{"Type":"NodeText","Data":"则是微观层面的实现保障。"}]}]},{"ID":"20250922205643-c9bic3t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-c9bic3t","updated":"20250922205643"},"Children":[{"ID":"20250922205643-ktfq9vo","Type":"NodeParagraph","Properties":{"id":"20250922205643-ktfq9vo","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测扩展（Predictable Scaling）"},{"Type":"NodeText","Data":"的再次提及，强调了LLM训练正在从“炼金术”走向“工业科学”，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可控性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可预测性"},{"Type":"NodeText","Data":"变得越来越重要。"}]}]},{"ID":"20250922205643-2flijlw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-2flijlw","updated":"20250922205643"},"Children":[{"ID":"20250922205643-qso8jvk","Type":"NodeParagraph","Properties":{"id":"20250922205643-qso8jvk","updated":"20250922205643"},"Children":[{"Type":"NodeText","Data":"这一部分的总结，为读者提供了一套完整的、经过业界验证的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模训练“工具箱”"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922205643-hhqvz51","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922205643-hhqvz51","updated":"20250922205643"},"Children":[{"ID":"20250922205643-4nqywuh","Type":"NodeParagraph","Properties":{"id":"20250922205643-4nqywuh","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"后期训练的“二元论”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205643-x44xsdz","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205643-x44xsdz","updated":"20250922205643"},"Children":[{"ID":"20250922205643-0gjcmgb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-0gjcmgb","updated":"20250922205643"},"Children":[{"ID":"20250922205643-gjp4frk","Type":"NodeParagraph","Properties":{"id":"20250922205643-gjp4frk","updated":"20250922205643"},"Children":[{"Type":"NodeText","Data":"文章清晰地将后期训练划分为两个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心且互补"},{"Type":"NodeText","Data":"的阶段："}]},{"ID":"20250922205643-y1mm52t","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922205643-y1mm52t","updated":"20250922205643"},"Children":[{"ID":"20250922205643-jvk5kky","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922205643-jvk5kky","updated":"20250922205643"},"Children":[{"ID":"20250922205643-ccksrdo","Type":"NodeParagraph","Properties":{"id":"20250922205643-ccksrdo","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调 (Instruction Tuning)"},{"Type":"NodeText","Data":": 目的是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“解锁/增强能力”"},{"Type":"NodeText","Data":"。它教会模型如何理解和执行人类的指令，使其从一个只会“预测下一个词”的语言模型，转变为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用的任务解决器"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205643-mjq8umr","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922205643-mjq8umr","updated":"20250922205643"},"Children":[{"ID":"20250922205643-r2fqpee","Type":"NodeParagraph","Properties":{"id":"20250922205643-r2fqpee","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调 (Alignment Tuning)"},{"Type":"NodeText","Data":": 目的是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“校准价值观”"},{"Type":"NodeText","Data":"。它教会模型生成的内容要符合"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类的偏好和价值观"},{"Type":"NodeText","Data":"（有用、诚实、无害），使其成为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"安全、可靠"},{"Type":"NodeText","Data":"的AI助手。"}]}]}]}]},{"ID":"20250922205643-0nkdpgk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-0nkdpgk","updated":"20250922205643"},"Children":[{"ID":"20250922205643-4yhaztb","Type":"NodeParagraph","Properties":{"id":"20250922205643-4yhaztb","updated":"20250922205643"},"Children":[{"Type":"NodeText","Data":"这个“二元论”框架，深刻地揭示了现代SOTA LLM成功的秘诀："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力与对齐，两者缺一不可"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922205643-kvhhybv","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922205643-kvhhybv","updated":"20250922205643"},"Children":[{"ID":"20250922205643-rnnxe5b","Type":"NodeParagraph","Properties":{"id":"20250922205643-rnnxe5b","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调数据的“三驾马车”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205643-z98giot","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205643-z98giot","updated":"20250922205643"},"Children":[{"ID":"20250922205643-fv3bi10","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-fv3bi10","updated":"20250922205643"},"Children":[{"ID":"20250922205643-rnhacul","Type":"NodeParagraph","Properties":{"id":"20250922205643-rnhacul","updated":"20250922205643"},"Children":[{"Type":"NodeText","Data":"图11及其解释，生动地展示了指令微调数据的三种主要来源："}]},{"ID":"20250922205643-uz9l7m1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205643-uz9l7m1","updated":"20250922205643"},"Children":[{"ID":"20250922205643-nyrddox","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-nyrddox","updated":"20250922205643"},"Children":[{"ID":"20250922205643-3qurnz8","Type":"NodeParagraph","Properties":{"id":"20250922205643-3qurnz8","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改造NLP任务"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"存量利用"},{"Type":"NodeText","Data":"，成本低，但可能与真实需求脱节。"}]}]},{"ID":"20250922205643-vx5oo2h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-vx5oo2h","updated":"20250922205643"},"Children":[{"ID":"20250922205643-hf61hcm","Type":"NodeParagraph","Properties":{"id":"20250922205643-hf61hcm","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"收集真实对话"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量最高"},{"Type":"NodeText","Data":"，最贴近用户，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成本极其昂贵"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922205643-nl0j40r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-nl0j40r","updated":"20250922205643"},"Children":[{"ID":"20250922205643-gshkpk2","Type":"NodeParagraph","Properties":{"id":"20250922205643-gshkpk2","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成数据"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性价比最高"},{"Type":"NodeText","Data":"，通过“蒸馏”强大模型的能力来大规模生成数据，是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推动开源社区发展的关键技术"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922205643-n7i1sf2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205643-n7i1sf2","updated":"20250922205643"},"Children":[{"ID":"20250922205643-r0nlt7k","Type":"NodeParagraph","Properties":{"id":"20250922205643-r0nlt7k","updated":"20250922205643"},"Children":[{"Type":"NodeText","Data":"这“三驾马-车”共同构成了指令微调的数据基础，不同的研究可以根据成本和目标进行选择和组合。"}]}]}]}]}]},{"ID":"20250922205643-bhebnex","Type":"NodeParagraph","Properties":{"id":"20250922205643-bhebnex","updated":"20250922205643"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第二十五部分完成了从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何构建和训练一个原始的LLM”"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何将其调教成一个真正有用且安全的AI助手”"},{"Type":"NodeText","Data":"的过渡。它不仅提供了训练技术的最终建议，更重要的是，为后期训练建立了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“能力+对齐”"},{"Type":"NodeText","Data":"的清晰框架，并详细阐述了作为“能力”基础的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"，其数据是如何被创造出来的。这为理解ChatGPT这类模型为何如此强大，提供了最直接的解释。"}]}]},{"ID":"20250922205828-05wkl2s","Type":"NodeParagraph","Properties":{"id":"20250922205828-05wkl2s","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922205828-ai2jvtm","Type":"NodeThematicBreak","Properties":{"id":"20250922205828-ai2jvtm","updated":"20250922205828"}},{"ID":"20250922205828-hfee2w9","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205828-hfee2w9","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二十六部分"}]},{"ID":"20250922205828-26srpwu","Type":"NodeParagraph","Properties":{"id":"20250922205828-26srpwu","updated":"20250922205830"},"Children":[{"Type":"NodeText","Data":"LLM可以通过遵循其任务描述很好地泛化到其他未见过的任务。特别是，已有研究表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令"},{"Type":"NodeText","Data":"是LLM任务泛化能力的关键因素：通过在去除了任务描述的标记数据集上对模型进行微调，会导致模型性能急剧下降。为了更好地为指令微调生成标记实例，一个名为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PromptSource"},{"Type":"NodeText","Data":"的众包平台被提出来，用于有效地为不同数据集创建、分享和验证任务描述。为了丰富训练实例，一些研究也尝试将现有实例的输入-输出对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反转"},{"Type":"NodeText","Data":"，并配以特殊设计的任务描述来进行指令微调。例如，给定一个问答对，我们可以通过预测以答案为条件的问题来创建一个新的实例（例如，“请根据答案生成一个问题：”）。"}]},{"ID":"20250922205828-assoobb","Type":"NodeParagraph","Properties":{"id":"20250922205828-assoobb","updated":"20250922205830"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Formatting Daily Chat Data (格式化日常聊天数据)."},{"Type":"NodeText","Data":" 尽管大量训练实例已被格式化为指令，但它们主要来自公共NLP数据集，要么缺乏指令多样性，要么与真实人类需求不匹配。为了克服这个问题，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"InstructGPT"},{"Type":"NodeText","Data":"提议将真实用户提交给OpenAI API的查询作为任务描述。此外，为了丰富任务多样性，人类标注员也被要求为现实生活中的任务编写指令，包括开放式生成、开放式问答、头脑风暴和聊天。然后，他们让另一组标注员直接回答这些指令作为输出。最后，他们将一个指令（即收集到的用户查询）和一个期望的输出（即人类编写的答案）配对作为一个训练实例。请注意，InstructGPT也将这些以自然语言格式化的真实世界任务用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调"},{"Type":"NodeText","Data":"（在5.2节中讨论）。此外，GPT-4设计了潜在的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高风险指令"},{"Type":"NodeText","Data":"，并通过监督式微调引导模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"拒绝"},{"Type":"NodeText","Data":"这些指令，以保障安全。考虑到高质量公共聊天数据的缺乏，一些研究也收集用户的聊天请求作为输入数据，然后利用ChatGPT或GPT-4生成响应作为输出数据。这类数据集的一个著名例子是来自ShareGPT的对话数据。此外，Dolly和OpenAssistant进一步发布了他们的对话数据，这些数据经过人类标注员的仔细标注，以达到高水平的质量。"}]},{"ID":"20250922205828-76h1slr","Type":"NodeParagraph","Properties":{"id":"20250922205828-76h1slr","updated":"20250922205830"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Formatting Synthetic Data (格式化合成数据)."},{"Type":"NodeText","Data":" 为了减轻人类标注或手动收集的负担，已提出了几种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"半自动化"},{"Type":"NodeText","Data":"的方法，通过将现有实例输入LLM来合成多样化的任务描述和实例，以构建实例。如图11(c)所示，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Instruct"},{"Type":"NodeText","Data":"方法仅需要175个实例作为初始任务池。然后，它从池中随机选择几个实例作为演示，并提示一个LLM生成新的指令和相应的输入-输出对。经过质量和多样性过滤后，新生成的实例将被添加到任务池中。因此，合成方法是为LLM生成大规模指令数据的一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有效且经济"},{"Type":"NodeText","Data":"的方式。然而，由Self-Instruct方法生成的实例可能过于简单或缺乏多样性。为了提高合成指令的质量，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WizardLM"},{"Type":"NodeText","Data":"通过提出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度和广度上的演进（Evol-Instruct）"},{"Type":"NodeText","Data":"来引入，以丰富实例的复杂性和多样性。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Align"},{"Type":"NodeText","Data":"建立了多个人类对齐的原则来过滤合成的实例。然后，它使用这些实例来训练一个LLM，以产生更对齐的实例。为了提升实例输出的质量，研究人员直接采用人类编写的文本作为输出，并使用ICL示例来合成相应的指令。"}]},{"ID":"20250922205828-calr7ta","Type":"NodeParagraph","Properties":{"id":"20250922205828-calr7ta","updated":"20250922205830"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Key Factors for Instruction Dataset Construction (指令数据集构建的关键因素)."},{"Type":"NodeText","Data":" 指令实例的质量对模型的性能有重要影响。在这里，我们讨论一些实例构建的基本因素。"}]},{"ID":"20250922205828-tdq7hd3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205828-tdq7hd3","updated":"20250922205830"},"Children":[{"ID":"20250922205828-c0awlib","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-c0awlib","updated":"20250922205828"},"Children":[{"ID":"20250922205828-q9aniqw","Type":"NodeParagraph","Properties":{"id":"20250922205828-q9aniqw","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩展指令 (Scaling the instructions)."},{"Type":"NodeText","Data":" 已有研究广泛证明，扩展任务数量可以极大地提升LLM的泛化能力。随着任务数量的增加，模型性能最初呈现持续增长的模式，而当达到一定水平时，增益变得微不足道。一个合理的推测是，一定数量的代表性任务可以提供相对充分的知识，增加更多任务可能不会带来额外的收益。此外，从多个方面（如长度、结构和创造性）提升任务描述的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"是有益的。至于每个任务的实例数量，研究发现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少量实例"},{"Type":"NodeText","Data":"通常就可以使模型在特定任务上的泛化性能达到饱和。特别是，最近的一些工作探索了用少量高质量指令数据（例如，一千或几千个实例）进行微调的效果，在评估任务上显示出非常有前景的结果。相比之下，另一条研究路线继续探索指令数据的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模效应"},{"Type":"NodeText","Data":"。例如，Orca将合成实例的规模扩大到500万，并带有逐步解释，它在广泛的任务上取得了优越的性能。"}]}]},{"ID":"20250922205828-o34x0w8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-o34x0w8","updated":"20250922205828"},"Children":[{"ID":"20250922205828-cki6ou3","Type":"NodeParagraph","Properties":{"id":"20250922205828-cki6ou3","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"格式化设计 (Formatting design)."},{"Type":"NodeText","Data":" 作为一个重要因素，自然语言格式的设计也极大地影响LLM的泛化性能。通常，我们可以为现有数据集的输入-输出对添加任务描述和可选的演示，其中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述"},{"Type":"NodeText","Data":"是LLM理解任务最关键的部分。此外，使用适当数量的范例作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示"},{"Type":"NodeText","Data":"可以带来显著的改进，这也减轻了模型对指令工程的敏感性。然而，将其他组件（例如，要避免的事情、原因和建议）纳入指令中，可能对LLM的性能产生微不足道甚至负面的影响。最近，为了激发LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逐步推理"},{"Type":"NodeText","Data":"能力，一些工作提议为一些推理数据集（如算术推理）加入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"示例。已有研究表明，用CoT和非CoT的例子共同微调LLM，可以在各种推理任务上取得良好性能，包括那些需要多跳推理能力的任务（例如，常识问答和算术推理），以及那些不需要这种推理方式的任务（例如，情感分析和抽取式问答）。"}]}]},{"ID":"20250922205828-puk099h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-puk099h","updated":"20250922205828"},"Children":[{"ID":"20250922205828-k95ogv2","Type":"NodeParagraph","Properties":{"id":"20250922205828-k95ogv2","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令质量提升 (Instruction quality improvement)."},{"Type":"NodeText","Data":" 数据质量对于指令微调的性能非常重要，大量的研究工作被提出来进一步提升现有指令数据集的质量。通常，这些方法主要依赖于精心设计的提示，来引导LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提炼或重写"},{"Type":"NodeText","Data":"给定的指令。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WizardLM"},{"Type":"NodeText","Data":"旨在通过设计提示来扩大和深化给定指令所需的知识，从而使Alpaca数据集变得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更复杂和多样化"},{"Type":"NodeText","Data":"。它还制定了过滤策略来移除低质量的指令。为了进一步提供细粒度的知识指导，最近的工作还将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识分类体系"},{"Type":"NodeText","Data":"纳入输入提示中，例如，知识要点和人机对话主题分类体系。为了保证指令质量，早期的方法主要采用闭源API或强大的开源LLM，这对于大规模指令合成会产生巨大的成本。考虑到这个问题，最近的研究广泛探索了使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相对较小的模型"},{"Type":"NodeText","Data":"进行数据合成的潜力。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"JiuZhang3.0"},{"Type":"NodeText","Data":"微调一个7B的语言模型，通过从GPT-4中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"蒸馏"},{"Type":"NodeText","Data":"知识来合成问题，然后利用它基于预训练语料库合成大量高质量的指令。这种方式可以在数学推理任务上取得比基线方法更好的性能，而数据合成成本仅为其20%。"}]}]},{"ID":"20250922205828-8rll209","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-8rll209","updated":"20250922205828"},"Children":[{"ID":"20250922205828-o5ignp3","Type":"NodeParagraph","Properties":{"id":"20250922205828-o5ignp3","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令选择 (Instruction selection)."},{"Type":"NodeText","Data":" 随着大量指令数据集的提出，从中选择高质量的来构建训练数据集变得非常重要。总的来说，现有的工作要么利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量评估指标"},{"Type":"NodeText","Data":"，要么使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM作为裁判模型"},{"Type":"NodeText","Data":"来对所有指令实例进行排序，然后选择得分相对较高的。具体来说，在指标方面，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"困惑度"},{"Type":"NodeText","Data":"和其他启发式测量（例如，长度）在实践中被广泛使用，例如，我们可以考虑移除高困惑度或非常短的指令，这些可能对应于低质量的。为了更好地估计一条指令对LLM能力的影响，也提出了更复杂的指标（例如，IFD），它们是通过组合多个简单指标计算得出的。此外，还引入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性感知的采样方法"},{"Type":"NodeText","Data":"，以确保代表性指令数据的整体覆盖率。此外，当有下游任务数据可用时，可以利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"跨实例梯度相似性"},{"Type":"NodeText","Data":"来衡量训练实例对目标任务的价值。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LESS"},{"Type":"NodeText","Data":"计算下游验证数据和训练指令数据的梯度，以基于影响函数的扩展来评估指令数据的贡献。"}]}]}]},{"ID":"20250922205828-h1gi8ru","Type":"NodeParagraph","Properties":{"id":"20250922205828-h1gi8ru","updated":"20250922205830"},"Children":[{"Type":"NodeText","Data":"总而言之，指令的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量"},{"Type":"NodeText","Data":"是在扩展实例数量时需要考虑的重要因素。随着LLM能力的提升，数据合成方法已成为生成大量指令数据的主流方法。遵循这一趋势，越来越多自动生成的指令数据集可用，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"选择和提炼"},{"Type":"NodeText","Data":"方法是有效使用这些数据集的关键。为了帮助读者理解不同因素如何影响指令微调，我们在5.1.4节中通过对多个专门构建的指令数据集进行实验，进行了一项实证研究。"}]},{"ID":"20250922205828-yzwedfk","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205828-yzwedfk","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.1.2 Instruction Tuning Strategies (指令微调策略)"}]},{"ID":"20250922205828-9wvmunn","Type":"NodeParagraph","Properties":{"id":"20250922205828-9wvmunn","updated":"20250922205830"},"Children":[{"Type":"NodeText","Data":"与预训练不同，指令微调通常更高效，因为只需要适量的实例进行训练。由于指令微调可以被视为一个监督训练过程，其优化在几个方面与预训练不同，例如，训练目标（即，序列到序列损失）和优化配置（例如，更小的批量大小和学习率），这在实践中需要特别注意。除了这些优化配置，还有四个重要的方面需要在指令微调中考虑："}]},{"ID":"20250922205828-588m29t","Type":"NodeParagraph","Properties":{"id":"20250922205828-588m29t","updated":"20250922205830"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Balancing the Data Distribution (平衡数据分布)."},{"Type":"NodeText","Data":" 由于指令微调涉及多种不同任务的混合，因此在微调期间平衡不同任务的比例很重要。一种广泛使用的方法是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"按样本比例混合"},{"Type":"NodeText","Data":"策略，即组合所有数据集并从混合数据集中平等地采样每个实例。"}]},{"ID":"20250922205828-gf2ix35","Type":"NodeBlockquote","Properties":{"id":"20250922205828-gf2ix35","updated":"20250922205830"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922205828-wdcy7vs","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205828-wdcy7vs","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922205828-dxi3p62","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205828-dxi3p62","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令数据集构建：从“手工业”到“智能制造”"}]},{"ID":"20250922205828-mej0h82","Type":"NodeParagraph","Properties":{"id":"20250922205828-mej0h82","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"这部分内容的核心是指令微调数据的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“生产方法学”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922205828-97i8bvu","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205828-97i8bvu","updated":"20250922205828"},"Children":[{"ID":"20250922205828-37t2eny","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-37t2eny","updated":"20250922205828"},"Children":[{"ID":"20250922205828-kbwp3ar","Type":"NodeParagraph","Properties":{"id":"20250922205828-kbwp3ar","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大生产模式"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205828-15hk9um","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922205828-15hk9um","updated":"20250922205828"},"Children":[{"ID":"20250922205828-ttgvhhf","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922205828-ttgvhhf","updated":"20250922205828"},"Children":[{"ID":"20250922205828-gy4kn80","Type":"NodeParagraph","Properties":{"id":"20250922205828-gy4kn80","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改造 (Formatting NLP Task Datasets)"},{"Type":"NodeText","Data":": 对存量学术数据集进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“包装”"},{"Type":"NodeText","Data":"，成本低，但可能脱离实际。"}]}]},{"ID":"20250922205828-fn5ij5a","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922205828-fn5ij5a","updated":"20250922205828"},"Children":[{"ID":"20250922205828-6yqitbg","Type":"NodeParagraph","Properties":{"id":"20250922205828-6yqitbg","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"采集 (Formatting Daily Chat Data)"},{"Type":"NodeText","Data":": 收集昂贵的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“纯天然”"},{"Type":"NodeText","Data":"人类数据（如InstructGPT），质量最高，最符合需求。"}]}]},{"ID":"20250922205828-qnqsaom","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922205828-qnqsaom","updated":"20250922205828"},"Children":[{"ID":"20250922205828-byvqoz4","Type":"NodeParagraph","Properties":{"id":"20250922205828-byvqoz4","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成 (Formatting Synthetic Data)"},{"Type":"NodeText","Data":": 利用AI"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自动化生产”"},{"Type":"NodeText","Data":"，成本最低，规模最大。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Instruct"},{"Type":"NodeText","Data":"是开创性的“生产线”，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WizardLM (Evol-Instruct)"},{"Type":"NodeText","Data":"则是对这条生产线的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“升级改造”"},{"Type":"NodeText","Data":"，旨在生产出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更复杂、更多样"},{"Type":"NodeText","Data":"的“产品”。"}]}]}]}]},{"ID":"20250922205828-q5eb6r3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-q5eb6r3","updated":"20250922205828"},"Children":[{"ID":"20250922205828-r2t4fyr","Type":"NodeParagraph","Properties":{"id":"20250922205828-r2t4fyr","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生产的“质量控制” (Key Factors)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205828-k1vfikr","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922205828-k1vfikr","updated":"20250922205828"},"Children":[{"ID":"20250922205828-fsr44xm","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922205828-fsr44xm","updated":"20250922205828"},"Children":[{"ID":"20250922205828-abwvuof","Type":"NodeParagraph","Properties":{"id":"20250922205828-abwvuof","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模与多样性 (Scaling \u0026amp; Diversity)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务种类越多越好"},{"Type":"NodeText","Data":"，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每个任务的样本量不必太多"},{"Type":"NodeText","Data":"。最近的研究（如Orca）也在探索"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“大力出奇迹”"},{"Type":"NodeText","Data":"，即使用海量的合成数据。"}]}]},{"ID":"20250922205828-fzn6gks","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922205828-fzn6gks","updated":"20250922205828"},"Children":[{"ID":"20250922205828-bfluli0","Type":"NodeParagraph","Properties":{"id":"20250922205828-bfluli0","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"格式设计 (Formatting Design)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205828-3anx21d","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205828-3anx21d","updated":"20250922205828"},"Children":[{"ID":"20250922205828-9umjfcq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-9umjfcq","updated":"20250922205828"},"Children":[{"ID":"20250922205828-ap1iqtp","Type":"NodeParagraph","Properties":{"id":"20250922205828-ap1iqtp","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述"},{"Type":"NodeText","Data":"是灵魂。"}]}]},{"ID":"20250922205828-pfouawo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-pfouawo","updated":"20250922205828"},"Children":[{"ID":"20250922205828-h2962hn","Type":"NodeParagraph","Properties":{"id":"20250922205828-h2962hn","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"加入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示 (Demonstrations)"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链 (CoT)"},{"Type":"NodeText","Data":"能极大提升性能和推理能力。"}]}]}]}]},{"ID":"20250922205828-gdbyiqv","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922205828-gdbyiqv","updated":"20250922205828"},"Children":[{"ID":"20250922205828-o5zvr1i","Type":"NodeParagraph","Properties":{"id":"20250922205828-o5zvr1i","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量提升 (Quality Improvement)"},{"Type":"NodeText","Data":": 这是一个活跃的研究方向。核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“用魔法打败魔法”"},{"Type":"NodeText","Data":"——使用更强大的LLM（或经过专门微调的小模型，如JiuZhang3.0）来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“重写”、“提炼”、“过滤”"},{"Type":"NodeText","Data":"现有的指令数据，使其质量更高。"}]}]},{"ID":"20250922205828-ik3o11g","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922205828-ik3o11g","updated":"20250922205828"},"Children":[{"ID":"20250922205828-pwv5kjr","Type":"NodeParagraph","Properties":{"id":"20250922205828-pwv5kjr","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据筛选 (Instruction Selection)"},{"Type":"NodeText","Data":": 面对海量的指令数据，如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“淘金”"},{"Type":"NodeText","Data":"？方法包括："}]},{"ID":"20250922205828-xvpb28u","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205828-xvpb28u","updated":"20250922205828"},"Children":[{"ID":"20250922205828-yxk7m5u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-yxk7m5u","updated":"20250922205828"},"Children":[{"ID":"20250922205828-qrp3wra","Type":"NodeParagraph","Properties":{"id":"20250922205828-qrp3wra","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简单指标"},{"Type":"NodeText","Data":"（如困惑度、长度）过滤。"}]}]},{"ID":"20250922205828-x2l88o3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-x2l88o3","updated":"20250922205828"},"Children":[{"ID":"20250922205828-x647tqp","Type":"NodeParagraph","Properties":{"id":"20250922205828-x647tqp","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM当裁判"},{"Type":"NodeText","Data":"来打分。"}]}]},{"ID":"20250922205828-6kv9m6w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-6kv9m6w","updated":"20250922205828"},"Children":[{"ID":"20250922205828-ufoe3ai","Type":"NodeParagraph","Properties":{"id":"20250922205828-ufoe3ai","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与下游任务的梯度相似性"},{"Type":"NodeText","Data":"来衡量数据的“价值”。"}]}]}]}]}]}]}]},{"ID":"20250922205828-d91fm88","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922205828-d91fm88","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调策略：如何“教”得更好"}]},{"ID":"20250922205828-o4ayeqf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205828-o4ayeqf","updated":"20250922205828"},"Children":[{"ID":"20250922205828-373j3jz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-373j3jz","updated":"20250922205828"},"Children":[{"ID":"20250922205828-4ggeexe","Type":"NodeParagraph","Properties":{"id":"20250922205828-4ggeexe","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心挑战"},{"Type":"NodeText","Data":": 指令微调的数据来自"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多种不同的任务"},{"Type":"NodeText","Data":"，如果简单混合，可能会导致模型在某些任务上学得好，在另一些任务上学得差。"}]}]},{"ID":"20250922205828-cj8ix0f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-cj8ix0f","updated":"20250922205828"},"Children":[{"ID":"20250922205828-1xp3g6q","Type":"NodeParagraph","Properties":{"id":"20250922205828-1xp3g6q","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平衡数据分布"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205828-bqmunzh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205828-bqmunzh","updated":"20250922205828"},"Children":[{"ID":"20250922205828-eq54no2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-eq54no2","updated":"20250922205828"},"Children":[{"ID":"20250922205828-kd4k5sa","Type":"NodeParagraph","Properties":{"id":"20250922205828-kd4k5sa","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"按样本比例混合 (examples-proportional mixing)"},{"Type":"NodeText","Data":": 这是最"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简单、最常用"},{"Type":"NodeText","Data":"的策略。不管每个任务的数据集大小如何，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一视同仁"},{"Type":"NodeText","Data":"，每个样本被抽到的概率都一样。这可以防止样本量超大的任务“淹没”那些样本虽少但很重要的任务。"}]}]}]}]}]}]},{"ID":"20250922205828-01ghga1","Type":"NodeThematicBreak","Properties":{"id":"20250922205828-01ghga1","updated":"20250922205830"}},{"ID":"20250922205828-mpak8eq","Type":"NodeBlockquote","Properties":{"id":"20250922205828-mpak8eq","updated":"20250922205830"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922205828-aans6nl","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922205828-aans6nl","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922205828-t2yq1ye","Type":"NodeParagraph","Properties":{"id":"20250922205828-t2yq1ye","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"第二十六部分是关于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调（Instruction Tuning）"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“方法论”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“实践指南”"},{"Type":"NodeText","Data":"。它系统地回答了两个核心问题："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1. 高质量的指令数据从哪里来？2. 有了数据之后，如何有效地进行训练？"}]},{"ID":"20250922205828-sx97xkm","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922205828-sx97xkm","updated":"20250922205828"},"Children":[{"ID":"20250922205828-kie33qc","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922205828-kie33qc","updated":"20250922205828"},"Children":[{"ID":"20250922205828-ttw9su7","Type":"NodeParagraph","Properties":{"id":"20250922205828-ttw9su7","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令数据的“炼金术”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205828-0z99rkt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205828-0z99rkt","updated":"20250922205828"},"Children":[{"ID":"20250922205828-qtmaezi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-qtmaezi","updated":"20250922205828"},"Children":[{"ID":"20250922205828-1o2rp0n","Type":"NodeParagraph","Properties":{"id":"20250922205828-1o2rp0n","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"本部分将指令数据的构建过程描绘成了一场从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“手工作坊”"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“智能化工厂”"},{"Type":"NodeText","Data":"的产业升级。"}]}]},{"ID":"20250922205828-ca0zx8l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-ca0zx8l","updated":"20250922205828"},"Children":[{"ID":"20250922205828-w2l7j6d","Type":"NodeParagraph","Properties":{"id":"20250922205828-w2l7j6d","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量 (Quality)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性 (Diversity)"},{"Type":"NodeText","Data":" 是贯穿始终的两条主线。无论是通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Evol-Instruct"},{"Type":"NodeText","Data":"提升复杂度，还是通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM裁判"},{"Type":"NodeText","Data":"进行筛选，所有努力的最终目标都是为了获得更高质量、更多样化的训练数据。"}]}]},{"ID":"20250922205828-kvmti81","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-kvmti81","updated":"20250922205828"},"Children":[{"ID":"20250922205828-5akajn2","Type":"NodeParagraph","Properties":{"id":"20250922205828-5akajn2","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“元学习”的趋势"},{"Type":"NodeText","Data":": 利用LLM来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提炼"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"筛选"},{"Type":"NodeText","Data":"训练数据本身，是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“元学习”"},{"Type":"NodeText","Data":"的体现。这表明LLM不仅是学习的目标，也正成为学习过程本身不可或缺的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922205828-z8skhti","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922205828-z8skhti","updated":"20250922205828"},"Children":[{"ID":"20250922205828-rj94vjq","Type":"NodeParagraph","Properties":{"id":"20250922205828-rj94vjq","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“因材施教”的训练策略"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205828-mkbdf9q","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205828-mkbdf9q","updated":"20250922205828"},"Children":[{"ID":"20250922205828-htobnlu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-htobnlu","updated":"20250922205828"},"Children":[{"ID":"20250922205828-oprt452","Type":"NodeParagraph","Properties":{"id":"20250922205828-oprt452","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"指令微调不是简单的模型训练，而更像是一门"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“教育的艺术”"},{"Type":"NodeText","Data":"。面对来自不同科目（任务）的“教材”（数据），如何安排课程（训练策略）至关重要。"}]}]},{"ID":"20250922205828-gqrhziw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-gqrhziw","updated":"20250922205828"},"Children":[{"ID":"20250922205828-80683uf","Type":"NodeParagraph","Properties":{"id":"20250922205828-80683uf","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平衡数据分布"},{"Type":"NodeText","Data":"是其中的第一课。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"按样本比例混合"},{"Type":"NodeText","Data":"的策略，体现了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“教育公平”"},{"Type":"NodeText","Data":"的思想，确保每个任务都有被学习的机会，从而培养出能力更全面的“通才”模型。"}]}]}]}]},{"ID":"20250922205828-cq9mpgl","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922205828-cq9mpgl","updated":"20250922205828"},"Children":[{"ID":"20250922205828-lw83bcn","Type":"NodeParagraph","Properties":{"id":"20250922205828-lw83bcn","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“做什么”到“如何做得更好”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922205828-19xjvqb","Type":"NodeList","ListData":{},"Properties":{"id":"20250922205828-19xjvqb","updated":"20250922205828"},"Children":[{"ID":"20250922205828-kem6fes","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-kem6fes","updated":"20250922205828"},"Children":[{"ID":"20250922205828-een36ar","Type":"NodeParagraph","Properties":{"id":"20250922205828-een36ar","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"本部分的内容超越了对基本概念的介绍，深入到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何做得更好”"},{"Type":"NodeText","Data":"的实践细节。"}]}]},{"ID":"20250922205828-d11s1us","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-d11s1us","updated":"20250922205828"},"Children":[{"ID":"20250922205828-az47idn","Type":"NodeParagraph","Properties":{"id":"20250922205828-az47idn","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"它不仅告诉我们有合成数据这种方法，还讨论了如何提升合成数据的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量"},{"Type":"NodeText","Data":"（WizardLM）；不仅告诉我们要筛选数据，还介绍了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多种筛选标准"},{"Type":"NodeText","Data":"（指标、LLM裁判、梯度相似性）。"}]}]},{"ID":"20250922205828-amq7uej","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922205828-amq7uej","updated":"20250922205828"},"Children":[{"ID":"20250922205828-gb2dte9","Type":"NodeParagraph","Properties":{"id":"20250922205828-gb2dte9","updated":"20250922205828"},"Children":[{"Type":"NodeText","Data":"这种深入细节的讨论，为该领域的实践者和研究者提供了极具价值的、可操作的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指导"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922205828-2xt5iwu","Type":"NodeParagraph","Properties":{"id":"20250922205828-2xt5iwu","updated":"20250922205828"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第二十六部分为我们揭开-了指令微调的“黑箱”。它清晰地表明，指令微调的成功，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一半靠数据，一半靠策略"},{"Type":"NodeText","Data":"。高质量、多样化的数据是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础"},{"Type":"NodeText","Data":"，而精巧的训练策略（如平衡数据分布）则是将数据潜力转化为模型能力的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"催化剂"},{"Type":"NodeText","Data":"。这一部分的论述，为理解和实践这一关键的LLM适配技术提供了坚实的理论和方法论支持。"}]}]},{"ID":"20250922210022-oggnpfp","Type":"NodeParagraph","Properties":{"id":"20250922210022-oggnpfp","updated":"20250922210022"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922210022-mxkuhr0","Type":"NodeThematicBreak","Properties":{"id":"20250922210022-mxkuhr0","updated":"20250922210022"}},{"ID":"20250922210022-x25tdf2","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210022-x25tdf2","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二十七部分"}]},{"ID":"20250922210022-3ud9c9b","Type":"NodeParagraph","Properties":{"id":"20250922210022-3ud9c9b","updated":"20250922210026"},"Children":[{"Type":"NodeText","Data":"此外，提升高质量集合（例如，FLAN和P3）的采样率通常可以根据最近的发现带来性能提升。此外，通常会设置一个最大上限来控制一个数据集在指令微tuning期间可以包含的最大样本数，这样做是为了防止较大的数据集压倒整个分布。在实践中，最大上限通常根据不同的数据集设置为几千或几万。最近，经验发现现有的指令数据集（表3）主要关注于提升LLM在某些方面的能力，单个数据集本身无法带来模型能力的全面提升。因此，通常建议使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多种现有指令数据集的混合"},{"Type":"NodeText","Data":"，以实现不同能力的均衡提升，包括NLP任务数据（例如，FLAN v2）、聊天数据（例如，ShareGPT）和合成数据（例如，GPT4-Alpaca）。"}]},{"ID":"20250922210022-931zljf","Type":"NodeParagraph","Properties":{"id":"20250922210022-931zljf","updated":"20250922210026"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Combining Instruction Tuning and Pre-Training (结合指令微-调与预训练)."},{"Type":"NodeText","Data":" 为了使微调过程更有效和稳定，OPT-IML在指令微调期间加入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练数据"},{"Type":"NodeText","Data":"，这可以被视为对模型微调的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正则化"},{"Type":"NodeText","Data":"。此外，一些研究尝试使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多任务学习"},{"Type":"NodeText","Data":"，从头开始用预训练数据（即纯文本）和指令微调数据（即格式化数据集）的混合来训练模型，而不是使用一个独立的两阶段过程（先预训练后指令微调）。具体来说，GLM-130B和Galactica将指令格式化的数据集作为预训练语料库的一小部分进行整合，这可能同时实现了预训练和指令微调的优势。"}]},{"ID":"20250922210022-nyb1gvh","Type":"NodeParagraph","Properties":{"id":"20250922210022-nyb1gvh","updated":"20250922210026"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Multi-stage Instruction Tuning (多阶段指令微调)."},{"Type":"NodeText","Data":" 对于指令微调，有两种重要的指令数据，即任务格式化的指令和日常聊天指令。通常，前者的数量远大于后者。平衡这两种指令数据的训练非常重要。除了仔细混合不同的指令数据，我们也可以采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多阶段指令微调策略"},{"Type":"NodeText","Data":"，其中LLM首先在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模任务格式化的指令"},{"Type":"NodeText","Data":"上进行微调，随后在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"日常聊天数据"},{"Type":"NodeText","Data":"上进行微调。为了避免"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力遗忘"},{"Type":"NodeText","Data":"问题，在第二阶段加入一定量的任务格式化指令也是有用的。实际上，这种多阶段微调策略也可以应用于其他指令微调的设置。例如，我们可以安排不同难易度和复杂度的微调阶段，逐步提升LLM遵循复杂指令的能力。"}]},{"ID":"20250922210022-0z68hat","Type":"NodeParagraph","Properties":{"id":"20250922210022-0z68hat","updated":"20250922210026"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Other Practical Tricks (其他实用技巧)."},{"Type":"NodeText","Data":" 在实践中，还有一些有用的策略和技巧，有助于提升LLM的微调性能。我们列出几个代表性的如下："}]},{"ID":"20250922210022-wcp1v8m","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210022-wcp1v8m","updated":"20250922210026"},"Children":[{"ID":"20250922210022-lkl4clj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-lkl4clj","updated":"20250922210022"},"Children":[{"ID":"20250922210022-vnbcd1f","Type":"NodeParagraph","Properties":{"id":"20250922210022-vnbcd1f","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效训练多轮聊天数据 (Efficient training for multi-turn chat data)."},{"Type":"NodeText","Data":" 给定一个多轮聊天示例（用户和聊天机器人之间的对话），一个直接的微调方法是将其分割成多个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文-响应对"},{"Type":"NodeText","Data":"进行训练：LLM被微调以根据相应的上下文为所有分割生成响应（即，在用户的每次发言后）。在这种微调方式中，很明显，来自一次对话的分割示例中存在重叠的话语。为了节省训练成本，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna"},{"Type":"NodeText","Data":"采用了一种高效的方式，将整个对话输入到LLM中，但依赖于一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"损失掩码"},{"Type":"NodeText","Data":"，该掩码只计算聊天机器人响应部分的损失用于训练。它可以显著减少由重叠话语带来的计算成本。"}]}]},{"ID":"20250922210022-jztq0uf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-jztq0uf","updated":"20250922210022"},"Children":[{"ID":"20250922210022-a5wzdiy","Type":"NodeParagraph","Properties":{"id":"20250922210022-a5wzdiy","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为LLM建立自我认同 (Establishing self-identification for LLM)."},{"Type":"NodeText","Data":" 为了将LLM部署于真实世界的应用，有必要建立其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"身份"},{"Type":"NodeText","Data":"，并让LLM意识到这些身份信息，例如名称、开发者和所属机构。一个实用的方法是创建与身份相关的指令来对LLM进行微调。在输入前加上自我认同的提示也是可行的，例如，“以下是人类与一个名为CHATBOTNAME，由DEVELOPER开发的AI助手之间的对话。”，其中CHATBOTNAME和DEVELOPER分别指聊天机器人的名称和开发者。"}]}]}]},{"ID":"20250922210022-v60207t","Type":"NodeParagraph","Properties":{"id":"20250922210022-v60207t","updated":"20250922210026"},"Children":[{"Type":"NodeText","Data":"除了上述实用策略和技巧，现有的工作还使用了其他技巧，例如，将多个示例拼接成一个序列以接近最大长度。"}]},{"ID":"20250922210022-7l1f4i0","Type":"NodeTable","TableAligns":[1,1,1,1,1,1],"Properties":{"colgroup":"|||||","id":"20250922210022-7l1f4i0","updated":"20250922210026"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Models"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"A800 Full Tuning"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"A800 LoRA Tuning"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"A800 Inference (16-bit)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3090 Inference (16-bit)"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3090 Inference (8-bit)"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"#GPU"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BS"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Time"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"#GPU"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BS"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Time"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"#GPU"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"#Token/s"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"#GPU"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"#Token/s"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"#GPU"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"#Token/s"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LLaMA (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.0h"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"80"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LLaMA (13B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.1h"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LLaMA (30B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.1h"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LLaMA (65B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11.2h"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4"}]}]}]},{"ID":"20250922210022-de7jlaw","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210022-de7jlaw","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 9：所需GPU数量、微调时间、设备批次大小（BS）（全参数微调和LoRA微调）以及推理速率（每秒生成的词元数）的基本统计数据。"}]},{"ID":"20250922210022-21bd7h8","Type":"NodeParagraph","Properties":{"id":"20250922210022-21bd7h8","updated":"20250922210026"},"Children":[{"Type":"NodeText","Data":"我们的实验基于两台Linux服务器进行，分别配备了8个A800-80G SXM4 GPU（带6个NVSwitch）和8个3090-24G GPU。A800和A100的主要区别在于NVLink互联速度。因此，我们对训练和推理效率的估计对于A100会略有提高，而其余的内存消耗将保持不变。对于全参数微调实验，我们使用数据并行训练、ZeRO Stage 3、BF16和梯度检查点。此外，LoRA微调可以在一个80G GPU上执行，利用INT8量化，秩设置为16。所有实验都是在Alpaca-52K数据集上通过训练LLaMA模型三个周期进行的。两种训练设置的最大序列长度都设置为512。推理实验的批次大小设置为1。"}]},{"ID":"20250922210022-jko552m","Type":"NodeBlockquote","Properties":{"id":"20250922210022-jko552m","updated":"20250922210026"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210022-180x6wp","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210022-180x6wp","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922210022-gbej2i7","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210022-gbej2i7","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表9解析：LLM微调与推理的“成本账单”"}]},{"ID":"20250922210022-f7s76b4","Type":"NodeParagraph","Properties":{"id":"20250922210022-f7s76b4","updated":"20250922210022"},"Children":[{"Type":"NodeText","Data":"这张表格非常直观地展示了在不同规模的LLaMA模型上进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全参数微调 (Full Tuning)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效微调 (LoRA Tuning)"},{"Type":"NodeText","Data":" 以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理 (Inference)"},{"Type":"NodeText","Data":" 所需的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬件资源、时间和性能"},{"Type":"NodeText","Data":"，是一份极具参考价值的“成本账单”。"}]},{"ID":"20250922210022-42kk4j9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210022-42kk4j9","updated":"20250922210022"},"Children":[{"ID":"20250922210022-wtmidg6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-wtmidg6","updated":"20250922210022"},"Children":[{"ID":"20250922210022-vuyr5gl","Type":"NodeParagraph","Properties":{"id":"20250922210022-vuyr5gl","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全参数微调 (Full Tuning) - “重资产”投入"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210022-4cjz1as","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210022-4cjz1as","updated":"20250922210022"},"Children":[{"ID":"20250922210022-i6peal0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-i6peal0","updated":"20250922210022"},"Children":[{"ID":"20250922210022-7xskq3g","Type":"NodeParagraph","Properties":{"id":"20250922210022-7xskq3g","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"资源需求"},{"Type":"NodeText","Data":": 随着模型从7B增长到65B，所需的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPU数量"},{"Type":"NodeText","Data":"从2个线性增加到16个。这清晰地表明全参数微调是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计算密集型"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内存密集型"},{"Type":"NodeText","Data":"的。"}]}]},{"ID":"20250922210022-bjt28pu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-bjt28pu","updated":"20250922210022"},"Children":[{"ID":"20250922210022-yy812r2","Type":"NodeParagraph","Properties":{"id":"20250922210022-yy812r2","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"时间成本"},{"Type":"NodeText","Data":": 微调时间也随模型增大而显著增加，从3小时到超过11小时。"}]}]}]}]},{"ID":"20250922210022-9gxoz6j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-9gxoz6j","updated":"20250922210022"},"Children":[{"ID":"20250922210022-5enyqvk","Type":"NodeParagraph","Properties":{"id":"20250922210022-5enyqvk","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LoRA微调 - “轻量化”革命"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210022-d0cmco9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210022-d0cmco9","updated":"20250922210022"},"Children":[{"ID":"20250922210022-3ru84tr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-3ru84tr","updated":"20250922210022"},"Children":[{"ID":"20250922210022-c6fq6u1","Type":"NodeParagraph","Properties":{"id":"20250922210022-c6fq6u1","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"惊人的效率"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"所有规模"},{"Type":"NodeText","Data":"的模型，从7B到65B，都"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只需要1个GPU"},{"Type":"NodeText","Data":"就可以进行LoRA微调！这与全参数微调需要多达16个GPU形成了鲜明对比。"}]}]},{"ID":"20250922210022-4cs5l1b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-4cs5l1b","updated":"20250922210022"},"Children":[{"ID":"20250922210022-fhvv716","Type":"NodeParagraph","Properties":{"id":"20250922210022-fhvv716","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“以时间换空间”"},{"Type":"NodeText","Data":": 虽然LoRA大大降低了对GPU数量和显存的需求，但微调时间相对更长（例如65B模型需要60.6小时）。这是一种典型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“以时间换空间”"},{"Type":"NodeText","Data":"的权衡。对于资源有限的开发者来说，这是完全可以接受的。"}]}]}]}]},{"ID":"20250922210022-ro6yc95","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-ro6yc95","updated":"20250922210022"},"Children":[{"ID":"20250922210022-tzhntc6","Type":"NodeParagraph","Properties":{"id":"20250922210022-tzhntc6","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理 (Inference) - 性能与硬件的博弈"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210022-j8qg8dq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210022-j8qg8dq","updated":"20250922210022"},"Children":[{"ID":"20250922210022-mexsby1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-mexsby1","updated":"20250922210022"},"Children":[{"ID":"20250922210022-ekqj5wa","Type":"NodeParagraph","Properties":{"id":"20250922210022-ekqj5wa","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型越大，速度越慢"},{"Type":"NodeText","Data":": 在相同的硬件（如A800）和精度（16-bit）下，推理速度（#Token/s）随着模型规模的增大而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"急剧下降"},{"Type":"NodeText","Data":"，从7B的36.6 Token/s降到65B的8.8 Token/s。"}]}]},{"ID":"20250922210022-rafq7eo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-rafq7eo","updated":"20250922210022"},"Children":[{"ID":"20250922210022-gf4nfr0","Type":"NodeParagraph","Properties":{"id":"20250922210022-gf4nfr0","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬件决定上限"},{"Type":"NodeText","Data":": 在相同模型（如7B）和精度下，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"A800 (36.6 Token/s) 的速度远快于3090 (24.3 Token/s)"},{"Type":"NodeText","Data":"，体现了高端计算卡的巨大优势。"}]}]},{"ID":"20250922210022-6rgmgh0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-6rgmgh0","updated":"20250922210022"},"Children":[{"ID":"20250922210022-yf8s9xw","Type":"NodeParagraph","Properties":{"id":"20250922210022-yf8s9xw","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"量化是关键"},{"Type":"NodeText","Data":": 在3090上，将模型从16-bit量化到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"8-bit"},{"Type":"NodeText","Data":"，虽然能运行，但速度会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大幅下降"},{"Type":"NodeText","Data":"（例如7B模型从24.3降到7.5 Token/s）。这表明量化虽然能降低显存门槛，但通常会带来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能开销"},{"Type":"NodeText","Data":"（除非有专门的硬件支持，如INT8 Tensor Core）。"}]}]}]}]}]},{"ID":"20250922210022-7h2xxtx","Type":"NodeParagraph","Properties":{"id":"20250922210022-7h2xxtx","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格用数据雄辩地证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LoRA"},{"Type":"NodeText","Data":"等参数高效微调技术对于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"普及LLM微调"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命性意义"},{"Type":"NodeText","Data":"。它使得在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单个消费级/专业级GPU"},{"Type":"NodeText","Data":"上微调大型模型成为可能。同时，它也揭示了LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理部署"},{"Type":"NodeText","Data":"的核心挑战——即在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型效果、硬件成本和响应速度"},{"Type":"NodeText","Data":"之间找到最佳平衡点。"}]}]},{"ID":"20250922210022-1cwnvif","Type":"NodeThematicBreak","Properties":{"id":"20250922210022-1cwnvif","updated":"20250922210026"}},{"ID":"20250922210022-42uzdu6","Type":"NodeBlockquote","Properties":{"id":"20250922210022-42uzdu6","updated":"20250922210026"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210022-eqb8t39","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210022-eqb8t39","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922210022-w39yuo3","Type":"NodeParagraph","Properties":{"id":"20250922210022-w39yuo3","updated":"20250922210022"},"Children":[{"Type":"NodeText","Data":"第二十七部分深入探讨了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调（Instruction Tuning）的“高级战术”"},{"Type":"NodeText","Data":"，并提供了一份关于微调与推理成本的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实证“账单”"},{"Type":"NodeText","Data":"。它将讨论从“用什么数据”推进到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何更聪明、更高效地使用数据和资源”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922210022-d1zh0fm","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210022-d1zh0fm","updated":"20250922210022"},"Children":[{"ID":"20250922210022-ihocc1c","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210022-ihocc1c","updated":"20250922210022"},"Children":[{"ID":"20250922210022-kg3a6z1","Type":"NodeParagraph","Properties":{"id":"20250922210022-kg3a6z1","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练策略的“组合拳”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210022-4rv8mg5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210022-4rv8mg5","updated":"20250922210022"},"Children":[{"ID":"20250922210022-o7xhox8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-o7xhox8","updated":"20250922210022"},"Children":[{"ID":"20250922210022-fww8sbs","Type":"NodeParagraph","Properties":{"id":"20250922210022-fww8sbs","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练与微调的协同"},{"Type":"NodeText","Data":": 文章提出了两种高级策略来打破预训练和微调之间的壁垒。一种是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“微调中加入预训练数据”"},{"Type":"NodeText","Data":"，这就像是在专业课学习中，不时复习基础课内容，起到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正则化"},{"Type":"NodeText","Data":"的作用，防止模型在特定任务上"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过拟合"},{"Type":"NodeText","Data":"。另一种是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“从头开始混合训练”"},{"Type":"NodeText","Data":"，这是一种更激进的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多任务学习"},{"Type":"NodeText","Data":"范式，试图一开始就培养一个既博学又能干的模型。"}]}]},{"ID":"20250922210022-ib41osx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-ib41osx","updated":"20250922210022"},"Children":[{"ID":"20250922210022-2ywhyeq","Type":"NodeParagraph","Properties":{"id":"20250922210022-2ywhyeq","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多阶段微调"},{"Type":"NodeText","Data":": 这是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“课程化”"},{"Type":"NodeText","Data":"的微调策略。先用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模、结构化"},{"Type":"NodeText","Data":"的任务数据进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通识技能”"},{"Type":"NodeText","Data":"训练，再用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高质量、多样化"},{"Type":"NodeText","Data":"的聊天数据进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“对话能力”"},{"Type":"NodeText","Data":"的专项提升。这种“先广后精”的策略能更高效地培养出强大的对话模型，并有效缓解"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“灾难性遗忘”"},{"Type":"NodeText","Data":"问题。"}]}]}]}]},{"ID":"20250922210022-kig87dz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210022-kig87dz","updated":"20250922210022"},"Children":[{"ID":"20250922210022-jsgkosu","Type":"NodeParagraph","Properties":{"id":"20250922210022-jsgkosu","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实用技巧的“锦囊妙计”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210022-wikkyp4","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210022-wikkyp4","updated":"20250922210022"},"Children":[{"ID":"20250922210022-li5q0rf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-li5q0rf","updated":"20250922210022"},"Children":[{"ID":"20250922210022-mxts0mb","Type":"NodeParagraph","Properties":{"id":"20250922210022-mxts0mb","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多轮对话的高效训练"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna"},{"Type":"NodeText","Data":"采用的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“损失掩码（Loss Mask）”"},{"Type":"NodeText","Data":"技术是一个非常聪明的工程优化。它在一次前向传播中处理整个对话，但只在模型需要生成的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“回答”"},{"Type":"NodeText","Data":"部分计算损失。这极大地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"节省了计算资源"},{"Type":"NodeText","Data":"，避免了在重复的上下文上进行不必要的梯度计算，是处理长对话数据的一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“最佳实践”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210022-kbfc1ug","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-kbfc1ug","updated":"20250922210022"},"Children":[{"ID":"20250922210022-8w2eacm","Type":"NodeParagraph","Properties":{"id":"20250922210022-8w2eacm","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"建立“自我认同”"},{"Type":"NodeText","Data":": 为模型设定一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“角色”或“身份”"},{"Type":"NodeText","Data":"（如“你是由XXX开发的AI助手”），并通过微调让其记住，这对于构建一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"品牌化、一致性强"},{"Type":"NodeText","Data":"的商业应用至关重要。"}]}]}]}]},{"ID":"20250922210022-ja4j0pu","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922210022-ja4j0pu","updated":"20250922210022"},"Children":[{"ID":"20250922210022-79yxe42","Type":"NodeParagraph","Properties":{"id":"20250922210022-79yxe42","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成本与收益的量化分析 (表9)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210022-l3k5mi4","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210022-l3k5mi4","updated":"20250922210022"},"Children":[{"ID":"20250922210022-gc9zze2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-gc9zze2","updated":"20250922210022"},"Children":[{"ID":"20250922210022-9gio9b8","Type":"NodeParagraph","Properties":{"id":"20250922210022-9gio9b8","updated":"20250922210022"},"Children":[{"Type":"NodeText","Data":"表9是本部分"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最具实践指导意义"},{"Type":"NodeText","Data":"的内容。它不再是定性的讨论，而是提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定量的、可触摸的"},{"Type":"NodeText","Data":"数据。"}]}]},{"ID":"20250922210022-1nbqp7s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-1nbqp7s","updated":"20250922210022"},"Children":[{"ID":"20250922210022-xalih2o","Type":"NodeParagraph","Properties":{"id":"20250922210022-xalih2o","updated":"20250922210022"},"Children":[{"Type":"NodeText","Data":"它雄辩地证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LoRA"},{"Type":"NodeText","Data":"的巨大价值：用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可接受的时间延长"},{"Type":"NodeText","Data":"换取了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指数级的硬件资源降低"},{"Type":"NodeText","Data":"，使得LLM微调从大型企业的“专利”变成了普通开发者和研究者也能企及的技术。"}]}]},{"ID":"20250922210022-xxpc8mj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210022-xxpc8mj","updated":"20250922210022"},"Children":[{"ID":"20250922210022-o4wawg7","Type":"NodeParagraph","Properties":{"id":"20250922210022-o4wawg7","updated":"20250922210022"},"Children":[{"Type":"NodeText","Data":"同时，推理部分的性能数据也清晰地揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型规模、硬件性能和量化精度"},{"Type":"NodeText","Data":"三者之间复杂的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"权衡关系"},{"Type":"NodeText","Data":"，为模型部署提供了直接的数据参考。"}]}]}]}]}]},{"ID":"20250922210022-ac0krlj","Type":"NodeParagraph","Properties":{"id":"20250922210022-ac0krlj","updated":"20250922210022"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第二十七部分从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略、技巧到成本"},{"Type":"NodeText","Data":"，为指令微调提供了一幅"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全景式的实践地图"},{"Type":"NodeText","Data":"。它不仅展示了如何通过高级策略（如多阶段微调）来提升模型性能，还提供了具体的工程技巧（如损失掩码）来提高训练效率，最后通过详实的数据（表9）量化了不同方案的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成本与收益"},{"Type":"NodeText","Data":"。这使得指令微调不再是一个模糊的概念，而是一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有方法、有技巧、可衡量"},{"Type":"NodeText","Data":"的系统工程。"}]}]},{"ID":"20250922210316-tcijsls","Type":"NodeParagraph","Properties":{"id":"20250922210316-tcijsls","updated":"20250922210316"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922210316-9044qhw","Type":"NodeThematicBreak","Properties":{"id":"20250922210316-9044qhw","updated":"20250922210316"}},{"ID":"20250922210316-n1wmasw","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210316-n1wmasw","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二十八部分"}]},{"ID":"20250922210316-sg3dozx","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210316-sg3dozx","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.1.3 The Effect of Instruction Tuning (指令微调的效果)"}]},{"ID":"20250922210316-mf4k8q2","Type":"NodeParagraph","Properties":{"id":"20250922210316-mf4k8q2","updated":"20250922210339"},"Children":[{"Type":"NodeText","Data":"在本部分中，我们从三个主要方面讨论指令微调对LLM的影响。"}]},{"ID":"20250922210316-9aw3qkj","Type":"NodeParagraph","Properties":{"id":"20250922210316-9aw3qkj","updated":"20250922210339"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Performance Improvement (性能提升)."},{"Type":"NodeText","Data":" 尽管只在适量的实例上进行微调，指令微调已成为提升或解锁LLM能力的重要方式。最近的研究在多种规模（从77M到540B）的语言模型上进行了实验，表明不同规模的模型都能从指令微调中受益，随着参数规模的增加，性能提升也更明显。此外，经过指令微调的较小模型甚至可以胜过未经微调的较大模型。除了模型规模，指令微调在各种模型架构、预训练目标和模型适配方法上都展现出一致的改进。在实践中，指令微调为增强现有语言模型（包括小尺寸的PLM）的能力提供了一种通用方法。而且，它比预训练的成本低得多，因为LLM所需的指令数据量远小于预训练数据。"}]},{"ID":"20250922210316-q2bvdnt","Type":"NodeParagraph","Properties":{"id":"20250922210316-q2bvdnt","updated":"20250922210339"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Task Generalization (任务泛化)."},{"Type":"NodeText","Data":" 指令微调鼓励模型理解自然语言指令以完成任务。它赋予LLM一种能力（通常被视为一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现能力"},{"Type":"NodeText","Data":"），即在没有演示的情况下遵循人类指令来执行特定任务，即使是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"未见过的任务"},{"Type":"NodeText","Data":"上。大量研究已证实了指令微调在实现对已见和未见任务的优越性能方面的有效性。此外，指令微调已被证明有助于缓解LLM的一些弱点（例如，重复生成或在不完成特定任务的情况下补充输入），从而带来解决现实世界任务的卓越能力。此外，经过指令微调训练的LLM可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"跨语言泛化"},{"Type":"NodeText","Data":"到相关任务。例如，BLOOMZ-P3是基于BLOOM，使用仅包含英语的任务集合P3进行微调的。有趣的是，与BLOOM相比，BLOOMZ-P3在多语言句子完成任务上取得了超过50%的提升，这表明指令微调可以帮助LLM从仅包含英语的数据集中获得通用的任务技能，并将这些技能转移到其他语言。此外，研究发现，仅使用英语指令可以在多语言任务上产生令人满意的结果，这有助于减少特定语言的指令工程工作。"}]},{"ID":"20250922210316-eudykhe","Type":"NodeParagraph","Properties":{"id":"20250922210316-eudykhe","updated":"20250922210339"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Domain Specialization (领域专业化)."},{"Type":"NodeText","Data":" 现有的LLM在传统NLP任务（例如，生成和推理）和日常问题上已展现出卓越的能力。然而，它们可能仍然缺乏完成特定任务（如医学、法律和金融）所需的领域知识（关于LLM在不同应用中的详细讨论见第8节）。指令微调是使现有通用LLM适应成为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域特定专家"},{"Type":"NodeText","Data":"的有效方法。例如，研究人员提议使用医疗数据集微调Flan-PaLM，以创建"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Med-PaLM"},{"Type":"NodeText","Data":"，这是一个医疗知识助手，其性能水平与临床医生专家相当。此外，最近的一项研究微调了FLAN-T5，以支持带有自然语言指令的电子商务推荐系统，在各种推荐任务中表现出强大的性能。还有一些基于LLaMA进行指令微调的开源医疗模型，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BenTsao"},{"Type":"NodeText","Data":"。此外，研究人员还在法律、金融和算术计算领域探索了指令微调。"}]},{"ID":"20250922210316-7qu3enq","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210316-7qu3enq","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.1.4 Empirical Analysis for Instruction Tuning (指令微调的实证分析)"}]},{"ID":"20250922210316-uymm2zx","Type":"NodeParagraph","Properties":{"id":"20250922210316-uymm2zx","updated":"20250922210339"},"Children":[{"Type":"NodeText","Data":"用不同的指令集微调LLM往往会导致模型变体在下游任务上表现各异。在本节中，我们将探索不同类型的指令在微调LLM（即LLaMA（7B）和LLaMA（13B））中的效果，并检验几种指令改进策略的有效性。"}]},{"ID":"20250922210316-0yili4n","Type":"NodeParagraph","Properties":{"id":"20250922210316-0yili4n","updated":"20250922210339"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Instruction Datasets (指令数据集)."},{"Type":"NodeText","Data":" 根据5.1.1节的讨论，我们主要考虑三种常见的指令，如下所示："}]},{"ID":"20250922210316-54e7jn7","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210316-54e7jn7","updated":"20250922210339"},"Children":[{"ID":"20250922210315-o16ll43","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-o16ll43","updated":"20250922210315"},"Children":[{"ID":"20250922210316-grsokm0","Type":"NodeParagraph","Properties":{"id":"20250922210316-grsokm0","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务特定指令 (Task-specific instructions)."},{"Type":"NodeText","Data":" 对于第一类指令，我们采用最常用的多任务指令数据集"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FLAN-T5"},{"Type":"NodeText","Data":"，该数据集通过组合先前工作中的四种数据混合，包含1,836个任务和超过15M条指令。"}]}]},{"ID":"20250922210315-zlkvo46","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-zlkvo46","updated":"20250922210315"},"Children":[{"ID":"20250922210316-89pquq5","Type":"NodeParagraph","Properties":{"id":"20250922210316-89pquq5","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"日常聊天指令 (Daily chat instructions)."},{"Type":"NodeText","Data":" 这类指令是用户提出的关于日常生活的对话，与现实生活场景更密切相关。我们采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ShareGPT"},{"Type":"NodeText","Data":"指令集，包含63K条真实用户指令。它已被用作Vicuna的核心指令。"}]}]},{"ID":"20250922210315-x8bmf7p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-x8bmf7p","updated":"20250922210315"},"Children":[{"ID":"20250922210316-hbie20a","Type":"NodeParagraph","Properties":{"id":"20250922210316-hbie20a","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成指令 (Synthetic instructions)."},{"Type":"NodeText","Data":" 除了重用现有的指令，我们也可以使用LLM自动合成大量的指令。我们采用流行的合成指令数据集"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Instruct-52K"},{"Type":"NodeText","Data":"，它包含52K条指令，配对约82K个实例输入和输出。这些生成的指令与人类编写的种子任务（例如，语法检查、头脑风暴）具有相似的数据分布。"}]}]}]},{"ID":"20250922210316-zus8z0g","Type":"NodeParagraph","Properties":{"id":"20250922210316-zus8z0g","updated":"20250922210339"},"Children":[{"Type":"NodeText","Data":"由于原始的FLAN-T5数据集非常大（即超过15M），我们从中随机抽样了80,000条指令，以便与类似规模的其他指令数据集（即ShareGPT和Self-Instruct-52K）进行公平比较。在我们的实验中，我们测试了每个单独的指令集以探索它们各自的效果，并检验它们的组合效果对模型性能的影响。"}]},{"ID":"20250922210316-7y0ik1q","Type":"NodeParagraph","Properties":{"id":"20250922210316-7y0ik1q","updated":"20250922210339"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Improvement Strategies (改进策略)."},{"Type":"NodeText","Data":" 尽管来自人类用户的真实世界指令更适合微调LLM，但在大规模收集它们很困难。作为人类生成指令的替代方案，大多数现有研究主要采用由LLM生成的合成指令。然而，合成指令存在一些潜在问题，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主题多样性差"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令难度不均"},{"Type":"NodeText","Data":"（要么太简单，要么太难）。因此，有必要提高合成指令的质量。接下来，我们总结了现有工作中广泛使用的四种主要改进策略如下："}]},{"ID":"20250922210316-n9sylof","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210316-n9sylof","updated":"20250922210339"},"Children":[{"ID":"20250922210315-yflejex","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-yflejex","updated":"20250922210315"},"Children":[{"ID":"20250922210316-x1cn489","Type":"NodeParagraph","Properties":{"id":"20250922210316-x1cn489","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增强指令复杂性 (Enhancing the instruction complexity)."},{"Type":"NodeText","Data":" 如现有工作中所讨论的，增强指令的复杂性可以提升LLM的遵循"}]}]}]},{"ID":"20250922210316-062zqqx","Type":"NodeTable","TableAligns":[1,1,1,1,1,1],"Properties":{"colgroup":"|||||","id":"20250922210316-062zqqx","updated":"20250922210339"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Models"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dataset Mixtures"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Instruction Numbers"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Lexical Diversity"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Chat"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"QA"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AlpacaFarm"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MMLU"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"① FLAN-T5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"80,000"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.48"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"23.77"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"38.58"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"② ShareGPT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"63,184"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"77.31"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"81.30"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"38.11"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"③ Self-Instruct-52K"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"82,439"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"25.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"/*"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"37.52"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"② + ③"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"145,623"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.22"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"71.36"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41.26"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"① + ② + ③"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"225,623"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.28"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"43.69"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"③ Self-Instruct-52K"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"82,439"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"25.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"/*"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"37.52"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"w/ complexity"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70,000"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70.43"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"76.96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"39.73"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"w/ diversity"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70,000"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"75.59"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"81.55"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"38.01"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"w/ difficulty"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70,000"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"73.48"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"79.15"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32.55"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"w/ scaling"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"220,000"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"57.78"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"51.13"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"33.81"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA (13B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"① FLAN-T5"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"80,000"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.48"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"22.12"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.12"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"② ShareGPT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"63,184"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"77.31"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"77.13"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"47.49"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"③ Self-Instruct-52K"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"82,439"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"25.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"/*"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"36.73"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"② + ③"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"145,623"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.22"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"72.85"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41.16"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"① + ② + ③"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"225,623"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.28"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"69.49"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"43.50"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"③ Self-Instruct-52K"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"82,439"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"25.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"/*"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"36.73"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"w/ complexity"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70,000"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70.43"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"77.94"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"46.89"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"w/ diversity"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70,000"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"75.59"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"44.97"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"w/ difficulty"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70,000"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"73.48"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"80.45"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"43.15"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"w/ scaling"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"220,000"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"57.78"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58.12"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"38.07"}]}]}]},{"ID":"20250922210316-n2v329l","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210316-n2v329l","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 10：基于LLaMA（7B）和LLaMA（13B）模型在聊天和QA设置下的指令微调实验结果（均为单轮对话）。"}]},{"ID":"20250922210316-phmpknq","Type":"NodeParagraph","Properties":{"id":"20250922210316-phmpknq","updated":"20250922210339"},"Children":[{"Type":"NodeText","Data":"我们在Self-Instruct-52K数据集上应用了四种指令改进策略，即增强复杂性（w/ complexity）、增加多样性（w/ diversity）、平衡难度（w/ difficulty）和扩展指令数量（w/ scaling）。"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"*"}]},{"Type":"NodeText","Data":"由于我们选择在Self-Instruct-52K上微调的LLaMA（7B）/（13B）模型作为基线，我们省略了微调模型与Self-Instruct-52K自身的胜率。"}]},{"ID":"20250922210316-hnar1f0","Type":"NodeBlockquote","Properties":{"id":"20250922210316-hnar1f0","updated":"20250922210339"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210316-2nftelt","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210316-2nftelt","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922210316-w0vg38v","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210316-w0vg38v","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表10解析：指令微调的“配方”实验"}]},{"ID":"20250922210316-dfsob9e","Type":"NodeParagraph","Properties":{"id":"20250922210316-dfsob9e","updated":"20250922210316"},"Children":[{"Type":"NodeText","Data":"这张表格通过在LLaMA 7B和13B上的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"受控实验"},{"Type":"NodeText","Data":"，系统地探究了不同"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令数据"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改进策略"},{"Type":"NodeText","Data":"对模型在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"聊天（Chat）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问答（QA）"},{"Type":"NodeText","Data":"两种场景下性能的影响，是一份信息量极大的“实验报告”。"}]},{"ID":"20250922210316-bdtgadv","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210316-bdtgadv","updated":"20250922210316"},"Children":[{"ID":"20250922210315-2y9hhfd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-2y9hhfd","updated":"20250922210315"},"Children":[{"ID":"20250922210316-a0rmyvt","Type":"NodeParagraph","Properties":{"id":"20250922210316-a0rmyvt","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同数据集的“专长”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210316-zx4w1vj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210316-zx4w1vj","updated":"20250922210316"},"Children":[{"ID":"20250922210315-q8iy6f8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-q8iy6f8","updated":"20250922210315"},"Children":[{"ID":"20250922210316-9bplecm","Type":"NodeParagraph","Properties":{"id":"20250922210316-9bplecm","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FLAN-T5 (任务型)"},{"Type":"NodeText","Data":": 在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"QA任务 (MMLU, BBH3k) 上表现最好"},{"Type":"NodeText","Data":"。这符合直觉，因为它本身就是由各种结构化的问答、分类等任务构成的。"}]}]},{"ID":"20250922210315-p3gm4gj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-p3gm4gj","updated":"20250922210315"},"Children":[{"ID":"20250922210316-n2yq76q","Type":"NodeParagraph","Properties":{"id":"20250922210316-n2yq76q","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ShareGPT (聊天型)"},{"Type":"NodeText","Data":": 在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"聊天任务 (AlpacaFarm) 上表现最好"},{"Type":"NodeText","Data":"。因为它来源于真实的人类对话，所以能更好地教会模型如何进行自然的、有帮助的对话。"}]}]},{"ID":"20250922210315-30higkr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-30higkr","updated":"20250922210315"},"Children":[{"ID":"20250922210316-cblxkio","Type":"NodeParagraph","Properties":{"id":"20250922210316-cblxkio","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Instruct-52K (合成型)"},{"Type":"NodeText","Data":": 表现居中，是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性价比高"},{"Type":"NodeText","Data":"的选择，但其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词汇多样性（Lexical Diversity）最低"},{"Type":"NodeText","Data":"，说明合成数据可能比较单调。"}]}]}]}]},{"ID":"20250922210315-tefhspf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-tefhspf","updated":"20250922210315"},"Children":[{"ID":"20250922210316-zeu8j0t","Type":"NodeParagraph","Properties":{"id":"20250922210316-zeu8j0t","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“混合”的力量"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210316-tzksa6u","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210316-tzksa6u","updated":"20250922210316"},"Children":[{"ID":"20250922210315-ydlwsqi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-ydlwsqi","updated":"20250922210315"},"Children":[{"ID":"20250922210316-n6vxsin","Type":"NodeParagraph","Properties":{"id":"20250922210316-n6vxsin","updated":"20250922210316"},"Children":[{"Type":"NodeText","Data":"将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三种数据集混合（①+②+③）"},{"Type":"NodeText","Data":"后，模型在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"QA任务上取得了最佳性能"},{"Type":"NodeText","Data":"（7B和13B的MMLU分数最高）。这说明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样化"},{"Type":"NodeText","Data":"的指令数据能带来更全面的能力提升，实现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“1+1+1 \u0026gt; 3”"},{"Type":"NodeText","Data":"的效果。"}]}]}]}]},{"ID":"20250922210315-n53ul4e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-n53ul4e","updated":"20250922210315"},"Children":[{"ID":"20250922210316-j4nnqm8","Type":"NodeParagraph","Properties":{"id":"20250922210316-j4nnqm8","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成数据改进策略的有效性"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210316-hsp019y","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210316-hsp019y","updated":"20250922210316"},"Children":[{"ID":"20250922210315-8kxy0ew","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-8kxy0ew","updated":"20250922210315"},"Children":[{"ID":"20250922210316-q9b26ym","Type":"NodeParagraph","Properties":{"id":"20250922210316-q9b26ym","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增强复杂性 (w/ complexity)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增加多样性 (w/ diversity)"},{"Type":"NodeText","Data":": 这两种策略"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"普遍有效"},{"Type":"NodeText","Data":"！它们在聊天和QA任务上都带来了显著的性能提升。特别是对于13B模型，多样性策略在BBH3k上带来了惊人的提升（从25.43到36.40）。这说明，让合成数据"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更难、更丰富"},{"Type":"NodeText","Data":"是提升模型能力的关键。"}]}]},{"ID":"20250922210315-3h4wt6n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-3h4wt6n","updated":"20250922210315"},"Children":[{"ID":"20250922210316-nc40kza","Type":"NodeParagraph","Properties":{"id":"20250922210316-nc40kza","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平衡难度 (w/ difficulty)"},{"Type":"NodeText","Data":": 在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"聊天"},{"Type":"NodeText","Data":"任务上效果很好，但在QA任务上表现一般甚至略有下降。这可能意味着，对于聊天，中等难度的指令最能激发模型的对话能力；而对于需要知识和推理的QA任务，可能需要更具挑战性的指令。"}]}]},{"ID":"20250922210315-ej0imqs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-ej0imqs","updated":"20250922210315"},"Children":[{"ID":"20250922210316-0mxhso1","Type":"NodeParagraph","Properties":{"id":"20250922210316-0mxhso1","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单纯增加数量 (w/ scaling)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"效果最差，甚至有害"},{"Type":"NodeText","Data":"！在所有指标上，单纯将指令数量从82K增加到220K都导致了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能的全面下降"},{"Type":"NodeText","Data":"。这雄辩地证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令的“质”远比“量”重要"},{"Type":"NodeText","Data":"。盲目地堆砌低质量的合成数据是有害的。"}]}]}]}]},{"ID":"20250922210315-wrd699s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-wrd699s","updated":"20250922210315"},"Children":[{"ID":"20250922210316-ja800a0","Type":"NodeParagraph","Properties":{"id":"20250922210316-ja800a0","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型规模的影响"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210316-7z3zcri","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210316-7z3zcri","updated":"20250922210316"},"Children":[{"ID":"20250922210315-ergeh45","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-ergeh45","updated":"20250922210315"},"Children":[{"ID":"20250922210316-k1kggdx","Type":"NodeParagraph","Properties":{"id":"20250922210316-k1kggdx","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"13B模型全面优于7B模型"},{"Type":"NodeText","Data":"。在几乎所有的数据集和设置下，LLaMA-13B的性能都显著高于7B。这再次验证了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“规模法则”"},{"Type":"NodeText","Data":"在指令微调中依然有效。"}]}]}]}]}]},{"ID":"20250922210316-ai9v12c","Type":"NodeParagraph","Properties":{"id":"20250922210316-ai9v12c","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格提供了关于指令微调极其宝贵的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实践洞见"},{"Type":"NodeText","Data":"："}]},{"ID":"20250922210316-058sl06","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210316-058sl06","updated":"20250922210316"},"Children":[{"ID":"20250922210315-hl1l214","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210315-hl1l214","updated":"20250922210315"},"Children":[{"ID":"20250922210316-fxbwsrt","Type":"NodeParagraph","Properties":{"id":"20250922210316-fxbwsrt","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据类型要匹配任务场景"},{"Type":"NodeText","Data":"（聊天用ShareGPT，QA用FLAN）。"}]}]},{"ID":"20250922210315-87bdqig","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210315-87bdqig","updated":"20250922210315"},"Children":[{"ID":"20250922210316-p3k7zw9","Type":"NodeParagraph","Properties":{"id":"20250922210316-p3k7zw9","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合多样化的数据源"},{"Type":"NodeText","Data":"能带来最全面的能力提升。"}]}]},{"ID":"20250922210315-h8d5f43","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922210315-h8d5f43","updated":"20250922210315"},"Children":[{"ID":"20250922210316-9rw9s4t","Type":"NodeParagraph","Properties":{"id":"20250922210316-9rw9s4t","updated":"20250922210316"},"Children":[{"Type":"NodeText","Data":"对于合成数据，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提升质量（复杂性、多样性）是王道"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210315-eoytuqa","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922210315-eoytuqa","updated":"20250922210315"},"Children":[{"ID":"20250922210316-183er7y","Type":"NodeParagraph","Properties":{"id":"20250922210316-183er7y","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"盲目增加低质量数据数量是有害的"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210315-fnlp7q7","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NS4=","Num":5},"Properties":{"id":"20250922210315-fnlp7q7","updated":"20250922210315"},"Children":[{"ID":"20250922210316-jk9fggm","Type":"NodeParagraph","Properties":{"id":"20250922210316-jk9fggm","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型越大，指令微调的效果越好"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922210316-lw7jwoe","Type":"NodeThematicBreak","Properties":{"id":"20250922210316-lw7jwoe","updated":"20250922210339"}},{"ID":"20250922210316-iunrljf","Type":"NodeBlockquote","Properties":{"id":"20250922210316-iunrljf","updated":"20250922210339"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210316-h1wm9om","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210316-h1wm9om","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922210316-kttn0ae","Type":"NodeParagraph","Properties":{"id":"20250922210316-kttn0ae","updated":"20250922210316"},"Children":[{"Type":"NodeText","Data":"第二十八部分是关于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调（Instruction Tuning）"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“成果汇报”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“科学实验”"},{"Type":"NodeText","Data":"。它首先从宏观上总结了指令微调带来的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大核心收益"},{"Type":"NodeText","Data":"，然后通过详实的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实证分析（表10）"},{"Type":"NodeText","Data":"，深入探究了影响微调效果的关键因素。"}]},{"ID":"20250922210316-hr7gnu8","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210316-hr7gnu8","updated":"20250922210316"},"Children":[{"ID":"20250922210315-wtdu5nc","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210315-wtdu5nc","updated":"20250922210315"},"Children":[{"ID":"20250922210316-kprct7h","Type":"NodeParagraph","Properties":{"id":"20250922210316-kprct7h","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调的“三大功绩”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210316-dumtyru","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210316-dumtyru","updated":"20250922210316"},"Children":[{"ID":"20250922210315-1y4sfhv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-1y4sfhv","updated":"20250922210315"},"Children":[{"ID":"20250922210316-yti1kxv","Type":"NodeParagraph","Properties":{"id":"20250922210316-yti1kxv","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能提升 (Performance Improvement)"},{"Type":"NodeText","Data":": 这是最直接的收益。指令微调能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"显著提升"},{"Type":"NodeText","Data":"模型在各种任务上的表现，甚至能让"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“小模型超越大模型”"},{"Type":"NodeText","Data":"（指微调后的小模型胜过未微调的大模型），是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性价比极高"},{"Type":"NodeText","Data":"的能力提升手段。"}]}]},{"ID":"20250922210315-1ommr53","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-1ommr53","updated":"20250922210315"},"Children":[{"ID":"20250922210316-sarjdnw","Type":"NodeParagraph","Properties":{"id":"20250922210316-sarjdnw","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务泛化 (Task Generalization)"},{"Type":"NodeText","Data":": 这是最神奇的收益。它教会模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“举一反三”"},{"Type":"NodeText","Data":"，能够处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从未见过"},{"Type":"NodeText","Data":"的任务和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"跨语言"},{"Type":"NodeText","Data":"的任务。这使得模型从一个只能做特定任务的“专才”，向一个能理解通用指令的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通才”"},{"Type":"NodeText","Data":"迈进。"}]}]},{"ID":"20250922210315-kowimwy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-kowimwy","updated":"20250922210315"},"Children":[{"ID":"20250922210316-v7soh4v","Type":"NodeParagraph","Properties":{"id":"20250922210316-v7soh4v","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域专业化 (Domain Specialization)"},{"Type":"NodeText","Data":": 这是最具应用价值的收益。通过在特定领域（如医疗、法律、金融）的指令数据上进行微调，可以快速地将一个通用模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“改造”"},{"Type":"NodeText","Data":"成一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域专家"},{"Type":"NodeText","Data":"（如Med-PaLM），极大地拓展了LLM的应用边界。"}]}]}]}]},{"ID":"20250922210315-nus075h","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210315-nus075h","updated":"20250922210315"},"Children":[{"ID":"20250922210316-b9gvagx","Type":"NodeParagraph","Properties":{"id":"20250922210316-b9gvagx","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实证分析的深刻洞见 (表10)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210316-4wwiy34","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210316-4wwiy34","updated":"20250922210316"},"Children":[{"ID":"20250922210315-93qyicb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-93qyicb","updated":"20250922210315"},"Children":[{"ID":"20250922210316-e9y9n03","Type":"NodeParagraph","Properties":{"id":"20250922210316-e9y9n03","updated":"20250922210316"},"Children":[{"Type":"NodeText","Data":"表10的实验设计非常精巧，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"控制变量"},{"Type":"NodeText","Data":"的方法，系统地验证了多个关于指令微调的假设，并得出了几条"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“金科玉律”"},{"Type":"NodeText","Data":"："}]},{"ID":"20250922210316-jpmlph3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210316-jpmlph3","updated":"20250922210316"},"Children":[{"ID":"20250922210315-cliwner","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-cliwner","updated":"20250922210315"},"Children":[{"ID":"20250922210316-81rlpd4","Type":"NodeParagraph","Properties":{"id":"20250922210316-81rlpd4","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据要对口"},{"Type":"NodeText","Data":": 任务型数据利于QA，聊天型数据利于对话。"}]}]},{"ID":"20250922210315-hzvzjdk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-hzvzjdk","updated":"20250922210315"},"Children":[{"ID":"20250922210316-22mcsht","Type":"NodeParagraph","Properties":{"id":"20250922210316-22mcsht","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性出奇迹"},{"Type":"NodeText","Data":": 混合不同来源的数据能带来最均衡、最强大的综合能力。"}]}]},{"ID":"20250922210315-uv0y0m3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-uv0y0m3","updated":"20250922210315"},"Children":[{"ID":"20250922210316-wlex93h","Type":"NodeParagraph","Properties":{"id":"20250922210316-wlex93h","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量远胜于数量"},{"Type":"NodeText","Data":": 对于合成数据，提升其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"是提升模型性能的关键。而盲目地、不加控制地增加数据量，反而会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“稀释”"},{"Type":"NodeText","Data":"学习效果，导致性能下降。这为社区的“数据竞赛”敲响了警钟。"}]}]},{"ID":"20250922210315-hipcz7h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210315-hipcz7h","updated":"20250922210315"},"Children":[{"ID":"20250922210316-f4rhken","Type":"NodeParagraph","Properties":{"id":"20250922210316-f4rhken","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模是硬道理"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更大的模型能更好地从指令中学习"},{"Type":"NodeText","Data":"，规模法则在这里依然适用。"}]}]}]}]}]}]}]},{"ID":"20250922210316-fj81zpx","Type":"NodeParagraph","Properties":{"id":"20250922210316-fj81zpx","updated":"20250922210316"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第二十八部分的核心在于，它不仅"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定性地"},{"Type":"NodeText","Data":"阐述了指令微调为何重要，更通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定量地"},{"Type":"NodeText","Data":"实验分析，揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何才能做好指令微调"},{"Type":"NodeText","Data":"。它将指令微调从一个模糊的概念，变成了一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有理论、有方法、有数据支撑"},{"Type":"NodeText","Data":"的系统工程。通过阅读本部分，读者可以深刻理解指令微调的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"巨大价值"},{"Type":"NodeText","Data":"，并掌握进行高效指令微调的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心原则和实践策略"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210540-qgj774l","Type":"NodeParagraph","Properties":{"id":"20250922210540-qgj774l","updated":"20250922210540"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922210540-7qo3tss","Type":"NodeThematicBreak","Properties":{"id":"20250922210540-7qo3tss","updated":"20250922210540"}},{"ID":"20250922210540-qgsyx6p","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210540-qgsyx6p","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二十九部分"}]},{"ID":"20250922210540-uanaw5i","Type":"NodeParagraph","Properties":{"id":"20250922210540-uanaw5i","updated":"20250922210601"},"Children":[{"Type":"NodeText","Data":"复杂指令的能力。为了验证这一策略，我们遵循WizardLM的做法，逐步增加复杂性层次，例如，增加约束、增加推理步骤和复杂化输入。我们利用公开发布的WizardLM-70K指令作为增强复杂性的指令数据集，该数据集是通过上述增强方法在Self-Instruct-52K数据集基础上生成的。"}]},{"ID":"20250922210540-bg7em3x","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210540-bg7em3x","updated":"20250922210601"},"Children":[{"ID":"20250922210540-snnwe02","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-snnwe02","updated":"20250922210540"},"Children":[{"ID":"20250922210540-r6o0dte","Type":"NodeParagraph","Properties":{"id":"20250922210540-r6o0dte","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增加主题多样性 (Increasing the topic diversity)."},{"Type":"NodeText","Data":" 除了复杂性，提升指令数据集的主题多样性可以帮助激发LLM在现实世界中不同任务上的不同能力。然而，直接控制自指令过程以生成多样化的指令是很困难的。遵循YuLan-Chat的做法，我们使用ChatGPT通过特定的提示来重写Self-Instruct-52K数据集中的指令，使其适应293个主题。最终，我们获得了70K条指令作为增加多样性的数据集。"}]}]},{"ID":"20250922210540-k8gp750","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-k8gp750","updated":"20250922210540"},"Children":[{"ID":"20250922210540-00bstoa","Type":"NodeParagraph","Properties":{"id":"20250922210540-00bstoa","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩展指令数量 (Scaling the instruction number)."},{"Type":"NodeText","Data":" 除了上述方面，指令的数量也是可能影响模型性能的一个重要因素。特别是，使用更多的指令可以扩展任务知识并提升LLM的指令遵循能力。为了检验这一策略，我们从MOSS项目发布的合成指令集中抽样新的指令，因为它们也是使用相同的自指令方法合成的。我们将它们与Self-Instruct-52K数据集混合，组成一个包含220K条指令的更大数据集。"}]}]},{"ID":"20250922210540-f4mbuqp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-f4mbuqp","updated":"20250922210540"},"Children":[{"ID":"20250922210540-93ipnb9","Type":"NodeParagraph","Properties":{"id":"20250922210540-93ipnb9","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平衡指令难度 (Balancing the instruction difficulty)."},{"Type":"NodeText","Data":" 由于合成指令往往包含过易或过难的指令，这很可能导致LLM的训练不稳定甚至过拟合。为了探索潜在的影响，我们利用LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"困惑度得分"},{"Type":"NodeText","Data":"来估计指令的难度，并移除过易或过难的指令。为了生成相同规模的指令以进行公平比较，我们采用一个LLaMA（7B）模型来计算来自大型指令数据集的220K条指令的困惑度，然后保留70K条具有中等困惑度得分的指令作为难度平衡的数据集。"}]}]}]},{"ID":"20250922210540-18q5uej","Type":"NodeParagraph","Properties":{"id":"20250922210540-18q5uej","updated":"20250922210601"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Experimental Setup (实验设置)."},{"Type":"NodeText","Data":" 为了进行关于指令数据效果的实验，我们利用这些新的指令数据集来微调LLaMA，这是一个已被广泛用于指令微调的流行LLM骨干。我们使用来自YuLan-Chat的代码进行实验，并在一个拥有8个A800-80G GPU的服务器上训练LLaMA 7B和13B。所有的超参数设置与斯坦福Alpaca保持一致。为了更好地评估微调模型的指令遵循能力，我们考虑了两种设置，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"聊天设置"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"QA设置"},{"Type":"NodeText","Data":"。聊天设置主要利用来自日常聊天的用户指令和查询，而QA设置则主要采用来自现有NLP数据集的问答示例。聊天设置的评估是基于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AlpacaFarm评估集"},{"Type":"NodeText","Data":"进行的。我们不采用完整的成对比较，而是选择在Self-Instruct-52K上微调的LLaMA 7B和13B模型作为参考基线，然后将它们与分别使用不同指令微调的其他LLaMA 7B和13B模型进行比较。由于我们的重点是检验生成指令的不同策略的有效性，因此在Self-Instruct-52K上微调的模型可以作为一个很好的参考。遵循AlpacaFarm，对于每次比较，我们使用ChatGPT自动标注两个比较模型中哪个响应对用户查询来说是最好的，并报告"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"胜率（%）"},{"Type":"NodeText","Data":"作为评估指标。对于QA设置，我们选择两个基准，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MMLU"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BBH"},{"Type":"NodeText","Data":"，并通过使用启发式规则解析来自这些LLM的答案，根据它们的默认设置评估准确率。"}]},{"ID":"20250922210540-rpxh1rh","Type":"NodeParagraph","Properties":{"id":"20250922210540-rpxh1rh","updated":"20250922210601"},"Children":[{"Type":"NodeText","Data":"对于指令微调和评估，我们都采用了以下提示：“以下是人类与一个AI助手之间的对话。AI助手为用户的问题提供有帮助的、详细且礼貌的回答。\\n"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"["}]},{"Type":"NodeText","Data":"|Human|"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"]"}]},{"Type":"NodeText","Data":":{input}\\n"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"["}]},{"Type":"NodeText","Data":"|AI|"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"]"}]},{"Type":"NodeText","Data":":”。为了复现我们的结果，我们在以下链接发布了代码和数据：https://github.com/RUCAIBox/LLMSurvey/tree/main/Experiments。"}]},{"ID":"20250922210540-9mdn0vo","Type":"NodeParagraph","Properties":{"id":"20250922210540-9mdn0vo","updated":"20250922210601"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Results and Analysis (结果与分析)."},{"Type":"NodeText","Data":" 使用不同指令数据集基于7B和13B LLaMA的结果在表10中。接下来，我们总结和分析我们的发现。"}]},{"ID":"20250922210540-v4epik9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210540-v4epik9","updated":"20250922210601"},"Children":[{"ID":"20250922210540-3aq3hqd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-3aq3hqd","updated":"20250922210540"},"Children":[{"ID":"20250922210540-p2u7ygm","Type":"NodeParagraph","Properties":{"id":"20250922210540-p2u7ygm","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务格式化的指令更适合QA设置，但可能不适用于聊天设置。"},{"Type":"NodeText","Data":"通过比较使用FLAN-T5与ShareGPT和Self-Instruct-52K进行指令微调的性能，我们观察到FLAN-T5在QA基准上大多取得了更好的性能，而在聊天设置上表现不佳。原因是FLAN-T5是由来自现有NLP任务（例如，翻译和阅读理解）的指令和示例组成的混合体。因此，用FLAN-T5微调的LLaMA在QA任务上表现更好，但在用户查询上表现较差。相比之下，ShareGPT由真实世界的人-ChatGPT对话组成，能够更好地激发LLaMA遵循日常生活中的用户指令，但可能不适合完成QA任务。"}]}]},{"ID":"20250922210540-8dl4yiq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-8dl4yiq","updated":"20250922210540"},"Children":[{"ID":"20250922210540-b3hgqv3","Type":"NodeParagraph","Properties":{"id":"20250922210540-b3hgqv3","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合不同种类的指令有助于提升LLM的综合能力。"},{"Type":"NodeText","Data":"在混合了三种指令进行微调后，我们可以看到派生的LLaMA变体（使用FLAN-T5、ShareGPT和Self-Instruct-52K）在两种任务设置中都表现良好。在MMLU上，LLaMA（7B）的性能可以大幅超越使用单个指令集的版本，即43.69 vs. 38.58（FLAN-T5）。这表明混合多种来源的指令数据集有助于提升指令微调模型的性能，这既扩展了指令数量，也增加了多样性。"}]}]},{"ID":"20250922210540-8ptj3rj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-8ptj3rj","updated":"20250922210540"},"Children":[{"ID":"20250922210540-tl0jhwk","Type":"NodeParagraph","Properties":{"id":"20250922210540-tl0jhwk","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增强指令的复杂性和多样性可以带来模型性能的提升。"},{"Type":"NodeText","Data":"通过分别增加Self-Instruct-52K数据集的复杂性和多样性，LLaMA的聊天和QA性能可以得到持续的提升，例如，LLaMA（7B）在MMLU上从37.52提升到39.73。这表明这两种策略对于提升LLM的指令遵循能力都是有用的。此外，我们可以看到，提升复杂性在QA任务上带来了更大的性能提升。原因是QA任务大多由评估LLM的难题组成，这些问题可以被学习了复杂指令的LLM更好地解决。"}]}]},{"ID":"20250922210540-rpa991m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-rpa991m","updated":"20250922210540"},"Children":[{"ID":"20250922210540-rlco9nj","Type":"NodeParagraph","Properties":{"id":"20250922210540-rlco9nj","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简单地增加指令数量可能不是那么有用，而平衡难度也并非总是有帮助。"},{"Type":"NodeText","Data":"如表10所示的结果，在我们的实验中，平衡难度和增加微调指令的数量并不是很有帮助。特别是对于扩展指令数量，它甚至损害了性能，例如，LLaMA（7B）在BBH上从29.81下降到26.63。这表明，简单地扩展没有质量控制的合成指令数量可能无法有效提升性能。此外，用中等难度的指令进行微调在聊天设置中表现良好，但在QA设置中略微降低了性能。一个可能的原因是，我们用高困惑度得分过滤掉了复杂和困难的指令，损害了模型在回答复杂问题上的性能。"}]}]},{"ID":"20250922210540-51e9oh6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-51e9oh6","updated":"20250922210540"},"Children":[{"ID":"20250922210540-iurz7xr","Type":"NodeParagraph","Properties":{"id":"20250922210540-iurz7xr","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更大的模型规模带来更好的指令遵循性能。"},{"Type":"NodeText","Data":"通过比较用同一指令数据集微调的LLaMA（7B）和LLaMA（13B）模型的性能，我们可以看到LLaMA（13B）大多取得了更好的性能。这表明扩展模型大小有助于提升指令遵循能力。此外，我们可以看到QA性能得到了很大的提升，例如，在MMLU上从38.11提升到47.49。这很可能是因为更大的模型通常具有更好的知识利用和推理能力，可以更准确地回答更复杂的问题。"}]}]}]},{"ID":"20250922210540-m130cwq","Type":"NodeBlockquote","Properties":{"id":"20250922210540-m130cwq","updated":"20250922210601"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210540-quhbjay","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210540-quhbjay","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调建议"}]},{"ID":"20250922210540-l2256cq","Type":"NodeParagraph","Properties":{"id":"20250922210540-l2256cq","updated":"20250922210540"},"Children":[{"Type":"NodeText","Data":"要对LLM进行指令微调，可以根据表9中关于所需GPU数量和微调时间的基本统计数据来准备计算资源。在搭建好开发环境后，我们建议初学者遵循"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca仓库"},{"Type":"NodeText","Data":"的代码进行指令微调。随后，应该像我们在本节中讨论的那样，选择基础模型并构建指令数据集。当训练的计算资源受限时，用户可以利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LoRA"},{"Type":"NodeText","Data":"进行参数高效微调（见5.3节）。至于推理，用户可以进一步使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"量化"},{"Type":"NodeText","Data":"方法在更少或更小的GPU上部署LLM（见5.3节）。"}]}]},{"ID":"20250922210540-1fob5ei","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210540-1fob5ei","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.2 Alignment Tuning (对齐微调)"}]},{"ID":"20250922210540-xr8ndkf","Type":"NodeParagraph","Properties":{"id":"20250922210540-xr8ndkf","updated":"20250922210601"},"Children":[{"Type":"NodeText","Data":"本部分首先介绍对齐的背景及其定义和标准，然后重点讨论为对齐LLM收集人类反馈数据，最后讨论用于对齐微调的关键技术——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从人类反馈中进行强化学习（RLHF）"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922210540-g3qheid","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922210540-g3qheid","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.2.1 Background and Criteria for Alignment (对齐的背景与标准)"}]},{"ID":"20250922210540-5q83rda","Type":"NodeParagraph","Properties":{"id":"20250922210540-5q83rda","updated":"20250922210601"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Background (背景)."},{"Type":"NodeText","Data":" LLM在广泛的NLP任务中已展现出卓越的能力。然而，这些模型有时可能会表现出意想不到的行为，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"捏造虚假信息、追求不准确的目标，以及产生有害、误导和有偏见"},{"Type":"NodeText","Data":"的表达。对于LLM，语言建模目标通过词语预测来预训练模型参数，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"没有考虑人类的价值观或偏好"},{"Type":"NodeText","Data":"。为了避免这些意外行为，提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐"},{"Type":"NodeText","Data":"，以使LLM的行为符合人类的期望。然而，与原始的"}]},{"ID":"20250922210540-gom03ps","Type":"NodeBlockquote","Properties":{"id":"20250922210540-gom03ps","updated":"20250922210601"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210540-du3wzzd","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210540-du3wzzd","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922210540-75ix235","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210540-75ix235","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实证分析的严谨性"}]},{"ID":"20250922210540-64vs61l","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210540-64vs61l","updated":"20250922210540"},"Children":[{"ID":"20250922210540-gtxb2np","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-gtxb2np","updated":"20250922210540"},"Children":[{"ID":"20250922210540-m7xh8wl","Type":"NodeParagraph","Properties":{"id":"20250922210540-m7xh8wl","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"受控实验"},{"Type":"NodeText","Data":": 作者通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"固定模型（LLaMA 7B/13B）、固定超参（同Alpaca）"},{"Type":"NodeText","Data":"，只改变"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令数据集"},{"Type":"NodeText","Data":"这一个变量，来进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严谨的科学探究"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210540-zx7qu4u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-zx7qu4u","updated":"20250922210540"},"Children":[{"ID":"20250922210540-falcapn","Type":"NodeParagraph","Properties":{"id":"20250922210540-falcapn","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多维度评估"},{"Type":"NodeText","Data":": 同时在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"聊天（AlpacaFarm）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问答（MMLU, BBH）"},{"Type":"NodeText","Data":"两个场景下进行评估，使得结论更具"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"说服力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210540-8axjm33","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-8axjm33","updated":"20250922210540"},"Children":[{"ID":"20250922210540-wr25tr4","Type":"NodeParagraph","Properties":{"id":"20250922210540-wr25tr4","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动化评估"},{"Type":"NodeText","Data":": 使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT作为裁判"},{"Type":"NodeText","Data":"（AlpacaFarm），是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效、可扩展"},{"Type":"NodeText","Data":"的评估方法，代表了LLM评估的前沿趋势。"}]}]}]},{"ID":"20250922210540-ta2oy9k","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210540-ta2oy9k","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结果分析的深刻洞见（已在表10解析中详述）"}]},{"ID":"20250922210540-8qyzbsu","Type":"NodeParagraph","Properties":{"id":"20250922210540-8qyzbsu","updated":"20250922210540"},"Children":[{"Type":"NodeText","Data":"这部分内容是对表10实验结果的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文字化总结和深入解读"},{"Type":"NodeText","Data":"。核心结论再次被强调："}]},{"ID":"20250922210540-5zbrud9","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210540-5zbrud9","updated":"20250922210540"},"Children":[{"ID":"20250922210540-gcrqaob","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210540-gcrqaob","updated":"20250922210540"},"Children":[{"ID":"20250922210540-f7obd74","Type":"NodeParagraph","Properties":{"id":"20250922210540-f7obd74","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据-任务匹配"},{"Type":"NodeText","Data":": 任务型数据利于QA，聊天型数据利于对话。"}]}]},{"ID":"20250922210540-qx259m4","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210540-qx259m4","updated":"20250922210540"},"Children":[{"ID":"20250922210540-f4hlwvn","Type":"NodeParagraph","Properties":{"id":"20250922210540-f4hlwvn","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合的力量"},{"Type":"NodeText","Data":": 混合数据能带来最全面的能力。"}]}]},{"ID":"20250922210540-tu5njae","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922210540-tu5njae","updated":"20250922210540"},"Children":[{"ID":"20250922210540-2dicjjt","Type":"NodeParagraph","Properties":{"id":"20250922210540-2dicjjt","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质胜于量"},{"Type":"NodeText","Data":": 提升复杂性和多样性有效，盲目堆砌数量有害。"}]}]},{"ID":"20250922210540-op8ii60","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922210540-op8ii60","updated":"20250922210540"},"Children":[{"ID":"20250922210540-gp117qu","Type":"NodeParagraph","Properties":{"id":"20250922210540-gp117qu","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":": 模型越大，学得越好。"}]}]}]},{"ID":"20250922210540-p1q3cv5","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210540-p1q3cv5","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“授人以渔”的实践建议"}]},{"ID":"20250922210540-o7yr1cd","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210540-o7yr1cd","updated":"20250922210540"},"Children":[{"ID":"20250922210540-e37nfby","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-e37nfby","updated":"20250922210540"},"Children":[{"ID":"20250922210540-0t7acvk","Type":"NodeParagraph","Properties":{"id":"20250922210540-0t7acvk","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"手把手教学"},{"Type":"NodeText","Data":": 这部分内容非常贴心，为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"初学者"},{"Type":"NodeText","Data":"提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰、可操作"},{"Type":"NodeText","Data":"的路线图。"}]},{"ID":"20250922210540-u3srlc0","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210540-u3srlc0","updated":"20250922210540"},"Children":[{"ID":"20250922210540-cehh9v1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-cehh9v1","updated":"20250922210540"},"Children":[{"ID":"20250922210540-cidvaa8","Type":"NodeParagraph","Properties":{"id":"20250922210540-cidvaa8","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第一步：准备资源"},{"Type":"NodeText","Data":"（参考表9）。"}]}]},{"ID":"20250922210540-bsai14m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-bsai14m","updated":"20250922210540"},"Children":[{"ID":"20250922210540-9nxt9q6","Type":"NodeParagraph","Properties":{"id":"20250922210540-9nxt9q6","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二步：搭建环境"},{"Type":"NodeText","Data":"（参考Alpaca代码库）。"}]}]},{"ID":"20250922210540-63aea7n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-63aea7n","updated":"20250922210540"},"Children":[{"ID":"20250922210540-7xmzbzs","Type":"NodeParagraph","Properties":{"id":"20250922210540-7xmzbzs","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三步：选择模型和数据"},{"Type":"NodeText","Data":"（参考本节讨论）。"}]}]}]}]},{"ID":"20250922210540-b6a6n3k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-b6a6n3k","updated":"20250922210540"},"Children":[{"ID":"20250922210540-c4ko0lq","Type":"NodeParagraph","Properties":{"id":"20250922210540-c4ko0lq","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“Plan B”"},{"Type":"NodeText","Data":": 充分考虑到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"资源受限"},{"Type":"NodeText","Data":"的情况，并给出了解决方案："}]},{"ID":"20250922210540-3u2u0d3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210540-3u2u0d3","updated":"20250922210540"},"Children":[{"ID":"20250922210540-zsqu6y8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-zsqu6y8","updated":"20250922210540"},"Children":[{"ID":"20250922210540-9gxptcq","Type":"NodeParagraph","Properties":{"id":"20250922210540-9gxptcq","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练时资源不够"},{"Type":"NodeText","Data":": 用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LoRA"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210540-nu2kyky","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-nu2kyky","updated":"20250922210540"},"Children":[{"ID":"20250922210540-znpq9pb","Type":"NodeParagraph","Properties":{"id":"20250922210540-znpq9pb","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理时资源不够"},{"Type":"NodeText","Data":": 用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"量化（Quantization）"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922210540-ncb6suh","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210540-ncb6suh","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调：从“能干”到“可靠”"}]},{"ID":"20250922210540-97zvrvo","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210540-97zvrvo","updated":"20250922210540"},"Children":[{"ID":"20250922210540-g2zdqy6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-g2zdqy6","updated":"20250922210540"},"Children":[{"ID":"20250922210540-vx8352x","Type":"NodeParagraph","Properties":{"id":"20250922210540-vx8352x","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题的提出"},{"Type":"NodeText","Data":": LLM虽然强大（“能干”），但其行为可能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“脱缰”"},{"Type":"NodeText","Data":"——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"产生虚假、有害、有偏见"},{"Type":"NodeText","Data":"的内容。"}]}]},{"ID":"20250922210540-0khheqc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-0khheqc","updated":"20250922210540"},"Children":[{"ID":"20250922210540-342w54k","Type":"NodeParagraph","Properties":{"id":"20250922210540-342w54k","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本原因"},{"Type":"NodeText","Data":": 预训练目标（预测下一个词）与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类的价值观和偏好"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"脱节"},{"Type":"NodeText","Data":"的。模型只学会了“怎么说”，但不知道“该怎么说”。"}]}]},{"ID":"20250922210540-uo67hvd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-uo67hvd","updated":"20250922210540"},"Children":[{"ID":"20250922210540-9v70ka4","Type":"NodeParagraph","Properties":{"id":"20250922210540-9v70ka4","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解决方案"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐 (Human Alignment)"},{"Type":"NodeText","Data":"。其核心目标是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将人类的价值观注入模型"},{"Type":"NodeText","Data":"，使其行为符合人类的期望。这是让LLM从一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“聪明的工具”"},{"Type":"NodeText","Data":"转变为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“可靠的助手”"},{"Type":"NodeText","Data":"的关键一步。"}]}]}]}]},{"ID":"20250922210540-jghd6me","Type":"NodeThematicBreak","Properties":{"id":"20250922210540-jghd6me","updated":"20250922210601"}},{"ID":"20250922210540-14kwxen","Type":"NodeBlockquote","Properties":{"id":"20250922210540-14kwxen","updated":"20250922210601"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210540-30jr58x","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210540-30jr58x","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922210540-vtwjggy","Type":"NodeParagraph","Properties":{"id":"20250922210540-vtwjggy","updated":"20250922210540"},"Children":[{"Type":"NodeText","Data":"第二十九部分是指令微调章节的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“压轴戏”"},{"Type":"NodeText","Data":"，它通过严谨的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实证分析"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可操作的实践建议"},{"Type":"NodeText","Data":"，将理论知识转化为了看得见、摸得着的结论和指南。同时，它也顺理成章地引出了LLM发展的下一个核心议题——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调（Alignment Tuning）"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922210540-83uy2ie","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210540-83uy2ie","updated":"20250922210540"},"Children":[{"ID":"20250922210540-8i0e90l","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210540-8i0e90l","updated":"20250922210540"},"Children":[{"ID":"20250922210540-ev9m6si","Type":"NodeParagraph","Properties":{"id":"20250922210540-ev9m6si","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学方法论的体现"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210540-1hlgnqi","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210540-1hlgnqi","updated":"20250922210540"},"Children":[{"ID":"20250922210540-kcgyubl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-kcgyubl","updated":"20250922210540"},"Children":[{"ID":"20250922210540-x0qcvzh","Type":"NodeParagraph","Properties":{"id":"20250922210540-x0qcvzh","updated":"20250922210540"},"Children":[{"Type":"NodeText","Data":"本部分的实验设计和分析，是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学方法论"},{"Type":"NodeText","Data":"在AI研究中的一次完美展示。它通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提出假设、控制变量、进行实验、分析结果、得出结论"},{"Type":"NodeText","Data":"的完整流程，将“指令微调”这门“艺术”转化为了可以量化研究的“科学”。"}]}]},{"ID":"20250922210540-2t7g4po","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-2t7g4po","updated":"20250922210540"},"Children":[{"ID":"20250922210540-dmnwmcv","Type":"NodeParagraph","Properties":{"id":"20250922210540-dmnwmcv","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“质量远胜于数量”"},{"Type":"NodeText","Data":"这一核心结论，是通过数据得出的，具有极强的说服力，为社区提供了宝贵的、反直觉的经验。"}]}]}]}]},{"ID":"20250922210540-g5t29yd","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210540-g5t29yd","updated":"20250922210540"},"Children":[{"ID":"20250922210540-b2c0n4n","Type":"NodeParagraph","Properties":{"id":"20250922210540-b2c0n4n","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“象牙塔”到“现实世界”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210540-sis86ih","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210540-sis86ih","updated":"20250922210540"},"Children":[{"ID":"20250922210540-14srwfr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-14srwfr","updated":"20250922210540"},"Children":[{"ID":"20250922210540-uthjuln","Type":"NodeParagraph","Properties":{"id":"20250922210540-uthjuln","updated":"20250922210540"},"Children":[{"Type":"NodeText","Data":"“指令微调建议”部分，体现了本综述"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强烈的实践导向"},{"Type":"NodeText","Data":"。它不仅告诉读者“是什么”和“为什么”，更重要的是，它告诉读者"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“怎么做”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210540-e9isl73","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-e9isl73","updated":"20250922210540"},"Children":[{"ID":"20250922210540-7d3mzye","Type":"NodeParagraph","Properties":{"id":"20250922210540-7d3mzye","updated":"20250922210540"},"Children":[{"Type":"NodeText","Data":"通过推荐具体的代码库（Alpaca）、技术方案（LoRA, Quantization），它为资源有限的开发者和研究者"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"铺平了通往LLM微调的道路"},{"Type":"NodeText","Data":"，极大地降低了实践门槛。"}]}]}]}]},{"ID":"20250922210540-c98bd1y","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922210540-c98bd1y","updated":"20250922210540"},"Children":[{"ID":"20250922210540-3sdu2l4","Type":"NodeParagraph","Properties":{"id":"20250922210540-3sdu2l4","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力与价值观的辩证统一"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210540-wbh18j8","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210540-wbh18j8","updated":"20250922210540"},"Children":[{"ID":"20250922210540-1qe6ek0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-1qe6ek0","updated":"20250922210540"},"Children":[{"ID":"20250922210540-piqgxbx","Type":"NodeParagraph","Properties":{"id":"20250922210540-piqgxbx","updated":"20250922210540"},"Children":[{"Type":"NodeText","Data":"从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调"},{"Type":"NodeText","Data":"的过渡，自然地引出了LLM发展的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心矛盾"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力（Capability）"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐（Alignment）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210540-zz8v9au","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-zz8v9au","updated":"20250922210540"},"Children":[{"ID":"20250922210540-rnn53aw","Type":"NodeParagraph","Properties":{"id":"20250922210540-rnn53aw","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"主要解决的是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“能力”"},{"Type":"NodeText","Data":"问题，让模型变得更强大、更通用。"}]}]},{"ID":"20250922210540-n98e7rw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-n98e7rw","updated":"20250922210540"},"Children":[{"ID":"20250922210540-onctlz3","Type":"NodeParagraph","Properties":{"id":"20250922210540-onctlz3","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调"},{"Type":"NodeText","Data":"则主要解决"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“价值观”"},{"Type":"NodeText","Data":"问题，让模型变得更安全、更可靠。"}]}]},{"ID":"20250922210540-gshgr54","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210540-gshgr54","updated":"20250922210540"},"Children":[{"ID":"20250922210540-vj7vqjk","Type":"NodeParagraph","Properties":{"id":"20250922210540-vj7vqjk","updated":"20250922210540"},"Children":[{"Type":"NodeText","Data":"这两者共同构成了打造一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"负责任的、有用的AI"},{"Type":"NodeText","Data":"的两个基本面，缺一不可。"}]}]}]}]}]},{"ID":"20250922210540-me9rf8y","Type":"NodeParagraph","Properties":{"id":"20250922210540-me9rf8y","updated":"20250922210540"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第二十九部分是理论与实践的完美结合。它用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据"},{"Type":"NodeText","Data":"为指令微调的各种策略“排座次”，用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指南"},{"Type":"NodeText","Data":"为初学者“铺路”，深刻地揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"质量"},{"Type":"NodeText","Data":"在数据工程中的核心地位。最终，通过引出“对齐”这一主题，它将我们对LLM的思考从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“它能做什么”"},{"Type":"NodeText","Data":"，提升到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“它应该做什么”"},{"Type":"NodeText","Data":"的更高哲学层面。"}]}]},{"ID":"20250922210728-n9gbp3k","Type":"NodeParagraph","Properties":{"id":"20250922210728-n9gbp3k","updated":"20250922210728"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922210728-w1fxz6a","Type":"NodeThematicBreak","Properties":{"id":"20250922210728-w1fxz6a","updated":"20250922210728"}},{"ID":"20250922210728-k5hfui1","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210728-k5hfui1","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三十部分"}]},{"ID":"20250922210728-a0f5l4q","Type":"NodeParagraph","Properties":{"id":"20250922210728-a0f5l4q","updated":"20250922210740"},"Children":[{"Type":"NodeText","Data":"预训练和适配调整（例如，指令微调），这种对齐需要考虑非常不同的标准（例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性、诚实性和无害性"},{"Type":"NodeText","Data":"）。已有研究表明，对齐在某种程度上可能会损害LLM的通用能力，这在相关文献中被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐税（alignment tax）"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922210728-hzaid3l","Type":"NodeParagraph","Properties":{"id":"20250922210728-hzaid3l","updated":"20250922210740"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alignment Criteria (对齐标准)."},{"Type":"NodeText","Data":" 最近，人们越来越关注为规范LLM的行为制定多方面的标准。在这里，我们以三个代表性的对齐标准（即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用、诚-实和无害"},{"Type":"NodeText","Data":"）为例进行讨论，这些标准在现有文献中被广泛采用。此外，从不同角度还有其他的LLM对齐标准，包括行为、意图、激励和内部方面，这些标准与上述三个标准基本相似（或至少具有相似的对齐技术）。根据特定需求修改这三个标准也是可行的，例如，用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正确性"},{"Type":"NodeText","Data":"替代诚实性。接下来，我们对这三个代表性对齐标准进行简要解释："}]},{"ID":"20250922210728-jlt5n32","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-jlt5n32","updated":"20250922210740"},"Children":[{"ID":"20250922210728-9p785pf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-9p785pf","updated":"20250922210728"},"Children":[{"ID":"20250922210728-oiol53a","Type":"NodeParagraph","Properties":{"id":"20250922210728-oiol53a","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性 (Helpfulness)."},{"Type":"NodeText","Data":" 为了有用，LLM应表现出明确的意图，以尽可能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简洁高效"},{"Type":"NodeText","Data":"的方式帮助用户解决他们的任务或回答他们的问题。在更高层面上，当需要进一步澄清时，LLM应展现出通过相关查询引出额外相关信息的能力，并表现出适当水平的敏感性、洞察力和审慎性。实现有用行为的对齐对LLM来说具有挑战性，因为很难精确定义和衡量用户的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"意图"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210728-ambdchq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-ambdchq","updated":"20250922210728"},"Children":[{"ID":"20250922210728-d4g0sz5","Type":"NodeParagraph","Properties":{"id":"20250922210728-d4g0sz5","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"诚实性 (Honesty)."},{"Type":"NodeText","Data":" 在基本层面上，一个被对齐为诚实的LLM应该向用户呈现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"准确的内容"},{"Type":"NodeText","Data":"，而不是捏造信息。此外，LLM在其输出中传达"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"适当程度的不确定性"},{"Type":"NodeText","Data":"至关重要，以避免任何形式的欺骗或信息误传。这要求模型了解自身的能力和知识水平（例如，“知之为知之，不知为不知”）。根据中的讨论，与有用性和无害性相比，诚实性是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更客观"},{"Type":"NodeText","Data":"的标准，因此诚实性对齐的开发可能可以减少对人类努力的依赖。"}]}]},{"ID":"20250922210728-wuu4kof","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-wuu4kof","updated":"20250922210728"},"Children":[{"ID":"20250922210728-eu8q6l4","Type":"NodeParagraph","Properties":{"id":"20250922210728-eu8q6l4","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无害性 (Harmlessness)."},{"Type":"NodeText","Data":" 为了无害，模型产生的语言不应具有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"攻击性或歧视性"},{"Type":"NodeText","Data":"。在能力范围内，模型应能够检测到旨在索取恶意目的请求的隐蔽企图。理想情况下，当模型被诱导执行危险行为（例如，实施犯罪）时，LLM应礼貌地拒绝。然而，哪些行为被认为是-有害的以及在何种程度上，很大程度上取决于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"谁"},{"Type":"NodeText","Data":"在使用LLM、提出的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题类型"},{"Type":"NodeText","Data":"以及LLM被使用的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"情境"},{"Type":"NodeText","Data":"（例如，时间）。"}]}]}]},{"ID":"20250922210728-rkcwcmo","Type":"NodeParagraph","Properties":{"id":"20250922210728-rkcwcmo","updated":"20250922210740"},"Children":[{"Type":"NodeText","Data":"正如我们所见，这些标准非常"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主观"},{"Type":"NodeText","Data":"，并且是基于人类认知发展的。因此，很难将它们直接形式化为LLM的优化目标。在现有的工作中，有许多方法可以在对齐LLM时满足这些标准。一种有前景的技术是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"红队测试"},{"Type":"NodeText","Data":"，它涉及使用手动或自动化的方式，以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性"},{"Type":"NodeText","Data":"的方式探测LLM以生成有害输出，然后更新LLM以防止此类输出。"}]},{"ID":"20250922210728-rbxhetp","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210728-rbxhetp","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.2.2 Collecting Human Feedback (收集人类反馈)"}]},{"ID":"20250922210728-msoqhu7","Type":"NodeParagraph","Properties":{"id":"20250922210728-msoqhu7","updated":"20250922210740"},"Children":[{"Type":"NodeText","Data":"在预训练阶段，LLM是使用大规模语料库上的语言建模目标进行训练的。然而，它无法考虑人类对LLM输出的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主观和定性"},{"Type":"NodeText","Data":"评估（在本综述中称为人类反馈）。高质量的人类反馈对于使LLM与人类偏好和价值观对齐至关重要。在本部分中，我们讨论如何为反馈数据收集选择一个人类标注员团队。"}]},{"ID":"20250922210728-jzom3r1","Type":"NodeParagraph","Properties":{"id":"20250922210728-jzom3r1","updated":"20250922210740"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Human Labeler Selection (人类标注员选择)."},{"Type":"NodeText","Data":" 在现有的工作中，生成人类反馈数据的主要方法是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类标注"},{"Type":"NodeText","Data":"。这突显了选择合适的人类标注员的关键作用。为了提供高质量的反馈，人类标注员应该具有合格的教育水平和出色的英语水平。例如，Sparrow要求人类标注员是英国本土的英语使用者，并且至少获得了本科学历。即便如此，一些研究发现，研究人员的意图与人类标注员之间仍然存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不匹配"},{"Type":"NodeText","Data":"，这可能导致低质量的人类反馈，并使LLM产生意想不到的输出。为了解决这个问题，InstructGPT进一步进行了一个筛选过程来过滤标注员，通过评估人类标注员和研究人员之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一致性"},{"Type":"NodeText","Data":"。具体来说，研究人员首先标注少量数据，然后衡量他们自己与人类标注员之间的一致性。具有最高一致性的标注员将被选中进行后续的标注工作。在其他一些工作中，使用“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超级评分员（super raters）"},{"Type":"NodeText","Data":"”来确保人类反馈的高质量。研究人员评估人类标注员的表现，并选择一组表现良好的人类标注员（例如，一致性高）作为超级评分员。超级评分员将在后续的研究中被优先考虑与研究人员合作。当人类标注员标注LLM的输出时，指定详细的指令并为人类标注员提供即时指导是很有帮助的，这可以进一步规范标注员的标注行为。"}]},{"ID":"20250922210728-9m2x4gb","Type":"NodeParagraph","Properties":{"id":"20250922210728-9m2x4gb","updated":"20250922210740"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Human Feedback Collection (人类反馈收集)."},{"Type":"NodeText","Data":" 在现有的工作中，主要有三种从人类标注员那里收集反馈和偏好数据的方法。"}]},{"ID":"20250922210728-7w8fdmq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-7w8fdmq","updated":"20250922210740"},"Children":[{"ID":"20250922210728-ehlp3lo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-ehlp3lo","updated":"20250922210728"},"Children":[{"ID":"20250922210728-c2t3jtr","Type":"NodeParagraph","Properties":{"id":"20250922210728-c2t3jtr","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于排序的方法 (Ranking-based approach)."},{"Type":"NodeText","Data":" 在早期的工作中，人类标注员通常以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"粗粒度"},{"Type":"NodeText","Data":"的方式评估模型生成的输出（即，只选择最好的），而没有考虑更细粒度的对齐标准。然而，不同的标注员可能对最佳候选输出的选择持有不同意见，并且这种方法忽略了未被选择的样本，这可能导致不准确或不完整的人类反馈。为了解决这个问题，后续的研究引入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Elo评分系统"},{"Type":"NodeText","Data":"，通过比较候选输出来推导偏好排名。输出的排名作为训练信号，引导模型偏爱某些输出而非其他，从而引导出更可靠和更安全的输出。"}]}]},{"ID":"20250922210728-bxzd445","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-bxzd445","updated":"20250922210728"},"Children":[{"ID":"20250922210728-e7sqkqx","Type":"NodeParagraph","Properties":{"id":"20250922210728-e7sqkqx","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于问题的方法 (Question-based approach)."},{"Type":"NodeText","Data":" 此外，人类标注员可以通过回答研究人员设计的某些问题来提供更详细的反馈，涵盖对齐"}]}]}]},{"ID":"20250922210728-pstadxx","Type":"NodeBlockquote","Properties":{"id":"20250922210728-pstadxx","updated":"20250922210740"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210728-sjbfbjx","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210728-sjbfbjx","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922210728-38u7504","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210728-38u7504","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐：为AI装上“道德罗盘”"}]},{"ID":"20250922210728-gqtonj5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-gqtonj5","updated":"20250922210728"},"Children":[{"ID":"20250922210728-oyvyd43","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-oyvyd43","updated":"20250922210728"},"Children":[{"ID":"20250922210728-btrj3vt","Type":"NodeParagraph","Properties":{"id":"20250922210728-btrj3vt","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为什么需要对齐"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210728-i331518","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-i331518","updated":"20250922210728"},"Children":[{"ID":"20250922210728-hv5140j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-hv5140j","updated":"20250922210728"},"Children":[{"ID":"20250922210728-nc3ebvq","Type":"NodeParagraph","Properties":{"id":"20250922210728-nc3ebvq","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本矛盾"},{"Type":"NodeText","Data":": LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练目标（预测下一个词）"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类的期望（有用、诚实、无害）"},{"Type":"NodeText","Data":"之间存在根本的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不一致"},{"Type":"NodeText","Data":"。模型只会模仿数据，而数据本身可能包含错误、偏见和有害信息。"}]}]},{"ID":"20250922210728-q26dh8c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-q26dh8c","updated":"20250922210728"},"Children":[{"ID":"20250922210728-dw3b59d","Type":"NodeParagraph","Properties":{"id":"20250922210728-dw3b59d","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐税 (Alignment Tax)"},{"Type":"NodeText","Data":": 一个深刻的洞见。对齐的过程，本质上是在给模型增加"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“约束”"},{"Type":"NodeText","Data":"。这种约束可能会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“牺牲”"},{"Type":"NodeText","Data":"掉模型的一部分"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用能力"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"创造性"},{"Type":"NodeText","Data":"。例如，一个极度安全的模型可能会拒绝回答很多模棱两可的问题。这是一个必须面对的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"权衡"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922210728-0ouq8mg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-0ouq8mg","updated":"20250922210728"},"Children":[{"ID":"20250922210728-tt3zji5","Type":"NodeParagraph","Properties":{"id":"20250922210728-tt3zji5","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐的“3H”标准"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210728-3svej9e","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-3svej9e","updated":"20250922210728"},"Children":[{"ID":"20250922210728-8lmk03s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-8lmk03s","updated":"20250922210728"},"Children":[{"ID":"20250922210728-0nkbn11","Type":"NodeParagraph","Properties":{"id":"20250922210728-0nkbn11","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用 (Helpful)"},{"Type":"NodeText","Data":": 不仅要给出答案，还要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理解用户的真实意图"},{"Type":"NodeText","Data":"，并以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效、简洁"},{"Type":"NodeText","Data":"的方式提供帮助。这是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“情商”"},{"Type":"NodeText","Data":"的要求。"}]}]},{"ID":"20250922210728-16a5aq3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-16a5aq3","updated":"20250922210728"},"Children":[{"ID":"20250922210728-d9i8fye","Type":"NodeParagraph","Properties":{"id":"20250922210728-d9i8fye","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"诚实 (Honest)"},{"Type":"NodeText","Data":": 不仅要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"事实准确"},{"Type":"NodeText","Data":"，还要能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表达不确定性"},{"Type":"NodeText","Data":"（“知之为知之，不知为不知”）。这是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“智商”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“诚信”"},{"Type":"NodeText","Data":"的要求。作者指出这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最客观"},{"Type":"NodeText","Data":"的一条，可能最容易通过技术手段实现。"}]}]},{"ID":"20250922210728-7v2s7vo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-7v2s7vo","updated":"20250922210728"},"Children":[{"ID":"20250922210728-i2ly7jt","Type":"NodeParagraph","Properties":{"id":"20250922210728-i2ly7jt","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无害 (Harmless)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不产生攻击性、歧视性"},{"Type":"NodeText","Data":"内容，并能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"识别和拒绝恶意"},{"Type":"NodeText","Data":"的诱导。这是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“道德底线”"},{"Type":"NodeText","Data":"的要求，也是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最主观、最复杂"},{"Type":"NodeText","Data":"的一条，因为它与文化、情境高度相关。"}]}]}]}]},{"ID":"20250922210728-3lbj41a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-3lbj41a","updated":"20250922210728"},"Children":[{"ID":"20250922210728-0goqyj2","Type":"NodeParagraph","Properties":{"id":"20250922210728-0goqyj2","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"红队测试 (Red Teaming)"},{"Type":"NodeText","Data":": 是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主动的、对抗性的"},{"Type":"NodeText","Data":"安全测试方法。不是被动地等待模型犯错，而是像“黑客”一样，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专门设计各种刁钻、恶意的提示，去攻击和诱导模型犯错"},{"Type":"NodeText","Data":"，然后利用这些“失败案例”来修复和加固模型。这是保障模型安全性的关键实践。"}]}]}]},{"ID":"20250922210728-kusgh4z","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210728-kusgh4z","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类反馈：对齐的“数据源”"}]},{"ID":"20250922210728-ewwkd3r","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-ewwkd3r","updated":"20250922210728"},"Children":[{"ID":"20250922210728-yqyd57q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-yqyd57q","updated":"20250922210728"},"Children":[{"ID":"20250922210728-hkj9rng","Type":"NodeParagraph","Properties":{"id":"20250922210728-hkj9rng","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标注员的选择是关键 (Human Labeler Selection)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210728-gryl2db","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-gryl2db","updated":"20250922210728"},"Children":[{"ID":"20250922210728-le0r6m8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-le0r6m8","updated":"20250922210728"},"Children":[{"ID":"20250922210728-q5q35dd","Type":"NodeParagraph","Properties":{"id":"20250922210728-q5q35dd","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高标准"},{"Type":"NodeText","Data":": 对标注员的要求极高，不仅要语言流利，还要有良好的教育背景。"}]}]},{"ID":"20250922210728-qjdywmm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-qjdywmm","updated":"20250922210728"},"Children":[{"ID":"20250922210728-fhnnq6x","Type":"NodeParagraph","Properties":{"id":"20250922210728-fhnnq6x","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“对表”"},{"Type":"NodeText","Data":": 通过让标注员与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心研究人员"},{"Type":"NodeText","Data":"标注同一批数据，来计算"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“一致性”"},{"Type":"NodeText","Data":"，筛选出最理解项目意图的标注员。"}]}]},{"ID":"20250922210728-kwjcu6c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-kwjcu6c","updated":"20250922210728"},"Children":[{"ID":"20250922210728-odtju5p","Type":"NodeParagraph","Properties":{"id":"20250922210728-odtju5p","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“超级评分员”"},{"Type":"NodeText","Data":": 建立一个经过考验的、高质量的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心标注员团队"},{"Type":"NodeText","Data":"，是保证数据质量的关键。"}]}]}]}]},{"ID":"20250922210728-1ep3z7r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-1ep3z7r","updated":"20250922210728"},"Children":[{"ID":"20250922210728-gjneo3q","Type":"NodeParagraph","Properties":{"id":"20250922210728-gjneo3q","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反馈的收集方式"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210728-pza53mt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-pza53mt","updated":"20250922210728"},"Children":[{"ID":"20250922210728-ygngnwb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-ygngnwb","updated":"20250922210728"},"Children":[{"ID":"20250922210728-ufb5669","Type":"NodeParagraph","Properties":{"id":"20250922210728-ufb5669","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于排序 (Ranking-based)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最核心、最常用"},{"Type":"NodeText","Data":"的方法。相比于让标注员给出一个绝对分数（这很难统一标准），让他们在两个或多个回答中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“选出更好的一个”"},{"Type":"NodeText","Data":"要简单得多，也更符合人类的直觉。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Elo评分系统"},{"Type":"NodeText","Data":"就是将这种成对的比较，转化为一个全局的、量化的排名。"}]}]},{"ID":"20250922210728-cxlzw38","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-cxlzw38","updated":"20250922210728"},"Children":[{"ID":"20250922210728-rvhrovl","Type":"NodeParagraph","Properties":{"id":"20250922210728-rvhrovl","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于问题 (Question-based)"},{"Type":"NodeText","Data":": 这是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更细粒度"},{"Type":"NodeText","Data":"的反馈。通过设计一系列具体的问题（例如，“这个回答是否全面？”“它是否包含了不相关的信息？”），来收集关于回答"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多个维度"},{"Type":"NodeText","Data":"的反馈。"}]}]}]}]}]}]},{"ID":"20250922210728-4tk96x8","Type":"NodeThematicBreak","Properties":{"id":"20250922210728-4tk96x8","updated":"20250922210740"}},{"ID":"20250922210728-1k3an5m","Type":"NodeBlockquote","Properties":{"id":"20250922210728-1k3an5m","updated":"20250922210740"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210728-7s7u1ya","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210728-7s7u1ya","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922210728-l4bmtl3","Type":"NodeParagraph","Properties":{"id":"20250922210728-l4bmtl3","updated":"20250922210728"},"Children":[{"Type":"NodeText","Data":"第三十部分深入探讨了大型语言模型（LLM）发展的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“灵魂”所在——对齐（Alignment）"},{"Type":"NodeText","Data":"。它系统地阐述了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为什么需要对齐、对齐的标准是什么，以及如何获取用于对齐的高质量数据"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922210728-q0phfuz","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210728-q0phfuz","updated":"20250922210728"},"Children":[{"ID":"20250922210728-bttlwm5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210728-bttlwm5","updated":"20250922210728"},"Children":[{"ID":"20250922210728-wd0wfmt","Type":"NodeParagraph","Properties":{"id":"20250922210728-wd0wfmt","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“能力”到“品性”的升华"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210728-45sm2f9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-45sm2f9","updated":"20250922210728"},"Children":[{"ID":"20250922210728-566x5is","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-566x5is","updated":"20250922210728"},"Children":[{"ID":"20250922210728-7tjgivd","Type":"NodeParagraph","Properties":{"id":"20250922210728-7tjgivd","updated":"20250922210728"},"Children":[{"Type":"NodeText","Data":"如果说预训练和指令微调解决了LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“智商”"},{"Type":"NodeText","Data":"（能力）问题，那么对齐微调则旨在解决其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“情商”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“德商”"},{"Type":"NodeText","Data":"（品性）问题。"}]}]},{"ID":"20250922210728-4wvidu7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-4wvidu7","updated":"20250922210728"},"Children":[{"ID":"20250922210728-hld2d9v","Type":"NodeParagraph","Properties":{"id":"20250922210728-hld2d9v","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“对齐税”"},{"Type":"NodeText","Data":"概念的提出，深刻揭示了这一过程的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂性与权衡"},{"Type":"NodeText","Data":"。它告诉我们，追求一个绝对安全、绝对对齐的模型，可能会以牺牲其部分能力和创造性为代价。如何在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“有用性”、“创造性”"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“安全性”"},{"Type":"NodeText","Data":"之间找到最佳平衡点，是LLM发展中一个永恒的挑战。"}]}]}]}]},{"ID":"20250922210728-nv9q2i7","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210728-nv9q2i7","updated":"20250922210728"},"Children":[{"ID":"20250922210728-sjp46b3","Type":"NodeParagraph","Properties":{"id":"20250922210728-sjp46b3","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“3H”标准：构建负责任AI的基石"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210728-v99myu0","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-v99myu0","updated":"20250922210728"},"Children":[{"ID":"20250922210728-txsddc8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-txsddc8","updated":"20250922210728"},"Children":[{"ID":"20250922210728-qb8ln93","Type":"NodeParagraph","Properties":{"id":"20250922210728-qb8ln93","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用 (Helpful)、诚实 (Honest)、无害 (Harmless)"},{"Type":"NodeText","Data":" 这三大标准，为对齐工作提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰、可操作"},{"Type":"NodeText","Data":"的指导原则。"}]}]},{"ID":"20250922210728-975wob8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-975wob8","updated":"20250922210728"},"Children":[{"ID":"20250922210728-7xvd3o8","Type":"NodeParagraph","Properties":{"id":"20250922210728-7xvd3o8","updated":"20250922210728"},"Children":[{"Type":"NodeText","Data":"它将一个模糊的“对齐”概念，分解为了三个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可以被评估和优化"},{"Type":"NodeText","Data":"的具体维度，为后续的RLHF等技术实现奠定了基础。这套标准已成为业界广泛接受的共识。"}]}]}]}]},{"ID":"20250922210728-7a7enlc","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922210728-7a7enlc","updated":"20250922210728"},"Children":[{"ID":"20250922210728-wy0i06s","Type":"NodeParagraph","Properties":{"id":"20250922210728-wy0i06s","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类反馈工程：一门新兴的交叉学科"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210728-n75qjxq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210728-n75qjxq","updated":"20250922210728"},"Children":[{"ID":"20250922210728-oz0mq27","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-oz0mq27","updated":"20250922210728"},"Children":[{"ID":"20250922210728-a3e2smh","Type":"NodeParagraph","Properties":{"id":"20250922210728-a3e2smh","updated":"20250922210728"},"Children":[{"Type":"NodeText","Data":"本部分揭示了，获取高质量的人类反馈本身就是一门"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂的系统工程"},{"Type":"NodeText","Data":"，它融合了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"心理学、社会学和计算机科学"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210728-evdnn9m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-evdnn9m","updated":"20250922210728"},"Children":[{"ID":"20250922210728-oj52q5s","Type":"NodeParagraph","Properties":{"id":"20250922210728-oj52q5s","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从标注员的筛选（一致性检验、超级评分员）到反馈机制的设计（基于排序、基于问题）"},{"Type":"NodeText","Data":"，每一个环节都需要精心策划，才能保证输入给模型的“价值观数据”是准确、一致且高质量的。"}]}]},{"ID":"20250922210728-v3pdisp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210728-v3pdisp","updated":"20250922210728"},"Children":[{"ID":"20250922210728-8m2zhk8","Type":"NodeParagraph","Properties":{"id":"20250922210728-8m2zhk8","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于排序"},{"Type":"NodeText","Data":"的方法，特别是结合"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Elo评分系统"},{"Type":"NodeText","Data":"，已成为当前最主流、最高效的反馈收集范式。"}]}]}]}]}]},{"ID":"20250922210728-1x1ef2u","Type":"NodeParagraph","Properties":{"id":"20250922210728-1x1ef2u","updated":"20250922210728"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第三十部分从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"必要性、标准和数据来源"},{"Type":"NodeText","Data":"三个层面，系统地构建了对“对齐”这一核心概念的理解。它清晰地表明，对齐不仅是技术问题，更是一个涉及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"价值观、社会规范和人类认知"},{"Type":"NodeText","Data":"的复杂议题。而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高质量、精心设计的人类反馈"},{"Type":"NodeText","Data":"，则是将这些抽象的价值观注入到冰冷的模型参数中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"唯一桥梁"},{"Type":"NodeText","Data":"。这一部分的论述，为理解为何现代LLM（如ChatGPT, Claude）能够如此“懂事”和“可靠”提供了根本性的解释。"}]}]},{"ID":"20250922210909-d661toj","Type":"NodeParagraph","Properties":{"id":"20250922210909-d661toj","updated":"20250922210909"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922210909-h3xhrc0","Type":"NodeThematicBreak","Properties":{"id":"20250922210909-h3xhrc0","updated":"20250922210909"}},{"ID":"20250922210909-387bcpi","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210909-387bcpi","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三十一部分"}]},{"ID":"20250922210909-h6ansbq","Type":"NodeParagraph","Properties":{"id":"20250922210909-h6ansbq","updated":"20250922210930"},"Children":[{"Type":"NodeText","Data":"标准以及对LLM的额外约束。特别是在WebGPT中，为了帮助模型过滤和利用从检索到的文档中的相关信息，人类标注员被要求回答带有多个选项的问题，这些问题涉及检索到的文档对于回答给定输入是否有用。"}]},{"ID":"20250922210909-gub0mbb","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-gub0mbb","updated":"20250922210930"},"Children":[{"ID":"20250922210909-y6g1ms6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-y6g1ms6","updated":"20250922210909"},"Children":[{"ID":"20250922210909-lslcw1o","Type":"NodeParagraph","Properties":{"id":"20250922210909-lslcw1o","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于规则的方法 (Rule-based approach)."},{"Type":"NodeText","Data":" 许多研究也开发了基于规则的方法来提供更详细的人类反馈。作为一个典型的案例，Sparrow不仅选择标注员认为最好的响应，还使用一系列规则来测试模型生成的响应是否满足"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用、正确和无害"},{"Type":"NodeText","Data":"的对齐标准。通过这种方式，可以获得两种人类反馈数据：（1）通过成对比较模型生成的输出质量获得的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"响应偏好反馈"},{"Type":"NodeText","Data":"，以及（2）通过收集人类标注员的评估（即一个分数，表示生成的输出在多大程度上违反了规则）获得的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规则违反反馈"},{"Type":"NodeText","Data":"。此外，GPT-4利用一组零样本分类器（基于GPT-4本身）作为基于规则的奖励模型，可以自动确定模型生成的输出是否违反了一组人类编写的规则。"}]}]}]},{"ID":"20250922210909-8fagx8j","Type":"NodeParagraph","Properties":{"id":"20250922210909-8fagx8j","updated":"20250922210930"},"Children":[{"Type":"NodeText","Data":"接下来，我们将重点介绍一种著名的技术，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从人类反馈中进行强化学习（RLHF）"},{"Type":"NodeText","Data":"，该技术已在最近强大的LLM（如ChatGPT）中被广泛使用。如下文所讨论的，在5.2.1节中介绍的对齐标准可以通过学习人类对LLM响应用户查询的反馈来满足。"}]},{"ID":"20250922210909-tw4pktj","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210909-tw4pktj","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.2.3 Reinforcement Learning from Human Feedback (从人类反馈中进行强化学习)"}]},{"ID":"20250922210909-10hdac7","Type":"NodeParagraph","Properties":{"id":"20250922210909-10hdac7","updated":"20250922210930"},"Children":[{"Type":"NodeText","Data":"为了使LLM与人类价值观对齐，提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从人类反馈中进行强化学习（RLHF）"},{"Type":"NodeText","Data":"，用收集到的人类反馈数据来微调LLM，这有助于提升对齐标准（例如，有用性、诚实性和无害性）。RLHF采用强化学习（RL）算法（例如，近端策略优化（PPO））来使LLM适应人类反馈，通过学习一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型"},{"Type":"NodeText","Data":"。这种方法将人类纳入训练循环，以开发良好对齐的LLM，InstructGPT就是一个例证。"}]},{"ID":"20250922210909-ppdhr5l","Type":"NodeParagraph","Properties":{"id":"20250922210909-ppdhr5l","updated":"20250922210930"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF System (RLHF系统)."},{"Type":"NodeText","Data":" RLHF系统主要包括三个关键组成部分：一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"待对齐的预训练LM"},{"Type":"NodeText","Data":"，一个从人类反馈中学习的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型"},{"Type":"NodeText","Data":"，以及一个训练LM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RL算法"},{"Type":"NodeText","Data":"。具体来说，预训练LM通常是一个生成模型，用现有的预训练LM参数进行初始化。例如，OpenAI在其第一个流行的RLHF模型InstructGPT中使用了175B的GPT-3，而DeepMind在其GopherCite模型中使用了2800亿参数的模型Gopher。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型（RM）"},{"Type":"NodeText","Data":"提供（学习到的）指导信号，以反映人类对LM生成的文本的偏好，通常以标量值的形式。奖励模型可以有两种形式：一个微调过的LM或一个从头开始训练的LM。现有的工作通常采用参数规模与被对齐LM不同的奖励模型。例如，OpenAI使用6B的GPT-3，而DeepMind使用7B的Gopher作为奖励模型。最后，为了使用来自奖励模型的信号来优化预训练LM，需要为大规模模型微调设计一个特定的RL算法。具体来说，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"近端策略优化（PPO）"},{"Type":"NodeText","Data":"是现有工作中广泛用于对齐的RL算法。"}]},{"ID":"20250922210909-khhsjnw","Type":"NodeParagraph","Properties":{"id":"20250922210909-khhsjnw","updated":"20250922210930"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Key Steps for RLHF (RLHF的关键步骤)."},{"Type":"NodeText","Data":" 图12说明了RLHF的整个三步过程，如下文所述。"}]},{"ID":"20250922210909-w2w35lz","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-w2w35lz","updated":"20250922210930"},"Children":[{"ID":"20250922210909-jsgq8uy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-jsgq8uy","updated":"20250922210909"},"Children":[{"ID":"20250922210909-lz0ckjx","Type":"NodeParagraph","Properties":{"id":"20250922210909-lz0ckjx","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"监督微调 (Supervised fine-tuning)."},{"Type":"NodeText","Data":" 为了使LM初步表现出期望的行为，通常需要收集一个包含输入提示（指令）和期望输出的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"监督数据集"},{"Type":"NodeText","Data":"来对LM进行微调。这些提示和输出可以由人类标注员为某些特定任务编写，同时确保任务的多样性。例如，InstructGPT要求人类标注员为几种生成性任务（如开放式问答、头脑风暴、聊天和重写）编写提示（例如，“为我如何重拾对事业的热情列出五个想法”）和期望的输出。请注意，在特定的设置或场景中，第一步是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可选的"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210909-re0iwzc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-re0iwzc","updated":"20250922210909"},"Children":[{"ID":"20250922210909-ny6awxk","Type":"NodeParagraph","Properties":{"id":"20250922210909-ny6awxk","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型训练 (Reward model training)."},{"Type":"NodeText","Data":" 第二步是使用人类反馈数据来训练"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型（RM）"},{"Type":"NodeText","Data":"。具体来说，我们使用LM，以采样的提示（来自监督数据集或人类生成的提示）作为输入，生成一定数量的输出文本。然后，我们邀请人类标注员对这些对进行偏好标注。标注过程可以有多种形式，一种常见的方法是对生成的候选文本进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排序"},{"Type":"NodeText","Data":"，这可以减少标注员之间的不一致性。然后，RM被训练来预测人类偏好的输出。在InstructGPT中，标注员将模型生成的输出从最好到最差进行排序，然后RM（即6B的GPT-3）被训练来预测这个排名。请注意，在最近的工作中，响应对的偏好标注已由一个AI智能体（通常是一个对齐过的LLM）而不是人类来完成，这被称为“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从AI反馈中进行强化学习（RLAIF）"},{"Type":"NodeText","Data":"”。用典型的RLHF算法训练的LLM倾向于生成无害但帮助性较小的响应，这被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"回避问题"},{"Type":"NodeText","Data":"。为了保证无害性和有用性，RLAIF基于预设的对齐原则生成AI反馈"}]}]}]},{"ID":"20250922210909-ee17ud7","Type":"NodeParagraph","Properties":{"id":"20250922210909-ee17ud7","updated":"20250922210930"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915172223-m8aawzx.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922210909-4vn4cas","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210909-4vn4cas","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 12：RLHF算法的工作流程"}]},{"ID":"20250922210909-ql7hjvi","Type":"NodeBlockquote","Properties":{"id":"20250922210909-ql7hjvi","updated":"20250922210930"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210909-s2x8wim","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210909-s2x8wim","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922210909-us5pi4a","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922210909-us5pi4a","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图12解析：RLHF三步走——“胡萝卜加大棒”的AI驯化术"}]},{"ID":"20250922210909-sotcwkm","Type":"NodeParagraph","Properties":{"id":"20250922210909-sotcwkm","updated":"20250922210909"},"Children":[{"Type":"NodeText","Data":"这张图是理解"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF（从人类反馈中进行强化学习）"},{"Type":"NodeText","Data":"这一核心技术的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“圣经”"},{"Type":"NodeText","Data":"。它清晰地展示了将一个原始的、未经调教的LLM，转变为一个懂得人类偏好、行为得体的AI助手的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三个关键步骤"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922210909-4ut2hqj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-4ut2hqj","updated":"20250922210909"},"Children":[{"ID":"20250922210909-b7ofdh0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-b7ofdh0","updated":"20250922210909"},"Children":[{"ID":"20250922210909-5z6r2xb","Type":"NodeParagraph","Properties":{"id":"20250922210909-5z6r2xb","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第一步：监督微调 (Supervised Fine-tuning, SFT)"}]},{"ID":"20250922210909-nr93xv6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-nr93xv6","updated":"20250922210909"},"Children":[{"ID":"20250922210909-uqccs5j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-uqccs5j","updated":"20250922210909"},"Children":[{"ID":"20250922210909-41qyc4p","Type":"NodeParagraph","Properties":{"id":"20250922210909-41qyc4p","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“打基础”"},{"Type":"NodeText","Data":"。让模型初步学会如何按照指令生成有用的回答。"}]}]},{"ID":"20250922210909-7g0fgi7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-7g0fgi7","updated":"20250922210909"},"Children":[{"ID":"20250922210909-xco81xx","Type":"NodeParagraph","Properties":{"id":"20250922210909-xco81xx","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210909-sqnteaw","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210909-sqnteaw","updated":"20250922210909"},"Children":[{"ID":"20250922210909-3zvtuu1","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210909-3zvtuu1","updated":"20250922210909"},"Children":[{"ID":"20250922210909-bipfmix","Type":"NodeParagraph","Properties":{"id":"20250922210909-bipfmix","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"收集数据"},{"Type":"NodeText","Data":": 雇佣"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类标注员 (Human Annotator)"},{"Type":"NodeText","Data":" 编写高质量的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“提示-回答”"},{"Type":"NodeText","Data":"对（Demonstration Data）。"}]}]},{"ID":"20250922210909-oyggvsd","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210909-oyggvsd","updated":"20250922210909"},"Children":[{"ID":"20250922210909-mxy7pl2","Type":"NodeParagraph","Properties":{"id":"20250922210909-mxy7pl2","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练"},{"Type":"NodeText","Data":": 在这些高质量的示范数据上，对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练好的LLM (Pre-trained LM)"},{"Type":"NodeText","Data":" 进行标准的监督式微调。"}]}]}]}]},{"ID":"20250922210909-upm125x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-upm125x","updated":"20250922210909"},"Children":[{"ID":"20250922210909-pbtzh8n","Type":"NodeParagraph","Properties":{"id":"20250922210909-pbtzh8n","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类比"},{"Type":"NodeText","Data":": 就像教一个学生写作文，先给他看几篇"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"范文"},{"Type":"NodeText","Data":"，让他模仿学习。"}]}]}]}]},{"ID":"20250922210909-cw8sj6o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-cw8sj6o","updated":"20250922210909"},"Children":[{"ID":"20250922210909-bk7cwnn","Type":"NodeParagraph","Properties":{"id":"20250922210909-bk7cwnn","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二步：训练奖励模型 (Reward Model Training)"}]},{"ID":"20250922210909-mbyfmbp","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-mbyfmbp","updated":"20250922210909"},"Children":[{"ID":"20250922210909-73tn1m6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-73tn1m6","updated":"20250922210909"},"Children":[{"ID":"20250922210909-cc843qx","Type":"NodeParagraph","Properties":{"id":"20250922210909-cc843qx","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“立规矩”"},{"Type":"NodeText","Data":"。训练一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“裁判”"},{"Type":"NodeText","Data":"模型，让它学会判断什么样的回答是“好”的，什么样的是“坏”的。"}]}]},{"ID":"20250922210909-6i56l1y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-6i56l1y","updated":"20250922210909"},"Children":[{"ID":"20250922210909-bjcjzor","Type":"NodeParagraph","Properties":{"id":"20250922210909-bjcjzor","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210909-iq1sf52","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210909-iq1sf52","updated":"20250922210909"},"Children":[{"ID":"20250922210909-uasloh9","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210909-uasloh9","updated":"20250922210909"},"Children":[{"ID":"20250922210909-b72ryoi","Type":"NodeParagraph","Properties":{"id":"20250922210909-b72ryoi","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成多样化回答"},{"Type":"NodeText","Data":": 让第一步微调过的LM，对同一个提示，生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多个不同的回答"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210909-0gpsdzr","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210909-0gpsdzr","updated":"20250922210909"},"Children":[{"ID":"20250922210909-m6oo70k","Type":"NodeParagraph","Properties":{"id":"20250922210909-m6oo70k","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类排序"},{"Type":"NodeText","Data":": 邀请"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类标注员"},{"Type":"NodeText","Data":"对这些回答进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排序"},{"Type":"NodeText","Data":"（Ranking），从最好到最差。这就是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“人类反馈 (Human Feedback)”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210909-276f1md","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922210909-276f1md","updated":"20250922210909"},"Children":[{"ID":"20250922210909-ub94ecz","Type":"NodeParagraph","Properties":{"id":"20250922210909-ub94ecz","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练裁判"},{"Type":"NodeText","Data":": 用这些排序数据，训练一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型 (Reward Model)"},{"Type":"NodeText","Data":"。这个模型输入一个“提示-回答”对，输出一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分数"},{"Type":"NodeText","Data":"，分数越高代表人类越喜欢这个回答。"}]}]}]}]},{"ID":"20250922210909-y7ez2g6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-y7ez2g6","updated":"20250922210909"},"Children":[{"ID":"20250922210909-rcxqi3l","Type":"NodeParagraph","Properties":{"id":"20250922210909-rcxqi3l","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类比"},{"Type":"NodeText","Data":": 就像让学生对同一个作文题目写出多种开头，然后老师（人类标注员）给这些开头"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"打分"},{"Type":"NodeText","Data":"。最后，我们用这些打分数据，训练一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自动阅卷机”"},{"Type":"NodeText","Data":"（奖励模型）。"}]}]}]}]},{"ID":"20250922210909-4reqlqm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-4reqlqm","updated":"20250922210909"},"Children":[{"ID":"20250922210909-g8vwgsm","Type":"NodeParagraph","Properties":{"id":"20250922210909-g8vwgsm","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三步：强化学习微调 (RL Fine-tuning)"}]},{"ID":"20250922210909-i5r90e4","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-i5r90e4","updated":"20250922210909"},"Children":[{"ID":"20250922210909-11ku7z4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-11ku7z4","updated":"20250922210909"},"Children":[{"ID":"20250922210909-ylhhzod","Type":"NodeParagraph","Properties":{"id":"20250922210909-ylhhzod","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“实战演练”"},{"Type":"NodeText","Data":"。让模型在“裁判”的指导下，不断尝试生成更好的回答。"}]}]},{"ID":"20250922210909-4l29hn2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-4l29hn2","updated":"20250922210909"},"Children":[{"ID":"20250922210909-331ztod","Type":"NodeParagraph","Properties":{"id":"20250922210909-331ztod","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210909-rrtt4e7","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210909-rrtt4e7","updated":"20250922210909"},"Children":[{"ID":"20250922210909-7mepjzh","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210909-7mepjzh","updated":"20250922210909"},"Children":[{"ID":"20250922210909-f0wvb2t","Type":"NodeParagraph","Properties":{"id":"20250922210909-f0wvb2t","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型生成"},{"Type":"NodeText","Data":": LM接收一个提示，生成一个回答。"}]}]},{"ID":"20250922210909-hnrt3ml","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210909-hnrt3ml","updated":"20250922210909"},"Children":[{"ID":"20250922210909-03obi6l","Type":"NodeParagraph","Properties":{"id":"20250922210909-03obi6l","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"裁判打分"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型"},{"Type":"NodeText","Data":"对这个回答进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"打分"},{"Type":"NodeText","Data":"（给出Reward）。"}]}]},{"ID":"20250922210909-r4u6dsc","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922210909-r4u6dsc","updated":"20250922210909"},"Children":[{"ID":"20250922210909-v7nfty2","Type":"NodeParagraph","Properties":{"id":"20250922210909-v7nfty2","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略优化"},{"Type":"NodeText","Data":": 使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习算法（如PPO）"},{"Type":"NodeText","Data":"，根据这个分数来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调"},{"Type":"NodeText","Data":"LM的参数。目标是让LM学会生成能从奖励模型那里获得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更高分数"},{"Type":"NodeText","Data":"的回答。"}]}]}]}]},{"ID":"20250922210909-xgtonzt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-xgtonzt","updated":"20250922210909"},"Children":[{"ID":"20250922210909-gsi99b4","Type":"NodeParagraph","Properties":{"id":"20250922210909-gsi99b4","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类比"},{"Type":"NodeText","Data":": 让学生开始自由写作。写完一篇后，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自动阅卷机”"},{"Type":"NodeText","Data":"（奖励模型）给他打分。学生根据分数"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"调整自己的写作策略"},{"Type":"NodeText","Data":"，争取下次写出得分更高的文章。这个过程不断重复，学生的写作水平（模型生成质量）就会越来越高。"}]}]}]}]}]},{"ID":"20250922210909-88kjtmw","Type":"NodeParagraph","Properties":{"id":"20250922210909-88kjtmw","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最终产出"},{"Type":"NodeText","Data":": 经过这三步“驯化”后，原始的"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Pre-trained LM"},{"Type":"NodeText","Data":"​就进化为了一个"},{"Type":"NodeTextMark","TextMarkType":"strong code","TextMarkTextContent":"Aligned LM"},{"Type":"NodeText","Data":"​"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"（对齐过的LM）"},{"Type":"NodeText","Data":"，它的行为更符合人类的偏好和价值观。"}]}]},{"ID":"20250922210909-qoehija","Type":"NodeThematicBreak","Properties":{"id":"20250922210909-qoehija","updated":"20250922210930"}},{"ID":"20250922210909-743rnod","Type":"NodeBlockquote","Properties":{"id":"20250922210909-743rnod","updated":"20250922210930"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210909-z4vzujl","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922210909-z4vzujl","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922210909-b47ly3d","Type":"NodeParagraph","Properties":{"id":"20250922210909-b47ly3d","updated":"20250922210909"},"Children":[{"Type":"NodeText","Data":"第三十一部分深入到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调（Alignment Tuning）"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心技术——RLHF"},{"Type":"NodeText","Data":"，并系统地阐述了其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论基础、系统构成和实现步骤"},{"Type":"NodeText","Data":"。这是理解现代SOTA对话模型（如ChatGPT, Claude）为何如此强大的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术关键"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922210909-z6ymky0","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210909-z6ymky0","updated":"20250922210909"},"Children":[{"ID":"20250922210909-p0jol2n","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210909-p0jol2n","updated":"20250922210909"},"Children":[{"ID":"20250922210909-c6vuaku","Type":"NodeParagraph","Properties":{"id":"20250922210909-c6vuaku","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“监督”到“强化”的范式飞跃"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210909-zt6aui5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-zt6aui5","updated":"20250922210909"},"Children":[{"ID":"20250922210909-duhy2zs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-duhy2zs","updated":"20250922210909"},"Children":[{"ID":"20250922210909-nqyamts","Type":"NodeParagraph","Properties":{"id":"20250922210909-nqyamts","updated":"20250922210909"},"Children":[{"Type":"NodeText","Data":"传统的监督学习（如SFT）只能教会模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模仿”"},{"Type":"NodeText","Data":"，即学习已有的“标准答案”。"}]}]},{"ID":"20250922210909-witw9kc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-witw9kc","updated":"20250922210909"},"Children":[{"ID":"20250922210909-bw509fu","Type":"NodeParagraph","Properties":{"id":"20250922210909-bw509fu","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF"},{"Type":"NodeText","Data":"则是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“探索与发现”"},{"Type":"NodeText","Data":"的学习范式。模型可以生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练数据中从未出现过"},{"Type":"NodeText","Data":"的回答，并通过奖励模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“好/坏”信号"},{"Type":"NodeText","Data":"，自主地学习如何生成更好的内容。这种能力使得模型可以探索更广阔的答案空间，生成更具创造性和帮助性的回答。"}]}]}]}]},{"ID":"20250922210909-r1bwhb5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210909-r1bwhb5","updated":"20250922210909"},"Children":[{"ID":"20250922210909-65xgmsn","Type":"NodeParagraph","Properties":{"id":"20250922210909-65xgmsn","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF系统的“铁三角”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210909-wdlztxf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-wdlztxf","updated":"20250922210909"},"Children":[{"ID":"20250922210909-mo1huf0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-mo1huf0","updated":"20250922210909"},"Children":[{"ID":"20250922210909-8qjrpdw","Type":"NodeParagraph","Properties":{"id":"20250922210909-8qjrpdw","updated":"20250922210909"},"Children":[{"Type":"NodeText","Data":"文章清晰地指出了RLHF系统的三大核心组件："}]},{"ID":"20250922210909-3yfkef5","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922210909-3yfkef5","updated":"20250922210909"},"Children":[{"ID":"20250922210909-961ew4b","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922210909-961ew4b","updated":"20250922210909"},"Children":[{"ID":"20250922210909-83c2znd","Type":"NodeParagraph","Properties":{"id":"20250922210909-83c2znd","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"待对齐的语言模型 (LM)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“运动员”"},{"Type":"NodeText","Data":"，是学习的主体。"}]}]},{"ID":"20250922210909-m8r7j7i","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922210909-m8r7j7i","updated":"20250922210909"},"Children":[{"ID":"20250922210909-e2nomzg","Type":"NodeParagraph","Properties":{"id":"20250922210909-e2nomzg","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型 (RM)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“裁判”"},{"Type":"NodeText","Data":"，它代表了人类的价值观，为“运动员”的表现打分。"}]}]},{"ID":"20250922210909-i5jocad","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922210909-i5jocad","updated":"20250922210909"},"Children":[{"ID":"20250922210909-qrw2a13","Type":"NodeParagraph","Properties":{"id":"20250922210909-qrw2a13","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习算法 (PPO)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“教练”"},{"Type":"NodeText","Data":"，它根据“裁判”的分数，指导“运动员”如何调整策略以获得更高分。"}]}]}]}]},{"ID":"20250922210909-c5wumky","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-c5wumky","updated":"20250922210909"},"Children":[{"ID":"20250922210909-b5hzdr9","Type":"NodeParagraph","Properties":{"id":"20250922210909-b5hzdr9","updated":"20250922210909"},"Children":[{"Type":"NodeText","Data":"这个“铁三角”结构，巧妙地将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模语言模型的能力"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类的主观偏好"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习的优化能力"},{"Type":"NodeText","Data":"结合在了一起。"}]}]}]}]},{"ID":"20250922210909-grdnin8","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922210909-grdnin8","updated":"20250922210909"},"Children":[{"ID":"20250922210909-p493s1k","Type":"NodeParagraph","Properties":{"id":"20250922210909-p493s1k","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“三步走”的实践蓝图 (图12)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210909-1fnk4vz","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-1fnk4vz","updated":"20250922210909"},"Children":[{"ID":"20250922210909-crpm6ya","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-crpm6ya","updated":"20250922210909"},"Children":[{"ID":"20250922210909-askfaro","Type":"NodeParagraph","Properties":{"id":"20250922210909-askfaro","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SFT -\u0026gt; RM训练 -\u0026gt; RL微调"},{"Type":"NodeText","Data":" 这三步走，为实现RLHF提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰、可操作"},{"Type":"NodeText","Data":"的工程蓝图。"}]}]},{"ID":"20250922210909-m2pkvae","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-m2pkvae","updated":"20250922210909"},"Children":[{"ID":"20250922210909-yo01uqb","Type":"NodeParagraph","Properties":{"id":"20250922210909-yo01uqb","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SFT"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冷启动"},{"Type":"NodeText","Data":"阶段，为模型提供一个良好的初始状态。"}]}]},{"ID":"20250922210909-fpubm2n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-fpubm2n","updated":"20250922210909"},"Children":[{"ID":"20250922210909-lxeq5q2","Type":"NodeParagraph","Properties":{"id":"20250922210909-lxeq5q2","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RM训练"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心"},{"Type":"NodeText","Data":"，其质量直接决定了对齐的“天花板”。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型的好坏，就是人类价值观被模型理解得好坏的直接体现"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922210909-my9fwvn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-my9fwvn","updated":"20250922210909"},"Children":[{"ID":"20250922210909-kwuzlic","Type":"NodeParagraph","Properties":{"id":"20250922210909-kwuzlic","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RL微调"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化"},{"Type":"NodeText","Data":"阶段，通过PPO算法，将奖励模型学到的“价值观”真正"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内化"},{"Type":"NodeText","Data":"为语言模型自身的参数。"}]}]}]}]},{"ID":"20250922210909-2dpvkmb","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922210909-2dpvkmb","updated":"20250922210909"},"Children":[{"ID":"20250922210909-8x1gow2","Type":"NodeParagraph","Properties":{"id":"20250922210909-8x1gow2","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前沿的自动化趋势：RLAIF"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922210909-r4k8zhw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-r4k8zhw","updated":"20250922210909"},"Children":[{"ID":"20250922210909-y0upasa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-y0upasa","updated":"20250922210909"},"Children":[{"ID":"20250922210909-jf2w4qd","Type":"NodeParagraph","Properties":{"id":"20250922210909-jf2w4qd","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLAIF（从AI反馈中强化学习）"},{"Type":"NodeText","Data":"的提出，标志着对齐技术本身也在寻求"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动化"},{"Type":"NodeText","Data":"。它试图用一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"已经对齐好的、更强大的AI"},{"Type":"NodeText","Data":"来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"替代昂贵的人类标注员"},{"Type":"NodeText","Data":"进行偏好排序。这是一种“用魔法打败魔法”的思路，旨在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"降低对齐的成本"},{"Type":"NodeText","Data":"并"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提升其规模"},{"Type":"NodeText","Data":"。"}]}]}]}]}]}]},{"ID":"20250922210909-96hzwji","Type":"NodeList","ListData":{},"Properties":{"id":"20250922210909-96hzwji","updated":"20250922210930"},"Children":[{"ID":"20250922210909-zjsswem","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922210909-zjsswem","updated":"20250922210909"},"Children":[{"ID":"20250922210909-j6afkwh","Type":"NodeParagraph","Properties":{"id":"20250922210909-j6afkwh","updated":"20250922210909"}}]}]},{"ID":"20250922210909-qnlsvp7","Type":"NodeBlockquote","Properties":{"id":"20250922210909-qnlsvp7","updated":"20250922210930"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922210909-72j7m9g","Type":"NodeParagraph","Properties":{"id":"20250922210909-72j7m9g","updated":"20250922210909"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第三十一部分为我们揭开了RLHF的神秘面纱。它不仅解释了RLHF是什么，更重要的是，通过图12和详细的步骤拆解，告诉了我们"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF是如何工作的"},{"Type":"NodeText","Data":"。它清晰地表明，RLHF是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将人类主观、模糊的偏好，转化为机器可以理解和优化的数学信号（奖励）"},{"Type":"NodeText","Data":"的精妙机制。正是通过这套“胡萝卜加大棒”式的训练，才将原始的、野生的LLM，“驯化”成了我们今天看到的、彬彬有礼且乐于助人的AI助手。"}]}]},{"ID":"20250922211113-1rm68i2","Type":"NodeParagraph","Properties":{"id":"20250922211113-1rm68i2","updated":"20250922211113"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922211113-ra92yo9","Type":"NodeThematicBreak","Properties":{"id":"20250922211113-ra92yo9","updated":"20250922211113"}},{"ID":"20250922211113-qjcuawb","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211113-qjcuawb","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三十二部分"}]},{"ID":"20250922211113-tzv2s5h","Type":"NodeParagraph","Properties":{"id":"20250922211113-tzv2s5h","updated":"20250922211143"},"Children":[{"Type":"NodeText","Data":"在指令中。"}]},{"ID":"20250922211113-kv158dh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-kv158dh","updated":"20250922211143"},"Children":[{"ID":"20250922211113-wpenkca","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-wpenkca","updated":"20250922211113"},"Children":[{"ID":"20250922211113-aktwxz4","Type":"NodeParagraph","Properties":{"id":"20250922211113-aktwxz4","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RL微调 (RL fine-tuning)."},{"Type":"NodeText","Data":" 在此步骤中，对齐（即微调）LM被形式化为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RL问题"},{"Type":"NodeText","Data":"。在此设置中，预训练的LM充当"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略"},{"Type":"NodeText","Data":"，它接收一个提示作为输入并返回一个输出文本；其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动作空间"},{"Type":"NodeText","Data":"是词汇表；"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"状态"},{"Type":"NodeText","Data":"是当前生成的词元序列；而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励"},{"Type":"NodeText","Data":"由RM提供。为了避免与初始（微调前）的LM偏离过远，通常会在奖励函数中加入一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"惩罚项"},{"Type":"NodeText","Data":"。例如，InstructGPT使用PPO算法针对RM优化LM。对于每个输入提示，InstructGPT计算当前LM和初始LM生成结果之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"KL散度"},{"Type":"NodeText","Data":"作为惩罚。值得注意的是，第二步和最后一步可以在多轮中迭代，以更好地对齐LLM。由于RL算法的不稳定性，最近的工作用另一个监督式微调取代了RL微调，通过重用排名最高的样本并给予更高的奖励。"}]}]}]},{"ID":"20250922211113-5v4gjwb","Type":"NodeParagraph","Properties":{"id":"20250922211113-5v4gjwb","updated":"20250922211143"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Practical Strategies for RLHF (RLHF的实用策略)."},{"Type":"NodeText","Data":" 尽管RLHF在有效提升LLM与人类的对齐方面很有前景，但对于研究人员来说，成功地实现它在实践中具有挑战性。在本部分中，我们重点讨论几种用于提升RLHF有效性和效率的实用策略和技巧。具体来说，我们分别关注奖励模型的有效训练，以及高效且有效的RL训练。"}]},{"ID":"20250922211113-zzbpyrl","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-zzbpyrl","updated":"20250922211143"},"Children":[{"ID":"20250922211113-e5qjmnf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-e5qjmnf","updated":"20250922211113"},"Children":[{"ID":"20250922211113-osdo7of","Type":"NodeParagraph","Properties":{"id":"20250922211113-osdo7of","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有效的奖励模型训练 (Effective reward model training)."},{"Type":"NodeText","Data":" 尽管InstructGPT使用了一个小型的奖励模型（6B GPT模型），但越来越多的工作表明，使用一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型奖励模型"},{"Type":"NodeText","Data":"（例如，等于或大于原始模型大小）通常更有效，因为大型奖励模型在判断LLM生成输出的质量方面通常表现更好。在LLaMA 2中，使用预训练的聊天模型检查点来初始化奖励模型，他们认为这种方法可以通过共享相同的预训练知识，有效地减少待对齐模型与奖励模型之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"信息不匹配"},{"Type":"NodeText","Data":"。然而，在训练大规模奖励模型时，通常会遇到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过拟合"},{"Type":"NodeText","Data":"问题。作为一个简单而有效的解决方案，现有的工作引入了来自人类标注的对齐数据集中偏好响应的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LM损失"},{"Type":"NodeText","Data":"作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正则化项"},{"Type":"NodeText","Data":"，这缓解了奖励模型在二元分类任务上的过拟合。此外，由于存在多种对齐标准（例如，有用性和诚实性），训练一个能够满足所有对齐标准的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单一奖励模型"},{"Type":"NodeText","Data":"通常很困难。因此，训练专注于不同对齐标准的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多个奖励模型"},{"Type":"NodeText","Data":"是有用的，并通过特殊的组合策略（例如，均值池化和加权求和）来计算最终奖励。这种方式可以在多种标准上实现更灵活的规则或标准，例如，在放宽对有用性要求的同时，对无害性施加更严格的限制。"}]}]},{"ID":"20250922211113-gyscxqi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-gyscxqi","updated":"20250922211113"},"Children":[{"ID":"20250922211113-bxj7tb3","Type":"NodeParagraph","Properties":{"id":"20250922211113-bxj7tb3","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有效的RL训练 (Effective RL training)."},{"Type":"NodeText","Data":" 由于RL训练过程往往"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不稳定且对超参数敏感"},{"Type":"NodeText","Data":"，建议在RL训练之前，对语言模型进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"充分的监督微调"},{"Type":"NodeText","Data":"，以达到一个良好的模型能力。一种常用的方法是在RL之前，在对齐数据集中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最好的输出"},{"Type":"NodeText","Data":"（称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"拒绝采样"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"best-of-N"},{"Type":"NodeText","Data":"）上对LLM进行微调，直到收敛。给定一个提示，LLM首先会通过采样算法产生N个输出，然后奖励模型将选择模型中最好的候选者进行学习。在最好的样本上对LLM进行微调直到收敛后，将执行RL过程以进一步提升性能。LLaMA 2先后训练了五个版本的RLHF模型，其中LLM随着奖励模型的改进而逐步改进。通过这种方式，收集到的提示和人类偏好标注可以更好地反映当前模型检查点的问题，从而进行专门的微调来解决这些问题。此外，LLaMA 2还将先前迭代中的样本添加到后续迭代中，以缓解迭代优化期间可能出现的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力回归"},{"Type":"NodeText","Data":"问题。"}]}]},{"ID":"20250922211113-pi6y4qt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-pi6y4qt","updated":"20250922211113"},"Children":[{"ID":"20250922211113-4isx1gd","Type":"NodeParagraph","Properties":{"id":"20250922211113-4isx1gd","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效的RL训练 (Efficient RL training)."},{"Type":"NodeText","Data":" 由于RL训练需要迭代LLM和奖励模型的推理过程，它会极大地增加总内存和计算成本，特别是对于较大的奖励模型和LLM。作为一个实用的技巧，我们可以将奖励模型部署在一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单独的服务器"},{"Type":"NodeText","Data":"上，并调用相应的API与在其自己服务器上的LLM协同工作。此外，由于RLHF需要LLM生成多个候选输出，与其多次调用采样解码过程，不如利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"束搜索解码算法"},{"Type":"NodeText","Data":"更有效率。它只需要执行一次解码过程即可生成响应，同时这种策略也可以增强生成的候选响应的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922211113-jq6z0kd","Type":"NodeParagraph","Properties":{"id":"20250922211113-jq6z0kd","updated":"20250922211143"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915173516-x4189j1.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922211113-dlucc8r","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211113-dlucc8r","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 13：四种不同参数高效微调方法的示意图。"}]},{"ID":"20250922211113-5loc6zx","Type":"NodeParagraph","Properties":{"id":"20250922211113-5loc6zx","updated":"20250922211143"},"Children":[{"Type":"NodeText","Data":"MHA和FFN分别表示Transformer层中的多头注意力和前馈网络。"}]},{"ID":"20250922211113-u9pf9qo","Type":"NodeBlockquote","Properties":{"id":"20250922211113-u9pf9qo","updated":"20250922211143"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922211113-t032ex5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211113-t032ex5","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922211113-eu58zqi","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211113-eu58zqi","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图13解析：参数高效微调的“四种武器”"}]},{"ID":"20250922211113-w4frqrw","Type":"NodeParagraph","Properties":{"id":"20250922211113-w4frqrw","updated":"20250922211113"},"Children":[{"Type":"NodeText","Data":"这张图展示了四种主流的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）"},{"Type":"NodeText","Data":"技术，它们的核心思想都是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“冻结”"},{"Type":"NodeText","Data":"庞大的预训练模型主体，只"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“微调”"},{"Type":"NodeText","Data":"少量新增的、轻量级的参数。"}]},{"ID":"20250922211113-qsu3ly6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-qsu3ly6","updated":"20250922211113"},"Children":[{"ID":"20250922211113-t16tisa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-t16tisa","updated":"20250922211113"},"Children":[{"ID":"20250922211113-8wpvgau","Type":"NodeParagraph","Properties":{"id":"20250922211113-8wpvgau","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(a) Adapter Tuning (适配器微调)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211113-70ohki1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-70ohki1","updated":"20250922211113"},"Children":[{"ID":"20250922211113-ngdw87j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-ngdw87j","updated":"20250922211113"},"Children":[{"ID":"20250922211113-w2zaoub","Type":"NodeParagraph","Properties":{"id":"20250922211113-w2zaoub","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": 在Transformer的每个大模块（MHA和FFN）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"之后"},{"Type":"NodeText","Data":"，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"串联"},{"Type":"NodeText","Data":"插入一个小的、瓶颈状的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“适配器（Adapter）”"},{"Type":"NodeText","Data":"模块（图中绿色部分）。"}]}]},{"ID":"20250922211113-bcluuis","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-bcluuis","updated":"20250922211113"},"Children":[{"ID":"20250922211113-d9jk5r4","Type":"NodeParagraph","Properties":{"id":"20250922211113-d9jk5r4","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据流"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"... -\u0026gt; MHA -\u0026gt; Adapter -\u0026gt; FFN -\u0026gt; Adapter -\u0026gt; ..."},{"Type":"NodeText","Data":"​"}]}]},{"ID":"20250922211113-xmeu3qi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-xmeu3qi","updated":"20250922211113"},"Children":[{"ID":"20250922211113-osbgpxd","Type":"NodeParagraph","Properties":{"id":"20250922211113-osbgpxd","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非侵入式"},{"Type":"NodeText","Data":"，但串行结构可能增加推理延迟。"}]}]}]}]},{"ID":"20250922211113-44y6pri","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-44y6pri","updated":"20250922211113"},"Children":[{"ID":"20250922211113-0xocygx","Type":"NodeParagraph","Properties":{"id":"20250922211113-0xocygx","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(b) Prefix Tuning (前缀微调)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211113-107a705","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-107a705","updated":"20250922211113"},"Children":[{"ID":"20250922211113-ryp2vpd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-ryp2vpd","updated":"20250922211113"},"Children":[{"ID":"20250922211113-7xm2qfp","Type":"NodeParagraph","Properties":{"id":"20250922211113-7xm2qfp","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": 在Transformer的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每一层"},{"Type":"NodeText","Data":"，都在键（Key）和值（Value）的前面"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"拼接"},{"Type":"NodeText","Data":"上一段可训练的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“前缀（Prefix）”"},{"Type":"NodeText","Data":"向量（图中绿色部分）。"}]}]},{"ID":"20250922211113-hwr41aj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-hwr41aj","updated":"20250922211113"},"Children":[{"ID":"20250922211113-456ziht","Type":"NodeParagraph","Properties":{"id":"20250922211113-456ziht","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据流"},{"Type":"NodeText","Data":": 在注意力计算时，Query会与 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[Prefix_Key, Original_Key]"},{"Type":"NodeText","Data":"​ 和 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[Prefix_Value, Original_Value]"},{"Type":"NodeText","Data":"​ 进行交互。"}]}]},{"ID":"20250922211113-49h2piz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-49h2piz","updated":"20250922211113"},"Children":[{"ID":"20250922211113-1y3x1hd","Type":"NodeParagraph","Properties":{"id":"20250922211113-1y3x1hd","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特点"},{"Type":"NodeText","Data":": 通过影响注意力计算来引导模型行为，效果较好但实现稍复杂。"}]}]}]}]},{"ID":"20250922211113-mfo70th","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-mfo70th","updated":"20250922211113"},"Children":[{"ID":"20250922211113-igxgqw2","Type":"NodeParagraph","Properties":{"id":"20250922211113-igxgqw2","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(c) Prompt Tuning (提示微调)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211113-oqr3hho","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-oqr3hho","updated":"20250922211113"},"Children":[{"ID":"20250922211113-00a8k28","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-00a8k28","updated":"20250922211113"},"Children":[{"ID":"20250922211113-3kqaqow","Type":"NodeParagraph","Properties":{"id":"20250922211113-3kqaqow","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": 这是Prefix Tuning的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简化版"},{"Type":"NodeText","Data":"。它只在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输入层（Input Layer）"},{"Type":"NodeText","Data":"，即词嵌入之后，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"拼接"},{"Type":"NodeText","Data":"上一段可训练的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“软提示（Soft Prompt）”"},{"Type":"NodeText","Data":"向量（图中绿色部分）。"}]}]},{"ID":"20250922211113-hl9ucli","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-hl9ucli","updated":"20250922211113"},"Children":[{"ID":"20250922211113-4lbev2q","Type":"NodeParagraph","Properties":{"id":"20250922211113-4lbev2q","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据流"},{"Type":"NodeText","Data":": 整个模型的输入变成了 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"[Soft_Prompt_Embeddings, Original_Input_Embeddings]"},{"Type":"NodeText","Data":"​。"}]}]},{"ID":"20250922211113-j0637u9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-j0637u9","updated":"20250922211113"},"Children":[{"ID":"20250922211113-9bc5dl7","Type":"NodeParagraph","Properties":{"id":"20250922211113-9bc5dl7","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最简单、可训练参数最少"},{"Type":"NodeText","Data":"，但效果可能不如其他方法强大，对模型规模有一定依赖。"}]}]}]}]},{"ID":"20250922211113-jlf2shv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-jlf2shv","updated":"20250922211113"},"Children":[{"ID":"20250922211113-id7jbul","Type":"NodeParagraph","Properties":{"id":"20250922211113-id7jbul","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(d) Low-Rank Adaptation (LoRA，低秩适配)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211113-4kvf5qw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-4kvf5qw","updated":"20250922211113"},"Children":[{"ID":"20250922211113-9sesyjb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-9sesyjb","updated":"20250922211113"},"Children":[{"ID":"20250922211113-6cit1c0","Type":"NodeParagraph","Properties":{"id":"20250922211113-6cit1c0","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最主流、最有效"},{"Type":"NodeText","Data":"的PEFT方法之一。它假设模型在微调时的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数更新矩阵是“低秩”的"},{"Type":"NodeText","Data":"。因此，它"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不改变原有的权重矩阵"},{"Type":"NodeText","Data":"，而是在旁边"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并联"},{"Type":"NodeText","Data":"一个由两个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"低秩矩阵（A和B）"},{"Type":"NodeText","Data":"相乘构成的“旁路”。"}]}]},{"ID":"20250922211113-kcbtw0n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-kcbtw0n","updated":"20250922211113"},"Children":[{"ID":"20250922211113-ihy4mkh","Type":"NodeParagraph","Properties":{"id":"20250922211113-ihy4mkh","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据流"},{"Type":"NodeText","Data":": 最终的输出是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"原始模块的输出"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"W*x"},{"Type":"NodeText","Data":"​ "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"加上"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"旁路的输出"},{"Type":"NodeText","Data":" "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"B*A*x"},{"Type":"NodeText","Data":"​。"}]}]},{"ID":"20250922211113-vzu2epm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-vzu2epm","updated":"20250922211113"},"Children":[{"ID":"20250922211113-mag8ssv","Type":"NodeParagraph","Properties":{"id":"20250922211113-mag8ssv","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不引入任何推理延迟"},{"Type":"NodeText","Data":"（因为训练后可以将旁路矩阵"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"BA"},{"Type":"NodeText","Data":"​合并回原始矩阵"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"W"},{"Type":"NodeText","Data":"​），效果强大，已成为事实上的行业标准。"}]}]}]}]}]}]},{"ID":"20250922211113-rqctbrn","Type":"NodeThematicBreak","Properties":{"id":"20250922211113-rqctbrn","updated":"20250922211143"}},{"ID":"20250922211113-kx4j246","Type":"NodeBlockquote","Properties":{"id":"20250922211113-kx4j246","updated":"20250922211143"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922211113-x9f3jt5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211113-x9f3jt5","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922211113-lxwhp3q","Type":"NodeParagraph","Properties":{"id":"20250922211113-lxwhp3q","updated":"20250922211113"},"Children":[{"Type":"NodeText","Data":"第三十二部分深入到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF的实践细节和高级策略"},{"Type":"NodeText","Data":"，并自然地过渡到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效微调（PEFT）"},{"Type":"NodeText","Data":"这一重要主题。"}]},{"ID":"20250922211113-a8ukvkg","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211113-a8ukvkg","updated":"20250922211113"},"Children":[{"ID":"20250922211113-1w6c91d","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211113-1w6c91d","updated":"20250922211113"},"Children":[{"ID":"20250922211113-pgu8emk","Type":"NodeParagraph","Properties":{"id":"20250922211113-pgu8emk","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF的“艺术与科学”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211113-ph8pk5i","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-ph8pk5i","updated":"20250922211113"},"Children":[{"ID":"20250922211113-j6xkxck","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-j6xkxck","updated":"20250922211113"},"Children":[{"ID":"20250922211113-3lhj8ap","Type":"NodeParagraph","Properties":{"id":"20250922211113-3lhj8ap","updated":"20250922211113"},"Children":[{"Type":"NodeText","Data":"本部分揭示了成功实施RLHF不仅是一门科学，更是一门"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"艺术"},{"Type":"NodeText","Data":"。它充满了各种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"权衡和技巧"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211113-omkrk0l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-omkrk0l","updated":"20250922211113"},"Children":[{"ID":"20250922211113-695hjnz","Type":"NodeParagraph","Properties":{"id":"20250922211113-695hjnz","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型 (RM) 的训练艺术"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211113-izpdozn","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-izpdozn","updated":"20250922211113"},"Children":[{"ID":"20250922211113-9sqlmph","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-9sqlmph","updated":"20250922211113"},"Children":[{"ID":"20250922211113-fwteoj8","Type":"NodeParagraph","Properties":{"id":"20250922211113-fwteoj8","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"越大越好"},{"Type":"NodeText","Data":": 更大的RM能更准确地捕捉人类偏好。"}]}]},{"ID":"20250922211113-t2wb412","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-t2wb412","updated":"20250922211113"},"Children":[{"ID":"20250922211113-o3h1048","Type":"NodeParagraph","Properties":{"id":"20250922211113-o3h1048","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"同源初始化"},{"Type":"NodeText","Data":": 使用聊天模型来初始化RM，可以减少"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“信息差”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211113-wabeked","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-wabeked","updated":"20250922211113"},"Children":[{"ID":"20250922211113-9vnqhvw","Type":"NodeParagraph","Properties":{"id":"20250922211113-9vnqhvw","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多目标与正则化"},{"Type":"NodeText","Data":": 使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多个RM"},{"Type":"NodeText","Data":"分别对齐不同目标（如有用性、无害性），并加入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LM损失作为正则化"},{"Type":"NodeText","Data":"防止过拟合，是提升RM质量的高级技巧。"}]}]}]}]},{"ID":"20250922211113-mibcngt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-mibcngt","updated":"20250922211113"},"Children":[{"ID":"20250922211113-o3r8ve5","Type":"NodeParagraph","Properties":{"id":"20250922211113-o3r8ve5","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习 (RL) 的训练艺术"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211113-7d0c83a","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-7d0c83a","updated":"20250922211113"},"Children":[{"ID":"20250922211113-9a762lp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-9a762lp","updated":"20250922211113"},"Children":[{"ID":"20250922211113-x21z3yn","Type":"NodeParagraph","Properties":{"id":"20250922211113-x21z3yn","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SFT是基础"},{"Type":"NodeText","Data":": 充分的SFT是RL成功的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前提"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211113-ig7i3l0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-ig7i3l0","updated":"20250922211113"},"Children":[{"ID":"20250922211113-5u5witb","Type":"NodeParagraph","Properties":{"id":"20250922211113-5u5witb","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"迭代优化"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模型-数据”飞轮"},{"Type":"NodeText","Data":"。通过多轮迭代，用当前模型生成的数据来训练下一代模型，实现模型的持续自我改进，这是LLaMA 2成功的关键。"}]}]},{"ID":"20250922211113-ivme63z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-ivme63z","updated":"20250922211113"},"Children":[{"ID":"20250922211113-0o9oeok","Type":"NodeParagraph","Properties":{"id":"20250922211113-0o9oeok","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"效率考量"},{"Type":"NodeText","Data":": 将RM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"服务化部署"},{"Type":"NodeText","Data":"、使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"束搜索"},{"Type":"NodeText","Data":"生成候选，都是重要的工程优化，旨在解决RLHF流程"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计算成本高昂"},{"Type":"NodeText","Data":"的问题。"}]}]}]}]}]}]},{"ID":"20250922211113-hc7v3mu","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211113-hc7v3mu","updated":"20250922211113"},"Children":[{"ID":"20250922211113-m1gy4l9","Type":"NodeParagraph","Properties":{"id":"20250922211113-m1gy4l9","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PEFT的“四小龙” (图13)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211113-qqhb54a","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-qqhb54a","updated":"20250922211113"},"Children":[{"ID":"20250922211113-v11jnl9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-v11jnl9","updated":"20250922211113"},"Children":[{"ID":"20250922211113-ft46q9r","Type":"NodeParagraph","Properties":{"id":"20250922211113-ft46q9r","updated":"20250922211113"},"Children":[{"Type":"NodeText","Data":"在讨论完昂贵的RLHF后，引入PEFT恰逢其时。它旨在解决"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“微调成本太高”"},{"Type":"NodeText","Data":"这一根本问题。"}]}]},{"ID":"20250922211113-787lgqr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-787lgqr","updated":"20250922211113"},"Children":[{"ID":"20250922211113-xg9jmhn","Type":"NodeParagraph","Properties":{"id":"20250922211113-xg9jmhn","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“四两拨千斤”"},{"Type":"NodeText","Data":"。通过只微调"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极少量（通常\u0026lt;1%）"},{"Type":"NodeText","Data":"的参数，来达到接近"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全参数微调"},{"Type":"NodeText","Data":"的效果。"}]}]},{"ID":"20250922211113-ecaines","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-ecaines","updated":"20250922211113"},"Children":[{"ID":"20250922211113-dtlbtha","Type":"NodeParagraph","Properties":{"id":"20250922211113-dtlbtha","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四种主流方法"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211113-019h5xw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211113-019h5xw","updated":"20250922211113"},"Children":[{"ID":"20250922211113-wencqs2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-wencqs2","updated":"20250922211113"},"Children":[{"ID":"20250922211113-5fcmzrf","Type":"NodeParagraph","Properties":{"id":"20250922211113-5fcmzrf","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Adapter"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Prefix/Prompt Tuning"},{"Type":"NodeText","Data":" 是早期的探索，它们通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"添加"},{"Type":"NodeText","Data":"新的小模块或向量来影响模型。"}]}]},{"ID":"20250922211113-5ct7kb5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211113-5ct7kb5","updated":"20250922211113"},"Children":[{"ID":"20250922211113-ijt11lu","Type":"NodeParagraph","Properties":{"id":"20250922211113-ijt11lu","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LoRA"},{"Type":"NodeText","Data":" 则是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"革命性的"},{"Type":"NodeText","Data":"，它通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"修改"},{"Type":"NodeText","Data":"现有权重矩阵的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更新方式"},{"Type":"NodeText","Data":"（低秩分解），在不增加推理延迟的情况下实现了强大的性能，已成为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PEFT领域的王者"},{"Type":"NodeText","Data":"。"}]}]}]}]}]}]}]},{"ID":"20250922211113-s66h2yx","Type":"NodeParagraph","Properties":{"id":"20250922211113-s66h2yx","updated":"20250922211113"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第三十二部分为我们描绘了一幅从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"昂贵、复杂但效果强大的RLHF"},{"Type":"NodeText","Data":"，到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"轻量、高效且应用广泛的PEFT"},{"Type":"NodeText","Data":"的技术图景。它深刻地揭示了LLM领域的一个核心发展趋势：在追求极致性能的同时，研究者们也在不懈地探索如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"降低技术的应用门槛和成本"},{"Type":"NodeText","Data":"。RLHF定义了对齐的“天花板”，而PEFT则为广大开发者"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"铺设了通往这个天花板的、更经济的道路"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211314-dqsm1fw","Type":"NodeParagraph","Properties":{"id":"20250922211314-dqsm1fw","updated":"20250922211314"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922211314-allc79s","Type":"NodeThematicBreak","Properties":{"id":"20250922211314-allc79s","updated":"20250922211314"}},{"ID":"20250922211314-v14bat1","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211314-v14bat1","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三十三部分"}]},{"ID":"20250922211314-gcutf8v","Type":"NodeParagraph","Properties":{"id":"20250922211314-gcutf8v","updated":"20250922211324"},"Children":[{"Type":"NodeText","Data":"cipels in instructions。"}]},{"ID":"20250922211314-1yn0cz0","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-1yn0cz0","updated":"20250922211324"},"Children":[{"ID":"20250922211314-bfm9xl8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-bfm9xl8","updated":"20250922211314"},"Children":[{"ID":"20250922211314-qld7o4j","Type":"NodeParagraph","Properties":{"id":"20250922211314-qld7o4j","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RL fine-tuning (RL微调)."},{"Type":"NodeText","Data":" 在此步骤中，对齐（即微调）LM被形式化为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RL问题"},{"Type":"NodeText","Data":"。在此设置中，预训练的LM充当"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略"},{"Type":"NodeText","Data":"，它接收一个提示作为输入并返回一个输出文本；其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动作空间"},{"Type":"NodeText","Data":"是词汇表；"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"状态"},{"Type":"NodeText","Data":"是当前生成的词元序列；而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励"},{"Type":"NodeText","Data":"由RM提供。为了避免与初始（微调前）的LM偏离过远，通常会在奖励函数中加入一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"惩罚项"},{"Type":"NodeText","Data":"。例如，InstructGPT使用PPO算法针对RM优化LM。对于每个输入提示，InstructGPT计算当前LM和初始LM生成结果之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"KL散度"},{"Type":"NodeText","Data":"作为惩罚。值得注意的是，第二步和最后一步可以在多轮中迭代，以更好地对齐LLM。由于RL算法的不稳定性，最近的工作用另一个监督式微调取代了RL微调，通过重用排名最高的样本并给予更高的奖励。"}]}]}]},{"ID":"20250922211314-uvxcdag","Type":"NodeParagraph","Properties":{"id":"20250922211314-uvxcdag","updated":"20250922211324"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Practical Strategies for RLHF (RLHF的实用策略)."},{"Type":"NodeText","Data":" 尽管RLHF在有效提升LLM与人类的对齐方面很有前景，但对于研究人员来说，成功地实现它在实践中具有挑战性。在本部分中，我们重点讨论几种用于提升RLHF有效性和效率的实用策略和技巧。具体来说，我们分别关注奖励模型的有效训练，以及高效且有效的RL训练。"}]},{"ID":"20250922211314-zr6yruz","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-zr6yruz","updated":"20250922211324"},"Children":[{"ID":"20250922211314-gqfvqis","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-gqfvqis","updated":"20250922211314"},"Children":[{"ID":"20250922211314-v2u02o8","Type":"NodeParagraph","Properties":{"id":"20250922211314-v2u02o8","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有效的奖励模型训练 (Effective reward model training)."},{"Type":"NodeText","Data":" 尽管InstructGPT使用了一个小型的奖励模型（6B GPT模型），但越来越多的工作表明，使用一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型奖励模型"},{"Type":"NodeText","Data":"（例如，等于或大于原始模型大小）通常更有效，因为大型奖励模型在判断LLM生成输出的质量方面通常表现更好。在LLaMA 2中，使用预训练的聊天模型检查点来初始化奖励模型，他们认为这种方法可以通过共享相同的预训练知识，有效地减少待对齐模型与奖励模型之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"信息不匹配"},{"Type":"NodeText","Data":"。然而，在训练大规模奖励模型时，通常会遇到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过拟合"},{"Type":"NodeText","Data":"问题。作为一个简单而有效的解决方案，现有的工作引入了来自人类标注的对齐数据集中偏好响应的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LM损失"},{"Type":"NodeText","Data":"作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正则化项"},{"Type":"NodeText","Data":"，这缓解了奖励模型在二元分类任务上的过拟合。此外，由于存在多种对齐标准（例如，有用性和诚实性），训练一个能够满足所有对齐标准的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单一奖励模型"},{"Type":"NodeText","Data":"通常很困难。因此，训练专注于不同对齐标准的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多个奖励模型"},{"Type":"NodeText","Data":"是有用的，并通过特殊的组合策略（例如，均值池化和加权求和）来计算最终奖励。这种方式可以在多种标准上实现更灵活的规则或标准，例如，在放宽对有用性要求的同时，对无害性施加更严格的限制。"}]}]},{"ID":"20250922211314-isp7bfx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-isp7bfx","updated":"20250922211314"},"Children":[{"ID":"20250922211314-kti130a","Type":"NodeParagraph","Properties":{"id":"20250922211314-kti130a","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有效的RL训练 (Effective RL training)."},{"Type":"NodeText","Data":" 由于RL训练过程往往"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不稳定且对超参数敏感"},{"Type":"NodeText","Data":"，建议在RL训练之前，对语言模型进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"充分的监督微调"},{"Type":"NodeText","Data":"，以达到一个良好的模型能力。一种常用的方法是在RL之前，在对齐数据集中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最好的输出"},{"Type":"NodeText","Data":"（称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"拒绝采样"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"best-of-N"},{"Type":"NodeText","Data":"）上对LLM进行微调，直到收敛。给定一个提示，LLM首先会通过采样算法产生N个输出，然后奖励模型将选择模型中最好的候选者进行学习。在最好的样本上对LLM进行微调直到收敛后，将执行RL过程以进一步提升性能。LLaMA 2先后训练了五个版本的RLHF模型，其中LLM随着奖励模型的改进而逐步改进。通过这种方式，收集到的提示和人类偏好标注可以更好地反映当前模型检查点的问题，从而进行专门的微调来解决这些问题。此外，LLaMA 2还将先前迭代中的样本添加到后续迭代中，以缓解迭代优化期间可能出现的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力回归"},{"Type":"NodeText","Data":"问题。"}]}]},{"ID":"20250922211314-ywv3r1c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-ywv3r1c","updated":"20250922211314"},"Children":[{"ID":"20250922211314-ray9fq9","Type":"NodeParagraph","Properties":{"id":"20250922211314-ray9fq9","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效的RL训练 (Efficient RL training)."},{"Type":"NodeText","Data":" 由于RL训练需要迭代LLM和奖励模型的推理过程，它会极大地增加总内存和计算成本，特别是对于较大的奖励模型和LLM。作为一个实用的技巧，我们可以将奖励模型部署在一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单独的服务器"},{"Type":"NodeText","Data":"上，并调用相应的API与在其自己服务器上的LLM协同工作。此外，由于RLHF需要LLM生成多个候选输出，与其多次调用采样解码过程，不如利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"束搜索解码算法"},{"Type":"NodeText","Data":"更有效率。它只需要执行一次解码过程即可生成响应，同时这种策略也可以增强生成的候选响应的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922211314-9jgfa27","Type":"NodeParagraph","Properties":{"id":"20250922211314-9jgfa27","updated":"20250922211324"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Process-Supervised RLHF (过程监督的RLHF)."},{"Type":"NodeText","Data":" 在现有的RLHF文献中，RL训练的监督方法通常采用两种主要形式，即使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结果监督信号"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程监督信号"},{"Type":"NodeText","Data":"。结果监督的RLHF采用一个量化分数来评估LLM生成的整个文本的质量。相比之下，过程监督的RLHF对生成内容中的每个单独组件（例如，句子、词语或推理步骤）进行评估，利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"细粒度的监督信号"},{"Type":"NodeText","Data":"来指导训练，帮助LLM提炼不受欢迎的生成内容。接下来，我们讨论过程监督RLHF的两个关键方面。"}]},{"ID":"20250922211314-ph2mzni","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-ph2mzni","updated":"20250922211324"},"Children":[{"ID":"20250922211314-68mmwz9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-68mmwz9","updated":"20250922211314"},"Children":[{"ID":"20250922211314-lzy0sbx","Type":"NodeParagraph","Properties":{"id":"20250922211314-lzy0sbx","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"获取细粒度的监督信号 (Obtaining Fine-grained Supervision Signals)."},{"Type":"NodeText","Data":" 与结果奖励相比，获取细粒度的监督信号更为困难。OpenAI发布了一个名为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PRM800k"},{"Type":"NodeText","Data":"的细粒度标注数据集，包含12K个过程标注的数学问题（即MATH数据集）和由这些问题的LLM生成的75K个解决方案，其中数学问题的每个推理步骤在PRM800k中被标记为正面、负面或中性。考虑到人类标注过程的成本和效率，一些方法旨在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动标注"},{"Type":"NodeText","Data":"中间推理步骤的正确性，例如，使用强大的LLM直接替代人类标注员或使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"蒙特卡洛树搜索"},{"Type":"NodeText","Data":"。在获得细粒度的监督信号后，现有的工作通常利用它们来训练"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程监督的奖励模型（PRM）"},{"Type":"NodeText","Data":"，这些模型可以在RLHF过程中产生"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"步骤级别"},{"Type":"NodeText","Data":"的奖励（例如，基于句子或基于词元的奖励）。此外，RLMEC不是利用判别模型来产生奖励，而是利用一个在以最小编辑约束的重写任务上训练的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成式奖励模型"},{"Type":"NodeText","Data":"，来提供词元级别的奖励。此外，对于难以收集细粒度监督信号的下游任务，也可以利用结果监督信号来执行过程监督的RLHF。"}]}]},{"ID":"20250922211314-xrqy4lk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-xrqy4lk","updated":"20250922211314"},"Children":[{"ID":"20250922211314-de5jb7r","Type":"NodeParagraph","Properties":{"id":"20250922211314-de5jb7r","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用PRM (Utilizing the PRMs)."},{"Type":"NodeText","Data":" 为了有效地利用来自PRM的过程监督信号，现有的工作主要利用这些细粒度的信号来评估LLM响应中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单个部分"},{"Type":"NodeText","Data":"，然后引导LLM调整其生成行为以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大化"},{"Type":"NodeText","Data":"接收到的响应奖励。具体来说，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专家迭代"},{"Type":"NodeText","Data":"是一种有效的RL算法，已被用于通过向专家策略学习来改进基础策略。通常，专家迭代包含两个主要阶段："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略改进"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"蒸馏"},{"Type":"NodeText","Data":"。在策略改进阶段，专家策略在PRM的指导下处理系统性的搜索过程以产生样本。随后，在蒸馏阶段，第一阶段由专家策略生成的样本被用来通过监督微调来改进基础策略。除了专家迭代，PRM还可以用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重排"},{"Type":"NodeText","Data":"LLM生成的最终答案的候选者或在逐步推理期间选择更好的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"中间推理步骤"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922211314-8erng3x","Type":"NodeParagraph","Properties":{"id":"20250922211314-8erng3x","updated":"20250922211324"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.2.4 Alignment without RLHF (无RLHF的对齐)"},{"Type":"NodeText","Data":"\n尽管RLHF在使LLM的行为与人类价值观和偏好对齐方面取得了巨大成功，但它也存在显著的局限性。首先，RLHF需要同时训练多个LM，包括被对齐的模型、奖励模型和参考模型，这在算法流程和实践中的内存消耗上都"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常繁琐"},{"Type":"NodeText","Data":"。此外，RLHF中常用的PPO算法相当"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂"},{"Type":"NodeText","Data":"，并且通常对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超参数敏感"},{"Type":"NodeText","Data":"。作为替代方案，越来越多的研究探索直接优化LLM以遵循人类偏好，使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"监督微调"},{"Type":"NodeText","Data":"而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无需强化学习"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922211314-bd7ne02","Type":"NodeParagraph","Properties":{"id":"20250922211314-bd7ne02","updated":"20250922211324"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Overview (概述)."},{"Type":"NodeText","Data":" 无RLHF对齐方法的基本思想是直接在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高质量的对齐数据集"},{"Type":"NodeText","Data":"上使用监督学习来微调LLM。它基本上假设响应反馈或避免不安全行为的黄金规则已经被注入或包含在专门策划的对齐数据集中，因此LLM可以通过合适的微调策略直接从这些演示数据中学习到对齐的行为。因此，要实现这种方法，有两个关键问题："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐数据集的构建"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调损失的设计"},{"Type":"NodeText","Data":"。对于第一个问题，对齐数据集可以由一个对齐过的LLM根据人类编写的安全原则"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动构建"},{"Type":"NodeText","Data":"，或通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编辑操作"},{"Type":"NodeText","Data":"来提炼现有示例。此外，我们也可以重用现有的奖励模型从现有的人类反馈数据中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"选择高分响应"},{"Type":"NodeText","Data":"。对于第二个问题，无RLHF对齐方法主要以监督学习的方式（与原始指令微调损失相同）在高质量的对齐数据集上微调LLM，同时可以使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辅助学习目标"},{"Type":"NodeText","Data":"来增强对齐性能，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排序响应"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比指令-响应对"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922211314-hc1e16v","Type":"NodeParagraph","Properties":{"id":"20250922211314-hc1e16v","updated":"20250922211324"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alignment Data Collection (对齐数据的收集)."},{"Type":"NodeText","Data":" 对齐数据的构建对于有效地使LLM的行为与人类偏好对齐至关重要。为了收集高质量的对齐数据，一些工作尝试重用现有的奖励模型来选择高分响应，另一些则探索利用强大的LLM（例如，ChatGPT）或构建一个模拟环境来生成合成的对齐示例。接下来，我们将讨论这三条研究路线。"}]},{"ID":"20250922211314-gprnpq2","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-gprnpq2","updated":"20250922211324"},"Children":[{"ID":"20250922211314-8spzuu8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-8spzuu8","updated":"20250922211314"},"Children":[{"ID":"20250922211314-rf8adt3","Type":"NodeParagraph","Properties":{"id":"20250922211314-rf8adt3","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于奖励模型的方法 (Reward model based approaches)."},{"Type":"NodeText","Data":" RLHF中的奖励模型已被训练用于衡量LLM响应的对齐程度。直接利用现有的奖励模型来选择高质量的响应作为后续微调的对齐数据是很自然的。基于这个思想，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RAFT"},{"Type":"NodeText","Data":"采用在人类偏好数据上训练的奖励模型来对LLM的响应进行排序，并收集那些具有较高奖励的响应进行监督微调。此外，奖励模型也可以用来为模型响应打分，并将它们分配到不同的质量组中。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Quark"},{"Type":"NodeText","Data":"根据奖励分数将LLM的响应分到不同的分位数中。每个分位数都附有一个特殊的奖励词元，以表示该分位数的奖励水平。在最高奖励词元的条件下，LLM随后被提示生成高质量的响应。给定一个初始答案和相应的人类反馈，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ILF"},{"Type":"NodeText","Data":"首先采用LLM生成精炼的答案，然后利用奖励模型选择与反馈最匹配的答案进行进一步训练。作为对齐LLM的宝贵资源，一些"}]}]}]},{"ID":"20250922211314-6k1wdw5","Type":"NodeBlockquote","Properties":{"id":"20250922211314-6k1wdw5","updated":"20250922211324"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922211314-azse4k9","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211314-azse4k9","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922211314-zqcvped","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211314-zqcvped","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程监督RLHF：从“看结果”到“看过程”"}]},{"ID":"20250922211314-7i9570k","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-7i9570k","updated":"20250922211314"},"Children":[{"ID":"20250922211314-d7a850o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-d7a850o","updated":"20250922211314"},"Children":[{"ID":"20250922211314-8y38o8k","Type":"NodeParagraph","Properties":{"id":"20250922211314-8y38o8k","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心区别"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211314-z51sos5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-z51sos5","updated":"20250922211314"},"Children":[{"ID":"20250922211314-xf1iazo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-xf1iazo","updated":"20250922211314"},"Children":[{"ID":"20250922211314-rze36so","Type":"NodeParagraph","Properties":{"id":"20250922211314-rze36so","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结果监督 (Outcome-Supervised)"},{"Type":"NodeText","Data":": 传统的RLHF，只对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最终生成的完整文本"},{"Type":"NodeText","Data":"给出一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总分"},{"Type":"NodeText","Data":"。这就像考试只看总分，不看每道题的具体对错。"}]}]},{"ID":"20250922211314-hm55ufx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-hm55ufx","updated":"20250922211314"},"Children":[{"ID":"20250922211314-pajlsfu","Type":"NodeParagraph","Properties":{"id":"20250922211314-pajlsfu","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程监督 (Process-Supervised)"},{"Type":"NodeText","Data":": 对生成过程中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每一个步骤"},{"Type":"NodeText","Data":"（如数学题的每一步推理）都进行对错判断和打分。这就像批改作业时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"会指出具体错在哪一步"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922211314-7jggspz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-7jggspz","updated":"20250922211314"},"Children":[{"ID":"20250922211314-lp7r0kv","Type":"NodeParagraph","Properties":{"id":"20250922211314-lp7r0kv","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优势"},{"Type":"NodeText","Data":": 过程监督提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更细粒度、更精确"},{"Type":"NodeText","Data":"的指导信号，能帮助模型更好地学习"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理"},{"Type":"NodeText","Data":"任务，因为它能定位并修正推理链条中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体错误环节"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211314-55ntdu6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-55ntdu6","updated":"20250922211314"},"Children":[{"ID":"20250922211314-6cqe470","Type":"NodeParagraph","Properties":{"id":"20250922211314-6cqe470","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"挑战"},{"Type":"NodeText","Data":": 获取这种细粒度的“过程”标注数据，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成本极高"},{"Type":"NodeText","Data":"。因此，研究方向转向了如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动化"},{"Type":"NodeText","Data":"这一过程，例如用GPT-4当“助教”来批改作业，或者通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专家迭代（Expert Iteration）"},{"Type":"NodeText","Data":"等算法，让模型在“过程奖励模型”的指导下进行自我探索和学习。"}]}]}]},{"ID":"20250922211314-9kn0rf0","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211314-9kn0rf0","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无RLHF的对齐：另辟蹊径"}]},{"ID":"20250922211314-d27twnn","Type":"NodeParagraph","Properties":{"id":"20250922211314-d27twnn","updated":"20250922211314"},"Children":[{"Type":"NodeText","Data":"这部分内容探讨了对RLHF的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“革命”"},{"Type":"NodeText","Data":"，即能否"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"绕过复杂、不稳定的强化学习"},{"Type":"NodeText","Data":"，用更简单的方法实现对齐。"}]},{"ID":"20250922211314-7n1dan6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-7n1dan6","updated":"20250922211314"},"Children":[{"ID":"20250922211314-vz6c2vg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-vz6c2vg","updated":"20250922211314"},"Children":[{"ID":"20250922211314-9y1mbsp","Type":"NodeParagraph","Properties":{"id":"20250922211314-9y1mbsp","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动机"},{"Type":"NodeText","Data":": RLHF（特别是PPO算法）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"太复杂、太难训练、对超参数太敏感"},{"Type":"NodeText","Data":"，而且需要维护多个模型，工程上非常繁琐。"}]}]},{"ID":"20250922211314-r0nh3yw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-r0nh3yw","updated":"20250922211314"},"Children":[{"ID":"20250922211314-6ub4nbt","Type":"NodeParagraph","Properties":{"id":"20250922211314-6ub4nbt","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将对齐问题转化为一个更高质量的监督微调（SFT）问题"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922211314-y9x3c4m","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-y9x3c4m","updated":"20250922211314"},"Children":[{"ID":"20250922211314-zlf1qug","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-zlf1qug","updated":"20250922211314"},"Children":[{"ID":"20250922211314-1neu9sf","Type":"NodeParagraph","Properties":{"id":"20250922211314-1neu9sf","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"假设"},{"Type":"NodeText","Data":": 只要我们能构建一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“足够好”"},{"Type":"NodeText","Data":"的对齐数据集，其中只包含符合人类偏好的“正面范例”，那么通过简单的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"监督微调"},{"Type":"NodeText","Data":"，就能教会模型对齐。"}]}]},{"ID":"20250922211314-uv4mxhn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-uv4mxhn","updated":"20250922211314"},"Children":[{"ID":"20250922211314-ohxxarz","Type":"NodeParagraph","Properties":{"id":"20250922211314-ohxxarz","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两个关键"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211314-obwd61o","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211314-obwd61o","updated":"20250922211314"},"Children":[{"ID":"20250922211314-1j8x4d0","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211314-1j8x4d0","updated":"20250922211314"},"Children":[{"ID":"20250922211314-dxjd2xt","Type":"NodeParagraph","Properties":{"id":"20250922211314-dxjd2xt","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何构建“足够好”的数据集？"}]}]},{"ID":"20250922211314-07qvsui","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211314-07qvsui","updated":"20250922211314"},"Children":[{"ID":"20250922211314-78egugo","Type":"NodeParagraph","Properties":{"id":"20250922211314-78egugo","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何设计“足够好”的微调损失函数？"}]}]}]}]}]}]},{"ID":"20250922211314-rpql53t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-rpql53t","updated":"20250922211314"},"Children":[{"ID":"20250922211314-gp9t3qn","Type":"NodeParagraph","Properties":{"id":"20250922211314-gp9t3qn","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐数据的“生产线”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211314-pdas4vf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-pdas4vf","updated":"20250922211314"},"Children":[{"ID":"20250922211314-epit4zy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-epit4zy","updated":"20250922211314"},"Children":[{"ID":"20250922211314-v4bwxjp","Type":"NodeParagraph","Properties":{"id":"20250922211314-v4bwxjp","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于奖励模型筛选 (Reward model based)"},{"Type":"NodeText","Data":": 这是最直接的方法。用一个已经训练好的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型"},{"Type":"NodeText","Data":"，去给海量的模型生成内容"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“打分”"},{"Type":"NodeText","Data":"，然后只挑选那些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高分"},{"Type":"NodeText","Data":"的回答作为“正面范例”来微调。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RAFT"},{"Type":"NodeText","Data":"是这一思路的代表。"}]}]},{"ID":"20250922211314-63i4ioe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-63i4ioe","updated":"20250922211314"},"Children":[{"ID":"20250922211314-7m5e1bk","Type":"NodeParagraph","Properties":{"id":"20250922211314-7m5e1bk","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于LLM生成 (LLM based generative)"},{"Type":"NodeText","Data":": 利用一个已经"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐好的、强大的LLM"},{"Type":"NodeText","Data":"（如GPT-4），让它根据人类制定的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“宪法（Constitution）”"},{"Type":"NodeText","Data":"或原则，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动生成"},{"Type":"NodeText","Data":"大量符合价值观的回答。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Constitutional AI"},{"Type":"NodeText","Data":"是这一思想的开创者。"}]}]},{"ID":"20250922211314-uo5l56x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-uo5l56x","updated":"20250922211314"},"Children":[{"ID":"20250922211314-3b1a7ou","Type":"NodeParagraph","Properties":{"id":"20250922211314-3b1a7ou","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于交互模拟 (LLM based interactive)"},{"Type":"NodeText","Data":": 在一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模拟社会"},{"Type":"NodeText","Data":"中，让多个LLM智能体相互交互、相互批评、相互改进，从而生成对齐的数据。"}]}]}]}]}]},{"ID":"20250922211314-b30tocl","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211314-b30tocl","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调损失的创新"}]},{"ID":"20250922211314-8iyr0u5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-8iyr0u5","updated":"20250922211314"},"Children":[{"ID":"20250922211314-cefzevx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-cefzevx","updated":"20250922211314"},"Children":[{"ID":"20250922211314-puy9289","Type":"NodeParagraph","Properties":{"id":"20250922211314-puy9289","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越简单SFT"},{"Type":"NodeText","Data":": 除了标准的交叉熵损失，无RLHF对齐方法还探索了更复杂的损失函数。"}]},{"ID":"20250922211314-m70f2vb","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-m70f2vb","updated":"20250922211314"},"Children":[{"ID":"20250922211314-n9te97t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-n9te97t","updated":"20250922211314"},"Children":[{"ID":"20250922211314-bsd7dem","Type":"NodeParagraph","Properties":{"id":"20250922211314-bsd7dem","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"直接偏好优化 (Direct Preference Optimization, DPO)"},{"Type":"NodeText","Data":": 这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无RLHF对齐的里程碑式工作"},{"Type":"NodeText","Data":"。它通过巧妙的数学变换，将RLHF中复杂的“奖励建模+强化学习”过程，等价地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推导"},{"Type":"NodeText","Data":"成一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简单的、可以直接用偏好对（\u0026lt;赢的回答, 输的回答\u0026gt;）进行优化的分类损失"},{"Type":"NodeText","Data":"。DPO极大地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简化"},{"Type":"NodeText","Data":"了对齐过程，效果却不输RLHF，已成为当前最主流的对齐技术之一。"}]}]},{"ID":"20250922211314-4jn2kqo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-4jn2kqo","updated":"20250922211314"},"Children":[{"ID":"20250922211314-iu4rzbg","Type":"NodeParagraph","Properties":{"id":"20250922211314-iu4rzbg","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辅助损失"},{"Type":"NodeText","Data":": 在SFT的基础上，增加一些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辅助目标"},{"Type":"NodeText","Data":"，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排序损失（Ranking Loss）"},{"Type":"NodeText","Data":"，明确地告诉模型“好的回答”的概率应该高于“坏的回答”。"}]}]}]}]}]}]},{"ID":"20250922211314-i48b2av","Type":"NodeThematicBreak","Properties":{"id":"20250922211314-i48b2av","updated":"20250922211324"}},{"ID":"20250922211314-t45k9ac","Type":"NodeBlockquote","Properties":{"id":"20250922211314-t45k9ac","updated":"20250922211324"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922211314-zm8tbqa","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211314-zm8tbqa","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922211314-78r91kz","Type":"NodeParagraph","Properties":{"id":"20250922211314-78r91kz","updated":"20250922211314"},"Children":[{"Type":"NodeText","Data":"第三十二和三十三部分（合并分析）系统地探讨了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调（Alignment Tuning）"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大技术路线"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以RLHF为代表的“强化学习”路线"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以DPO为代表的“监督学习”路线"},{"Type":"NodeText","Data":"。这展现了AI对齐领域内部深刻的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术思辨和范式演进"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922211314-yrckwjl","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211314-yrckwjl","updated":"20250922211314"},"Children":[{"ID":"20250922211314-jz4vjkm","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211314-jz4vjkm","updated":"20250922211314"},"Children":[{"ID":"20250922211314-3w9ifmx","Type":"NodeParagraph","Properties":{"id":"20250922211314-3w9ifmx","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“结果”到“过程”的深化 (RLHF内部演进)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211314-4ycvalt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-4ycvalt","updated":"20250922211314"},"Children":[{"ID":"20250922211314-9t8ypuq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-9t8ypuq","updated":"20250922211314"},"Children":[{"ID":"20250922211314-k7v04ni","Type":"NodeParagraph","Properties":{"id":"20250922211314-k7v04ni","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程监督RLHF"},{"Type":"NodeText","Data":"的提出，标志着RLHF技术自身正在从一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"粗粒度的“结果导向”"},{"Type":"NodeText","Data":"，向一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"细粒度的“过程导向”"},{"Type":"NodeText","Data":"深化。"}]}]},{"ID":"20250922211314-syah9sj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-syah9sj","updated":"20250922211314"},"Children":[{"ID":"20250922211314-q1afd9l","Type":"NodeParagraph","Properties":{"id":"20250922211314-q1afd9l","updated":"20250922211314"},"Children":[{"Type":"NodeText","Data":"这对于解决需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严密逻辑链条"},{"Type":"NodeText","Data":"的复杂推理任务至关重要，因为它能帮助模型“知其然，并知其所以然”，修复推理过程中的具体错误。"}]}]}]}]},{"ID":"20250922211314-9mun82n","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211314-9mun82n","updated":"20250922211314"},"Children":[{"ID":"20250922211314-lytwwff","Type":"NodeParagraph","Properties":{"id":"20250922211314-lytwwff","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“大道至简”的范式革命 (无RLHF路线)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211314-2uws15f","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-2uws15f","updated":"20250922211314"},"Children":[{"ID":"20250922211314-xjrikde","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-xjrikde","updated":"20250922211314"},"Children":[{"ID":"20250922211314-xiedcku","Type":"NodeParagraph","Properties":{"id":"20250922211314-xiedcku","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无RLHF对齐"},{"Type":"NodeText","Data":"的兴起，是对RLHF"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“过度复杂”"},{"Type":"NodeText","Data":"问题的一次深刻反思和大胆的“拨乱反正”。"}]}]},{"ID":"20250922211314-8by1h1a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-8by1h1a","updated":"20250922211314"},"Children":[{"ID":"20250922211314-nzq7ssz","Type":"NodeParagraph","Properties":{"id":"20250922211314-nzq7ssz","updated":"20250922211314"},"Children":[{"Type":"NodeText","Data":"其核心哲学是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能否用更简单的监督学习，实现与复杂的强化学习同样甚至更好的效果？"}]}]},{"ID":"20250922211314-vn8xkh2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-vn8xkh2","updated":"20250922211314"},"Children":[{"ID":"20250922211314-2qqg9dd","Type":"NodeParagraph","Properties":{"id":"20250922211314-2qqg9dd","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DPO (直接偏好优化)"},{"Type":"NodeText","Data":"的成功，响亮地回答了“能”。它通过严谨的数学推导，将RLHF的目标"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“翻译”"},{"Type":"NodeText","Data":"成了一个等价的、可以直接用SFT方式优化的新目标。这不仅是技术上的巨大简化，更是理论上的一次深刻洞见。DPO的出现，极大地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"降低了对齐的技术门槛"},{"Type":"NodeText","Data":"，加速了整个领域的创新。"}]}]}]}]},{"ID":"20250922211314-9u2t7wu","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922211314-9u2t7wu","updated":"20250922211314"},"Children":[{"ID":"20250922211314-lsr7ew1","Type":"NodeParagraph","Properties":{"id":"20250922211314-lsr7ew1","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据构建方法的“异曲同工”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211314-fx0vn2a","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211314-fx0vn2a","updated":"20250922211314"},"Children":[{"ID":"20250922211314-1y62br9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-1y62br9","updated":"20250922211314"},"Children":[{"ID":"20250922211314-n4mn30z","Type":"NodeParagraph","Properties":{"id":"20250922211314-n4mn30z","updated":"20250922211314"},"Children":[{"Type":"NodeText","Data":"无论是RLHF还是无RLHF对齐，它们成功的基石都是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高质量的偏好数据"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211314-mw5bb6p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-mw5bb6p","updated":"20250922211314"},"Children":[{"ID":"20250922211314-94neq99","Type":"NodeParagraph","Properties":{"id":"20250922211314-94neq99","updated":"20250922211314"},"Children":[{"Type":"NodeText","Data":"在如何获取这些数据上，两条路线殊途同归，都发展出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三条主流路径"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211314-rbxpaps","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211314-rbxpaps","updated":"20250922211314"},"Children":[{"ID":"20250922211314-y7xpabz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211314-y7xpabz","updated":"20250922211314"},"Children":[{"ID":"20250922211314-cclzd2q","Type":"NodeParagraph","Properties":{"id":"20250922211314-cclzd2q","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用现有奖励模型筛选"}]}]},{"ID":"20250922211314-exzhp85","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211314-exzhp85","updated":"20250922211314"},"Children":[{"ID":"20250922211314-o3h6rbd","Type":"NodeParagraph","Properties":{"id":"20250922211314-o3h6rbd","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用强大LLM生成（如Constitutional AI）"}]}]},{"ID":"20250922211314-xone5vw","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922211314-xone5vw","updated":"20250922211314"},"Children":[{"ID":"20250922211314-6ib2xfj","Type":"NodeParagraph","Properties":{"id":"20250922211314-6ib2xfj","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用多智能体交互模拟"}]}]}]}]},{"ID":"20250922211314-biepp8n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211314-biepp8n","updated":"20250922211314"},"Children":[{"ID":"20250922211314-gx86xio","Type":"NodeParagraph","Properties":{"id":"20250922211314-gx86xio","updated":"20250922211314"},"Children":[{"Type":"NodeText","Data":"这表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何高效、低成本地自动化生产高质量的对齐数据"},{"Type":"NodeText","Data":"，是整个对齐领域面临的共同核心挑战。"}]}]}]}]}]},{"ID":"20250922211314-pv1mpe9","Type":"NodeParagraph","Properties":{"id":"20250922211314-pv1mpe9","updated":"20250922211314"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这两部分内容为我们描绘了一幅生动的AI对齐"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术演进图谱"},{"Type":"NodeText","Data":"。它始于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开创性但复杂的RLHF"},{"Type":"NodeText","Data":"，在内部深化为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更精细的过程监督"},{"Type":"NodeText","Data":"，最终在外部演化出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更简单、更高效的DPO"},{"Type":"NodeText","Data":"这一革命性替代方案。这一演进过程完美地体现了科学与工程发展的内在规律："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在追求强大效果的同时，永远在探索更简洁、更优雅、更第一性的解决方案"},{"Type":"NodeText","Data":"。DPO的成功，正是这一规律的绝佳例证。"}]}]},{"ID":"20250922211511-e0508w9","Type":"NodeParagraph","Properties":{"id":"20250922211511-e0508w9","updated":"20250922211511"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922211511-1qk5be4","Type":"NodeThematicBreak","Properties":{"id":"20250922211511-1qk5be4","updated":"20250922211511"}},{"ID":"20250922211511-f6j896o","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211511-f6j896o","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三十四部分"}]},{"ID":"20250922211511-02ev3sw","Type":"NodeParagraph","Properties":{"id":"20250922211511-02ev3sw","updated":"20250922211526"},"Children":[{"Type":"NodeText","Data":"奖励模型已经被发布，包括来自OpenAssistant的DeBERTa-base/large/xxlarge，来自复旦大学的Moss-7B，以及来自斯坦福大学的Flan-T5-xl。"}]},{"ID":"20250922211511-8a6s2ln","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211511-8a6s2ln","updated":"20250922211526"},"Children":[{"ID":"20250922211511-gz7bq9f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-gz7bq9f","updated":"20250922211511"},"Children":[{"ID":"20250922211511-gbxxo5w","Type":"NodeParagraph","Properties":{"id":"20250922211511-gbxxo5w","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于LLM的生成方法 (LLM based generative approaches)."},{"Type":"NodeText","Data":" 奖励模型帮助从模型响应中选择对齐的数据。然而，训练奖励模型本身需要大量高质量的人类标记数据，这通常是昂贵且稀缺的。此外，尽管可以重用现有的奖励模型，但它们可能无法准确捕捉到另一个独立训练的LLM中的不对齐行为。因此，一些工作探索利用强大的LLM来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动生成"},{"Type":"NodeText","Data":"人类对齐的数据。作为一个代表性的工作，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"宪法AI（Constitutional AI）"},{"Type":"NodeText","Data":"提出，人类的监督来自于一套管理AI行为的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"原则（即自然语言指令）"},{"Type":"NodeText","Data":"。基于这些原则，LLM将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"批判"},{"Type":"NodeText","Data":"它们自己有害的响应，并反复"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"修正"},{"Type":"NodeText","Data":"它们，最终形成对齐的响应。类似地，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Align"},{"Type":"NodeText","Data":"首先采用自指令来生成覆盖不同主题的指令。然后，模型也被提示多个人类编写的原则，这些原则描述了期望的模型行为规则（也附带一些上下文范例），以生成有帮助、合乎道德且可靠的响应作为对齐数据。为了缓解原始SFT方法只能从正面响应中学习的局限性，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FIGA"},{"Type":"NodeText","Data":"开发了一种改进的监督对齐方法，其中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"负面（原始的低质量输出）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正面（由LLM精炼的输出）"},{"Type":"NodeText","Data":"响应被以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比"},{"Type":"NodeText","Data":"的方式加以利用，以使LLM能够深入理解哪些细粒度的修正真正导致了好的响应。"}]}]},{"ID":"20250922211511-1ov5tbd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-1ov5tbd","updated":"20250922211511"},"Children":[{"ID":"20250922211511-xbcvamp","Type":"NodeParagraph","Properties":{"id":"20250922211511-xbcvamp","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于LLM的交互方法 (LLM based interactive approaches)."},{"Type":"NodeText","Data":" 大多数现有方法在隔离环境中训练LLM，其中LLM并非处于实际环境中，无法通过外部反馈信号来提升自己。相比之下，人类在社交环境中通过与他人互动来学习社会规范和价值观。为了模仿这种学习方式，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Stable Alignment"},{"Type":"NodeText","Data":"构建了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模拟的交互环境"},{"Type":"NodeText","Data":"，由多个LLM智能体组成，其中AI智能体不断地相互交互，并接收关于改进的反馈。一旦一个中心智能体接收到一条指令，它会产生一个响应并与附近的智能体分享。这些批评智能体会生成包含对响应的评级和修正建议的反馈。然后，中心智能体会根据这些建议修正原始响应。这种对齐方法也可以扩展到真实世界的人类环境。"}]}]}]},{"ID":"20250922211511-k1b3wie","Type":"NodeParagraph","Properties":{"id":"20250922211511-k1b3wie","updated":"20250922211526"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Supervised Alignment Tuning (监督式对齐微调)."},{"Type":"NodeText","Data":" 在获得对齐数据后，设计合适的微调策略以进行直接对齐也至关重要。一个直接的方法是使用传统的序列到序列目标，在对齐数据上优化LLM。除了传统的优化目标，一些研究进一步探索了可以增强从对齐数据中学习的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辅助损失"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922211511-cr9oz9o","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211511-cr9oz9o","updated":"20250922211526"},"Children":[{"ID":"20250922211511-noz213v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-noz213v","updated":"20250922211511"},"Children":[{"ID":"20250922211511-h91sqdu","Type":"NodeParagraph","Properties":{"id":"20250922211511-h91sqdu","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主要训练目标 (Primary training objective)."},{"Type":"NodeText","Data":" 由于对齐数据通常由一个输入指令和一个输出响应组成，因此主要训练损失仍然是传统的用于序列到序列学习的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交叉熵损失"},{"Type":"NodeText","Data":"。基于这个损失，许多研究提出了多种改进变体，以增强监督式对齐微调。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoH"},{"Type":"NodeText","Data":"通过在标注的好和坏响应前分别加上“一个有帮助的回答：”和“一个无帮助的回答：”来构建训练数据，并且只计算那些带有特殊掩码的响应词元的损失。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Quark"},{"Type":"NodeText","Data":"将模型响应根据不同的对齐质量分到不同的分位数中，它在每个模型响应前加上一个特殊的奖励词元来表示该响应的奖励水平。这些研究基本上采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大似然目标"},{"Type":"NodeText","Data":"，并利用指令前缀来指导人类偏好的学习。"}]}]},{"ID":"20250922211511-jnewp89","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-jnewp89","updated":"20250922211511"},"Children":[{"ID":"20250922211511-pxyf527","Type":"NodeParagraph","Properties":{"id":"20250922211511-pxyf527","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"直接偏好优化 (Direct preference optimization, DPO)."},{"Type":"NodeText","Data":" 为了更好地在监督学习中模仿RLHF的学习方法，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DPO"},{"Type":"NodeText","Data":"提议使用策略模型（即被优化的语言模型）来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重新参数化"},{"Type":"NodeText","Data":"响应奖励，然后原始的奖励建模目标可以被重新形式化为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"仅基于策略模型"},{"Type":"NodeText","Data":"。通过这种方式，DPO"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"移除了显式的奖励建模步骤"},{"Type":"NodeText","Data":"，并且优化这个仅涉及策略模型的新学习目标等同于优化奖励。基于DPO，现有的工作已经提出了几种改进策略来增强其有效性或效率，例如，将正面响应和负面响应的优化分解为两个独立的组件，或在目标函数中移除参考模型的概率。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FIGA"},{"Type":"NodeText","Data":"设计了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词元级别的对比损失"},{"Type":"NodeText","Data":"，旨在鼓励期望的词元，惩罚不期望的词元，并忽略无关紧要的词元。尽管有效，但最近的工作也揭示了DPO在几个方面可能存在固有的局限性。首先，基于对幅度和梯度方向的分析，最近的工作揭示DPO可能在很好地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平衡正面实例和负面实例的学习"},{"Type":"NodeText","Data":"方面存在困难。此外，由于参考模型在DPO算法中为自己提供奖励分数，一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"弱的参考模型"},{"Type":"NodeText","Data":"也会影响对齐性能，这可以通过改进的学习策略或训练良好的策略模型来增强。"}]}]},{"ID":"20250922211511-o4o95el","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-o4o95el","updated":"20250922211511"},"Children":[{"ID":"20250922211511-7pe16h2","Type":"NodeParagraph","Properties":{"id":"20250922211511-7pe16h2","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辅助优化目标 (Auxiliary optimization objectives)."},{"Type":"NodeText","Data":" 除了主要的交叉熵损失，一些研究提出了辅助训练损失来增强从对齐数据中的学习。首先，由于每个指令的响应可以由奖励模型打分，可以使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排序损失"},{"Type":"NodeText","Data":"来训练模型以保持这些响应的排序顺序。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RRHF"},{"Type":"NodeText","Data":"从多个来源（包括模型自身、ChatGPT和GPT-4生成的响应，以及人类编写的响应）采样响应，涵盖了高质量和低质量的实例。为了与奖励模型的分数对齐，它进一步通过鼓励模型对排名较高的响应具有更高的条件对数概率来优化排序损失。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SLiC-HF"},{"Type":"NodeText","Data":"提议通过潜在空间中的距离来评估模型输出和人类偏好之间的相似性，并引入特定的校准"}]}]}]},{"ID":"20250922211511-nqudumr","Type":"NodeBlockquote","Properties":{"id":"20250922211511-nqudumr","updated":"20250922211526"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922211511-a8l0jh9","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211511-a8l0jh9","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922211511-y6ijnmy","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211511-y6ijnmy","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无RLHF对齐：方法的多样性"}]},{"ID":"20250922211511-jcyh03j","Type":"NodeParagraph","Properties":{"id":"20250922211511-jcyh03j","updated":"20250922211511"},"Children":[{"Type":"NodeText","Data":"这部分详细阐述了在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不使用强化学习"},{"Type":"NodeText","Data":"的情况下，如何实现对齐的两种核心技术："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据构建"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"损失函数设计"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922211511-4tnmy0r","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211511-4tnmy0r","updated":"20250922211511"},"Children":[{"ID":"20250922211511-bn39fjx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-bn39fjx","updated":"20250922211511"},"Children":[{"ID":"20250922211511-isl7m3u","Type":"NodeParagraph","Properties":{"id":"20250922211511-isl7m3u","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据构建的三条路径"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211511-dxzrp4g","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211511-dxzrp4g","updated":"20250922211511"},"Children":[{"ID":"20250922211511-5tt65ko","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211511-5tt65ko","updated":"20250922211511"},"Children":[{"ID":"20250922211511-7mbwp4e","Type":"NodeParagraph","Properties":{"id":"20250922211511-7mbwp4e","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励模型筛选 (Reward model based)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“废物利用”"},{"Type":"NodeText","Data":"。利用已有的奖励模型，从海量数据中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“淘金”"},{"Type":"NodeText","Data":"，筛选出高分样本作为训练数据。"}]}]},{"ID":"20250922211511-2uq502k","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211511-2uq502k","updated":"20250922211511"},"Children":[{"ID":"20250922211511-u5942x0","Type":"NodeParagraph","Properties":{"id":"20250922211511-u5942x0","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM生成 (LLM based generative)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自我进化”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922211511-bcnvhjh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211511-bcnvhjh","updated":"20250922211511"},"Children":[{"ID":"20250922211511-omqvo90","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-omqvo90","updated":"20250922211511"},"Children":[{"ID":"20250922211511-nyr0pp5","Type":"NodeParagraph","Properties":{"id":"20250922211511-nyr0pp5","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"宪法AI (Constitutional AI)"},{"Type":"NodeText","Data":": 这是一个里程碑式的思想。它为AI设定一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“宪法”"},{"Type":"NodeText","Data":"（原则），然后让AI自己"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“批判和修正”"},{"Type":"NodeText","Data":"自己的输出，直到符合宪法。这是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内部的、自监督的"},{"Type":"NodeText","Data":"对齐过程。"}]}]},{"ID":"20250922211511-ypxulh3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-ypxulh3","updated":"20250922211511"},"Children":[{"ID":"20250922211511-f3vouvb","Type":"NodeParagraph","Properties":{"id":"20250922211511-f3vouvb","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FIGA"},{"Type":"NodeText","Data":": 提出了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比学习"},{"Type":"NodeText","Data":"的方法，同时利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“好的”"},{"Type":"NodeText","Data":"（修正后）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“坏的”"},{"Type":"NodeText","Data":"（修正前）的例子，让模型更深刻地理解"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“为什么好，好在哪里”"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922211511-wub1t7n","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922211511-wub1t7n","updated":"20250922211511"},"Children":[{"ID":"20250922211511-zzaxr21","Type":"NodeParagraph","Properties":{"id":"20250922211511-zzaxr21","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM交互 (LLM based interactive)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“社会化学习”"},{"Type":"NodeText","Data":"。通过构建一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“AI社会”"},{"Type":"NodeText","Data":"，让多个LLM智能体相互交互、相互评价，从中学习社会规范。这是一种更接近人类学习方式的、前瞻性的探索。"}]}]}]}]},{"ID":"20250922211511-tehcp1i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-tehcp1i","updated":"20250922211511"},"Children":[{"ID":"20250922211511-9azdurr","Type":"NodeParagraph","Properties":{"id":"20250922211511-9azdurr","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"损失函数设计的创新"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211511-avla9al","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211511-avla9al","updated":"20250922211511"},"Children":[{"ID":"20250922211511-w2jfyvx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-w2jfyvx","updated":"20250922211511"},"Children":[{"ID":"20250922211511-pmkv1iu","Type":"NodeParagraph","Properties":{"id":"20250922211511-pmkv1iu","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从模仿到偏好"},{"Type":"NodeText","Data":": 简单的SFT损失只是在“模仿”好的例子。新的损失函数设计旨在更直接地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“学习偏好”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211511-npbahv7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-npbahv7","updated":"20250922211511"},"Children":[{"ID":"20250922211511-9vdq09c","Type":"NodeParagraph","Properties":{"id":"20250922211511-9vdq09c","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DPO (Direct Preference Optimization)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心革命"},{"Type":"NodeText","Data":"。它在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论上"},{"Type":"NodeText","Data":"证明了RLHF的奖励最大化目标，可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"等价地"},{"Type":"NodeText","Data":"转化为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可以直接用偏好对进行优化的SFT损失"},{"Type":"NodeText","Data":"。这使得研究者可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“鱼与熊掌兼得”"},{"Type":"NodeText","Data":"——既享受到RLHF学习偏好的好处，又避免了其复杂和不稳定的过程。DPO的成功使其成为当前对齐技术的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"新SOTA"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211511-4c8t658","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-4c8t658","updated":"20250922211511"},"Children":[{"ID":"20250922211511-sal4x0c","Type":"NodeParagraph","Properties":{"id":"20250922211511-sal4x0c","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DPO的局限与改进"},{"Type":"NodeText","Data":": DPO也并非完美，后续研究指出了其在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"平衡正负样本学习"},{"Type":"NodeText","Data":"上的困难，以及对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参考模型质量的依赖"},{"Type":"NodeText","Data":"，并据此提出了各种改进方案。"}]}]},{"ID":"20250922211511-zhlzutk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-zhlzutk","updated":"20250922211511"},"Children":[{"ID":"20250922211511-is2nqly","Type":"NodeParagraph","Properties":{"id":"20250922211511-is2nqly","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辅助损失"},{"Type":"NodeText","Data":": 除了主要的损失，还可以加入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排序损失（Ranking Loss, 如RRHF）"},{"Type":"NodeText","Data":"等辅助目标，更明确地告诉模型“A的概率应该大于B”。"}]}]}]}]}]},{"ID":"20250922211511-dmjm69v","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211511-dmjm69v","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心技术的演进：从RLHF到DPO"}]},{"ID":"20250922211511-iesgvob","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211511-iesgvob","updated":"20250922211511"},"Children":[{"ID":"20250922211511-qdw8iiq","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211511-qdw8iiq","updated":"20250922211511"},"Children":[{"ID":"20250922211511-wil7x5y","Type":"NodeParagraph","Properties":{"id":"20250922211511-wil7x5y","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动机"},{"Type":"NodeText","Data":": 解决RLHF的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂性、不稳定性、高成本"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211511-zdgsm1q","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211511-zdgsm1q","updated":"20250922211511"},"Children":[{"ID":"20250922211511-gx03nxw","Type":"NodeParagraph","Properties":{"id":"20250922211511-gx03nxw","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": 将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习问题"},{"Type":"NodeText","Data":"（奖励最大化）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"转化"},{"Type":"NodeText","Data":"为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"监督学习问题"},{"Type":"NodeText","Data":"（损失最小化）。"}]}]},{"ID":"20250922211511-q4cezjk","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922211511-q4cezjk","updated":"20250922211511"},"Children":[{"ID":"20250922211511-8u15hqb","Type":"NodeParagraph","Properties":{"id":"20250922211511-8u15hqb","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键突破"},{"Type":"NodeText","Data":": DPO提供了这种转化的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学桥梁和理论保证"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211511-dkxpi3j","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922211511-dkxpi3j","updated":"20250922211511"},"Children":[{"ID":"20250922211511-tzf0zv2","Type":"NodeParagraph","Properties":{"id":"20250922211511-tzf0zv2","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"影响"},{"Type":"NodeText","Data":": 极大地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简化了对齐流程"},{"Type":"NodeText","Data":"，降低了技术门槛，加速了整个领域的迭代。"}]}]}]}]},{"ID":"20250922211511-eq91943","Type":"NodeThematicBreak","Properties":{"id":"20250922211511-eq91943","updated":"20250922211526"}},{"ID":"20250922211511-21uviue","Type":"NodeBlockquote","Properties":{"id":"20250922211511-21uviue","updated":"20250922211526"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922211511-udozep5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211511-udozep5","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922211511-hwkovqn","Type":"NodeParagraph","Properties":{"id":"20250922211511-hwkovqn","updated":"20250922211511"},"Children":[{"Type":"NodeText","Data":"第三十四部分是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无RLHF对齐"},{"Type":"NodeText","Data":"这一前沿领域的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统性梳理"},{"Type":"NodeText","Data":"，它清晰地展示了研究者们是如何通过在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“算法（损失函数）”"},{"Type":"NodeText","Data":"两个层面的创新，来寻求一种比RLHF更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简单、高效、稳定"},{"Type":"NodeText","Data":"的对齐范式。"}]},{"ID":"20250922211511-dkou1bc","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211511-dkou1bc","updated":"20250922211511"},"Children":[{"ID":"20250922211511-roypqf6","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211511-roypqf6","updated":"20250922211511"},"Children":[{"ID":"20250922211511-7384klq","Type":"NodeParagraph","Properties":{"id":"20250922211511-7384klq","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐的“第一性原理”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211511-ko0iskx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211511-ko0iskx","updated":"20250922211511"},"Children":[{"ID":"20250922211511-ubkngmx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-ubkngmx","updated":"20250922211511"},"Children":[{"ID":"20250922211511-9wdcomd","Type":"NodeParagraph","Properties":{"id":"20250922211511-9wdcomd","updated":"20250922211511"},"Children":[{"Type":"NodeText","Data":"本部分回归到了对齐的本质："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"让模型学会区分“好”与“坏”"},{"Type":"NodeText","Data":"。RLHF通过奖励模型和强化学习来实现这一点，而无RLHF方法则试图通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更直接"},{"Type":"NodeText","Data":"的方式——精心构建的数据和损失函数——来达到同样的目的。"}]}]}]}]},{"ID":"20250922211511-uccue31","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211511-uccue31","updated":"20250922211511"},"Children":[{"ID":"20250922211511-1rcrt58","Type":"NodeParagraph","Properties":{"id":"20250922211511-1rcrt58","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据构建的“智能化”与“自动化”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211511-v7ewcwn","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211511-v7ewcwn","updated":"20250922211511"},"Children":[{"ID":"20250922211511-ktud0gh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-ktud0gh","updated":"20250922211511"},"Children":[{"ID":"20250922211511-z47pi6d","Type":"NodeParagraph","Properties":{"id":"20250922211511-z47pi6d","updated":"20250922211511"},"Children":[{"Type":"NodeText","Data":"无论是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"宪法AI"},{"Type":"NodeText","Data":"的“自我批判”，还是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Stable Alignment"},{"Type":"NodeText","Data":"的“社会模拟”，都体现了一个清晰的趋势："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用LLM自身的能力，来自动化地生成对齐所需的数据"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211511-ubhcv08","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-ubhcv08","updated":"20250922211511"},"Children":[{"ID":"20250922211511-yh5yz0h","Type":"NodeParagraph","Properties":{"id":"20250922211511-yh5yz0h","updated":"20250922211511"},"Children":[{"Type":"NodeText","Data":"这不仅是为了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"降低成本"},{"Type":"NodeText","Data":"，更是因为一个强大的AI可能比普通人类标注员更能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"探索模型能力的边界"},{"Type":"NodeText","Data":"，生成更多样、更具挑战性的“好”与“坏”的例子。"}]}]}]}]},{"ID":"20250922211511-s8iqo1f","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922211511-s8iqo1f","updated":"20250922211511"},"Children":[{"ID":"20250922211511-3alnzys","Type":"NodeParagraph","Properties":{"id":"20250922211511-3alnzys","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算法设计的“大道至简”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211511-eiumlae","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211511-eiumlae","updated":"20250922211511"},"Children":[{"ID":"20250922211511-j5no7t6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-j5no7t6","updated":"20250922211511"},"Children":[{"ID":"20250922211511-h1nfy4n","Type":"NodeParagraph","Properties":{"id":"20250922211511-h1nfy4n","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DPO的出现是本部分乃至整个对齐领域的“高光时刻”"},{"Type":"NodeText","Data":"。它不是对RLHF的小修小补，而是一次"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"范式级的简化和革命"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211511-dxkfxek","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-dxkfxek","updated":"20250922211511"},"Children":[{"ID":"20250922211511-ddob2qk","Type":"NodeParagraph","Properties":{"id":"20250922211511-ddob2qk","updated":"20250922211511"},"Children":[{"Type":"NodeText","Data":"DPO的成功雄辩地证明了，许多复杂的机器学习问题，其背后可能隐藏着更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简洁、更优雅"},{"Type":"NodeText","Data":"的数学形式。找到这把“奥卡姆剃刀”，往往能带来巨大的工程和理论突破。"}]}]},{"ID":"20250922211511-vr6ay0p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211511-vr6ay0p","updated":"20250922211511"},"Children":[{"ID":"20250922211511-457r1dh","Type":"NodeParagraph","Properties":{"id":"20250922211511-457r1dh","updated":"20250922211511"},"Children":[{"Type":"NodeText","Data":"后续对DPO的改进和分析，也表明该领域正在快速地从“它有效”的阶段，进入到“它为什么有效，以及如何让它更有效”的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度理论探究"},{"Type":"NodeText","Data":"阶段。"}]}]}]}]}]},{"ID":"20250922211511-zlkf266","Type":"NodeParagraph","Properties":{"id":"20250922211511-zlkf266","updated":"20250922211511"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第三十四部分的核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“范式转移”"},{"Type":"NodeText","Data":"。它展示了AI对齐技术正在从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第一代（复杂的RLHF）"},{"Type":"NodeText","Data":"，向"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二代（简洁的DPO）"},{"Type":"NodeText","Data":"演进。这一演进的背后，是社区对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"降低技术门槛、提升工程效率"},{"Type":"NodeText","Data":"的不懈追求，以及对问题本质更深刻的数学理解。DPO及其后续工作，已成为当前对齐领域"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最活跃、最富成果"},{"Type":"NodeText","Data":"的研究方向。"}]}]},{"ID":"20250922211711-ke4g99a","Type":"NodeParagraph","Properties":{"id":"20250922211711-ke4g99a","updated":"20250922211711"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922211711-rs8etnk","Type":"NodeThematicBreak","Properties":{"id":"20250922211711-rs8etnk","updated":"20250922211711"}},{"ID":"20250922211711-6zzu6ot","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211711-6zzu6ot","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三十五部分"}]},{"ID":"20250922211711-2ooc409","Type":"NodeParagraph","Properties":{"id":"20250922211711-2ooc409","updated":"20250922211737"},"Children":[{"Type":"NodeText","Data":"和正则化损失，以分别根据人类偏好数据来校准候选序列。类似地，可以通过奖励模型中正面和负面响应之间的差异来构建正则化损失，以增强LLM对正面和负-面响应的区分。其次，为了增强响应和指令之间的相关性，一些工作采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比学习"},{"Type":"NodeText","Data":"来推高正确的指令-响应对的概率，同时推低不正确的指令-响应对的概率。具体来说，对于一个输出响应，提出的方法将目标指令与其他不相关的指令进行对比。通过这样做，它可以使模型学习到指令和响应之间的正确关联。"}]},{"ID":"20250922211711-cb0nmyv","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211711-cb0nmyv","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.2.5 Remarks on SFT and RLHF (关于SFT和RLHF的评论)"}]},{"ID":"20250922211711-03ym9n4","Type":"NodeParagraph","Properties":{"id":"20250922211711-03ym9n4","updated":"20250922211737"},"Children":[{"Type":"NodeText","Data":"正如5.1节所讨论的，指令微调是使用格式化的演示数据（指令与期望的输出配对）来训练预训练语言模型的过程。在早期探索中，指令数据主要从NLP任务中收集，而现在已扩展到更包含输入和输出文本对的多样化监督数据（例如，开放式对话的话语）。在LLM的背景下，用这类配对文本进行训练也称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"监督式微-调（SFT）"},{"Type":"NodeText","Data":"。在本部分中，我们主要使用缩写SFT进行讨论，而不是指令微调，因为其简洁性和普及性。"}]},{"ID":"20250922211711-95htlry","Type":"NodeParagraph","Properties":{"id":"20250922211711-95htlry","updated":"20250922211737"},"Children":[{"Type":"NodeText","Data":"由于SFT和RLHF是LLM的两种主要适配微调方法，因此理解它们之间的联系和区别非常重要。接下来，我们对此问题进行一些讨论。"}]},{"ID":"20250922211711-at3pcob","Type":"NodeParagraph","Properties":{"id":"20250922211711-at3pcob","updated":"20250922211737"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Overall Comparison with RL Formulation (与RL形式化的总体比较)."},{"Type":"NodeText","Data":" 遵循5.2.3节的讨论（与RL训练相关的部分），文本生成问题可以被形式化为一个基于RL的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"决策过程"},{"Type":"NodeText","Data":"。输入一个提示，LLM的任务是生成一个能恰当响应提示的文本补全。这个任务将一步步完成。在每一步，一个智能体（即LLM）将根据策略（即LLM的生成概率分布），在当前状态（当前生成的词元序列和其他可用上下文信息）的条件下执行一个动作（即生成一个词元）。期望LLM能产生一个高质量的输出文本，从而基于整个响应获得一个大的奖励分数。总的来说，RLHF和SFT可以被视为优化上述决策过程的两种不同训练方法。具体来说，RLHF首先学习奖励模型，然后利用它通过RL训练（例如，PPO）来改进LLM。作为比较，SFT采用了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"教师强制（teacher-forcing）"},{"Type":"NodeText","Data":"的方法，它直接优化演示输出的似然。这种词元级别的训练方式本质上是在做"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"行为克隆（behavior cloning）"},{"Type":"NodeText","Data":"（一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模仿学习"},{"Type":"NodeText","Data":"的特殊算法）：它利用专家的动作（即每一步的目标词元）作为监督标签，直接学习模仿专家的演示，而无需像典型的RL算法那样指定一个奖励模型。为了学习期望的策略，SFT采用了一种“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"局部"},{"Type":"NodeText","Data":"”优化方式（即词元级损失），基于演示数据，而RLHF则采用了一种“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全局"},{"Type":"NodeText","Data":"”优化方式（即文本级损失），通过引入人类偏好。"}]},{"ID":"20250922211711-6hghsgy","Type":"NodeParagraph","Properties":{"id":"20250922211711-6hghsgy","updated":"20250922211737"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pros and Cons of SFT (SFT的优缺点)."},{"Type":"NodeText","Data":" SFT已被证明是提升LLM在各种基准上性能的有效方法，可以极大地增强任务泛化能力并灵活地赋予特定功能（例如，建立聊天机器人的身份）。关于SFT的更多用处可以在5.1.3节中找到。人们普遍认为，SFT主要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解锁"},{"Type":"NodeText","Data":"能力，而不是向LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"注入"},{"Type":"NodeText","Data":"新能力。因此，当演示数据超出了LLM的知识或能力范围时，尝试通过SFT激发LLM的非内生能力可能会产生问题，例如，训练一个LLM回答关于其未知事实的问题。John Schulman在关于RLHF的演讲中提出了一个有趣的观点，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"蒸馏"},{"Type":"NodeText","Data":"高级模型来训练能力较弱的模型（例如，提示GPT-4生成响应作为微调数据）可能会增加产生"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幻觉"},{"Type":"NodeText","Data":"文本的可能性，从而可能影响LLM的事实准确性。此外，作为一种行为克隆方法，SFT旨在模仿（无需探索）构建演示数据的专家的行为。然而，不同标注员在写作风格、质量和演示数据的偏好上通常存在差异，这往往会影响SFT的学习性能。因此，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高质量的指令数据（而非数量）"},{"Type":"NodeText","Data":"是SFT阶段有效训练LLM的首要因素。"}]},{"ID":"20250922211711-e8ybgt6","Type":"NodeParagraph","Properties":{"id":"20250922211711-e8ybgt6","updated":"20250922211737"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pros and Cons of RLHF (RLHF的优缺点)."},{"Type":"NodeText","Data":" RLHF早期在深度RL的文献中被探索，然后被借用来提升语言模型的能力（例如，摘要），随后被采纳为开发InstructGPT的基础技术。最近，越来越多的证据表明RLHF在减轻有害响应和增强模型能力方面的有效性。特别是，LLaMA 2已经证明RLHF可以同时提升"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无害性"},{"Type":"NodeText","Data":"分数，并将其归因于数据标注中更好的人-LLM协同作用。他们从两个主要方面解释了原因。首先，由于人类标注员主要为RLHF提供偏好标注，它可以极大地缓解SFT中存在的标注员之间的差异。其次，偏好标注比编写演示数据容易得多，标注员甚至可以判断比他们自己创造的更优越的生成内容的质量，这使得探索一个超越人类标注员可以演示的更广阔的状态空间成为可能。另一个关键点是，RLHF本质上鼓励LLM通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比"},{"Type":"NodeText","Data":"自我生成的响应（区分好与坏的响应）来学习正确的策略。它不再强迫模型模仿外部的演示数据，因此可以像前文讨论的那样，缓解SFT带来的幻觉问题。实际上，RLHF已被证明是减少GPT-4中幻觉行为的重要方法。然而，RLHF继承了经典RL算法的缺点，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"样本效率低"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练不稳定"},{"Type":"NodeText","Data":"。当应用于LLM时，RLHF进一步依赖于一个强大的SFT模型作为初始模型检查点，以高效地取得良好性能。此外，人类标注员参与在一个复杂的迭代优化过程中，其中许多重要细节（例如，提示的选择、奖励模型训练和PPO训练的调度，以及超参数的设置）对整个模型性能有重要影响。"}]},{"ID":"20250922211711-l5h7d1i","Type":"NodeParagraph","Properties":{"id":"20250922211711-l5h7d1i","updated":"20250922211737"},"Children":[{"Type":"NodeText","Data":"总的来说，SFT对于在预训练后直接提升预训练模型检查点的模型能力特别有用，而RLHF则有望进一步提升SFT模型的能力。然而，RLHF的实现一直很困难，并且远未被（根据公开文献）充分探索，仍然需要更多的改进（例如，高效可靠的标注和简化的优化）。"}]},{"ID":"20250922211711-pftalml","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211711-pftalml","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.3 Parameter-Efficient Model Adaptation (参数高效模型适配)"}]},{"ID":"20250922211711-6ttdp2y","Type":"NodeParagraph","Properties":{"id":"20250922211711-6ttdp2y","updated":"20250922211737"},"Children":[{"Type":"NodeText","Data":"在上面，我们讨论了指令微调和对齐微调的方法，以根据特定目标适配LLM。由于LLM包含大量的模型参数，进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全参数微调"},{"Type":"NodeText","Data":"将非常昂贵。在本节中，我们将讨论如何在LLM上进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效微调"},{"Type":"NodeText","Data":"。我们首先回顾几种代表性的Transformer语言模型参数高效微调方法，然后总结关于参数高效微调LLM的现有工作。"}]},{"ID":"20250922211711-6pcxaef","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922211711-6pcxaef","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.3.1 Parameter-Efficient Fine-Tuning Methods (参数高效微调方法)"}]},{"ID":"20250922211711-ljobm4l","Type":"NodeParagraph","Properties":{"id":"20250922211711-ljobm4l","updated":"20250922211737"},"Children":[{"Type":"NodeText","Data":"在现有文献中，参数高效微调一直是一个重要课题，旨在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"减少可训练参数的数量"},{"Type":"NodeText","Data":"，同时尽可能保持良好的性能。接下来，我们简要回顾四种用于Transformer语言模型的参数高效微调方法，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"adapter tuning, prefix tuning, prompt tuning和LoRA"},{"Type":"NodeText","Data":"。这四种方法的示意图显示在图13中。"}]},{"ID":"20250922211711-48nf8tw","Type":"NodeParagraph","Properties":{"id":"20250922211711-48nf8tw","updated":"20250922211737"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Adapter Tuning."},{"Type":"NodeText","Data":" Adapter tuning将小型的神经网络模块（称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"adapter"},{"Type":"NodeText","Data":"）并入Transformer模型中。为了实现adapter模块，中提出了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"瓶颈架构"},{"Type":"NodeText","Data":"，它首先将原始特征向量压缩到一个较小的维度（然后进行非线性变换），然后将其恢复到原始维度。Adapter模块将被整合到每个Transformer层中，通常在Transformer层的两个核心部分（即注意力层和前馈层）之后进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"串行插入"},{"Type":"NodeText","Data":"。或者，也可以在Transformer层中使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并行adapter"},{"Type":"NodeText","Data":"，它将两个adapter模块分别与注意力层和前馈层并行放置。在微调期间，adapter模块将根据特定的任务目标进行优化，而原始语言模型的参数则被"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结"},{"Type":"NodeText","Data":"。通过这种方式，我们可以有效地减少微调期间的可训练参数数量。"}]},{"ID":"20250922211711-3bbxq9j","Type":"NodeBlockquote","Properties":{"id":"20250922211711-3bbxq9j","updated":"20250922211737"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922211711-e7iufo4","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211711-e7iufo4","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922211711-o4n8vho","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211711-o4n8vho","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SFT vs. RLHF: “模仿学习”与“强化学习”的深刻对比"}]},{"ID":"20250922211711-9mykztr","Type":"NodeParagraph","Properties":{"id":"20250922211711-9mykztr","updated":"20250922211711"},"Children":[{"Type":"NodeText","Data":"这部分内容是全篇综述中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思辨性最强"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最具洞察力"},{"Type":"NodeText","Data":"的部分之一。它从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习（RL）"},{"Type":"NodeText","Data":"的理论框架出发，深刻地剖析了SFT和RLHF这两种主流微调方法的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本质区别、各自的优缺点以及它们之间的关系"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922211711-nyjc9wc","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-nyjc9wc","updated":"20250922211711"},"Children":[{"ID":"20250922211711-h55pnic","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-h55pnic","updated":"20250922211711"},"Children":[{"ID":"20250922211711-p31e16l","Type":"NodeParagraph","Properties":{"id":"20250922211711-p31e16l","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本质区别：局部 vs. 全局，模仿 vs. 探索"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-pim39s3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-pim39s3","updated":"20250922211711"},"Children":[{"ID":"20250922211711-qrcijwm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-qrcijwm","updated":"20250922211711"},"Children":[{"ID":"20250922211711-3voyrcl","Type":"NodeParagraph","Properties":{"id":"20250922211711-3voyrcl","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SFT (监督微调)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-k1nx2r7","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-k1nx2r7","updated":"20250922211711"},"Children":[{"ID":"20250922211711-2ymkh3y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-2ymkh3y","updated":"20250922211711"},"Children":[{"ID":"20250922211711-odogay1","Type":"NodeParagraph","Properties":{"id":"20250922211711-odogay1","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本质"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"行为克隆 (Behavior Cloning)"},{"Type":"NodeText","Data":"，一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模仿学习"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211711-voq3lk7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-voq3lk7","updated":"20250922211711"},"Children":[{"ID":"20250922211711-k08no2f","Type":"NodeParagraph","Properties":{"id":"20250922211711-k08no2f","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化方式"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“局部”"},{"Type":"NodeText","Data":"优化。它在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每个词元（token）"},{"Type":"NodeText","Data":"的层面上，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"教师强制（Teacher Forcing）"},{"Type":"NodeText","Data":"，强迫模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确模仿"},{"Type":"NodeText","Data":"人类专家给出的“标准答案”。"}]}]}]}]},{"ID":"20250922211711-7t4sfk2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-7t4sfk2","updated":"20250922211711"},"Children":[{"ID":"20250922211711-i1102ug","Type":"NodeParagraph","Properties":{"id":"20250922211711-i1102ug","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF (从人类反馈中强化学习)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-zc7pwez","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-zc7pwez","updated":"20250922211711"},"Children":[{"ID":"20250922211711-3k2lkd1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-3k2lkd1","updated":"20250922211711"},"Children":[{"ID":"20250922211711-gkfdid5","Type":"NodeParagraph","Properties":{"id":"20250922211711-gkfdid5","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本质"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211711-t6bo8zb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-t6bo8zb","updated":"20250922211711"},"Children":[{"ID":"20250922211711-vrfersg","Type":"NodeParagraph","Properties":{"id":"20250922211711-vrfersg","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化方式"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“全局”"},{"Type":"NodeText","Data":"优化。它在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"整个响应（response）"},{"Type":"NodeText","Data":"的层面上，通过一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励信号"},{"Type":"NodeText","Data":"（来自奖励模型）来告诉模型这个回答“好不好”，然后让模型自己去"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"探索"},{"Type":"NodeText","Data":"如何生成能获得更高奖励的回答。"}]}]}]}]}]}]},{"ID":"20250922211711-xsuh0mg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-xsuh0mg","updated":"20250922211711"},"Children":[{"ID":"20250922211711-jk02wib","Type":"NodeParagraph","Properties":{"id":"20250922211711-jk02wib","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优缺点分析"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-6qh6vz5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-6qh6vz5","updated":"20250922211711"},"Children":[{"ID":"20250922211711-4flvtzz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-4flvtzz","updated":"20250922211711"},"Children":[{"ID":"20250922211711-dfqlel7","Type":"NodeParagraph","Properties":{"id":"20250922211711-dfqlel7","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SFT"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-yli041y","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-yli041y","updated":"20250922211711"},"Children":[{"ID":"20250922211711-orkmgao","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-orkmgao","updated":"20250922211711"},"Children":[{"ID":"20250922211711-oxwuozx","Type":"NodeParagraph","Properties":{"id":"20250922211711-oxwuozx","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简单、高效、稳定"},{"Type":"NodeText","Data":"，能快速地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解锁"},{"Type":"NodeText","Data":"模型在预训练中学到的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"潜在能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211711-cudpzng","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-cudpzng","updated":"20250922211711"},"Children":[{"ID":"20250922211711-pyolg8i","Type":"NodeParagraph","Properties":{"id":"20250922211711-pyolg8i","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-aorg8ft","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-aorg8ft","updated":"20250922211711"},"Children":[{"ID":"20250922211711-jhiro3s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-jhiro3s","updated":"20250922211711"},"Children":[{"ID":"20250922211711-or4oo26","Type":"NodeParagraph","Properties":{"id":"20250922211711-or4oo26","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力上限"},{"Type":"NodeText","Data":": 只能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模仿”"},{"Type":"NodeText","Data":"，无法超越演示数据的水平，难以注入新能力。"}]}]},{"ID":"20250922211711-ub9quav","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-ub9quav","updated":"20250922211711"},"Children":[{"ID":"20250922211711-xbvjxel","Type":"NodeParagraph","Properties":{"id":"20250922211711-xbvjxel","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"容易产生幻觉"},{"Type":"NodeText","Data":": 如果演示数据本身包含错误或超出模型知识范围（如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"蒸馏"},{"Type":"NodeText","Data":"GPT-4的数据来微调小模型），SFT会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"盲目地模仿这些错误"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211711-hsfzpa6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-hsfzpa6","updated":"20250922211711"},"Children":[{"ID":"20250922211711-hd1r6y0","Type":"NodeParagraph","Properties":{"id":"20250922211711-hd1r6y0","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对数据质量高度敏感"},{"Type":"NodeText","Data":": 标注员之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不一致性"},{"Type":"NodeText","Data":"会严重影响模型性能。"}]}]}]}]}]}]},{"ID":"20250922211711-qymedvf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-qymedvf","updated":"20250922211711"},"Children":[{"ID":"20250922211711-ol4b9vo","Type":"NodeParagraph","Properties":{"id":"20250922211711-ol4b9vo","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-koaceie","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-koaceie","updated":"20250922211711"},"Children":[{"ID":"20250922211711-ce085lx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-ce085lx","updated":"20250922211711"},"Children":[{"ID":"20250922211711-y71pmwy","Type":"NodeParagraph","Properties":{"id":"20250922211711-y71pmwy","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-lrx98e8","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-lrx98e8","updated":"20250922211711"},"Children":[{"ID":"20250922211711-410y511","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-410y511","updated":"20250922211711"},"Children":[{"ID":"20250922211711-f8anld3","Type":"NodeParagraph","Properties":{"id":"20250922211711-f8anld3","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越模仿"},{"Type":"NodeText","Data":": 能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"探索"},{"Type":"NodeText","Data":"并生成比人类演示"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更优"},{"Type":"NodeText","Data":"的回答。"}]}]},{"ID":"20250922211711-jw9c4mz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-jw9c4mz","updated":"20250922211711"},"Children":[{"ID":"20250922211711-jtrtewz","Type":"NodeParagraph","Properties":{"id":"20250922211711-jtrtewz","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缓解幻觉"},{"Type":"NodeText","Data":": 通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比"},{"Type":"NodeText","Data":"好坏响应，模型能更好地理解什么是事实，从而减少幻觉。"}]}]},{"ID":"20250922211711-utuxyn5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-utuxyn5","updated":"20250922211711"},"Children":[{"ID":"20250922211711-y8orghd","Type":"NodeParagraph","Properties":{"id":"20250922211711-y8orghd","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对标注要求更低"},{"Type":"NodeText","Data":": 让人类"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“做选择题”（排序）"},{"Type":"NodeText","Data":"比"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“做问答题”（写范文）"},{"Type":"NodeText","Data":"更容易，标注成本更低，一致性更高。"}]}]}]}]},{"ID":"20250922211711-vhe62q7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-vhe62q7","updated":"20250922211711"},"Children":[{"ID":"20250922211711-uhp1emx","Type":"NodeParagraph","Properties":{"id":"20250922211711-uhp1emx","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-dg8bklf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-dg8bklf","updated":"20250922211711"},"Children":[{"ID":"20250922211711-v44ppfd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-v44ppfd","updated":"20250922211711"},"Children":[{"ID":"20250922211711-qtsz2ji","Type":"NodeParagraph","Properties":{"id":"20250922211711-qtsz2ji","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂且不稳定"},{"Type":"NodeText","Data":": 继承了RL算法的通病，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练困难、对超参数敏感"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211711-imxbj55","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-imxbj55","updated":"20250922211711"},"Children":[{"ID":"20250922211711-o2301zh","Type":"NodeParagraph","Properties":{"id":"20250922211711-o2301zh","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"依赖强大的SFT基础"},{"Type":"NodeText","Data":": 需要在一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练得很好的SFT模型"},{"Type":"NodeText","Data":"上进行，否则难以收敛。"}]}]}]}]}]}]}]}]},{"ID":"20250922211711-4cx11n6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-4cx11n6","updated":"20250922211711"},"Children":[{"ID":"20250922211711-hnioj3m","Type":"NodeParagraph","Properties":{"id":"20250922211711-hnioj3m","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两者关系：承上启下"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-u1ikkon","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-u1ikkon","updated":"20250922211711"},"Children":[{"ID":"20250922211711-i9bob6n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-i9bob6n","updated":"20250922211711"},"Children":[{"ID":"20250922211711-j48gthu","Type":"NodeParagraph","Properties":{"id":"20250922211711-j48gthu","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SFT是基础，RLHF是进阶"},{"Type":"NodeText","Data":"。通常的最佳实践是："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"先通过SFT让模型达到一个较高的能力水平，再通过RLHF进一步提升其性能并与人类价值观对齐"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922211711-8h6y2oh","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211711-8h6y2oh","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效微调（PEFT）：让微调变得“亲民”"}]},{"ID":"20250922211711-pj5va64","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-pj5va64","updated":"20250922211711"},"Children":[{"ID":"20250922211711-4393yku","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-4393yku","updated":"20250922211711"},"Children":[{"ID":"20250922211711-7ks21cf","Type":"NodeParagraph","Properties":{"id":"20250922211711-7ks21cf","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心动机"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全参数微调太贵了！"},{"Type":"NodeText","Data":"对于上百亿参数的LLM，普通研究者和开发者根本无法承担其硬件和时间成本。"}]}]},{"ID":"20250922211711-0ffchq3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-0ffchq3","updated":"20250922211711"},"Children":[{"ID":"20250922211711-fracrid","Type":"NodeParagraph","Properties":{"id":"20250922211711-fracrid","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“冻结主干，微调旁路”"},{"Type":"NodeText","Data":"。只更新模型中一小部分（通常\u003c1%）的参数，而保持巨大的预训练模型主体"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结"},{"Type":"NodeText","Data":"不变。"}]}]},{"ID":"20250922211711-u83kere","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-u83kere","updated":"20250922211711"},"Children":[{"ID":"20250922211711-m1t5fhw","Type":"NodeParagraph","Properties":{"id":"20250922211711-m1t5fhw","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Adapter Tuning"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“外挂”模块"},{"Type":"NodeText","Data":"。在模型的固定位置"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"插入"},{"Type":"NodeText","Data":"一些小的、可训练的“适配器”模块。"}]}]}]}]},{"ID":"20250922211711-qr6sd8v","Type":"NodeThematicBreak","Properties":{"id":"20250922211711-qr6sd8v","updated":"20250922211737"}},{"ID":"20250922211711-ke28t0w","Type":"NodeBlockquote","Properties":{"id":"20250922211711-ke28t0w","updated":"20250922211737"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922211711-7wx92fq","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211711-7wx92fq","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922211711-rgyoqcv","Type":"NodeParagraph","Properties":{"id":"20250922211711-rgyoqcv","updated":"20250922211711"},"Children":[{"Type":"NodeText","Data":"第三十五部分是关于模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"后期训练（Post-training）"},{"Type":"NodeText","Data":"方法论的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思辨"},{"Type":"NodeText","Data":"，它系统地对比了SFT和RLHF这两种主流技术，并自然地引出了解决其高成本问题的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效微调（PEFT）"},{"Type":"NodeText","Data":"方案。"}]},{"ID":"20250922211711-9pgx89n","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211711-9pgx89n","updated":"20250922211711"},"Children":[{"ID":"20250922211711-3xcawry","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211711-3xcawry","updated":"20250922211711"},"Children":[{"ID":"20250922211711-wl8teyk","Type":"NodeParagraph","Properties":{"id":"20250922211711-wl8teyk","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“是什么”到“为什么”的深度剖析"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-amlmo2v","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-amlmo2v","updated":"20250922211711"},"Children":[{"ID":"20250922211711-u5nraj5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-u5nraj5","updated":"20250922211711"},"Children":[{"ID":"20250922211711-hr82a1u","Type":"NodeParagraph","Properties":{"id":"20250922211711-hr82a1u","updated":"20250922211711"},"Children":[{"Type":"NodeText","Data":"文章没有停留在简单介绍SFT和RLHF的步骤上，而是从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习的理论框架"},{"Type":"NodeText","Data":"出发，将SFT定性为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“行为克隆”（模仿学习）"},{"Type":"NodeText","Data":"，将RLHF定性为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“强化学习”"},{"Type":"NodeText","Data":"。这一定性深刻地揭示了两者在学习范式上的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本区别"},{"Type":"NodeText","Data":"：一个是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“学样”"},{"Type":"NodeText","Data":"，一个是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“试错”"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922211711-w36q6vp","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211711-w36q6vp","updated":"20250922211711"},"Children":[{"ID":"20250922211711-cf9111n","Type":"NodeParagraph","Properties":{"id":"20250922211711-cf9111n","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辩证的优缺点分析"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-vem7d3j","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-vem7d3j","updated":"20250922211711"},"Children":[{"ID":"20250922211711-abhmvx2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-abhmvx2","updated":"20250922211711"},"Children":[{"ID":"20250922211711-ncrg9sl","Type":"NodeParagraph","Properties":{"id":"20250922211711-ncrg9sl","updated":"20250922211711"},"Children":[{"Type":"NodeText","Data":"作者对两种方法进行了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"客观、辩证"},{"Type":"NodeText","Data":"的分析，清晰地指出了各自的适用场景和局限性。"}]},{"ID":"20250922211711-lj5gw6a","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-lj5gw6a","updated":"20250922211711"},"Children":[{"ID":"20250922211711-ogai0hm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-ogai0hm","updated":"20250922211711"},"Children":[{"ID":"20250922211711-yhe2oml","Type":"NodeParagraph","Properties":{"id":"20250922211711-yhe2oml","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SFT"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“快速入门”"},{"Type":"NodeText","Data":"的利器，擅长"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解锁"},{"Type":"NodeText","Data":"现有能力，但天花板较低，且容易"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“学坏”"},{"Type":"NodeText","Data":"（模仿错误）。"}]}]},{"ID":"20250922211711-12xe034","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-12xe034","updated":"20250922211711"},"Children":[{"ID":"20250922211711-8cni8lu","Type":"NodeParagraph","Properties":{"id":"20250922211711-8cni8lu","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLHF"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“精益求精”"},{"Type":"NodeText","Data":"的法宝，能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超越"},{"Type":"NodeText","Data":"模仿，探索更优解，并有效"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"抑制幻觉"},{"Type":"NodeText","Data":"，但过程"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂、昂贵且不稳定"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922211711-r8l2n1j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-r8l2n1j","updated":"20250922211711"},"Children":[{"ID":"20250922211711-hedjjt4","Type":"NodeParagraph","Properties":{"id":"20250922211711-hedjjt4","updated":"20250922211711"},"Children":[{"Type":"NodeText","Data":"这种辩证的分析，为实践者在不同场景下选择合适的技术路线提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深刻的洞见"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922211711-p6clc1a","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922211711-p6clc1a","updated":"20250922211711"},"Children":[{"ID":"20250922211711-pnu8sza","Type":"NodeParagraph","Properties":{"id":"20250922211711-pnu8sza","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术路线的演进与承接"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-y8xp3fv","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-y8xp3fv","updated":"20250922211711"},"Children":[{"ID":"20250922211711-hn17yxe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-hn17yxe","updated":"20250922211711"},"Children":[{"ID":"20250922211711-bkpshz4","Type":"NodeParagraph","Properties":{"id":"20250922211711-bkpshz4","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“SFT -\u0026gt; RLHF”"},{"Type":"NodeText","Data":" 被总结为一条"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"黄金实践路径"},{"Type":"NodeText","Data":"。先用SFT打好基础，再用RLHF进行精调，这既保证了效率，又追求了性能的上限。"}]}]}]}]},{"ID":"20250922211711-ginmeva","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922211711-ginmeva","updated":"20250922211711"},"Children":[{"ID":"20250922211711-p3pr6lf","Type":"NodeParagraph","Properties":{"id":"20250922211711-p3pr6lf","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题的提出与解决方案的引出"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211711-9b5ebqu","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211711-9b5ebqu","updated":"20250922211711"},"Children":[{"ID":"20250922211711-l4y3i9u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-l4y3i9u","updated":"20250922211711"},"Children":[{"ID":"20250922211711-tvsaa1x","Type":"NodeParagraph","Properties":{"id":"20250922211711-tvsaa1x","updated":"20250922211711"},"Children":[{"Type":"NodeText","Data":"在深刻分析了SFT和RLHF之后，文章自然地引出了它们共同面临的一个巨大障碍——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高昂的训练成本"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211711-gjh9bxz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211711-gjh9bxz","updated":"20250922211711"},"Children":[{"ID":"20250922211711-r4czkr1","Type":"NodeParagraph","Properties":{"id":"20250922211711-r4czkr1","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效微调（PEFT）"},{"Type":"NodeText","Data":"作为这一问题的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解决方案"},{"Type":"NodeText","Data":"被顺势提出。这种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“问题-分析-方案”"},{"Type":"NodeText","Data":"的行文逻辑非常清晰，使得PEFT的出现显得顺理成章且至关重要。"}]}]}]}]}]},{"ID":"20250922211711-18nnbzs","Type":"NodeParagraph","Properties":{"id":"20250922211711-18nnbzs","updated":"20250922211711"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第三十五部分是全篇综述中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论深度和实践指导意义"},{"Type":"NodeText","Data":"结合得最好的部分之一。它不仅让读者理解了SFT和RLHF的技术细节，更重要的是，理解了它们背后的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习理论、内在矛盾和相互关系"},{"Type":"NodeText","Data":"。最终，通过引出PEFT，它为整个后期训练的技术图景，补上了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何让这一切变得经济可行”"},{"Type":"NodeText","Data":"这块最关键的拼图。"}]}]},{"ID":"20250922211913-c16ytwz","Type":"NodeParagraph","Properties":{"id":"20250922211913-c16ytwz","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922211913-qetl67y","Type":"NodeThematicBreak","Properties":{"id":"20250922211913-qetl67y","updated":"20250922211913"}},{"ID":"20250922211913-ji4t1cc","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211913-ji4t1cc","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三十六部分"}]},{"ID":"20250922211913-qv4fh1r","Type":"NodeParagraph","Properties":{"id":"20250922211913-qv4fh1r","updated":"20250922211920"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Prefix Tuning (前缀微调)."},{"Type":"NodeText","Data":" 前缀微调在语言模型的每个Transformer层前添加一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀"},{"Type":"NodeText","Data":"序列，即一组可训练的连续向量。这些前缀向量是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务特定"},{"Type":"NodeText","Data":"的，可以被视为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"虚拟词元嵌入"},{"Type":"NodeText","Data":"。为了优化前缀向量，提出了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重参数化"},{"Type":"NodeText","Data":"技巧，通过学习一个将较小矩阵映射到前缀参数矩阵的MLP函数，而不是直接优化前缀。已有研究表明，该技巧对于稳定训练很有用。优化后，映射函数将被丢弃，只保留派生的前缀向量以增强任务特定性能。由于只训练前缀参数，它可以实现参数高效的模型优化。与前缀微调类似，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"p-tuning v2"},{"Type":"NodeText","Data":"将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"层级提示向量"},{"Type":"NodeText","Data":"并入Transformer架构中，专门用于自然语言理解，它还利用多任务学习来联合优化共享的提示。已有研究表明，它在提升不同参数规模的模型在自然语言理解任务上的性能方面很有用。"}]},{"ID":"20250922211913-j6if17w","Type":"NodeParagraph","Properties":{"id":"20250922211913-j6if17w","updated":"20250922211920"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Prompt Tuning (提示微调)."},{"Type":"NodeText","Data":" 与前缀微调不同，提示微调主要关注于在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输入层"},{"Type":"NodeText","Data":"并入可训练的提示向量。基于离散提示方法，它通过包含一组"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"软提示词元"},{"Type":"NodeText","Data":"（可以以自由形式或前缀形式）来增强输入文本，然后将经过提示增强的输入用于解决特定的下游任务。在实现上，任务特定的提示嵌入与输入文本嵌入相结合，然后被送入语言模型。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"P-tuning"},{"Type":"NodeText","Data":"提出了一种自由形式来组合上下文、提示和目标词元，可以应用于自然语言理解和生成的架构。他们进一步通过一个双向LSTM来学习软提示词元的表示。另一个代表性方法，名为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"prompt tuning"},{"Type":"NodeText","Data":"，直接在输入前添加前缀提示。在训练期间，只有提示嵌入会根据任务特定的监督信号进行学习。由于该方法仅在输入层包含少量可训练参数，研究发现其性能高度依赖于底层语言模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型能力"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922211913-fwnftly","Type":"NodeParagraph","Properties":{"id":"20250922211913-fwnftly","updated":"20250922211920"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Low-Rank Adaptation (LoRA, 低秩适配)."},{"Type":"NodeText","Data":" LoRA强加了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"低秩约束"},{"Type":"NodeText","Data":"来近似每个密集层的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更新矩阵"},{"Type":"NodeText","Data":"，从而减少用于适应下游任务的可训练参数。考虑优化一个参数矩阵W的情况。更新过程可以"}]},{"ID":"20250922211913-l9w2s9x","Type":"NodeParagraph","Properties":{"id":"20250922211913-l9w2s9x","updated":"20250922211920"},"Children":[{"Type":"NodeText","Data":"被写成一个通用形式：W ← W + ΔW。LoRA的基本思想是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结"},{"Type":"NodeText","Data":"原始矩阵W ∈ ℝ"},{"Type":"NodeTextMark","TextMarkType":"sup","TextMarkTextContent":"m×n"},{"Type":"NodeText","Data":"，同时通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"低秩分解矩阵"},{"Type":"NodeText","Data":"来近似参数更新ΔW，即ΔW = A · Bᵀ，其中A ∈ ℝ"},{"Type":"NodeTextMark","TextMarkType":"sup","TextMarkTextContent":"m×k"},{"Type":"NodeText","Data":"和B ∈ ℝ"},{"Type":"NodeTextMark","TextMarkType":"sup","TextMarkTextContent":"n×k"},{"Type":"NodeText","Data":"是用于任务适配的可训练参数，而k ≪ min(m, n)是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缩减的秩"},{"Type":"NodeText","Data":"。LoRA的主要优点是它可以极大地节省内存和存储使用（例如，VRAM）。此外，人们可以只保留一个大型模型的副本，同时维护多个任务特定的低秩分解矩阵，以适应不同的下游任务。此外，一些研究还讨论了如何以更有原则的方式设置秩，例如，基于重要性分数的分配和免搜索的最优秩选择。"}]},{"ID":"20250922211913-s2bi7ry","Type":"NodeParagraph","Properties":{"id":"20250922211913-s2bi7ry","updated":"20250922211920"},"Children":[{"Type":"NodeText","Data":"除了上述方法，关于Transformer语言模型的高效微调还有广泛的研究。然而，对高效微调的更全面讨论超出了本文的范围，可以在关于该主题的相关论文中找到。"}]},{"ID":"20250922211913-zfsu953","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922211913-zfsu953","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"5.3.2 Parameter-Efficient Fine-Tuning on LLMs (LLM上的参数高效微调)"}]},{"ID":"20250922211913-qp95hba","Type":"NodeParagraph","Properties":{"id":"20250922211913-qp95hba","updated":"20250922211920"},"Children":[{"Type":"NodeText","Data":"随着LLM的兴起，高效微调已吸引了越来越多的研究关注，以开发更轻量级的下游任务适配方法。"}]},{"ID":"20250922211913-sa3dhmw","Type":"NodeParagraph","Properties":{"id":"20250922211913-sa3dhmw","updated":"20250922211920"},"Children":[{"Type":"NodeText","Data":"特别是，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LoRA"},{"Type":"NodeText","Data":"已被广泛应用于开源LLM（例如，LLaMA和BLOOM）的参数高效微-调。在这些研究尝试中，LLaMA及其变体在参数高效微调方面获得了大量关注。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca-LoRA"},{"Type":"NodeText","Data":"是作为Alpaca（一个用52K人类指令遵循演示微调的7B LLaMA模型）的轻量级微调版本，使用LoRA进行训练的。关于Alpaca-LoRA在不同语言或模型规模上的广泛探索，可以在该合集页面中找到。最近的一项研究"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA-Adapter"},{"Type":"NodeText","Data":"在每个Transformer层中插入可学习的提示向量，其中提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零初始化注意力"},{"Type":"NodeText","Data":"，通过减轻欠拟合提示向量的影响来改善训练。他们还将这种方法扩展到多模态设置，例如，视觉问答。"}]},{"ID":"20250922211913-m63flui","Type":"NodeParagraph","Properties":{"id":"20250922211913-m63flui","updated":"20250922211920"},"Children":[{"Type":"NodeText","Data":"此外，一项实证研究已经进行，以检验不同微调方法对语言模型的影响。他们比较了四种高效微调方法，包括串行adapter tuning、并行adapter tuning和LoRA，在三个开源LLM上，即GPT-J（6B）、BLOOM（7.1B）和LLaMA（7B），进行评估。基于在六个数学推理数据集上的实验结果，他们表明这些高效微调方法在困难任务上表现不如参考基线GPT-3.5，而在简单任务上取得了相当的性能。总的来说，在这些比较方法中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LoRA表现相对较好"},{"Type":"NodeText","Data":"，同时使用的可训练参数要少得多。"}]},{"ID":"20250922211913-lnd7f77","Type":"NodeParagraph","Properties":{"id":"20250922211913-lnd7f77","updated":"20250922211920"},"Children":[{"Type":"NodeText","Data":"作为一个重要的资源，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PEFT库"},{"Type":"NodeText","Data":"（参数高效微调的缩写）已在GitHub上发布。它包含了几个广泛使用的高效微调方法，包括LoRA/AdaLoRA、prefix-tuning、P-Tuning和prompt-tuning。此外，它支持多种语言模型，如GPT-2和LLaMA，并且还涵盖了几种代表性的视觉Transformer模型（例如，ViT和Swin Transformer）。正如5.3.1节所讨论的，现有文献中已经提出了大量的-高效微调方法。然而，大多数这些方法都是在小尺寸的预训练语言模型上测试的，而不是在LLM上。到目前为止，仍然缺乏对不同高效微调方法在不同设置或任务下对大尺寸语言模型效果的深入调查。"}]},{"ID":"20250922211913-i1d6p85","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211913-i1d6p85","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6 UTILIZATION (利用)"}]},{"ID":"20250922211913-bwsnbsd","Type":"NodeParagraph","Properties":{"id":"20250922211913-bwsnbsd","updated":"20250922211918"},"Children":[{"Type":"NodeText","Data":"在预训练或适配微调之后，使用LLM的一个主要方法是为解决各种任务设计合适的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示策略"},{"Type":"NodeText","Data":"。在现有文献中，可以通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"手动创建"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动优化"},{"Type":"NodeText","Data":"来有效地学习任务特定的提示。一种代表性的提示方法是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习"},{"Type":"NodeText","Data":"，它将任务描述和/或演示以自然语言文本的形式进行组织。此外，可以采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链提示"},{"Type":"NodeText","Data":"来通过在提示中引入一系列中间推理步骤来增强上下文学习。此外，提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规划"},{"Type":"NodeText","Data":"来解决复杂任务，它首先将任务分解为更小的子任务，然后生成一个行动计划来逐一解决这些子任务。我们总结了这些提示方法的代表性工作在表11中。接下来，我们将详细阐述这四种技术。"}]},{"ID":"20250922211913-up0xrzf","Type":"NodeTable","TableAligns":[1,1,1],"Properties":{"colgroup":"||","id":"20250922211913-up0xrzf","updated":"20250922211918"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Approach"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Representative Work"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Key Point"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"In-context Learning (ICL)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"KATE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"演示选择（相似；k-NN）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"EPR"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"演示选择（密集检索；对比学习）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SG-ICL"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"演示选择（LLM作为演示生成器）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"APE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"演示格式（自动生成与选择）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Structured Prompting"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"演示格式（分组上下文编码；重缩放注意力）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GlobalE \u0026 LocalE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"演示顺序（基于熵的度量；用LLM生成探测集）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Chain-of-thought Prompting (CoT)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Complex CoT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"演示（基于复杂度的选择）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Auto-CoT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"演示（自动生成）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Selection-Inference"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"生成（选择与推理交替进行）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Self-consistency"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"生成（多样化路径；自集成）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"DIVERSE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"生成（多样化路径）；验证（逐步投票）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Rationale-augmented ensembles"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"生成（基本原理采样）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Planning"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Least-to-most prompting"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"计划生成（基于文本；问题分解）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"DECOMP"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"计划生成（基于文本；问题分解）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PS"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"计划生成（基于文本）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Faithful CoT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"计划生成（基于代码）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PAL"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"计划生成（基于代码；Python）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HuggingGPT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"计划生成（基于代码；来自HuggingFace的模型）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AdaPlanner"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"计划提炼（技能记忆）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"TIP"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"反馈获取（视觉感知）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RAP"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"反馈获取（LLM作为世界模型）；计划提炼（蒙特卡洛树搜索）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ChatCoT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"反馈获取（工具）；计划提炼（LLM与工具间的对话）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ReAct"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"反馈获取（工具）；计划提炼（协同推理与行动）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Reflexion"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"反馈获取（基于文本的自我反思）；计划提炼（动态记忆）"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Tree of Thoughts"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"反馈获取（投票比较）；计划提炼（基于树的搜索）"}]}]}]},{"ID":"20250922211913-k8wvdl3","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211913-k8wvdl3","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 11：典型的LLM利用方法及其在ICL、CoT和规划方面的要点。"}]},{"ID":"20250922211913-nhlq5aa","Type":"NodeParagraph","Properties":{"id":"20250922211913-nhlq5aa","updated":"20250922211918"},"Children":[{"Type":"NodeText","Data":"要点仅突出最重要的技术贡献。"}]},{"ID":"20250922211913-g7t3jq5","Type":"NodeBlockquote","Properties":{"id":"20250922211913-g7t3jq5","updated":"20250922211918"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922211913-68econq","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211913-68econq","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922211913-nkwaa7r","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922211913-nkwaa7r","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表11解析：LLM“使用手册”的核心技术"}]},{"ID":"20250922211913-5duwqde","Type":"NodeParagraph","Properties":{"id":"20250922211913-5duwqde","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"这张表格是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第6节（利用）"},{"Type":"NodeText","Data":"的核心纲要，它系统地梳理了当前"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何使用LLM”"},{"Type":"NodeText","Data":"的三大主流技术范式："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（ICL）"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规划（Planning）"},{"Type":"NodeText","Data":"，并列出了每个范式下的代表性工作和其核心技术贡献。"}]},{"ID":"20250922211913-yheib9b","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-yheib9b","updated":"20250922211913"},"Children":[{"ID":"20250922211913-adccyel","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-adccyel","updated":"20250922211913"},"Children":[{"ID":"20250922211913-ok7l509","Type":"NodeParagraph","Properties":{"id":"20250922211913-ok7l509","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (ICL) - “依样画葫芦”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211913-4ngokyp","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-4ngokyp","updated":"20250922211913"},"Children":[{"ID":"20250922211913-ythye3y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-ythye3y","updated":"20250922211913"},"Children":[{"ID":"20250922211913-g022n05","Type":"NodeParagraph","Properties":{"id":"20250922211913-g022n05","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心"},{"Type":"NodeText","Data":": 通过提供几个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“演示（Demonstration）”"},{"Type":"NodeText","Data":"示例，让LLM在不更新参数的情况下学会一个新任务。"}]}]},{"ID":"20250922211913-rozyxhe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-rozyxhe","updated":"20250922211913"},"Children":[{"ID":"20250922211913-8m2nuzc","Type":"NodeParagraph","Properties":{"id":"20250922211913-8m2nuzc","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键技术点"},{"Type":"NodeText","Data":": 优化ICL效果的关键在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“演示”"},{"Type":"NodeText","Data":"本身。"}]},{"ID":"20250922211913-urc0f34","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-urc0f34","updated":"20250922211913"},"Children":[{"ID":"20250922211913-we5e2rx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-we5e2rx","updated":"20250922211913"},"Children":[{"ID":"20250922211913-85h20db","Type":"NodeParagraph","Properties":{"id":"20250922211913-85h20db","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示选择 (Selection)"},{"Type":"NodeText","Data":": 如何从大量候选中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"选出"},{"Type":"NodeText","Data":"最有帮助的示例？（如KATE使用k-NN相似度检索）"}]}]},{"ID":"20250922211913-24x7hij","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-24x7hij","updated":"20250922211913"},"Children":[{"ID":"20250922211913-ax01t5r","Type":"NodeParagraph","Properties":{"id":"20250922211913-ax01t5r","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示格式 (Format)"},{"Type":"NodeText","Data":": 如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"组织和呈现"},{"Type":"NodeText","Data":"这些示例？（如APE自动生成模板）"}]}]},{"ID":"20250922211913-81uc4ug","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-81uc4ug","updated":"20250922211913"},"Children":[{"ID":"20250922211913-wv626mq","Type":"NodeParagraph","Properties":{"id":"20250922211913-wv626mq","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示顺序 (Order)"},{"Type":"NodeText","Data":": 示例的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排列顺序"},{"Type":"NodeText","Data":"也会影响结果。（如GlobalE \u0026 LocalE基于信息熵来排序）"}]}]}]}]}]}]},{"ID":"20250922211913-l6d7ocf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-l6d7ocf","updated":"20250922211913"},"Children":[{"ID":"20250922211913-nmpi248","Type":"NodeParagraph","Properties":{"id":"20250922211913-nmpi248","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链提示 (CoT) - “三思而后行”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211913-xpsm3eh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-xpsm3eh","updated":"20250922211913"},"Children":[{"ID":"20250922211913-c2y1e3a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-c2y1e3a","updated":"20250922211913"},"Children":[{"ID":"20250922211913-xxgc69r","Type":"NodeParagraph","Properties":{"id":"20250922211913-xxgc69r","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心"},{"Type":"NodeText","Data":": 在“输入-输出”对之间，加入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"中间的推理步骤"},{"Type":"NodeText","Data":"，引导模型进行逐步思考。"}]}]},{"ID":"20250922211913-npt3zxi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-npt3zxi","updated":"20250922211913"},"Children":[{"ID":"20250922211913-8or3ttv","Type":"NodeParagraph","Properties":{"id":"20250922211913-8or3ttv","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键技术点"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211913-3nwm0l0","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-3nwm0l0","updated":"20250922211913"},"Children":[{"ID":"20250922211913-2w8s405","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-2w8s405","updated":"20250922211913"},"Children":[{"ID":"20250922211913-4xx033m","Type":"NodeParagraph","Properties":{"id":"20250922211913-4xx033m","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示 (Demonstration)"},{"Type":"NodeText","Data":": CoT同样依赖演示，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Auto-CoT"},{"Type":"NodeText","Data":"等工作研究如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动生成"},{"Type":"NodeText","Data":"这些带有推理链的演示。"}]}]},{"ID":"20250922211913-w7nhya2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-w7nhya2","updated":"20250922211913"},"Children":[{"ID":"20250922211913-xaxfbkl","Type":"NodeParagraph","Properties":{"id":"20250922211913-xaxfbkl","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成 (Generation)"},{"Type":"NodeText","Data":": 如何生成更可靠的推理链？"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-consistency"},{"Type":"NodeText","Data":"通过生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多条不同的推理路径"},{"Type":"NodeText","Data":"然后"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"投票"},{"Type":"NodeText","Data":"，来提升结果的鲁棒性。"}]}]}]}]}]}]},{"ID":"20250922211913-o06t2h8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-o06t2h8","updated":"20250922211913"},"Children":[{"ID":"20250922211913-y8k5vw2","Type":"NodeParagraph","Properties":{"id":"20250922211913-y8k5vw2","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规划 (Planning) - “运筹帷幄”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211913-8ju44rs","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-8ju44rs","updated":"20250922211913"},"Children":[{"ID":"20250922211913-meq3ep4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-meq3ep4","updated":"20250922211913"},"Children":[{"ID":"20250922211913-mv5xbmf","Type":"NodeParagraph","Properties":{"id":"20250922211913-mv5xbmf","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心"},{"Type":"NodeText","Data":": 面对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极其复杂"},{"Type":"NodeText","Data":"的任务，先让LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分解任务、制定计划"},{"Type":"NodeText","Data":"，然后再"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逐步执行"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211913-5mxos6w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-5mxos6w","updated":"20250922211913"},"Children":[{"ID":"20250922211913-f3l92cd","Type":"NodeParagraph","Properties":{"id":"20250922211913-f3l92cd","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键技术点"},{"Type":"NodeText","Data":": 这是一个更复杂的“感知-规划-行动-反思”循环。"}]},{"ID":"20250922211913-oc57lzl","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-oc57lzl","updated":"20250922211913"},"Children":[{"ID":"20250922211913-mhlx7df","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-mhlx7df","updated":"20250922211913"},"Children":[{"ID":"20250922211913-lcsw8eb","Type":"NodeParagraph","Properties":{"id":"20250922211913-lcsw8eb","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计划生成 (Plan Generation)"},{"Type":"NodeText","Data":": 如何让LLM制定一个好计划？可以基于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本"},{"Type":"NodeText","Data":"（Least-to-most），也可以生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可执行的代码"},{"Type":"NodeText","Data":"（PAL）。"}]}]},{"ID":"20250922211913-9bl01lr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-9bl01lr","updated":"20250922211913"},"Children":[{"ID":"20250922211913-t9o5r8s","Type":"NodeParagraph","Properties":{"id":"20250922211913-t9o5r8s","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反馈获取 (Feedback Acquisition)"},{"Type":"NodeText","Data":": 计划执行后，如何从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"环境"},{"Type":"NodeText","Data":"中获取反馈？可以是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉"},{"Type":"NodeText","Data":"（TIP）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具返回"},{"Type":"NodeText","Data":"（ReAct, ChatCoT），甚至是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自我反思"},{"Type":"NodeText","Data":"（Reflexion）。"}]}]},{"ID":"20250922211913-31jtys6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-31jtys6","updated":"20250922211913"},"Children":[{"ID":"20250922211913-5a613x7","Type":"NodeParagraph","Properties":{"id":"20250922211913-5a613x7","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计划提炼 (Plan Refinement)"},{"Type":"NodeText","Data":": 如何根据反馈"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"修正计划"},{"Type":"NodeText","Data":"？可以使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"蒙特卡洛树搜索（RAP）"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"树状搜索（Tree of Thoughts）"},{"Type":"NodeText","Data":"等更复杂的搜索策略。"}]}]}]}]}]}]}]},{"ID":"20250922211913-bn385ua","Type":"NodeParagraph","Properties":{"id":"20250922211913-bn385ua","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格清晰地展示了LLM利用技术的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演进路径"},{"Type":"NodeText","Data":"："}]},{"ID":"20250922211913-10dhucg","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211913-10dhucg","updated":"20250922211913"},"Children":[{"ID":"20250922211913-m2y27fj","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211913-m2y27fj","updated":"20250922211913"},"Children":[{"ID":"20250922211913-8lx3555","Type":"NodeParagraph","Properties":{"id":"20250922211913-8lx3555","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"从简单的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模仿学习 (ICL)"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211913-lioo4wh","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211913-lioo4wh","updated":"20250922211913"},"Children":[{"ID":"20250922211913-nh83253","Type":"NodeParagraph","Properties":{"id":"20250922211913-nh83253","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"带解释的模仿学习 (CoT)"},{"Type":"NodeText","Data":"，提升推理能力。"}]}]},{"ID":"20250922211913-mjujpi7","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922211913-mjujpi7","updated":"20250922211913"},"Children":[{"ID":"20250922211913-k142cg2","Type":"NodeParagraph","Properties":{"id":"20250922211913-k142cg2","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"再到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"带反馈和修正的自主解决 (Planning)"},{"Type":"NodeText","Data":"，赋予模型解决超复杂任务和与环境交互的能力，这已是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自主智能体（Autonomous Agent）"},{"Type":"NodeText","Data":"的雏形。"}]}]}]}]},{"ID":"20250922211913-gr6ojg2","Type":"NodeThematicBreak","Properties":{"id":"20250922211913-gr6ojg2","updated":"20250922211918"}},{"ID":"20250922211913-6e0femc","Type":"NodeBlockquote","Properties":{"id":"20250922211913-6e0femc","updated":"20250922211918"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922211913-be27xwc","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922211913-be27xwc","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922211913-itkrwhu","Type":"NodeParagraph","Properties":{"id":"20250922211913-itkrwhu","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"第三十六部分是关于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型适配（Adaptation）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型利用（Utilization）"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心方法论"},{"Type":"NodeText","Data":"。它系统地介绍了如何通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效微调（PEFT）"},{"Type":"NodeText","Data":"技术来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"经济地“改造”"},{"Type":"NodeText","Data":"LLM，以及如何通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级提示策略"},{"Type":"NodeText","Data":"来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"智能地“使用”"},{"Type":"NodeText","Data":"LLM。"}]},{"ID":"20250922211913-qw0jxdp","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211913-qw0jxdp","updated":"20250922211913"},"Children":[{"ID":"20250922211913-pfxu0df","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211913-pfxu0df","updated":"20250922211913"},"Children":[{"ID":"20250922211913-mgvwhw8","Type":"NodeParagraph","Properties":{"id":"20250922211913-mgvwhw8","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PEFT：让模型适配“飞入寻常百姓家”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211913-ueikste","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-ueikste","updated":"20250922211913"},"Children":[{"ID":"20250922211913-f57ej26","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-f57ej26","updated":"20250922211913"},"Children":[{"ID":"20250922211913-b0yl5hl","Type":"NodeParagraph","Properties":{"id":"20250922211913-b0yl5hl","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"本部分是对PEFT技术，特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LoRA"},{"Type":"NodeText","Data":"的深入阐述和总结。它清晰地表明，PEFT的出现，尤其是LoRA的成功，是LLM技术"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"普及化"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键催化剂"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922211913-0nnjnhi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-0nnjnhi","updated":"20250922211913"},"Children":[{"ID":"20250922211913-me2yzkz","Type":"NodeParagraph","Properties":{"id":"20250922211913-me2yzkz","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"通过将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全参数微调"},{"Type":"NodeText","Data":"的高昂成本，降低到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单个GPU即可承受"},{"Type":"NodeText","Data":"的范围，PEFT使得广大的研究者、中小型企业和个人开发者都能够参与到LLM的“再创造”中来，极大地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"繁荣了整个开源生态"},{"Type":"NodeText","Data":"（如Alpaca-LoRA的涌现）。"}]}]},{"ID":"20250922211913-rl6k10p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-rl6k10p","updated":"20250922211913"},"Children":[{"ID":"20250922211913-g1rgbsf","Type":"NodeParagraph","Properties":{"id":"20250922211913-g1rgbsf","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PEFT库"},{"Type":"NodeText","Data":"的出现，进一步将这些技术标准化、工具化，降低了使用门槛。"}]}]}]}]},{"ID":"20250922211913-0o8gso9","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211913-0o8gso9","updated":"20250922211913"},"Children":[{"ID":"20250922211913-aol9s2j","Type":"NodeParagraph","Properties":{"id":"20250922211913-aol9s2j","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM利用的“三板斧”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211913-d3v3hct","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-d3v3hct","updated":"20250922211913"},"Children":[{"ID":"20250922211913-bokat2l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-bokat2l","updated":"20250922211913"},"Children":[{"ID":"20250922211913-kwlkeah","Type":"NodeParagraph","Properties":{"id":"20250922211913-kwlkeah","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"文章将“如何用好LLM”这一复杂问题，提炼为了三种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"层次递进"},{"Type":"NodeText","Data":"的提示范式，并由表11进行了系统性的梳理："}]},{"ID":"20250922211913-jf0f9g8","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922211913-jf0f9g8","updated":"20250922211913"},"Children":[{"ID":"20250922211913-2i4ngcl","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922211913-2i4ngcl","updated":"20250922211913"},"Children":[{"ID":"20250922211913-bo67la8","Type":"NodeParagraph","Properties":{"id":"20250922211913-bo67la8","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL (上下文学习)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础操作"},{"Type":"NodeText","Data":"。通过提供示例，让模型“照猫画虎”。核心在于如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"选择、格式化和排序"},{"Type":"NodeText","Data":"这些“虎”。"}]}]},{"ID":"20250922211913-wssb52c","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922211913-wssb52c","updated":"20250922211913"},"Children":[{"ID":"20250922211913-dorj0xv","Type":"NodeParagraph","Properties":{"id":"20250922211913-dorj0xv","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT (思维链)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"进阶操作"},{"Type":"NodeText","Data":"。不仅要给“虎”，还要把"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“画虎的步骤”"},{"Type":"NodeText","Data":"也给模型看，引导其学习"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理过程"},{"Type":"NodeText","Data":"。核心在于如何生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高质量的推理链"},{"Type":"NodeText","Data":"，并通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"集成（ensembling）"},{"Type":"NodeText","Data":"等方法提升其可靠性。"}]}]},{"ID":"20250922211913-wd3te5t","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922211913-wd3te5t","updated":"20250922211913"},"Children":[{"ID":"20250922211913-kpaayqk","Type":"NodeParagraph","Properties":{"id":"20250922211913-kpaayqk","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Planning (规划)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级操作"},{"Type":"NodeText","Data":"。面对画一只“麒麟”这样的复杂任务，需要让模型先"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自己制定绘画蓝图（计划）"},{"Type":"NodeText","Data":"，然后一步步执行，并根据"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反馈"},{"Type":"NodeText","Data":"不断"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"修正"},{"Type":"NodeText","Data":"。这已经是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自主智能（Autonomous Intelligence）"},{"Type":"NodeText","Data":"的范畴。"}]}]}]}]}]}]},{"ID":"20250922211913-cbz9ugn","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922211913-cbz9ugn","updated":"20250922211913"},"Children":[{"ID":"20250922211913-fpxm3wf","Type":"NodeParagraph","Properties":{"id":"20250922211913-fpxm3wf","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“被动接受”到“主动交互”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922211913-rq0pdfg","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-rq0pdfg","updated":"20250922211913"},"Children":[{"ID":"20250922211913-1ruf54j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-1ruf54j","updated":"20250922211913"},"Children":[{"ID":"20250922211913-nw57gaj","Type":"NodeParagraph","Properties":{"id":"20250922211913-nw57gaj","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"这三种利用方式的演进，也体现了人与LLM交互模式的深刻变化："}]},{"ID":"20250922211913-buheglv","Type":"NodeList","ListData":{},"Properties":{"id":"20250922211913-buheglv","updated":"20250922211913"},"Children":[{"ID":"20250922211913-h3evc0l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-h3evc0l","updated":"20250922211913"},"Children":[{"ID":"20250922211913-qmuzfr2","Type":"NodeParagraph","Properties":{"id":"20250922211913-qmuzfr2","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL"},{"Type":"NodeText","Data":": 人类提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"静态"},{"Type":"NodeText","Data":"的示例，LLM被动学习。"}]}]},{"ID":"20250922211913-aompdb5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-aompdb5","updated":"20250922211913"},"Children":[{"ID":"20250922211913-lejao24","Type":"NodeParagraph","Properties":{"id":"20250922211913-lejao24","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT"},{"Type":"NodeText","Data":": 人类（或LLM自身）提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构化的思考过程"},{"Type":"NodeText","Data":"，引导LLM进行推理。"}]}]},{"ID":"20250922211913-z3sns3r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-z3sns3r","updated":"20250922211913"},"Children":[{"ID":"20250922211913-xhjor7y","Type":"NodeParagraph","Properties":{"id":"20250922211913-xhjor7y","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Planning"},{"Type":"NodeText","Data":": LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主动地"},{"Type":"NodeText","Data":"分解任务、与外部工具/环境交互、获取反馈、进行自我反思和修正。"}]}]}]}]},{"ID":"20250922211913-ofwrhvs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922211913-ofwrhvs","updated":"20250922211913"},"Children":[{"ID":"20250922211913-2z985q6","Type":"NodeParagraph","Properties":{"id":"20250922211913-2z985q6","updated":"20250922211913"},"Children":[{"Type":"NodeText","Data":"这清晰地勾勒出LLM从一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“文本生成工具”"},{"Type":"NodeText","Data":"向一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“能够自主解决问题的智能体（Agent）”"},{"Type":"NodeText","Data":"演进的技术路径。"}]}]}]}]}]},{"ID":"20250922211913-qt2avmg","Type":"NodeParagraph","Properties":{"id":"20250922211913-qt2avmg","updated":"20250922211913"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第三十六部分的核心在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“赋能”"},{"Type":"NodeText","Data":"。PEFT通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"降低成本"},{"Type":"NodeText","Data":"来赋能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开发者"},{"Type":"NodeText","Data":"，让他们可以自由地定制LLM。而ICL, CoT, Planning等高级提示策略，则是通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"激发潜力"},{"Type":"NodeText","Data":"来赋能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM自身"},{"Type":"NodeText","Data":"，使其能够从简单的模仿，走向复杂的推理，乃至自主的规划与行动。这两者共同构成了LLM技术从实验室走向广泛应用的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键桥梁"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212304-5kc7teb","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922212304-5kc7teb","updated":"20250924151235"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.1 Prompting (提示)"}]},{"ID":"20250922212304-2gmudgl","Type":"NodeParagraph","Properties":{"id":"20250922212304-2gmudgl","updated":"20250924151235"},"Children":[{"Type":"NodeText","Data":"如先前的工作中所讨论的，提示是利用LLM解决各种任务的主要方法。由于提示的质量将在很大程度上影响LLM在特定任务上的性能，因此已经提出了一系列通过手动创建或自动优化来生成合适的任务提示的研究，本节将对此进行介绍。"}]},{"ID":"20250922212304-60onirq","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922212304-60onirq","updated":"20250924151235"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.1.1 Prompt Creation (提示创建)"}]},{"ID":"20250922212304-ma5lsix","Type":"NodeParagraph","Properties":{"id":"20250922212304-ma5lsix","updated":"20250924151235"},"Children":[{"Type":"NodeText","Data":"手动创建合适提示的过程也称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程"},{"Type":"NodeText","Data":"。一个精心设计的提示对于激发LLM完成特定任务的能力非常有帮助。在本部分中，我们首先介绍提示的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键组成部分"},{"Type":"NodeText","Data":"，并讨论几个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示设计原则"},{"Type":"NodeText","Data":"。然后，我们用不同的提示评估ChatGPT，以在几个代表性任务上展示结果。我们知道已有几篇现有的论文和网站呈现了设计好提示的建议和指南。相比之下，我们主要旨在讨论对提示创建有用的关键因素（组成和原则），并提供关于流行任务的实验结果和分析，作为对初学者的参考。"}]},{"ID":"20250922212304-cmqxjce","Type":"NodeParagraph","Properties":{"id":"20250922212304-cmqxjce","updated":"20250924151235"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Key Ingredients (关键组成部分)."},{"Type":"NodeText","Data":" 通常，有四个关键组成部分描绘了一个提示的功能，以激发LLM完成任务的能力，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述、输入数据、上下文信息和提示风格"},{"Type":"NodeText","Data":"。为了对我们的讨论有一个直观的理解，我们还在表13中展示了三个用于问答、元评论生成和文本到SQL的提示示例。"}]},{"ID":"20250922212304-3fjxkjs","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-3fjxkjs","updated":"20250924151235"},"Children":[{"ID":"20250922212304-huu9cf6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-huu9cf6","updated":"20250922212304"},"Children":[{"ID":"20250922212304-itx9xxw","Type":"NodeParagraph","Properties":{"id":"20250922212304-itx9xxw","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述 (Task description)."},{"Type":"NodeText","Data":" 任务描述通常是期望LLM遵循的特定指令。总的来说，应该用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然语言清晰地描述任务目标"},{"Type":"NodeText","Data":"。对于具有特殊输入或输出格式的任务，通常需要详细的说明，并且可以进一步利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关键词"},{"Type":"NodeText","Data":"来突出特殊设置，以更好地指导LLM完成任务。"}]}]},{"ID":"20250922212304-jw5g3fo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-jw5g3fo","updated":"20250922212304"},"Children":[{"ID":"20250922212304-1jt12a2","Type":"NodeParagraph","Properties":{"id":"20250922212304-1jt12a2","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输入数据 (Input data)."},{"Type":"NodeText","Data":" 在常见情况下，用自然语言描述输入数据（例如，一个待LLM响应的实例）是直接的。对于特殊输入数据，例如知识图谱和表格，有必要采用一种适当且方便的方式使它们对LLM可读。对于结构化数据，由于其简单性，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"线性化"},{"Type":"NodeText","Data":"通常被用来将原始记录（例如，知识三元组）转换为序列。此外，编程语言（例如，可执行代码）也已被用来形式化结构化数据，这也可以支持使用外部工具（例如，程序执行器）来产生精确的结果。"}]}]},{"ID":"20250922212304-gm3viv9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-gm3viv9","updated":"20250922212304"},"Children":[{"ID":"20250922212304-48wahsf","Type":"NodeParagraph","Properties":{"id":"20250922212304-48wahsf","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文信息 (Contextual information)."},{"Type":"NodeText","Data":" 除了任务描述和输入数据，上下文或背景信息对于特定任务也至关重要。例如，检索到的文档对于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放域问答"},{"Type":"NodeText","Data":"作为支持证据非常有用。检索到的文档的质量和它们与问题的相关性都会对生成的答案产生影响。因此，需要以适当的提示模式或表达格式包含此类信息。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文中的任务范例"},{"Type":"NodeText","Data":"对于激发LLM完成复杂任务也很有帮助，这可以更好地描绘任务目标、特殊的输出格式以及输入和输出之间的映射关系。"}]}]},{"ID":"20250922212304-hbdicu8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-hbdicu8","updated":"20250922212304"},"Children":[{"ID":"20250922212304-xj1h4lm","Type":"NodeParagraph","Properties":{"id":"20250922212304-xj1h4lm","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示风格 (Prompt style)."},{"Type":"NodeText","Data":" 对于不同的LLM，设计一个合适的提示风格以激发它们解决特定任务的能力很重要。总的来说，应该将提示表达为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰的问题或详细的指令"},{"Type":"NodeText","Data":"，以便能够被很好地理解和回答。在某些情况下，添加"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀或后缀"},{"Type":"NodeText","Data":"以更好地指导LLM也很有用。例如，使用前缀“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"让我们一步步思考"},{"Type":"NodeText","Data":"”可以帮助激发LLM执行逐步推理，而使用前缀“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"你是这个任务（或这个领域）的专家"},{"Type":"NodeText","Data":"”可以在某些特定任务上提升LLM的性能。此外，对于基于聊天的LLM（例如，ChatGPT），与其直接提供一个长而复杂的任务提示，不如建议将其分解为多个子任务的提示，然后通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多轮对话"},{"Type":"NodeText","Data":"将其输入LLM。"}]}]}]},{"ID":"20250922212304-ieet2ko","Type":"NodeParagraph","Properties":{"id":"20250922212304-ieet2ko","updated":"20250924151235"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Design Principles (设计原则)."},{"Type":"NodeText","Data":" 基于提示的关键组成部分，我们总结了几个关键的设计原则，可以帮助创建更有效的提示来解决各种任务。"}]},{"ID":"20250922212304-bsv5h1a","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-bsv5h1a","updated":"20250924151235"},"Children":[{"ID":"20250922212304-lqhqu2p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-lqhqu2p","updated":"20250922212304"},"Children":[{"ID":"20250922212304-x9m0hdr","Type":"NodeParagraph","Properties":{"id":"20250922212304-x9m0hdr","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰地表达任务目标 (Expressing the task goal clearly)."},{"Type":"NodeText","Data":" 任务描述不应含糊不清，否则可能导致不准确或不恰当的响应。这突出了在使用这些模型时需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰明确的指令"},{"Type":"NodeText","Data":"。一个清晰详细的描述应包含多个元素来解释一个任务，包括任务目标、输入/输出数据（例如，“给定一篇长文档，我希望你生成一个简洁的摘要。”），以及响应约束（例如，“摘要的长度不能超过50个词。”）。通过提供一个清晰明确的任务描述，LLM可以更有效地理解目标任务并生成期望的输出。"}]}]},{"ID":"20250922212304-6tk17vs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-6tk17vs","updated":"20250922212304"},"Children":[{"ID":"20250922212304-km6kqkq","Type":"NodeParagraph","Properties":{"id":"20250922212304-km6kqkq","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分解为简单、详细的子任务 (Decomposing into easy, detailed sub-tasks)."},{"Type":"NodeText","Data":" 为了解决复杂任务，将困难的任务分解为几个更简单、详细的子任务，以帮助LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一步步"},{"Type":"NodeText","Data":"完成目标，是很重要的。这与6.4节中的规划技术密切相关。例如，遵循的建议，我们可以用多个编号项的形式明确列出子任务（例如，“通过执行以下任务来编织一个连贯的叙述：1. ...; 2. ...; 3. ...”）。"}]}]}]},{"ID":"20250922212304-4u0p4ls","Type":"NodeTable","TableAligns":[1,1,1],"Properties":{"colgroup":"||","id":"20250922212304-4u0p4ls","updated":"20250924151235"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Ingredient"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Collected Prompts"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Prin."}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Task Description"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T1. 让你的提示尽可能详细，例如，“将文章总结成一个50词以内的短段落。应包括主要故事情节和结论，可以省略不重要的细节。”"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T2. 通过前缀提示让LLM知道它是一个专家是很有帮助的，例如，“你是一位计算机科学领域的资深专家。”"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T3. 告诉模型它应该做什么，而不是不应该做什么。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T4. 为了避免LLM生成过长的输出，你可以只使用提示：“问题：简短回答：”。此外，你也可以使用以下后缀，“用一个或几个词”，“用一两句话”。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Input Data"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"I1. 对于需要事实知识的问题，首先通过搜索引擎检索相关文档，然后将它们作为参考连接到提示中是很有用的。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝4"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"I2. 为了突出提示中的一些重要部分，请使用特殊标记，例如，引号（“”）和换行符（"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"\\"}]},{"Type":"NodeText","Data":"n）。你也可以同时使用它们来强调。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝4"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Contextual Information"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"C1. 对于复杂的任务，你可以清晰地描述完成它所需的中间步骤，例如，“请按以下步骤回答问题：步骤1 - 将问题分解为几个子问题，……”"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝2"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"C2. 如果你想让LLM为一段文本打分，有必要提供一个带有示例作为参考的详细评分标准描述。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"C3. 当LLM根据某些上下文生成文本时（例如，根据购买历史进行推荐），指示它们对基于上下文生成的-结果进行解释，有助于提高生成结果的质量。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝2"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"C4. 一种类似于思维树但可以在一个提示中完成的方法：例如，想象三个不同的专家正在回答这个问题。所有专家都会写下他们思考的一步，然后与专家组分享。然后所有专家会进入下一步，等等。如果任何专家在任何时候意识到他们错了，他们就会离开。问题是"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝2"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Demonstration"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"D1. 格式良好的上下文范例非常有用，特别是对于生成具有复杂格式的输出。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"D2. 对于少样本思维链提示，你也可以使用提示“让我们一步步思考”，并且少样本示例应该用“"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"\\"}]},{"Type":"NodeText","Data":"n”而不是句号分隔。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1 ⃝3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"D3. 你也可以在上下文中检索相似的示例，为LLM提供有用的任务特定知识。为了检索更相关的示例，首先获取问题的答案，然后将其与问题连接起来进行检索是很有用的。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝3 ⃝4"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"D4. 提示中上下文范例的多样性也很有用。如果不容易获得多样化的问题，你也可以寻求保持问题解决方案的多样性。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"D5. 当使用基于聊天的LLM时，你可以将上下文范例分解为多轮消息，以更好地匹配人-聊天机器人对话格式。类似地，你也可以将一个范例的推理过程分解为多轮对话。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"D6. 复杂且信息丰富的上下文范例可以帮助LLM回答复杂问题。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"D7. 由于一个符号序列通常可以被分为多个段（例如，i₁, i₂, i₃ → i₁, i₂ 和 i₂, i₃），前面的段可以用作上下文范例来指导LLM预测后续的段，同时提供历史信息。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝2 ⃝3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"D8. 对于上下文范例和提示组件，顺序很重要。对于非常长的输入数据，问题的位置（开头或结尾）也可能影响性能。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"D9. 如果你无法从现有数据集中获取上下文范例，另一种方法是使用LLM自己生成的零样本范例。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝3"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Other Designs"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"O1. 让LLM在得出结论前检查其输出，例如，“检查以上解决方案是否正确。”"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝2"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"O2. 如果LLM不能很好地解决任务，你可以通过提示LLM操作外部工具来寻求帮助。通过这种方式，这些工具应该被封装成可调用的API，并附有关于其功能的详细描述，以更好地指导LLM利用这些工具。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝4"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"O3. 提示应该是自包含的，最好不要在上下文中包含代词（例如，it和they）。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"O4. 当使用LLM比较两个或更多示例时，顺序会极大地影响性能。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"O5. 在提示之前，为LLM分配一个角色有助于它更好地完成后续的任务指令，例如，“我希望你扮演一名律师”。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"O6. OpenAI模型在英语上的表现比其他语言好。因此，先将输入翻译成英语再喂给LLM是很有用的。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝4"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"O7. 对于多项选择题，限制LLM的输出空间是很有用的。你可以使用更详细的解释或仅仅在logits上施加约束。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"O8. 对于基于排序的任务（例如，推荐），与其在排序后直接输出每个项目的完整文本，不如为未排序的项目分配指示符（例如，ABCD），并指示LLM直接输出排序后的指示符。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"⃝1"}]}]}]},{"ID":"20250922212304-1i5xkgi","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922212304-1i5xkgi","updated":"20250924151235"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 12：从在线笔记和我们作者的经验中收集到的用于设计提示的有用技巧集合，其中我们也显示了相关的组成和原则（在6.1.1节中介绍）。"}]},{"ID":"20250922212304-wq7azm2","Type":"NodeParagraph","Properties":{"id":"20250922212304-wq7azm2","updated":"20250924151235"},"Children":[{"Type":"NodeText","Data":"我们将原则缩写为Prin.，并为每个提示列出相关原则的ID。⃝1：清晰地表达任务目标；⃝2：分解为简单、详细的子任务；⃝3：提供少样本演示；⃝4：利用模型友好的格式。"}]},{"ID":"20250922212304-popa0h6","Type":"NodeBlockquote","Properties":{"id":"20250922212304-popa0h6","updated":"20250924151235"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922212304-58zzgb1","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922212304-58zzgb1","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922212304-uilb6we","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922212304-uilb6we","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表12解析：提示工程的“武功秘籍”"}]},{"ID":"20250922212304-9uja6fq","Type":"NodeParagraph","Properties":{"id":"20250922212304-9uja6fq","updated":"20250922212304"},"Children":[{"Type":"NodeText","Data":"这张表格是一份极其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"详尽和实用"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程（Prompt Engineering）“武功秘籍”"},{"Type":"NodeText","Data":"。它将设计一个好提示的智慧，分解成了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可操作、可复制"},{"Type":"NodeText","Data":"的具体技巧，并与前面提出的四大原则相对应。"}]},{"ID":"20250922212304-9yz734i","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-9yz734i","updated":"20250922212304"},"Children":[{"ID":"20250922212304-1qe00sz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-1qe00sz","updated":"20250922212304"},"Children":[{"ID":"20250922212304-3z4e783","Type":"NodeParagraph","Properties":{"id":"20250922212304-3z4e783","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": 设计提示就像是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与一个极其聪明但有时会“偷懒”或“误解”的实习生沟通"},{"Type":"NodeText","Data":"。你需要把任务"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"说得清清楚楚、明明白白"},{"Type":"NodeText","Data":"，提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"充足的背景和范例"},{"Type":"NodeText","Data":"，并使用他"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"习惯的沟通方式"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212304-bcx8y44","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-bcx8y44","updated":"20250922212304"},"Children":[{"ID":"20250922212304-afkme5r","Type":"NodeParagraph","Properties":{"id":"20250922212304-afkme5r","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四大原则的体现"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212304-orp4x7u","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922212304-orp4x7u","updated":"20250922212304"},"Children":[{"ID":"20250922212304-6g46jug","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922212304-6g46jug","updated":"20250922212304"},"Children":[{"ID":"20250922212304-48cnxha","Type":"NodeParagraph","Properties":{"id":"20250922212304-48cnxha","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰表达 (⃝1)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212304-j7bu9cb","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-j7bu9cb","updated":"20250922212304"},"Children":[{"ID":"20250922212304-v0wlfco","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-v0wlfco","updated":"20250922212304"},"Children":[{"ID":"20250922212304-mf5l2fx","Type":"NodeParagraph","Properties":{"id":"20250922212304-mf5l2fx","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体化"},{"Type":"NodeText","Data":": 不要说“总结一下”，要说“总结成50词以内，包含要点A和B”（T1）。"}]}]},{"ID":"20250922212304-bwdv0qe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-bwdv0qe","updated":"20250922212304"},"Children":[{"ID":"20250922212304-f2xr2sy","Type":"NodeParagraph","Properties":{"id":"20250922212304-f2xr2sy","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"角色扮演"},{"Type":"NodeText","Data":": 赋予模型一个“专家”角色（T2, O5），能激活其相关知识，让它更“入戏”。"}]}]},{"ID":"20250922212304-ejrs1sy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-ejrs1sy","updated":"20250922212304"},"Children":[{"ID":"20250922212304-i8cwp3d","Type":"NodeParagraph","Properties":{"id":"20250922212304-i8cwp3d","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正面指令"},{"Type":"NodeText","Data":": 告诉它“做什么”，而不是“不要做什么”（T3）。"}]}]},{"ID":"20250922212304-ok1y18c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-ok1y18c","updated":"20250922212304"},"Children":[{"ID":"20250922212304-g8tszzl","Type":"NodeParagraph","Properties":{"id":"20250922212304-g8tszzl","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"限制输出"},{"Type":"NodeText","Data":": 明确要求“简短回答”或指定格式（T4, O7, O8），避免滔滔不绝。"}]}]}]}]},{"ID":"20250922212304-nli8mhm","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922212304-nli8mhm","updated":"20250922212304"},"Children":[{"ID":"20250922212304-pd39bi5","Type":"NodeParagraph","Properties":{"id":"20250922212304-pd39bi5","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分解任务 (⃝2)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212304-jdgfr3b","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-jdgfr3b","updated":"20250922212304"},"Children":[{"ID":"20250922212304-lm360f2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-lm360f2","updated":"20250922212304"},"Children":[{"ID":"20250922212304-v5zyk46","Type":"NodeParagraph","Properties":{"id":"20250922212304-v5zyk46","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逐步指令"},{"Type":"NodeText","Data":": 对于复杂任务，明确给出“第一步做什么，第二步做什么”（C1）。"}]}]},{"ID":"20250922212304-74x1l3b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-74x1l3b","updated":"20250922212304"},"Children":[{"ID":"20250922212304-vjsqnrx","Type":"NodeParagraph","Properties":{"id":"20250922212304-vjsqnrx","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自我检查"},{"Type":"NodeText","Data":": 让模型在最后"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自我反思和检查"},{"Type":"NodeText","Data":"（O1），能有效提高准确率。"}]}]},{"ID":"20250922212304-l1v8at4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-l1v8at4","updated":"20250922212304"},"Children":[{"ID":"20250922212304-a0je72z","Type":"NodeParagraph","Properties":{"id":"20250922212304-a0je72z","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多视角思考"},{"Type":"NodeText","Data":": “三个专家”的比喻（C4）是一种激发模型进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多路径、批判性"},{"Type":"NodeText","Data":"思考的高级技巧。"}]}]}]}]},{"ID":"20250922212304-xyh0w9a","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922212304-xyh0w9a","updated":"20250922212304"},"Children":[{"ID":"20250922212304-m1a6szp","Type":"NodeParagraph","Properties":{"id":"20250922212304-m1a6szp","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提供演示 (⃝3)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212304-d8mige3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-d8mige3","updated":"20250922212304"},"Children":[{"ID":"20250922212304-uppl9re","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-uppl9re","updated":"20250922212304"},"Children":[{"ID":"20250922212304-hrbu6vs","Type":"NodeParagraph","Properties":{"id":"20250922212304-hrbu6vs","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本学习"},{"Type":"NodeText","Data":": 这是LLM最强大的能力之一。提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高质量、多样化、格式清晰"},{"Type":"NodeText","Data":"的范例（D1, D4, D6）是激发这一能力的关键。"}]}]},{"ID":"20250922212304-4k6ysah","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-4k6ysah","updated":"20250922212304"},"Children":[{"ID":"20250922212304-o6y5qj8","Type":"NodeParagraph","Properties":{"id":"20250922212304-o6y5qj8","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动态演示"},{"Type":"NodeText","Data":": 检索与当前问题"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最相似"},{"Type":"NodeText","Data":"的示例作为演示（D3），比使用固定示例效果更好。"}]}]},{"ID":"20250922212304-gztyovs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-gztyovs","updated":"20250922212304"},"Children":[{"ID":"20250922212304-hk0w8ko","Type":"NodeParagraph","Properties":{"id":"20250922212304-hk0w8ko","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对话式演示"},{"Type":"NodeText","Data":": 针对ChatGPT这类模型，将演示也"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分解成多轮对话"},{"Type":"NodeText","Data":"的形式（D5），能更好地适配模型的交互模式。"}]}]}]}]},{"ID":"20250922212304-57pouju","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922212304-57pouju","updated":"20250922212304"},"Children":[{"ID":"20250922212304-x9dxj7e","Type":"NodeParagraph","Properties":{"id":"20250922212304-x9dxj7e","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用模型友好格式 (⃝4)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212304-dxp46ww","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-dxp46ww","updated":"20250922212304"},"Children":[{"ID":"20250922212304-0edu91n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-0edu91n","updated":"20250922212304"},"Children":[{"ID":"20250922212304-iaoh50e","Type":"NodeParagraph","Properties":{"id":"20250922212304-iaoh50e","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部知识注入"},{"Type":"NodeText","Data":": 当模型内部知识不足时，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检索增强"},{"Type":"NodeText","Data":"，将相关信息直接“喂”给它（I1）。"}]}]},{"ID":"20250922212304-t118n35","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-t118n35","updated":"20250922212304"},"Children":[{"ID":"20250922212304-4umiwte","Type":"NodeParagraph","Properties":{"id":"20250922212304-4umiwte","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"善用“魔法咒语”"},{"Type":"NodeText","Data":": 使用模型在训练中常见的分隔符（如"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"###"},{"Type":"NodeText","Data":"​, "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\\n"},{"Type":"NodeText","Data":"​）或触发词（如"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"Let's think step-by-step"},{"Type":"NodeText","Data":"​），能让模型更好地理解指令结构（I2, D2）。"}]}]},{"ID":"20250922212304-vgd2ld8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-vgd2ld8","updated":"20250922212304"},"Children":[{"ID":"20250922212304-dz6fc3o","Type":"NodeParagraph","Properties":{"id":"20250922212304-dz6fc3o","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具调用 (Tool Use)"},{"Type":"NodeText","Data":": 明确告诉模型可以使用哪些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部工具API"},{"Type":"NodeText","Data":"，并提供清晰的描述（O2）。"}]}]},{"ID":"20250922212304-qkjakkf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-qkjakkf","updated":"20250922212304"},"Children":[{"ID":"20250922212304-a4h21i4","Type":"NodeParagraph","Properties":{"id":"20250922212304-a4h21i4","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言偏好"},{"Type":"NodeText","Data":": 承认并利用模型在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"英语"},{"Type":"NodeText","Data":"上的优势（O6）。"}]}]}]}]}]}]}]},{"ID":"20250922212304-7gfvfkw","Type":"NodeParagraph","Properties":{"id":"20250922212304-7gfvfkw","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实践智慧的结晶"},{"Type":"NodeText","Data":"。它将抽象的“提示工程”艺术，转化为了一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体的、可执行的战术手册"},{"Type":"NodeText","Data":"。对于任何希望提升LLM使用效果的人来说，这张表格都值得逐条学习和实践。"}]}]},{"ID":"20250922212304-tlbeklf","Type":"NodeBlockquote","Properties":{"id":"20250922212304-tlbeklf","updated":"20250924151235"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922212304-djgobid","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922212304-djgobid","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922212304-hvtg2ih","Type":"NodeParagraph","Properties":{"id":"20250922212304-hvtg2ih","updated":"20250922212304"},"Children":[{"Type":"NodeText","Data":"第三十七部分深入到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型利用（Utilization）"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心技术——提示工程（Prompt Engineering）"},{"Type":"NodeText","Data":"。它系统地解构了“提示”这一看似简单的概念，并提供了一套从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理论原则"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实践技巧"},{"Type":"NodeText","Data":"的完整框架。"}]},{"ID":"20250922212304-h5ejuz1","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922212304-h5ejuz1","updated":"20250922212304"},"Children":[{"ID":"20250922212304-e0hslgl","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922212304-e0hslgl","updated":"20250922212304"},"Children":[{"ID":"20250922212304-wis36xk","Type":"NodeParagraph","Properties":{"id":"20250922212304-wis36xk","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示的“四要素”解构"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212304-uevjtet","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-uevjtet","updated":"20250922212304"},"Children":[{"ID":"20250922212304-rkm6h4t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-rkm6h4t","updated":"20250922212304"},"Children":[{"ID":"20250922212304-0xjj1yt","Type":"NodeParagraph","Properties":{"id":"20250922212304-0xjj1yt","updated":"20250922212304"},"Children":[{"Type":"NodeText","Data":"文章将一个复杂的“提示”解构为四个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基本组成部分"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述、输入数据、上下文信息和提示风格"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212304-85d4vvo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-85d4vvo","updated":"20250922212304"},"Children":[{"ID":"20250922212304-amquuhm","Type":"NodeParagraph","Properties":{"id":"20250922212304-amquuhm","updated":"20250922212304"},"Children":[{"Type":"NodeText","Data":"这种解构非常有价值，因为它为设计和优化提示提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰的分析框架"},{"Type":"NodeText","Data":"。当一个提示效果不佳时，我们可以从这四个方面逐一排查和改进。"}]}]}]}]},{"ID":"20250922212304-b8unq6y","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922212304-b8unq6y","updated":"20250922212304"},"Children":[{"ID":"20250922212304-1zzx1lb","Type":"NodeParagraph","Properties":{"id":"20250922212304-1zzx1lb","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"设计原则的提炼"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212304-6mjbdj4","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-6mjbdj4","updated":"20250922212304"},"Children":[{"ID":"20250922212304-dhk4ax8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-dhk4ax8","updated":"20250922212304"},"Children":[{"ID":"20250922212304-sjyco5b","Type":"NodeParagraph","Properties":{"id":"20250922212304-sjyco5b","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰表达、分解任务、提供演示、利用模型友好格式"},{"Type":"NodeText","Data":"这四大原则，是从无数实践中提炼出的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“道”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212304-dnw0j0g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-dnw0j0g","updated":"20250922212304"},"Children":[{"ID":"20250922212304-dieyw4q","Type":"NodeParagraph","Properties":{"id":"20250922212304-dieyw4q","updated":"20250922212304"},"Children":[{"Type":"NodeText","Data":"它们高度概括了有效提示的共性，为初学者提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"宏观的指导思想"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922212304-v0ehrs2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922212304-v0ehrs2","updated":"20250922212304"},"Children":[{"ID":"20250922212304-vxynjaa","Type":"NodeParagraph","Properties":{"id":"20250922212304-vxynjaa","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实践技巧的“武功秘籍” (表12)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212304-dnbptm1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-dnbptm1","updated":"20250922212304"},"Children":[{"ID":"20250922212304-6ajeu8g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-6ajeu8g","updated":"20250922212304"},"Children":[{"ID":"20250922212304-d7fvik0","Type":"NodeParagraph","Properties":{"id":"20250922212304-d7fvik0","updated":"20250922212304"},"Children":[{"Type":"NodeText","Data":"表12是本部分"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最精华、最具实践价值"},{"Type":"NodeText","Data":"的内容。它将四大原则具体化为一系列"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可操作的“术”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212304-4pehg42","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-4pehg42","updated":"20250922212304"},"Children":[{"ID":"20250922212304-e5m8kbm","Type":"NodeParagraph","Properties":{"id":"20250922212304-e5m8kbm","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面性"},{"Type":"NodeText","Data":": 它覆盖了从任务描述的措辞（T1-T4），到如何呈现数据（I1-I2），再到如何利用上下文和演示（C1-D9），甚至包括角色扮演、工具使用等高级技巧（O1-O8），几乎囊括了所有主流的提示技巧。"}]}]},{"ID":"20250922212304-ym8ucn3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-ym8ucn3","updated":"20250922212304"},"Children":[{"ID":"20250922212304-rmnilzf","Type":"NodeParagraph","Properties":{"id":"20250922212304-rmnilzf","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实用性"},{"Type":"NodeText","Data":": 每一个技巧都非常具体，可以直接应用到日常的LLM使用中。例如，“告诉模型它是一个专家”（T2）和“让模型自我检查”（O1）都是简单但极其有效的技巧。"}]}]}]}]},{"ID":"20250922212304-63eydna","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922212304-63eydna","updated":"20250922212304"},"Children":[{"ID":"20250922212304-t58ljbv","Type":"NodeParagraph","Properties":{"id":"20250922212304-t58ljbv","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“对话”到“编程”的思维转变"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212304-awygnzf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212304-awygnzf","updated":"20250922212304"},"Children":[{"ID":"20250922212304-fg293lx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-fg293lx","updated":"20250922212304"},"Children":[{"ID":"20250922212304-3yjuelg","Type":"NodeParagraph","Properties":{"id":"20250922212304-3yjuelg","updated":"20250922212304"},"Children":[{"Type":"NodeText","Data":"整个部分实际上是在教我们如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“与AI编程”"},{"Type":"NodeText","Data":"。提示工程的本质，就是用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然语言"},{"Type":"NodeText","Data":"作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“编程语言”"},{"Type":"NodeText","Data":"，去精确地控制一个极其强大的、但有时行为不确定的“计算机”（LLM）来完成我们想要的任务。"}]}]},{"ID":"20250922212304-9d97clj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212304-9d97clj","updated":"20250922212304"},"Children":[{"ID":"20250922212304-jnhnthc","Type":"NodeParagraph","Properties":{"id":"20250922212304-jnhnthc","updated":"20250922212304"},"Children":[{"Type":"NodeText","Data":"清晰性、结构化、分解问题、提供示例——这些都是优秀软件工程的原则，在提示工程中同样适用。"}]}]}]}]}]},{"ID":"20250922212304-1ab3bwg","Type":"NodeParagraph","Properties":{"id":"20250922212304-1ab3bwg","updated":"20250922212304"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第三十七部分为我们提供了一份"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“LLM使用说明书”"},{"Type":"NodeText","Data":"。它系统地回答了“如何有效地向LLM提问”这一核心问题。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“四要素 -\u0026gt; 四原则 -\u0026gt; N技巧”"},{"Type":"NodeText","Data":"的层次化讲解，它将提示工程这门新兴的“艺术”变得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有章可循、有法可依"},{"Type":"NodeText","Data":"。掌握了这些原则和技巧，用户就能更好地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解锁和引导"},{"Type":"NodeText","Data":"LLM的强大能力，使其从一个有趣的玩具，变为一个真正高效的生产力工具。"}]}]},{"ID":"20250922212524-fqxtf8n","Type":"NodeParagraph","Properties":{"id":"20250922212524-fqxtf8n","updated":"20250924220356"},"Children":[{"Type":"NodeText","Data":"通过将目标任务分解为子任务，LLM可以专注于解决更容易的子任务，并最终在复杂任务上取得更准确的结果。"}]},{"ID":"20250922212524-st0vxxa","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-st0vxxa","updated":"20250924220356"},"Children":[{"ID":"20250922212523-qrlmubb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-qrlmubb","updated":"20250922212523"},"Children":[{"ID":"20250922212524-n2678ji","Type":"NodeParagraph","Properties":{"id":"20250922212524-n2678ji","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提供少样本演示 (Providing few-shot demonstrations)."},{"Type":"NodeText","Data":" 如6.2节所讨论的，LLM可以从用于解决复杂任务的上下文学习中受益，其中提示包含少量期望的输入-输出对的任务示例，即少样本演示。少样本演示可以帮助LLM在没有参数微调的情况下学习输入和输出之间的语义映射。在实践中，建议为目标任务生成一些高质量的演示，这将极大地有益于最终的任务性能。"}]}]},{"ID":"20250922212523-4khhgnz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-4khhgnz","updated":"20250922212523"},"Children":[{"ID":"20250922212524-yiarvb6","Type":"NodeParagraph","Properties":{"id":"20250922212524-yiarvb6","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用模型友好的格式 (Utilizing model-friendly format)."},{"Type":"NodeText","Data":" 由于LLM是在专门构建的数据集上进行预训练的，因此有一些提示格式可以使LLM更好地理解指令。例如，正如OpenAI文档所建议的，我们可以使用"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"###"},{"Type":"NodeText","Data":"​或"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"\u0026quot;\u0026quot;\u0026quot;"},{"Type":"NodeText","Data":"​作为停止符号来分隔指令和上下文，这可以被LLM更好地理解。作为一般准则，大多数现有的LLM在英语上执行任务更好，因此利用机器翻译将困难任务的指令翻译成英语是很有用的。"}]}]},{"ID":"20250922212523-4jsjkmn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-4jsjkmn","updated":"20250922212523"},"Children":[{"ID":"20250922212524-oo7369f","Type":"NodeParagraph","Properties":{"id":"20250922212524-oo7369f","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"采用角色扮演策略 (Adopting role-playing strategies)."},{"Type":"NodeText","Data":" 由于LLM是在包含不同角色和对话的广泛语料库上进行预训练的，它们拥有固有的角色扮演能力。可以通过特定的提示来利用这一特性，以增强某些特定领域相应的能力。例如，在解决数学问题时，我们可以使用像“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"你是一位数学专家"},{"Type":"NodeText","Data":"”这样的提示前缀。这使得LLM能够从专家的角度解决问题，从而更有效地利用其预训练的知识。通过用角色扮演提示来引导LLM，它们通常可以生成更合理和准确的解决方案。"}]}]}]},{"ID":"20250922212524-39xxbuf","Type":"NodeParagraph","Properties":{"id":"20250922212524-39xxbuf","updated":"20250924220356"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Useful Tips (有用技巧)."},{"Type":"NodeText","Data":" 除了设计原则，我们还在表12中展示了一系列基于现有工作或我们经验的有用提示技巧。请注意，这些技巧是以一般性方式建议的，并不表示它们是相应任务的最佳提示。本部分将持续更新更多指南或技巧。我们欢迎读者为这个提示技巧集合做出贡献。我们在此链接提供了贡献提示技巧的详细流程：https://github.com/RUCAIBox/LLMSurvey/tree/main/Prompts。"}]},{"ID":"20250922212524-lf58ubi","Type":"NodeParagraph","Properties":{"id":"20250922212524-lf58ubi","updated":"20250924220356"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Empirical Analysis (实证分析)."},{"Type":"NodeText","Data":" 我们进一步进行实证研究，以呈现提示对任务性能的影响。为了进行实验，我们选择了一系列任务，涵盖语言生成、知识利用、复杂推理、结构化数据生成和信息检索。对于每个任务，我们手动编写了一个遵循上述通用指南的提示。请注意，测试的提示可能不是这些任务的最佳提示，因为它们主要旨在帮助读者理解如何编写一个有效的提示来解决不同的任务。此外，我们为大多数任务添加了一个简化的提示作为比较。遵循7.4节中的实验设置，我们检验了ChatGPT在复杂推理任务（Colored Objects和GSM8k）上的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3样本"},{"Type":"NodeText","Data":"性能，以及在其他任务上的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本"},{"Type":"NodeText","Data":"性能。我们在表17中报告了实验结果，其中也包括了现有论文中的监督式性能作为参考。"}]},{"ID":"20250922212524-5q8qlze","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-5q8qlze","updated":"20250924220356"},"Children":[{"ID":"20250922212523-h3aao8k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-h3aao8k","updated":"20250922212523"},"Children":[{"ID":"20250922212524-yscumx0","Type":"NodeParagraph","Properties":{"id":"20250922212524-yscumx0","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精心设计的提示可以提升ChatGPT的零样本或少样本性能。"},{"Type":"NodeText","Data":"通过比较在同一任务上使用不同提示的结果，我们可以看到，使用精心设计的提示可以取得比简单提示更好的性能。在精心设计的提示中，我们提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更清晰表达的任务描述"},{"Type":"NodeText","Data":"（例如，WMT和WikiFact），或使用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型友好的格式"},{"Type":"NodeText","Data":"（例如，GSM8k和OBQA）。例如，对于WikiFact任务，带有更详细任务描述的提示导致性能从29.25提升到31.21。"}]}]},{"ID":"20250922212523-x573y86","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-x573y86","updated":"20250922212523"},"Children":[{"ID":"20250922212524-x85cp3u","Type":"NodeParagraph","Properties":{"id":"20250922212524-x85cp3u","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更复杂的任务可以从ChatGPT上精心的提示工程中获益更多。"},{"Type":"NodeText","Data":"在WikiFact和Colored Objects任务中，设计的提示极大地提升了ChatGPT的性能，即在WikiFact上从23.61提升到28.47，在Colored Objects上从53.20提升到66.75。这表明，让LLM在复杂任务上表现良好，提示工程是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"必不可少的"},{"Type":"NodeText","Data":"，因为这些任务通常具有特定的输出格式或需要背景知识。我们的示例提示提供了更详细的任务描述（例如，输出格式和任务目标），这可以帮助ChatGPT更好地理解完成复杂任务的要求。"}]}]},{"ID":"20250922212523-myrb6ar","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-myrb6ar","updated":"20250922212523"},"Children":[{"ID":"20250922212524-dr2f1az","Type":"NodeParagraph","Properties":{"id":"20250922212524-dr2f1az","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对于数学推理任务，设计基于编程语言格式的特定提示更有效。"},{"Type":"NodeText","Data":"对于GSM8k，设计的提示采用了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码格式的少样本演示"},{"Type":"NodeText","Data":"，将这个数学推理任务转换为代码生成任务，这可以利用ChatGPT强大的代码合成能力来解决数学问题。此外，借助外部程序执行器，我们能够获得比使用LLM进行算术运算更精确的结果。正如我们所见，GSM8k的性能从78.47提升到79.30，表明编程语言在数学推理任务中的有用性。"}]}]},{"ID":"20250922212523-glvigmn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-glvigmn","updated":"20250922212523"},"Children":[{"ID":"20250922212524-bo1j0yi","Type":"NodeParagraph","Properties":{"id":"20250922212524-bo1j0yi","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在知识利用和复杂推理任务中，带有适当提示的ChatGPT取得了与监督基线方法相当的性能，甚至超越了它们。"},{"Type":"NodeText","Data":"在知识利用和复杂推理任务中，带有适当的零样本或少样本提示的ChatGPT可以取得与监督方法相当甚至更好的性能，例如，在WikiFact上31.21（ChatGPT）vs. 34.20（监督基线）。尽管如此，ChatGPT在某些特定任务（例如，ARC和WikiFact）上仍然比监督基线模型表现得差，因为这些监督模型已经用任务特定的数据进行了专门优化。"}]}]},{"ID":"20250922212523-hfto7el","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-hfto7el","updated":"20250922212523"},"Children":[{"ID":"20250922212524-c8taqlm","Type":"NodeParagraph","Properties":{"id":"20250922212524-c8taqlm","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过合适的提示工程，LLM可以处理一些非传统的NLP任务。"},{"Type":"NodeText","Data":"借助特定的提示，ChatGPT也可以完成非传统的NLP任务，即通用推荐和对话式推荐。一个关键点是，这些任务可以用自然语言很好地表达或描述。然而，ChatGPT在这些任务上的性能仍然远未达到参考性能，因为LLM无法直接适配这些需要特定领域知识和任务适配的任务。"}]}]}]},{"ID":"20250922212524-bkfjcfh","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922212524-bkfjcfh","updated":"20250924220356"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.1.2 Prompt Optimization (提示优化)"}]},{"ID":"20250922212524-8xorsoa","Type":"NodeParagraph","Properties":{"id":"20250922212524-8xorsoa","updated":"20250924220356"},"Children":[{"Type":"NodeText","Data":"尽管手动创建任务提示更直观，但它耗时，更重要的是，模型对精心设计的提示高度敏感——不恰当的提示会导致低任务性能（如表17所示）。因此，大量研究提出了针对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"离散提示"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连续提示"},{"Type":"NodeText","Data":"的自动优化方法，以实现最佳性能。在本部分中，我们将从两个角度详细介绍这些研究，即离散提示和连续提示。"}]},{"ID":"20250922212524-dgzsk37","Type":"NodeParagraph","Properties":{"id":"20250922212524-dgzsk37","updated":"20250924220356"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Discrete Prompt Optimization (离散提示优化)."},{"Type":"NodeText","Data":" 离散提示通常由自然语言词元的序列组成。尽管形式简单灵活，但在离散空间中优化提示是一个具有挑战性的问题，因为存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"组合爆炸的巨大搜索空间"},{"Type":"NodeText","Data":"。为了自动搜索下游任务的有效提示，现有研究提出了广泛的离散提示优化方法，详细如下。"}]},{"ID":"20250922212524-eu5c9o9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-eu5c9o9","updated":"20250924220356"},"Children":[{"ID":"20250922212523-l0i8vwx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-l0i8vwx","updated":"20250922212523"},"Children":[{"ID":"20250922212524-fzhv9md","Type":"NodeParagraph","Properties":{"id":"20250922212524-fzhv9md","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于梯度的方法 (Gradient-based approaches)."},{"Type":"NodeText","Data":" 这类方法旨在通过梯度更新最大化输出似然来优化提示搜索过程。作为一个代表性的工作，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Auto-Prompt"},{"Type":"NodeText","Data":"提出了一种梯度引导的方法，通过近似替换提示词元与词汇表中另一个候选词元时的对数似然变化，来贪婪地搜索提示每个位置的最佳词元。"}]}]}]},{"ID":"20250922212524-rdz8k6v","Type":"NodeTable","TableAligns":[1,1,1,1,1],"Properties":{"colgroup":"||||","id":"20250922212524-rdz8k6v","updated":"20250924220356"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Tasks"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Datasets"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Instructions"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ChatGPT"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Supervised"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LG"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Translation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WMT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"我希望你扮演一名翻译。请将给定的英语句子翻译成捷克语。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"20.66"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"我希望你扮演一名翻译。翻译给定的英语句子到捷克语，并确保翻译后的句子在语义上与原句一致。\\n句子：{source sentence}\\n翻译："}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"21.12"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Summarization"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"XSum"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"请为给定的文档生成一个单句摘要。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"21.71"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"{document} 尽力总结给定文档的主要内容。并为其生成一个1句话的简短摘要。\\n摘要："}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"23.01"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"KU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Closed-Book QA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ARC"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"选择问题的答案。{query} {options}"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"85.19"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"根据给定的问题选择一个正确的答案，并输出相应的id，不要回答除答案id之外的其他内容。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"85.86"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Open-Book QA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"OBQA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"选择问题的答案：{question} {choices}。你必须只输出A, B, C, 或 D，没有任何额外解释。答案是"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"81.20"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"以下是一个需要多步推理、使用额外常识知识和丰富文本理解的问题。选择问题的答案：\\n问题：多褶鲨和琵琶鱼生活在海洋表面之下很深的地方，这就是为什么它们被称为\\n选项：\\nA. 深海动物\\nB. 鱼\\nC. 长海鱼\\nD. 远海动物\\n你必须只输出A, B, C, 或 D，没有任何额外解释。答案是"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"82.20"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Fact Extraction"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WikiF"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"用一个或几个词完成句子。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.25"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"用维基百科中的一个实体名称（必须是名词）尽可能简短地完成给定的句子，并确保完成的句子符合事实。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"31.21"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CR"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Symbolic Reasoning"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"C-Objects"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"问题：{problem}\\n答案："}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"53.20"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"你是推理问题专家。这里有一些关于符号推理的例子。你可以利用例子中的知识来解决最后一个问题。你应该遵循例子，并在没有外部解决方案或词语的情况下生成最终答案。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"66.75"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Math Word Problems"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GSM8k"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"问题：{problem}\\n解：让我们一步步思考。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78.47"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"让我们用python解决数学问题。这里有三个如何做的例子，\\n问：奥利维亚有"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"23。她买了五个每个"},{"Type":"NodeText","Data":"3的百吉饼。她还剩多少钱？\\n"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"`"}]},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"`"}]},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"`"}]},{"Type":"NodeText","Data":"def solution():\\n \"\"\"奥利维亚有"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"23。她买了五个每个"},{"Type":"NodeText","Data":"3的百吉饼。她还剩多少钱？\"\"\"\\n money"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"initial = 23\\n bagels = 5\\n bagel"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"cost = 3\\n money"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"spent = bagels "},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"*"}]},{"Type":"NodeText","Data":" bagel"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"cost\\n money"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"left = money"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"initial - money"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"spent\\n result = money"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"left\\n return result"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"`"}]},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"`"}]},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"`"}]},{"Type":"NodeText","Data":"\\n ... \\n这个问题怎么样？\\n问："}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"79.30"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SDG"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Code Synthesis"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HumanEval"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"我希望你扮演一个代码补全者。给定一个代码片段，你的目标是补全代码并确保它能实现所描述的功能。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"79.88"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Text-to-SQL"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Spider"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"### 仅补全sqlite SQL查询，无解释。\\n"},{"Type":"NodeTextMark","TextMarkType":"tag","TextMarkTextContent":"\\n### Sqlite SQL表及其属性：\\n"},{"Type":"NodeText","Data":"​\\n{table}\\n"},{"Type":"NodeTextMark","TextMarkType":"tag","TextMarkTextContent":"{foreign_key}\\n"},{"Type":"NodeText","Data":"​\\n### {question}\\n SELECT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70.10"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"IR"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Recommendation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MovieLens"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"我过去按顺序看了以下电影：\\n{user"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"his"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"text}\\n\\n现在有{recall"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"budget}部候选电影我可以接下来看：\\n{candidate"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"text"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"order}\\n请根据我的观看历史，衡量我最想看下一步的可能性，对这{recall"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"budget}部电影进行排序。请一步步思考。\\n注意我最近看的电影是{recent"},{"Type":"NodeBackslash","Data":"span","Children":[{"Type":"NodeText","Data":"_"}]},{"Type":"NodeText","Data":"item}。请用序号显示你的排序结果。用换行符分隔你的输出。你必须对给定的候选电影进行排序。你不能生成不在给定候选列表中的电影。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.80"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Conversational Recommendation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ReDial"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"推荐10个符合用户偏好的项目。推荐列表可以包含对话中提到过的项目。推荐列表的格式是：no. title (year)。除了推荐列表中的项目标题，不要提及任何其他内容。"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"17.20"}]}]}]},{"ID":"20250922212524-i8z3ig1","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922212524-i8z3ig1","updated":"20250924220356"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 17：ChatGPT在代表性任务上的提示示例及其性能。"}]},{"ID":"20250922212524-020i5en","Type":"NodeParagraph","Properties":{"id":"20250922212524-020i5en","updated":"20250924220356"},"Children":[{"Type":"NodeText","Data":"对于大多数任务，我们比较了简单和复杂提示的性能。我们也展示了已报道的监督式方法的性能。“LG”、“KU”、“CR”、“SDG”、“IR”分别是“语言生成”、“知识利用”、“复杂推理”、“结构化数据生成”、“信息检索”的缩写。“—”表示之前没有报道过的监督式结果。"}]},{"ID":"20250922212524-sqiex4c","Type":"NodeBlockquote","Properties":{"id":"20250922212524-sqiex4c","updated":"20250924220356"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922212524-h9msogc","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922212524-h9msogc","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922212524-pwaqm2y","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922212524-pwaqm2y","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表17解析：好提示 vs. 坏提示——效果天壤之别"}]},{"ID":"20250922212524-sxfor72","Type":"NodeParagraph","Properties":{"id":"20250922212524-sxfor72","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"这张表格通过在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多个任务"},{"Type":"NodeText","Data":"上对比"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"简单提示"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精心设计的复杂提示"},{"Type":"NodeText","Data":"的效果，用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实打实的数据"},{"Type":"NodeText","Data":"证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程（Prompt Engineering）的巨大价值"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922212524-3wi41eu","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-3wi41eu","updated":"20250922212524"},"Children":[{"ID":"20250922212523-iuzmfli","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-iuzmfli","updated":"20250922212523"},"Children":[{"ID":"20250922212524-rkpmqd4","Type":"NodeParagraph","Properties":{"id":"20250922212524-rkpmqd4","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"普遍有效性"},{"Type":"NodeText","Data":": 在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"所有"},{"Type":"NodeText","Data":"列出的任务中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂提示"},{"Type":"NodeText","Data":"的表现都"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优于或等于"},{"Type":"NodeText","Data":"简单提示。这雄辩地证明了，花时间设计一个好提示是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"值得的"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212523-j4s0a88","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-j4s0a88","updated":"20250922212523"},"Children":[{"ID":"20250922212524-2wzpw7d","Type":"NodeParagraph","Properties":{"id":"20250922212524-2wzpw7d","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂任务收益更大"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212524-3nedu24","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-3nedu24","updated":"20250922212524"},"Children":[{"ID":"20250922212523-crpe3vn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-crpe3vn","updated":"20250922212523"},"Children":[{"ID":"20250922212524-nz6dr7x","Type":"NodeParagraph","Properties":{"id":"20250922212524-nz6dr7x","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符号推理（C-Objects）"},{"Type":"NodeText","Data":"任务上，性能从"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"53.20"},{"Type":"NodeText","Data":"​飙升到"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"66.75"},{"Type":"NodeText","Data":"​。"}]}]},{"ID":"20250922212523-nsku1rr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-nsku1rr","updated":"20250922212523"},"Children":[{"ID":"20250922212524-b0ec2yq","Type":"NodeParagraph","Properties":{"id":"20250922212524-b0ec2yq","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"事实抽取（WikiF）"},{"Type":"NodeText","Data":"任务上，性能从"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"29.25"},{"Type":"NodeText","Data":"​提升到"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"31.21"},{"Type":"NodeText","Data":"​。"}]}]},{"ID":"20250922212523-m5u0cy6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-m5u0cy6","updated":"20250922212523"},"Children":[{"ID":"20250922212524-hyardka","Type":"NodeParagraph","Properties":{"id":"20250922212524-hyardka","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"这说明，任务越"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂、越需要精确性"},{"Type":"NodeText","Data":"，一个精心设计的提示所能带来的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能提升就越显著"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922212523-dndtg5v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-dndtg5v","updated":"20250922212523"},"Children":[{"ID":"20250922212524-tpu8xs5","Type":"NodeParagraph","Properties":{"id":"20250922212524-tpu8xs5","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“思维转换”的力量"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212524-h8xy51z","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-h8xy51z","updated":"20250922212524"},"Children":[{"ID":"20250922212523-7x5mrvt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-7x5mrvt","updated":"20250922212523"},"Children":[{"ID":"20250922212524-ug65b5e","Type":"NodeParagraph","Properties":{"id":"20250922212524-ug65b5e","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学应用题（GSM8k）"},{"Type":"NodeText","Data":"任务上，最引人注目的策略是将问题"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"转化为Python代码生成任务"},{"Type":"NodeText","Data":"。这不仅利用了模型强大的代码能力，还通过外部执行器保证了计算的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"绝对准确性"},{"Type":"NodeText","Data":"，性能提升显著。这是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“思维转换”"},{"Type":"NodeText","Data":"的提示技巧，将模型不擅长的事（精确计算）转化为它擅长的事（代码生成）。"}]}]}]}]},{"ID":"20250922212523-sm99duv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-sm99duv","updated":"20250922212523"},"Children":[{"ID":"20250922212524-mvcq93t","Type":"NodeParagraph","Properties":{"id":"20250922212524-mvcq93t","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与SOTA的比较"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212524-s1g5mvn","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-s1g5mvn","updated":"20250922212524"},"Children":[{"ID":"20250922212523-cms450t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-cms450t","updated":"20250922212523"},"Children":[{"ID":"20250922212524-eua4gob","Type":"NodeParagraph","Properties":{"id":"20250922212524-eua4gob","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识利用（KU）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理（CR）"},{"Type":"NodeText","Data":"等任务上，零/少样本的ChatGPT凭借好提示，其性能已经可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"接近甚至媲美"},{"Type":"NodeText","Data":"经过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完全监督训练（Supervised）"},{"Type":"NodeText","Data":"的模型。这再次证明了大型模型的强大潜力。"}]}]},{"ID":"20250922212523-y8nlz9m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-y8nlz9m","updated":"20250922212523"},"Children":[{"ID":"20250922212524-1rz4aqw","Type":"NodeParagraph","Properties":{"id":"20250922212524-1rz4aqw","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"但在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"翻译（Translation）、摘要（Summarization）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推荐（Recommendation）"},{"Type":"NodeText","Data":"等任务上，与监督SOTA仍有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"巨大差距"},{"Type":"NodeText","Data":"。这说明，对于这些已经有海量高质量、任务特定训练数据的成熟领域，专门训练的模型依然具有巨大优势。"}]}]}]}]},{"ID":"20250922212523-a6rmsk2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-a6rmsk2","updated":"20250922212523"},"Children":[{"ID":"20250922212524-4wrj01c","Type":"NodeParagraph","Properties":{"id":"20250922212524-4wrj01c","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非传统任务的探索"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212524-htl6k73","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-htl6k73","updated":"20250922212524"},"Children":[{"ID":"20250922212523-l5idol4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-l5idol4","updated":"20250922212523"},"Children":[{"ID":"20250922212524-bw5uqbz","Type":"NodeParagraph","Properties":{"id":"20250922212524-bw5uqbz","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推荐任务"},{"Type":"NodeText","Data":"上的尝试表明，通过提示工程，LLM可以被引导去完成一些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非传统的NLP任务"},{"Type":"NodeText","Data":"。虽然性能还不尽如人意，但这展示了LLM作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通用任务解决器”"},{"Type":"NodeText","Data":"的巨大潜力。"}]}]}]}]}]},{"ID":"20250922212524-fsbe2nk","Type":"NodeParagraph","Properties":{"id":"20250922212524-fsbe2nk","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格是一份关于提示工程价值的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强有力的实证报告"},{"Type":"NodeText","Data":"。它用数据告诉我们："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1. 好提示总是有用的。2. 任务越难，好提示越重要。3. 创新的提示策略（如转为代码）能带来惊喜。4. LLM的潜力巨大，但在许多成熟领域，专用模型依然是王者。"}]}]},{"ID":"20250922212524-wfj0v55","Type":"NodeThematicBreak","Properties":{"id":"20250922212524-wfj0v55","updated":"20250924220356"}},{"ID":"20250922212524-912b0iw","Type":"NodeBlockquote","Properties":{"id":"20250922212524-912b0iw","updated":"20250924220356"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922212524-e142y19","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922212524-e142y19","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922212524-fsst6x9","Type":"NodeParagraph","Properties":{"id":"20250922212524-fsst6x9","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"第三十八部分深入探讨了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程（Prompt Engineering）"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“道”与“术”"},{"Type":"NodeText","Data":"，并进一步引出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示优化（Prompt Optimization）"},{"Type":"NodeText","Data":"这一更前沿的自动化领域。"}]},{"ID":"20250922212524-lk34ufz","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922212524-lk34ufz","updated":"20250922212524"},"Children":[{"ID":"20250922212523-dfffb0l","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922212523-dfffb0l","updated":"20250922212523"},"Children":[{"ID":"20250922212524-c9l24js","Type":"NodeParagraph","Properties":{"id":"20250922212524-c9l24js","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的“道”：原则与思想"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212524-43mxj49","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-43mxj49","updated":"20250922212524"},"Children":[{"ID":"20250922212523-uf5k59b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-uf5k59b","updated":"20250922212523"},"Children":[{"ID":"20250922212524-zcod59s","Type":"NodeParagraph","Properties":{"id":"20250922212524-zcod59s","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"本部分将提示工程从一种“玄学”或“手艺”，提炼为一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统性的方法论"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212523-6922ee2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-6922ee2","updated":"20250922212523"},"Children":[{"ID":"20250922212524-byj2j9g","Type":"NodeParagraph","Properties":{"id":"20250922212524-byj2j9g","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四大原则（清晰、分解、演示、格式友好）"},{"Type":"NodeText","Data":"是提示工程的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“内功心法”"},{"Type":"NodeText","Data":"。它们提供了设计高效提示的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"宏观指导思想"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212523-7ouyzku","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-7ouyzku","updated":"20250922212523"},"Children":[{"ID":"20250922212524-r0ax2js","Type":"NodeParagraph","Properties":{"id":"20250922212524-r0ax2js","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"角色扮演策略"},{"Type":"NodeText","Data":"是一个深刻的洞见，它利用了LLM在预训练中学习到的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“人格”或“世界模型”"},{"Type":"NodeText","Data":"，通过激活特定的“专家”身份来引导模型调用相关的知识和推理模式。"}]}]}]}]},{"ID":"20250922212523-okrxhrh","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922212523-okrxhrh","updated":"20250922212523"},"Children":[{"ID":"20250922212524-lqt641f","Type":"NodeParagraph","Properties":{"id":"20250922212524-lqt641f","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的“术”：技巧与实践 (表12 \u0026amp; 表17)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212524-byv81pi","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-byv81pi","updated":"20250922212524"},"Children":[{"ID":"20250922212523-k351bua","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-k351bua","updated":"20250922212523"},"Children":[{"ID":"20250922212524-f3rpncv","Type":"NodeParagraph","Properties":{"id":"20250922212524-f3rpncv","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表12是“战术手册”"},{"Type":"NodeText","Data":"，它将宏观原则分解为一系列"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体、可操作"},{"Type":"NodeText","Data":"的技巧。这份清单的全面性和实用性，使其成为一份极具价值的实践指南。"}]}]},{"ID":"20250922212523-pb62rmh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-pb62rmh","updated":"20250922212523"},"Children":[{"ID":"20250922212524-euv0lxj","Type":"NodeParagraph","Properties":{"id":"20250922212524-euv0lxj","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表17是“实战演习”"},{"Type":"NodeText","Data":"，它用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定量的数据"},{"Type":"NodeText","Data":"雄辩地证明了这些战术的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有效性"},{"Type":"NodeText","Data":"。特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“好提示 vs. 坏提示”"},{"Type":"NodeText","Data":"的对比，直观地展示了提示工程对模型性能的巨大影响。"}]}]}]}]},{"ID":"20250922212523-cuoi4xm","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922212523-cuoi4xm","updated":"20250922212523"},"Children":[{"ID":"20250922212524-fblu78c","Type":"NodeParagraph","Properties":{"id":"20250922212524-fblu78c","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“手动”到“自动”：提示优化的提出"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212524-xs8ovtj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-xs8ovtj","updated":"20250922212524"},"Children":[{"ID":"20250922212523-cmrkcq0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-cmrkcq0","updated":"20250922212523"},"Children":[{"ID":"20250922212524-b3sf2qz","Type":"NodeParagraph","Properties":{"id":"20250922212524-b3sf2qz","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"在充分展示了手动设计提示的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强大威力"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"巨大工作量"},{"Type":"NodeText","Data":"之后，文章自然地引出了下一个核心问题："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"我们能否让机器自动找到最佳的提示？"}]}]},{"ID":"20250922212523-7mu5ibe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-7mu5ibe","updated":"20250922212523"},"Children":[{"ID":"20250922212524-dhk2a2z","Type":"NodeParagraph","Properties":{"id":"20250922212524-dhk2a2z","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示优化（Prompt Optimization）"},{"Type":"NodeText","Data":"就是对这个问题的回答。它旨在将提示工程从一门"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“艺术”"},{"Type":"NodeText","Data":"转变为一门"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“科学”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自动化工程”"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922212523-c0nc3lg","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922212523-c0nc3lg","updated":"20250922212523"},"Children":[{"ID":"20250922212524-dmku7y4","Type":"NodeParagraph","Properties":{"id":"20250922212524-dmku7y4","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"离散提示优化的挑战"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212524-8r6xm7d","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212524-8r6xm7d","updated":"20250922212524"},"Children":[{"ID":"20250922212523-ybf2abk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-ybf2abk","updated":"20250922212523"},"Children":[{"ID":"20250922212524-5pl33ie","Type":"NodeParagraph","Properties":{"id":"20250922212524-5pl33ie","updated":"20250922212524"},"Children":[{"Type":"NodeText","Data":"文章指出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"离散提示优化"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本困难——组合爆炸"},{"Type":"NodeText","Data":"。在由成千上万个词元构成的巨大词汇表中，搜索一个最优的词元序列，其搜索空间是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"天文数字"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212523-1yu37z0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212523-1yu37z0","updated":"20250922212523"},"Children":[{"ID":"20250922212524-rgcgb3f","Type":"NodeParagraph","Properties":{"id":"20250922212524-rgcgb3f","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于梯度的方法（如Auto-Prompt）"},{"Type":"NodeText","Data":"是对这一挑战的初步尝试，它试图用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"梯度信号"},{"Type":"NodeText","Data":"来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指导"},{"Type":"NodeText","Data":"这个庞大的搜索过程，使其比随机搜索更高效。"}]}]}]}]}]},{"ID":"20250922212524-gwbxz2f","Type":"NodeParagraph","Properties":{"id":"20250922212524-gwbxz2f","updated":"20250922212524"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第三十八部分完成了从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何手动设计好提示”"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“为何以及如何自动寻找好提示”"},{"Type":"NodeText","Data":"的逻辑递进。它首先为提示工程建立了一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完整的理论和实践框架"},{"Type":"NodeText","Data":"，然后指出了其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“手工业”"},{"Type":"NodeText","Data":"模式的局限性，从而为引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“工业化、自动化”"},{"Type":"NodeText","Data":"的提示优化技术铺平了道路。这标志着人机交互正在从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类适应机器"},{"Type":"NodeText","Data":"，向"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"机器自主学习如何更好地与人类协作"},{"Type":"NodeText","Data":"的更高阶段演进。"}]}]},{"ID":"20250922212739-u21im65","Type":"NodeParagraph","Properties":{"id":"20250922212739-u21im65","updated":"20250924220356"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922212739-hxgdc6b","Type":"NodeThematicBreak","Properties":{"id":"20250922212739-hxgdc6b","updated":"20250924220356"}},{"ID":"20250922212739-57zcwbc","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922212739-57zcwbc","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第三十九部分"}]},{"ID":"20250922212739-1urmb83","Type":"NodeParagraph","Properties":{"id":"20250922212739-1urmb83","updated":"20250922212755"},"Children":[{"Type":"NodeText","Data":"然而，这样的搜索过程可能极其昂贵，因为它需要为提示的每个位置评估每个候选词元，导致大量的额外前向传播。因此，一种改进的梯度方法被提出来，通过将离散的词元转换为连续的嵌入，并在优化期间在连续空间上计算梯度。"}]},{"ID":"20250922212739-nsl6ekb","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212739-nsl6ekb","updated":"20250922212755"},"Children":[{"ID":"20250922212738-1xn95b8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-1xn95b8","updated":"20250922212738"},"Children":[{"ID":"20250922212739-zjfuc25","Type":"NodeParagraph","Properties":{"id":"20250922212739-zjfuc25","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于RL的方法 (RL-based approaches)."},{"Type":"NodeText","Data":" 由于离-散提示很难通过梯度反向传播来学习，一些研究提出将离散提示优化形式化为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习（RL）问题"},{"Type":"NodeText","Data":"，并利用RL算法进行优化。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RLPrompt"},{"Type":"NodeText","Data":"训练一个策略网络来生成期望的提示，并带有多个奖励函数。在这种方法中，还提出了几种有效的奖励稳定化策略来增强RL训练的效率。与之前需要足够数据进行训练的工作相比，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"TEMPERA"},{"Type":"NodeText","Data":"提议在测试时通过利用一个预训练的RL智能体来顺序编辑手动编写的初始提示的不同部分来编辑提示。尽管这些方法简单有效，但它们探索的是一个手动定义的编辑空间（例如，添加、交换和删除），并专注于修改原始提示，这限制了提示搜索的灵活性。相比之下，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PRewrite"},{"Type":"NodeText","Data":"利用RL来训练一个提示重写器，以生成新的提示而不是修改，这不对提示重写施加任何限制，并提供了改进的灵活性。"}]}]},{"ID":"20250922212738-qonprkv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-qonprkv","updated":"20250922212738"},"Children":[{"ID":"20250922212739-e0p1rf8","Type":"NodeParagraph","Properties":{"id":"20250922212739-e0p1rf8","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于编辑的方法 (Edit-based approaches)."},{"Type":"NodeText","Data":" 对于上述方法，基于梯度和基于RL的微调对于更大的模型来说可能计算量极大，并且可能不适用于基于API的模型调用（例如，ChatGPT）。因此，另一条研究路线旨在直接根据任务性能编辑现有的提示。具体来说，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPS"},{"Type":"NodeText","Data":"借鉴了遗传算法的思想，并提出了一种遗传提示搜索方法，该方法利用一个语言模型（即T5）通过采用完形填空的形式来编辑提示。除了基于模型的编辑方法，人类定义的操作也可以用于提示编辑，包括删除、交换、释义和添加。基于这些操作，它们迭代地编辑提示，并在模型在一小部分示例上的性能指导下，贪婪地搜索最佳提示。"}]}]},{"ID":"20250922212738-in9ixm6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-in9ixm6","updated":"20250922212738"},"Children":[{"ID":"20250922212739-vnlzxiu","Type":"NodeParagraph","Properties":{"id":"20250922212739-vnlzxiu","updated":"20250922212739"},"Children":[{"Type":"NodeText","Data":"-"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于LLM的方法 (LLM-based approaches)."},{"Type":"NodeText","Data":" 由于LLM的卓越能力，越来越多的研究直接利用LLM作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示生成器"},{"Type":"NodeText","Data":"。具体来说，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"APE"},{"Type":"NodeText","Data":"利用一个LLM生成初始提示，然后选择准确率最高的提示，最后通过迭代的蒙特卡洛搜索方法改进最佳候选者。然而，这种方法没有有效地约束提示搜索空间，这很可能导致不稳定的结果。为了实现良好的性能和快速收敛，一条研究路线利用启发式方法（例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"进化算法"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性学习"},{"Type":"NodeText","Data":"）进行提示优化。另一条研究路线则借鉴了基于梯度的模型优化器，用于LLM-based的提示优化。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"APO"},{"Type":"NodeText","Data":"指示LLM生成关于如何将旧提示提炼为新的改进提示的文本反馈，然后执行文本梯度下降。然而，它们在提示空间中的搜索可能效率低下，没有充分考虑先前提示的整个提炼轨迹，因此可能导致次优结果。因此，一些最近的研究将先前的提示及其分数结合起来，以指导LLM逐步生成更好的新提示。为了进一步设计关于提示优化器设计的形式化指南，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPO"},{"Type":"NodeText","Data":"对LLM-based的提示优化器与基于梯度的模型优化器进行了系统的类比。它进一步开发了一个更形式化的LLM-based提示优化框架，该框架广泛借鉴了机器学习优化的思想。具体来说，它从先前的提示中检索相关的提示，并利用基于生成的提炼策略来执行更新。为了避免每次迭代的巨大变化，GPO进一步采用了基于余弦的衰减策略来控制编辑距离。然而，这些方法仍然在探索巨大的有效提示空间方面存在困难。受人类式试错的启发，提示优化被进一步形式化为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"战略规划问题"},{"Type":"NodeText","Data":"，并使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"蒙特卡洛树搜索"},{"Type":"NodeText","Data":"来导航巨大的提示空间。"}]}]}]},{"ID":"20250922212739-j9iev7i","Type":"NodeParagraph","Properties":{"id":"20250922212739-j9iev7i","updated":"20250922212755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Continuous Prompt Optimization (连续提示优化)."},{"Type":"NodeText","Data":" 与离散提示不同，连续提示由一组"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连续的嵌入"},{"Type":"NodeText","Data":"组成，可以通过基于下游任务损失的梯度更新直接进行优化。请注意，连续提示优化主要在PLM中进行研究，但在LLM时代受到的关注有限，因为它们的参数量巨大。为内容完整性，我们包含了对这部分的讨论。在先前的工作中，大多数研究通常依赖监督学习，基于任务数据来训练连续提示。此外，在数据稀缺的场景中，可以采用迁移学习方法来缓解目标任务上标记数据的缺乏。下面将详细介绍这两种方法。"}]},{"ID":"20250922212739-z3xinzr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212739-z3xinzr","updated":"20250922212755"},"Children":[{"ID":"20250922212738-psj1t8g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-psj1t8g","updated":"20250922212738"},"Children":[{"ID":"20250922212739-poxtmsm","Type":"NodeParagraph","Properties":{"id":"20250922212739-poxtmsm","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有足够数据时的提示学习 (Prompt learning with sufficient data)."},{"Type":"NodeText","Data":" 在这种方法中，大多数现有方法将连续提示视为可训练的模型参数，然后利用监督学习，通过在充足的下游任务数据上最小化交叉熵损失来优化连续提示。如5.3.1节所讨论的，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"prefix tuning"},{"Type":"NodeText","Data":"在语言模型的每个Transformer层前添加一个前缀序列（即一组可训练的连续向量），而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"prompt tuning"},{"Type":"NodeText","Data":"仅在输入层并入可训练的提示向量。通过固定LLM的大规模参数并仅微调连续提示向量，这类方法可以实现极高的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数效率"},{"Type":"NodeText","Data":"（5.3节）。然而，这些方法通常"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"独立于输入"},{"Type":"NodeText","Data":"，缺乏对输入语义的充分考虑。因此，中的作者提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文微调（context tuning）"},{"Type":"NodeText","Data":"，其中连续提示是基于输入文本推导出来的，并通过下游任务损失进行学习。"}]}]},{"ID":"20250922212738-yqy5ldd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-yqy5ldd","updated":"20250922212738"},"Children":[{"ID":"20250922212739-3gpnbl9","Type":"NodeParagraph","Properties":{"id":"20250922212739-3gpnbl9","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据稀缺时的提示迁移 (Prompt transferring with scarce data)."},{"Type":"NodeText","Data":" 监督学习方法要求有充足的训练数据来学习最优的连续提示，这在数据稀缺的领域和任务中可能表现不佳。为了解决这个问题，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SPoT"},{"Type":"NodeText","Data":"提出了一种基于提示的迁移学习方法，它首先为几个代表性的源任务学习一个单一的连续提示，然后使用这个提示来初始化目标任务的提示。然而，这种方法利用相同的提示来解决目标任务的所有实例。对于单个任务，即使是一个学习得很好的提示，也可能不适用于来自大群体的所有数据实例。为了解决这个问题，一种改进的方法在提示迁移过程中设计了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自适应注意力机制"},{"Type":"NodeText","Data":"来推导目标提示，同时考虑了任务级和实例级的信息。提示迁移范式可以利用编码在源提示中的数据充足的源任务的知识，来解决数据稀缺的目标任务。"}]}]}]},{"ID":"20250922212739-uyhat1i","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922212739-uyhat1i","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.2 In-Context Learning (上下文学习)"}]},{"ID":"20250922212739-h5h90re","Type":"NodeParagraph","Properties":{"id":"20250922212739-h5h90re","updated":"20250922212755"},"Children":[{"Type":"NodeText","Data":"作为一种特殊的提示形式，上下文学习（ICL）首先与GPT-3一同被提出，现已成为利用LLM的典型方法。"}]},{"ID":"20250922212739-69uolpq","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922212739-69uolpq","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.2.1 ICL Formulation (ICL的公式化)"}]},{"ID":"20250922212739-13aup6x","Type":"NodeParagraph","Properties":{"id":"20250922212739-13aup6x","updated":"20250922212755"},"Children":[{"Type":"NodeText","Data":"正如中所述，ICL使用一个格式化的自然语言提示，由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述"},{"Type":"NodeText","Data":"和/或几个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务示例作为演示"},{"Type":"NodeText","Data":"组成。图14展示了ICL的一个示意图。首先，从任务数据集中选择几个示例作为演示。然后，它们以特定的顺序组合起来，形成带有专门设计模板的自然语言提示。"}]},{"ID":"20250922212739-x7x6dx5","Type":"NodeBlockquote","Properties":{"id":"20250922212739-x7x6dx5","updated":"20250922212755"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922212739-k8g2xyx","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922212739-k8g2xyx","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922212739-m7i0wvi","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922212739-m7i0wvi","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示优化：从“手工业”到“自动化”"}]},{"ID":"20250922212739-xzd815v","Type":"NodeParagraph","Properties":{"id":"20250922212739-xzd815v","updated":"20250922212739"},"Children":[{"Type":"NodeText","Data":"这部分内容系统地梳理了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动化提示优化"},{"Type":"NodeText","Data":"的各种技术路线，其核心目标都是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"取代耗时耗力的人工提示工程"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922212739-l1ghszk","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212739-l1ghszk","updated":"20250922212739"},"Children":[{"ID":"20250922212738-vpmnexh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-vpmnexh","updated":"20250922212738"},"Children":[{"ID":"20250922212739-q9343if","Type":"NodeParagraph","Properties":{"id":"20250922212739-q9343if","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"离散提示优化 (Discrete Prompt Optimization)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212739-sgdx69g","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212739-sgdx69g","updated":"20250922212739"},"Children":[{"ID":"20250922212738-tgmiu6r","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-tgmiu6r","updated":"20250922212738"},"Children":[{"ID":"20250922212739-f179zcz","Type":"NodeParagraph","Properties":{"id":"20250922212739-f179zcz","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"挑战"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"组合爆炸"},{"Type":"NodeText","Data":"的搜索空间。"}]}]},{"ID":"20250922212738-9yss1c4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-9yss1c4","updated":"20250922212738"},"Children":[{"ID":"20250922212739-gb1vcxs","Type":"NodeParagraph","Properties":{"id":"20250922212739-gb1vcxs","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四大技术路线"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212739-w5kho6d","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922212739-w5kho6d","updated":"20250922212739"},"Children":[{"ID":"20250922212738-mjf5kil","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922212738-mjf5kil","updated":"20250922212738"},"Children":[{"ID":"20250922212739-djzy7ro","Type":"NodeParagraph","Properties":{"id":"20250922212739-djzy7ro","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于梯度 (Gradient-based)"},{"Type":"NodeText","Data":": 试图用梯度信号来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“指导”"},{"Type":"NodeText","Data":"在离散空间中的搜索，但计算成本高。"}]}]},{"ID":"20250922212738-55po6ly","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922212738-55po6ly","updated":"20250922212738"},"Children":[{"ID":"20250922212739-qp89h4x","Type":"NodeParagraph","Properties":{"id":"20250922212739-qp89h4x","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于强化学习 (RL-based)"},{"Type":"NodeText","Data":": 将提示生成视为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略"},{"Type":"NodeText","Data":"，用任务性能作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奖励"},{"Type":"NodeText","Data":"来优化这个策略。更灵活，但同样面临RL的训练难题。"}]}]},{"ID":"20250922212738-2zmdbld","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922212738-2zmdbld","updated":"20250922212738"},"Children":[{"ID":"20250922212739-2mvta2k","Type":"NodeParagraph","Properties":{"id":"20250922212739-2mvta2k","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于编辑 (Edit-based)"},{"Type":"NodeText","Data":": 从一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“还不错”"},{"Type":"NodeText","Data":"的初始提示开始，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“编辑”"},{"Type":"NodeText","Data":"（如增删改）操作进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"局部优化"},{"Type":"NodeText","Data":"。简单高效，但容易陷入局部最优。"}]}]},{"ID":"20250922212738-90drytj","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922212738-90drytj","updated":"20250922212738"},"Children":[{"ID":"20250922212739-j19f0kg","Type":"NodeParagraph","Properties":{"id":"20250922212739-j19f0kg","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于LLM (LLM-based)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“用魔法打败魔法”"},{"Type":"NodeText","Data":"。直接让一个强大的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM"},{"Type":"NodeText","Data":"来扮演"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“提示工程师”"},{"Type":"NodeText","Data":"的角色，负责生成、评估和迭代提示。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最前沿、最强大"},{"Type":"NodeText","Data":"的方向。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPO"},{"Type":"NodeText","Data":"等工作试图将机器学习的优化理论（如梯度下降）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类比"},{"Type":"NodeText","Data":"到这个过程中，为其提供理论指导。"}]}]}]}]}]}]},{"ID":"20250922212738-bw54fnv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-bw54fnv","updated":"20250922212738"},"Children":[{"ID":"20250922212739-wgaiar2","Type":"NodeParagraph","Properties":{"id":"20250922212739-wgaiar2","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连续提示优化 (Continuous Prompt Optimization)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212739-mrqd90g","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212739-mrqd90g","updated":"20250922212739"},"Children":[{"ID":"20250922212738-4dtow6f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-4dtow6f","updated":"20250922212738"},"Children":[{"ID":"20250922212739-yzvod3o","Type":"NodeParagraph","Properties":{"id":"20250922212739-yzvod3o","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"放弃离散的词元"},{"Type":"NodeText","Data":"，直接在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连续的嵌入空间"},{"Type":"NodeText","Data":"中优化一段"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“软提示（soft prompt）”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212738-gd2ku0f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-gd2ku0f","updated":"20250922212738"},"Children":[{"ID":"20250922212739-m1zk8so","Type":"NodeParagraph","Properties":{"id":"20250922212739-m1zk8so","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优势"},{"Type":"NodeText","Data":": 可以直接用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"梯度下降"},{"Type":"NodeText","Data":"进行端到端的优化，更高效。"}]}]},{"ID":"20250922212738-g96gihb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-g96gihb","updated":"20250922212738"},"Children":[{"ID":"20250922212739-cmjtq88","Type":"NodeParagraph","Properties":{"id":"20250922212739-cmjtq88","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"挑战"},{"Type":"NodeText","Data":": 在LLM时代，由于全参数微调成本极高，这类需要微调的方法关注度相对下降，但在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效微调（PEFT）"},{"Type":"NodeText","Data":"的背景下，它仍然是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Prefix/Prompt Tuning"},{"Type":"NodeText","Data":"等技术的核心。"}]}]},{"ID":"20250922212738-a5qkzxi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-a5qkzxi","updated":"20250922212738"},"Children":[{"ID":"20250922212739-ke5txtl","Type":"NodeParagraph","Properties":{"id":"20250922212739-ke5txtl","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两个场景"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212739-po3xr5k","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922212739-po3xr5k","updated":"20250922212739"},"Children":[{"ID":"20250922212738-i7b0poq","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922212738-i7b0poq","updated":"20250922212738"},"Children":[{"ID":"20250922212739-21neemn","Type":"NodeParagraph","Properties":{"id":"20250922212739-21neemn","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据充足"},{"Type":"NodeText","Data":": 直接在下游任务上进行监督学习。"}]}]},{"ID":"20250922212738-awk50tl","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922212738-awk50tl","updated":"20250922212738"},"Children":[{"ID":"20250922212739-cawec8i","Type":"NodeParagraph","Properties":{"id":"20250922212739-cawec8i","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据稀缺"},{"Type":"NodeText","Data":": 通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"迁移学习"},{"Type":"NodeText","Data":"，将从数据丰富的任务上学到的“好提示”迁移到新任务上。"}]}]}]}]}]}]}]},{"ID":"20250922212739-c7ufbqt","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922212739-c7ufbqt","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（ICL）：LLM的“超能力”"}]},{"ID":"20250922212739-7qx5i9n","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212739-7qx5i9n","updated":"20250922212739"},"Children":[{"ID":"20250922212738-mwwqple","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-mwwqple","updated":"20250922212738"},"Children":[{"ID":"20250922212739-g7dhr99","Type":"NodeParagraph","Properties":{"id":"20250922212739-g7dhr99","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定义"},{"Type":"NodeText","Data":": ICL是LLM最"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"神奇、最核心"},{"Type":"NodeText","Data":"的能力之一。它是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特殊的提示形式"},{"Type":"NodeText","Data":"，通过在提示中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“演示”"},{"Type":"NodeText","Data":"几个任务示例，就能让LLM在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不进行任何参数更新"},{"Type":"NodeText","Data":"的情况下，学会并完成一个新任务。"}]}]},{"ID":"20250922212738-ez2v7ge","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-ez2v7ge","updated":"20250922212738"},"Children":[{"ID":"20250922212739-yh3jekj","Type":"NodeParagraph","Properties":{"id":"20250922212739-yh3jekj","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与微调的区别"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212739-elevj2i","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212739-elevj2i","updated":"20250922212739"},"Children":[{"ID":"20250922212738-pu6xocr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-pu6xocr","updated":"20250922212738"},"Children":[{"ID":"20250922212739-25hnxo7","Type":"NodeParagraph","Properties":{"id":"20250922212739-25hnxo7","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调 (Fine-tuning)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改变模型"},{"Type":"NodeText","Data":"。通过训练更新模型的权重。"}]}]},{"ID":"20250922212738-ouu6ad0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-ouu6ad0","updated":"20250922212738"},"Children":[{"ID":"20250922212739-f3uud60","Type":"NodeParagraph","Properties":{"id":"20250922212739-f3uud60","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改变输入"},{"Type":"NodeText","Data":"。只在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理时"},{"Type":"NodeText","Data":"通过提示提供示例，模型本身保持不变。"}]}]}]}]},{"ID":"20250922212738-wu83rlx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-wu83rlx","updated":"20250922212738"},"Children":[{"ID":"20250922212739-0hlztw6","Type":"NodeParagraph","Properties":{"id":"20250922212739-0hlztw6","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"公式化"},{"Type":"NodeText","Data":": ICL的过程可以被形式化为一个函数调用，输入是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述、演示示例和新的查询"},{"Type":"NodeText","Data":"，输出是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"答案"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922212739-bnkli1m","Type":"NodeThematicBreak","Properties":{"id":"20250922212739-bnkli1m","updated":"20250922212755"}},{"ID":"20250922212739-v8wdmyb","Type":"NodeBlockquote","Properties":{"id":"20250922212739-v8wdmyb","updated":"20250922212912"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922212739-sxxiobk","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922212739-sxxiobk","updated":"20250922212912"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922212739-exqtrcw","Type":"NodeParagraph","Properties":{"id":"20250922212739-exqtrcw","updated":"20250922212739"},"Children":[{"Type":"NodeText","Data":"第三十九部分是关于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型利用（Utilization）"},{"Type":"NodeText","Data":"方法论的深化，它从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“手动”的提示工程"},{"Type":"NodeText","Data":"，全面过渡到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自动”的提示优化"},{"Type":"NodeText","Data":"，并正式引入了LLM最核心的利用方式之一——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（ICL）"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922212739-jid6z8m","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922212739-jid6z8m","updated":"20250922212739"},"Children":[{"ID":"20250922212738-njcabol","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922212738-njcabol","updated":"20250922212738"},"Children":[{"ID":"20250922212739-b4tqfot","Type":"NodeParagraph","Properties":{"id":"20250922212739-b4tqfot","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示优化的“军备竞赛”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212739-kobemdj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212739-kobemdj","updated":"20250922212739"},"Children":[{"ID":"20250922212738-ae04sra","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-ae04sra","updated":"20250922212738"},"Children":[{"ID":"20250922212739-0symlmg","Type":"NodeParagraph","Properties":{"id":"20250922212739-0symlmg","updated":"20250922212739"},"Children":[{"Type":"NodeText","Data":"本部分系统地展示了自动化提示优化领域的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“百家争鸣”"},{"Type":"NodeText","Data":"。从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于梯度/RL的数学优化"},{"Type":"NodeText","Data":"，到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于编辑的启发式搜索"},{"Type":"NodeText","Data":"，再到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于LLM的“元优化”"},{"Type":"NodeText","Data":"，各种技术路线都在试图解决"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何自动找到最佳提示”"},{"Type":"NodeText","Data":"这一核心问题。"}]}]},{"ID":"20250922212738-qe05lve","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-qe05lve","updated":"20250922212738"},"Children":[{"ID":"20250922212739-6zh5k21","Type":"NodeParagraph","Properties":{"id":"20250922212739-6zh5k21","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于LLM的提示优化"},{"Type":"NodeText","Data":"无疑是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最前沿、最激动人心"},{"Type":"NodeText","Data":"的方向。它开启了一种全新的范式："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"让AI自己来优化如何与AI沟通"},{"Type":"NodeText","Data":"。这不仅是技术的进步，更是人机交互理念的一次深刻变革。"}]}]}]}]},{"ID":"20250922212738-4iba2zj","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922212738-4iba2zj","updated":"20250922212738"},"Children":[{"ID":"20250922212739-9jrm0qm","Type":"NodeParagraph","Properties":{"id":"20250922212739-9jrm0qm","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“离散”与“连续”的二元对立"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212739-rj8po6t","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212739-rj8po6t","updated":"20250922212739"},"Children":[{"ID":"20250922212738-iczjb9d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-iczjb9d","updated":"20250922212738"},"Children":[{"ID":"20250922212739-cdazpyk","Type":"NodeParagraph","Properties":{"id":"20250922212739-cdazpyk","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"离散提示"},{"Type":"NodeText","Data":"（自然语言词元）的优点是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可解释、灵活"},{"Type":"NodeText","Data":"，但优化极其困难（组合爆炸）。"}]}]},{"ID":"20250922212738-dyge2jq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-dyge2jq","updated":"20250922212738"},"Children":[{"ID":"20250922212739-y4xtwya","Type":"NodeParagraph","Properties":{"id":"20250922212739-y4xtwya","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连续提示"},{"Type":"NodeText","Data":"（向量嵌入）的优点是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可微分、易于优化"},{"Type":"NodeText","Data":"，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺乏可解释性"},{"Type":"NodeText","Data":"，更像是一种模型的内部技巧。"}]}]},{"ID":"20250922212738-ybmzucr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-ybmzucr","updated":"20250922212738"},"Children":[{"ID":"20250922212739-97rotim","Type":"NodeParagraph","Properties":{"id":"20250922212739-97rotim","updated":"20250922212739"},"Children":[{"Type":"NodeText","Data":"这两条路线分别代表了提示优化的两种不同哲学，并且在PEFT等领域相互交融。"}]}]}]}]},{"ID":"20250922212738-q0pzvi4","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922212738-q0pzvi4","updated":"20250922212738"},"Children":[{"ID":"20250922212739-5oy93pk","Type":"NodeParagraph","Properties":{"id":"20250922212739-5oy93pk","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL的正式登场"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212739-ekecu0x","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212739-ekecu0x","updated":"20250922212739"},"Children":[{"ID":"20250922212738-2p4cmak","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-2p4cmak","updated":"20250922212738"},"Children":[{"ID":"20250922212739-h1w9seu","Type":"NodeParagraph","Properties":{"id":"20250922212739-h1w9seu","updated":"20250922212739"},"Children":[{"Type":"NodeText","Data":"ICL被作为一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“特殊的、结构化的”"},{"Type":"NodeText","Data":"提示形式被引入。它的提出，标志着对LLM利用方式的理解进入了一个新阶段。"}]}]},{"ID":"20250922212738-a8bx1nz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212738-a8bx1nz","updated":"20250922212738"},"Children":[{"ID":"20250922212739-71qg0gh","Type":"NodeParagraph","Properties":{"id":"20250922212739-71qg0gh","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL的革命性"},{"Type":"NodeText","Data":"在于，它证明了LLM可以在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理时（inference-time）"},{"Type":"NodeText","Data":"进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"快速、零成本"},{"Type":"NodeText","Data":"的任务学习，这在根本上挑战了传统的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“训练-微调”"},{"Type":"NodeText","Data":"范式。"}]}]}]}]}]},{"ID":"20250922212739-dx1vder","Type":"NodeParagraph","Properties":{"id":"20250922212739-dx1vder","updated":"20250922212739"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第三十九部分的核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自动化”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“在情境中学习”"},{"Type":"NodeText","Data":"。它首先为我们展示了学术界和工业界为了将提示工程从“手艺”变为“科学”所做的巨大努力，系统地梳理了提示优化的各种技术路径。然后，通过正式引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL"},{"Type":"NodeText","Data":"，它为我们揭示了LLM一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最独特、最强大"},{"Type":"NodeText","Data":"的利用方式，为后续深入探讨ICL的机制和设计奠定了基础。这标志着我们对LLM的利用，正在从简单的“问答”，走向更复杂的“现场教学”。"}]}]},{"ID":"20250922212944-1d76zer","Type":"NodeParagraph","Properties":{"id":"20250922212944-1d76zer","updated":"20250922212944"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922212944-idtcop9","Type":"NodeThematicBreak","Properties":{"id":"20250922212944-idtcop9","updated":"20250922212944"}},{"ID":"20250922212944-f8rqwi3","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922212944-f8rqwi3","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第四十部分"}]},{"ID":"20250922212944-r18wghf","Type":"NodeParagraph","Properties":{"id":"20250922212944-r18wghf","updated":"20250922213028"},"Children":[{"Type":"NodeText","Data":"最后，测试实例作为演示的附加输入，供LLM生成输出。基于任务演示，LLM可以在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"没有明确梯度更新"},{"Type":"NodeText","Data":"的情况下识别和执行新任务。"}]},{"ID":"20250922212944-aksvhvy","Type":"NodeParagraph","Properties":{"id":"20250922212944-aksvhvy","updated":"20250922213028"},"Children":[{"Type":"NodeText","Data":"形式上，让D"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"k"},{"Type":"NodeText","Data":" = {"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"f"},{"Type":"NodeText","Data":"("},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"x"},{"Type":"NodeText","Data":"₁, "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"y"},{"Type":"NodeText","Data":"₁), . . . , "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"f"},{"Type":"NodeText","Data":"("},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"x"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"k"},{"Type":"NodeText","Data":", "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"y"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"k"},{"Type":"NodeText","Data":")}表示一个包含k个示例的演示集，其中"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"f"},{"Type":"NodeText","Data":"("},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"x"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"k"},{"Type":"NodeText","Data":", "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"y"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"k"},{"Type":"NodeText","Data":")是将第k个任务示例转换为自然语言提示的提示函数。给定任务描述I、演示D"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"k"},{"Type":"NodeText","Data":"和一个新的输入查询"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"x"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"k+1"},{"Type":"NodeText","Data":"，由LLM生成的输出"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"ŷ"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"k+1"},{"Type":"NodeText","Data":"的预测可以形式化如下："}]},{"ID":"20250922212944-cxaxmij","Type":"NodeParagraph","Properties":{"id":"20250922212944-cxaxmij","updated":"20250922213028"},"Children":[{"Type":"NodeText","Data":"LLM(\n  "},{"Type":"NodeTextMark","TextMarkType":"u","TextMarkTextContent":"I, *f*(*x*₁, *y*₁), . . . , *f*(*x*k, *y*k)"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"demonstrations"},{"Type":"NodeText","Data":",\n  "},{"Type":"NodeTextMark","TextMarkType":"u","TextMarkTextContent":"*f*(*x*k+1,"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"input"},{"Type":"NodeText","Data":"\n  "},{"Type":"NodeTextMark","TextMarkType":"u","TextMarkTextContent":")"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"answer"},{"Type":"NodeText","Data":"\n) → "},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"ŷ"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"k+1"},{"Type":"NodeText","Data":".\n(11)"}]},{"ID":"20250922212944-sqcwjqi","Type":"NodeParagraph","Properties":{"id":"20250922212944-sqcwjqi","updated":"20250922213028"},"Children":[{"Type":"NodeText","Data":"其中实际答案"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"y"},{"Type":"NodeTextMark","TextMarkType":"sub","TextMarkTextContent":"k+1"},{"Type":"NodeText","Data":"留空待LLM预测。由于ICL的性能在很大程度上依赖于演示，因此在提示中正确地设计它们非常重要。根据方程(11)的构建过程，我们关注格式化提示中演示的三个主要方面，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何选择构成演示的示例、如何用函数"},{"Type":"NodeTextMark","TextMarkType":"strong em","TextMarkTextContent":"f"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(·)将每个示例格式化到提示中，以及如何以合理的顺序排列演示"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922212944-h7sdm7a","Type":"NodeParagraph","Properties":{"id":"20250922212944-h7sdm7a","updated":"20250922213028"},"Children":[{"Type":"NodeText","Data":"在综述论文中已经对ICL进行了全面的回顾，我们建议读者参考它以获得关于该主题的更通用、详细的讨论。与该综述相比，我们特别关注将ICL应用于LLM的两个主要方面，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示设计"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL的底层机制"},{"Type":"NodeText","Data":"。此外，ICL与指令微调（在5.1节中讨论）有密切的联系，因为两者都利用自然语言来格式化任务或实例。然而，指令微调需要对LLM进行微调以进行适配，而ICL仅提示LLM进行利用。此外，指令微调可以增强LLM执行目标任务的ICL能力，特别是在零样本设置中（仅使用任务描述）。"}]},{"ID":"20250922212944-tm8wsih","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922212944-tm8wsih","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.2.2 Demonstration Design (演示设计)"}]},{"ID":"20250922212944-3gkuat2","Type":"NodeParagraph","Properties":{"id":"20250922212944-3gkuat2","updated":"20250922213028"},"Children":[{"Type":"NodeText","Data":"一些研究表明，ICL的有效性在很大程度上受到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示设计"},{"Type":"NodeText","Data":"的影响。遵循6.2.1节的讨论，我们将从三个主要方面介绍ICL的演示设计，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示选择、格式和顺序"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922212944-noi7gxy","Type":"NodeParagraph","Properties":{"id":"20250922212944-noi7gxy","updated":"20250922213028"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Demonstration Selection (演示选择)."},{"Type":"NodeText","Data":" ICL的性能往往会随着不同的演示示例而有很大的变化，因此选择一个能够有效利用LLM的ICL能力的示例"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"子集"},{"Type":"NodeText","Data":"非常重要。主要有两种演示选择方法，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"启发式方法"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于LLM的方法"},{"Type":"NodeText","Data":"："}]},{"ID":"20250922212944-jwfzpzf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-jwfzpzf","updated":"20250922213028"},"Children":[{"ID":"20250922212943-egqjwkz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-egqjwkz","updated":"20250922212943"},"Children":[{"ID":"20250922212944-4cx030t","Type":"NodeParagraph","Properties":{"id":"20250922212944-4cx030t","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"启发式方法 (Heuristic approaches)."},{"Type":"NodeText","Data":" 由于其简单性和低成本，现有工作广泛采用启发式方法来选择演示。一些研究采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"k-NN"},{"Type":"NodeText","Data":"（k近邻）为基础的检索器来选择与查询"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语义相关"},{"Type":"NodeText","Data":"的示例。然而，它们是为每个示例单独进行选择，而不是将示例集作为一个整体来评估。为了解决这个问题，提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于多样性"},{"Type":"NodeText","Data":"的选择策略，为特定任务选择最具代表性的示例集。此外，在中，在选择演示时同时考虑了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相关性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212943-ocsc42x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-ocsc42x","updated":"20250922212943"},"Children":[{"ID":"20250922212944-y771fsi","Type":"NodeParagraph","Properties":{"id":"20250922212944-y771fsi","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于LLM的方法 (LLM-based approaches)."},{"Type":"NodeText","Data":" 另一条研究路线利用LLM来选择演示。例如，LLM可以用来直接衡量每个示例在添加该示例后"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"性能增益"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"信息量"},{"Type":"NodeText","Data":"。此外，EPR提出了一种两阶段检索方法，首先用一个无监督方法（例如，BM25）召回相似的示例，然后用一个密集检索器（用LLM标记的正负样本进行训练）对它们进行排序。作为一种替代方法，演示选择的任务可以被形式化为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RL问题"},{"Type":"NodeText","Data":"，其中LLM充当奖励函数，为训练策略模型提供反馈。由于LLM在文本标注方面表现良好，一些最近的研究直接使用LLM本身作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示生成器"},{"Type":"NodeText","Data":"，而无需人类干预。"}]}]}]},{"ID":"20250922212944-4niwimd","Type":"NodeParagraph","Properties":{"id":"20250922212944-4niwimd","updated":"20250922213028"},"Children":[{"Type":"NodeText","Data":"总而言之，如中所讨论的，ICL中选择的演示示例应包含"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"足够的关于待解决任务的信息"},{"Type":"NodeText","Data":"，并且与测试查询"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相关"},{"Type":"NodeText","Data":"，对于上述两种选择方法都是如此。"}]},{"ID":"20250922212944-zxeb2as","Type":"NodeParagraph","Properties":{"id":"20250922212944-zxeb2as","updated":"20250922213028"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Demonstration Format (演示格式)."},{"Type":"NodeText","Data":" 在选择任务示例之后，下一步是将它们整合并格式化为一个自然语言提示供LLM使用。一个直接的方法是用相应的输入-输出对来实例化一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预定义的模板"},{"Type":"NodeText","Data":"。为了构建信息更丰富的模板，最近的研究考虑添加"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述"},{"Type":"NodeText","Data":"或用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链提示"},{"Type":"NodeText","Data":"增强LLM的推理能力。例如，在中，作者收集了一个由人类编写的大规模任务描述数据集。用这个数据集进行微调后，在已见任务上的性能可以得到提升，并且LLM在某种程度上也可以泛化到未见任务。为了降低标注成本，一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"半自动化"},{"Type":"NodeText","Data":"的方法被提出来，通过使用一个由人类编写的任务描述组成的种子集来引导LLM为新任务生成任务描述。由于为不同任务手动标注演示格式成本高昂，一些工作也研究了如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动生成高质量的格式"},{"Type":"NodeText","Data":"。作为两种代表性方法，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Auto-CoT"},{"Type":"NodeText","Data":"利用带有零样本提示“让我们一步步思考”的LLM来生成中间推理步骤，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"least-to-most prompting"},{"Type":"NodeText","Data":"首先查询LLM执行问题分解，然后利用LLM基于先前已解决的子问题的中间答案来顺序解决子问题。"}]},{"ID":"20250922212944-33n6f9u","Type":"NodeParagraph","Properties":{"id":"20250922212944-33n6f9u","updated":"20250922213028"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Demonstration Order (演示顺序)."},{"Type":"NodeText","Data":" LLM被证明有时会遭受"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"近因偏差（recency bias）"},{"Type":"NodeText","Data":"，即它们倾向于重复靠近演示末尾的答案。因此，以合理的顺序排列演示（即任务示例）非常重要。早期的工作提出了几种启发式方法来快速找到一个好的顺序。例如，演示可以根据它们与"}]},{"ID":"20250922212944-wze59tx","Type":"NodeParagraph","Properties":{"id":"20250922212944-wze59tx","updated":"20250922213028"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915174823-u1yq7s1.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922212944-hbagfhx","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922212944-hbagfhx","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 14：上下文学习（ICL）和思维链（CoT）提示的比较示意图。"}]},{"ID":"20250922212944-r3mx96t","Type":"NodeParagraph","Properties":{"id":"20250922212944-r3mx96t","updated":"20250922213028"},"Children":[{"Type":"NodeText","Data":"ICL用自然语言描述、几个演示和一个测试查询来提示LLM，而CoT提示则在提示中引入了一系列中间推理步骤。"}]},{"ID":"20250922212944-zdycbw4","Type":"NodeBlockquote","Properties":{"id":"20250922212944-zdycbw4","updated":"20250922213028"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922212944-jcuqr1g","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922212944-jcuqr1g","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922212944-h76u9xq","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922212944-h76u9xq","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图14解析：ICL vs. CoT —— “授人以鱼”与“授人以渔”"}]},{"ID":"20250922212944-failyrw","Type":"NodeParagraph","Properties":{"id":"20250922212944-failyrw","updated":"20250922212944"},"Children":[{"Type":"NodeText","Data":"这张图非常直观地对比了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（ICL）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"这两种提示方法的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心区别"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922212944-0slmx7w","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-0slmx7w","updated":"20250922212944"},"Children":[{"ID":"20250922212943-pgnj5u1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-pgnj5u1","updated":"20250922212943"},"Children":[{"ID":"20250922212944-qc1zkl0","Type":"NodeParagraph","Properties":{"id":"20250922212944-qc1zkl0","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习 (In-Context Learning, ICL)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212944-wnv0cyo","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-wnv0cyo","updated":"20250922212944"},"Children":[{"ID":"20250922212943-9twvaug","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-9twvaug","updated":"20250922212943"},"Children":[{"ID":"20250922212944-kfxinf8","Type":"NodeParagraph","Properties":{"id":"20250922212944-kfxinf8","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模式"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“输入 -\u0026gt; 输出”"},{"Type":"NodeText","Data":"的直接映射。"}]}]},{"ID":"20250922212943-g8bjfpw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-g8bjfpw","updated":"20250922212943"},"Children":[{"ID":"20250922212944-kvvc44r","Type":"NodeParagraph","Properties":{"id":"20250922212944-kvvc44r","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容"},{"Type":"NodeText","Data":": 提示中只包含"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题和最终答案"},{"Type":"NodeText","Data":"。例如，“Q: ... How many candies do you have left? A: The answer is 8.”"}]}]},{"ID":"20250922212943-em2oo6p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-em2oo6p","updated":"20250922212943"},"Children":[{"ID":"20250922212944-3jsco28","Type":"NodeParagraph","Properties":{"id":"20250922212944-3jsco28","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习方式"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"归纳学习"},{"Type":"NodeText","Data":"。模型需要自己从几个“问题-答案”对中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“悟出”"},{"Type":"NodeText","Data":"解决这类问题的方法。"}]}]},{"ID":"20250922212943-cmyy2jl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-cmyy2jl","updated":"20250922212943"},"Children":[{"ID":"20250922212944-z556c3h","Type":"NodeParagraph","Properties":{"id":"20250922212944-z556c3h","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类比"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“授人以鱼”"},{"Type":"NodeText","Data":"。直接给几个现成的答案，让模型自己学着做。"}]}]}]}]},{"ID":"20250922212943-jaxpfng","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-jaxpfng","updated":"20250922212943"},"Children":[{"ID":"20250922212944-bhfona3","Type":"NodeParagraph","Properties":{"id":"20250922212944-bhfona3","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链提示 (Chain-of-Thought Prompting, CoT)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212944-5nuym9d","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-5nuym9d","updated":"20250922212944"},"Children":[{"ID":"20250922212943-vu2mml7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-vu2mml7","updated":"20250922212943"},"Children":[{"ID":"20250922212944-pi23zec","Type":"NodeParagraph","Properties":{"id":"20250922212944-pi23zec","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模式"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“输入 -\u0026gt; 推理过程 -\u0026gt; 输出”"},{"Type":"NodeText","Data":"的完整链条。"}]}]},{"ID":"20250922212943-x3hy453","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-x3hy453","updated":"20250922212943"},"Children":[{"ID":"20250922212944-nbl0zms","Type":"NodeParagraph","Properties":{"id":"20250922212944-nbl0zms","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容"},{"Type":"NodeText","Data":": 提示中不仅包含问题和答案，还明确地展示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何从问题得到答案”的中间推理步骤"},{"Type":"NodeText","Data":"。例如，“Q: ... what is the perimeter ...? A: For a rectangle, add up the length and width and double it. So, the perimeter ... is (6 + 3) x 2 = 18 cm. The answer is 18 cm.”"}]}]},{"ID":"20250922212943-zmhuxp3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-zmhuxp3","updated":"20250922212943"},"Children":[{"ID":"20250922212944-3jasimb","Type":"NodeParagraph","Properties":{"id":"20250922212944-3jasimb","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"学习方式"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模仿学习"},{"Type":"NodeText","Data":"。模型被明确地教导了解决问题的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“思考过程”"},{"Type":"NodeText","Data":"，它只需要模仿这个过程来解决新问题。"}]}]},{"ID":"20250922212943-u2gh0gp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-u2gh0gp","updated":"20250922212943"},"Children":[{"ID":"20250922212944-y2c3rvq","Type":"NodeParagraph","Properties":{"id":"20250922212944-y2c3rvq","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类比"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“授人以渔”"},{"Type":"NodeText","Data":"。不仅给答案，还把"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解题方法和步骤"},{"Type":"NodeText","Data":"也教给模型。"}]}]}]}]},{"ID":"20250922212943-mljh4lr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-mljh4lr","updated":"20250922212943"},"Children":[{"ID":"20250922212944-9a58yr1","Type":"NodeParagraph","Properties":{"id":"20250922212944-9a58yr1","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对LLM的要求"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212944-wqexfqs","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-wqexfqs","updated":"20250922212944"},"Children":[{"ID":"20250922212943-3v4k0lx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-3v4k0lx","updated":"20250922212943"},"Children":[{"ID":"20250922212944-07tiucf","Type":"NodeParagraph","Properties":{"id":"20250922212944-07tiucf","updated":"20250922212944"},"Children":[{"Type":"NodeText","Data":"ICL要求LLM有很强的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"抽象和归纳能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212943-681ko9o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-681ko9o","updated":"20250922212943"},"Children":[{"ID":"20250922212944-ctt9up3","Type":"NodeParagraph","Properties":{"id":"20250922212944-ctt9up3","updated":"20250922212944"},"Children":[{"Type":"NodeText","Data":"CoT则将复杂的推理任务"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分解"},{"Type":"NodeText","Data":"成了更简单的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模仿推理步骤”"},{"Type":"NodeText","Data":"的任务，从而降低了对模型“顿悟”能力的要求，使其更容易解决复杂问题。"}]}]}]}]}]},{"ID":"20250922212944-iomlir6","Type":"NodeParagraph","Properties":{"id":"20250922212944-iomlir6","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张图的核心区别在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"是否显式地提供了“过程”"},{"Type":"NodeText","Data":"。ICL是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐式"},{"Type":"NodeText","Data":"的引导，而CoT是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"显式"},{"Type":"NodeText","Data":"的教学。对于需要多步推理的复杂任务，CoT通过“手把手”教学的方式，能更有效地激发LLM的潜力。"}]}]},{"ID":"20250922212944-96de4zk","Type":"NodeThematicBreak","Properties":{"id":"20250922212944-96de4zk","updated":"20250922213028"}},{"ID":"20250922212944-6b3tmd0","Type":"NodeBlockquote","Properties":{"id":"20250922212944-6b3tmd0","updated":"20250922213028"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922212944-cp7f08m","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922212944-cp7f08m","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922212944-krlyzey","Type":"NodeParagraph","Properties":{"id":"20250922212944-krlyzey","updated":"20250922212944"},"Children":[{"Type":"NodeText","Data":"第四十部分深入探讨了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（ICL）"},{"Type":"NodeText","Data":"这一LLM核心能力的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“工程学”"},{"Type":"NodeText","Data":"，系统地拆解了成功实施ICL的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大关键环节：演示选择、格式和顺序"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922212944-j7fb5nw","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922212944-j7fb5nw","updated":"20250922212944"},"Children":[{"ID":"20250922212943-dk4v8mm","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922212943-dk4v8mm","updated":"20250922212943"},"Children":[{"ID":"20250922212944-colmdru","Type":"NodeParagraph","Properties":{"id":"20250922212944-colmdru","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL的本质与地位"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212944-soav9vi","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-soav9vi","updated":"20250922212944"},"Children":[{"ID":"20250922212943-r4z5tr2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-r4z5tr2","updated":"20250922212943"},"Children":[{"ID":"20250922212944-uwupn1z","Type":"NodeParagraph","Properties":{"id":"20250922212944-uwupn1z","updated":"20250922212944"},"Children":[{"Type":"NodeText","Data":"文章首先明确了ICL的本质：一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"在推理时（inference-time）"},{"Type":"NodeText","Data":"通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示"},{"Type":"NodeText","Data":"进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零参数更新"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"快速学习"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922212943-z1w8iw1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-z1w8iw1","updated":"20250922212943"},"Children":[{"ID":"20250922212944-t2hvhi7","Type":"NodeParagraph","Properties":{"id":"20250922212944-t2hvhi7","updated":"20250922212944"},"Children":[{"Type":"NodeText","Data":"它与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调"},{"Type":"NodeText","Data":"的关系被清晰地界定：两者都使用自然语言格式化任务，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调是“训练时”的适配，改变模型本身；而ICL是“推理时”的利用，不改变模型"},{"Type":"NodeText","Data":"。指令微调可以增强ICL的能力。"}]}]}]}]},{"ID":"20250922212943-85e7ky5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922212943-85e7ky5","updated":"20250922212943"},"Children":[{"ID":"20250922212944-8u2tbkj","Type":"NodeParagraph","Properties":{"id":"20250922212944-8u2tbkj","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示设计的“三驾马车”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212944-1ujma4k","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-1ujma4k","updated":"20250922212944"},"Children":[{"ID":"20250922212943-btyz8gv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-btyz8gv","updated":"20250922212943"},"Children":[{"ID":"20250922212944-bg8n4su","Type":"NodeParagraph","Properties":{"id":"20250922212944-bg8n4su","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示选择 (Demonstration Selection)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“选对老师”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922212944-mskp1ve","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-mskp1ve","updated":"20250922212944"},"Children":[{"ID":"20250922212943-sk8v731","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-sk8v731","updated":"20250922212943"},"Children":[{"ID":"20250922212944-0cpgl3c","Type":"NodeParagraph","Properties":{"id":"20250922212944-0cpgl3c","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心矛盾"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相关性 vs. 多样性"},{"Type":"NodeText","Data":"。演示既要与当前问题相关，又要足够多样以覆盖任务的各个方面。"}]}]},{"ID":"20250922212943-068xwtb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-068xwtb","updated":"20250922212943"},"Children":[{"ID":"20250922212944-f2oxctx","Type":"NodeParagraph","Properties":{"id":"20250922212944-f2oxctx","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法演进"},{"Type":"NodeText","Data":": 从简单的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"k-NN（只看相关性）"},{"Type":"NodeText","Data":"，到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于多样性"},{"Type":"NodeText","Data":"的策略，再到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"利用LLM自身"},{"Type":"NodeText","Data":"来判断示例的“信息量”或直接生成示例。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"用LLM来优化给LLM的输入"},{"Type":"NodeText","Data":"，再次体现了“元学习”的思想。"}]}]}]}]},{"ID":"20250922212943-w66iaqg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-w66iaqg","updated":"20250922212943"},"Children":[{"ID":"20250922212944-3cq1lnw","Type":"NodeParagraph","Properties":{"id":"20250922212944-3cq1lnw","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示格式 (Demonstration Format)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“编好教材”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922212944-ts8dcb6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-ts8dcb6","updated":"20250922212944"},"Children":[{"ID":"20250922212943-9ln5s20","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-9ln5s20","updated":"20250922212943"},"Children":[{"ID":"20250922212944-r8c8qex","Type":"NodeParagraph","Properties":{"id":"20250922212944-r8c8qex","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心"},{"Type":"NodeText","Data":": 如何将“问题-答案”对包装成LLM易于理解的格式。"}]}]},{"ID":"20250922212943-um4s5zc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-um4s5zc","updated":"20250922212943"},"Children":[{"ID":"20250922212944-o02z32g","Type":"NodeParagraph","Properties":{"id":"20250922212944-o02z32g","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级格式"},{"Type":"NodeText","Data":": 简单的模板已不够，加入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务描述"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"已成为提升复杂任务性能的标配。"}]}]},{"ID":"20250922212943-d2b5pwi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-d2b5pwi","updated":"20250922212943"},"Children":[{"ID":"20250922212944-a0ylmkk","Type":"NodeParagraph","Properties":{"id":"20250922212944-a0ylmkk","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动化"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Auto-CoT"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"least-to-most prompting"},{"Type":"NodeText","Data":"等技术的出现，标志着演示格式的构建也正在走向"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动化"},{"Type":"NodeText","Data":"，减轻了人工设计的负担。"}]}]}]}]},{"ID":"20250922212943-eo38lde","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-eo38lde","updated":"20250922212943"},"Children":[{"ID":"20250922212944-2ysw7x8","Type":"NodeParagraph","Properties":{"id":"20250922212944-2ysw7x8","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"演示顺序 (Demonstration Order)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“安排好课程顺序”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922212944-8s826rp","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-8s826rp","updated":"20250922212944"},"Children":[{"ID":"20250922212943-ctf7gb0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-ctf7gb0","updated":"20250922212943"},"Children":[{"ID":"20250922212944-ckr5zv1","Type":"NodeParagraph","Properties":{"id":"20250922212944-ckr5zv1","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心问题"},{"Type":"NodeText","Data":": 解决LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“近因偏差”"},{"Type":"NodeText","Data":"，即模型过度关注最后看到的示例。"}]}]},{"ID":"20250922212943-t2om4a6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-t2om4a6","updated":"20250922212943"},"Children":[{"ID":"20250922212944-7emb0am","Type":"NodeParagraph","Properties":{"id":"20250922212944-7emb0am","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": 通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"启发式规则"},{"Type":"NodeText","Data":"（如按与查询的相似度排序）来安排演示的顺序，以获得更稳健的性能。"}]}]}]}]}]}]},{"ID":"20250922212943-9h2ud47","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922212943-9h2ud47","updated":"20250922212943"},"Children":[{"ID":"20250922212944-b5ri2bu","Type":"NodeParagraph","Properties":{"id":"20250922212944-b5ri2bu","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图14的画龙点睛"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922212944-dk6wwdr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922212944-dk6wwdr","updated":"20250922212944"},"Children":[{"ID":"20250922212943-ziyl7vf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922212943-ziyl7vf","updated":"20250922212943"},"Children":[{"ID":"20250922212944-qex6uuj","Type":"NodeParagraph","Properties":{"id":"20250922212944-qex6uuj","updated":"20250922212944"},"Children":[{"Type":"NodeText","Data":"图14通过一个直观的例子，清晰地区分了ICL和CoT。这个对比是理解现代提示工程的关键：ICL依赖模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"归纳"},{"Type":"NodeText","Data":"，而CoT则通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模仿"},{"Type":"NodeText","Data":"来简化推理。"}]}]}]}]}]},{"ID":"20250922212944-9cfh90r","Type":"NodeParagraph","Properties":{"id":"20250922212944-9cfh90r","updated":"20250922212944"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第四十部分将ICL从一个神奇的现象，解构成了一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统化、可操作的工程方法"},{"Type":"NodeText","Data":"。它告诉我们，ICL的成功并非偶然，而是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精心选择、巧妙格式化和合理排序"},{"Type":"NodeText","Data":"的演示共同作用的结果。这一部分的论述，为实践者如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大限度地利用和激发LLM的上下文学习能力"},{"Type":"NodeText","Data":"，提供了全面而深入的指导。"}]}]},{"ID":"20250922213129-ccwpptn","Type":"NodeParagraph","Properties":{"id":"20250922213129-ccwpptn","updated":"20250922213129"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922213129-qn69vjb","Type":"NodeThematicBreak","Properties":{"id":"20250922213129-qn69vjb","updated":"20250922213129"}},{"ID":"20250922213129-vge854l","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213129-vge854l","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第四十一部分"}]},{"ID":"20250922213129-t8xpf85","Type":"NodeParagraph","Properties":{"id":"20250922213129-t8xpf85","updated":"20250922213153"},"Children":[{"Type":"NodeText","Data":"查询在嵌入空间中的相似度：越相似，越靠后。此外，全局和局部熵度量可以用来为不同的演示顺序打分。为了整合更多的任务信息，一些最近的研究提出最小化压缩和传输任务标签所需的代码长度，这受到了信息论的启发。然而，这些方法需要额外的标记数据作为验证集来评估特定演示顺序的性能。为了消除这种需求，中的作者提议从LLM本身采样验证数据。"}]},{"ID":"20250922213129-ddd9b1a","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922213129-ddd9b1a","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.2.3 Underlying Mechanism (底层机制)"}]},{"ID":"20250922213129-wd7i0yl","Type":"NodeParagraph","Properties":{"id":"20250922213129-wd7i0yl","updated":"20250922213153"},"Children":[{"Type":"NodeText","Data":"预训练后，LLM可以展现出引人入胜的ICL能力而无需更新。接下来，我们将讨论关于LLM的ICL能力的两个关键问题，即“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练如何影响ICL能力"},{"Type":"NodeText","Data":"”和“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM在推理过程中如何执行ICL"},{"Type":"NodeText","Data":"”。"}]},{"ID":"20250922213129-zw3uu1r","Type":"NodeParagraph","Properties":{"id":"20250922213129-zw3uu1r","updated":"20250922213153"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"How Pre-Training Affects ICL? (预训练如何影响ICL？)"},{"Type":"NodeText","Data":" ICL首先在GPT-3中被提出，并且已经表明ICL能力随着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更大的模型规模"},{"Type":"NodeText","Data":"而变得更加显著。此外，一些研究揭示，小规模PLM也可以通过在专门设计的训练任务上进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续预训练"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调"},{"Type":"NodeText","Data":"来展示出强大的ICL能力，这些任务通常在训练过程中在输入中包含额外的任务示例。这表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练任务的设计"},{"Type":"NodeText","Data":"是影响LLM的ICL能力的一个重要因素。除了训练任务，最近的研究还调查了ICL与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练语料库"},{"Type":"NodeText","Data":"之间的关系。例如，ICL可以被理论上解释为在表现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长程连贯性"},{"Type":"NodeText","Data":"的文档上进行预训练的产物。此外，另一项研究从理论上分析，当扩展参数和数据时，基于下一个词预测的LLM可以通过学习语言数据中存在的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"组合结构"},{"Type":"NodeText","Data":"（例如，词和短语如何组合形成更大的语言单位如句子）来涌现出ICL的能力。"}]},{"ID":"20250922213129-t3yb68x","Type":"NodeParagraph","Properties":{"id":"20250922213129-t3yb68x","updated":"20250922213153"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"How LLMs Perform ICL? (LLM如何执行ICL？)"},{"Type":"NodeText","Data":" 在推理阶段，研究人员关注于分析ICL能力是如何基于给定的演示来运作的，因为没有涉及显式的学习或更新。根据中的讨论，LLM利用演示主要有两种方式："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务识别"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务学习"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922213129-ikrp3h9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213129-ikrp3h9","updated":"20250922213153"},"Children":[{"ID":"20250922213129-b51bnt0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-b51bnt0","updated":"20250922213129"},"Children":[{"ID":"20250922213129-ftle860","Type":"NodeParagraph","Properties":{"id":"20250922213129-ftle860","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务识别 (Task recognition)."},{"Type":"NodeText","Data":" 第一种方式是，LLM从演示中识别任务，并利用从预训练中获得的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"先验知识"},{"Type":"NodeText","Data":"来解决新的测试任务。一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可能近似正确（PAC）"},{"Type":"NodeText","Data":"框架被提出来评估ICL的可学习性。它假设在预训练数据中存在一个代表任务的潜在变量，并且LLM已被证明能够从演示中捕捉这个变量，从而使它们能够识别ICL中的任务。此外，将ICL解释为任务识别得到了几项实证研究的支持。例如，已经观察到，用从输入或标签空间中采样的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"随机"},{"Type":"NodeText","Data":"输入或标签替换演示的输入或标签，并"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不会严重损害"},{"Type":"NodeText","Data":"LLM的性能，这表明LLM主要是从演示中识别目标任务，而不是从中学习。类似地，即使提示模板不相关或具有误导性，LLM也可以表现出不错的性能。"}]}]},{"ID":"20250922213129-i31e5pk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-i31e5pk","updated":"20250922213129"},"Children":[{"ID":"20250922213129-c8b5439","Type":"NodeParagraph","Properties":{"id":"20250922213129-c8b5439","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务学习 (Task learning).-"},{"Type":"NodeText","Data":" 第二种方式是，LLM仅通过演示学习在预训练阶段"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"未见过"},{"Type":"NodeText","Data":"的新任务。特别是，任务学习主要从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"梯度下降"},{"Type":"NodeText","Data":"的角度进行分析，并被视为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐式微调"},{"Type":"NodeText","Data":"。然后，ICL可以解释如下：通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前向计算"},{"Type":"NodeText","Data":"，LLM为其演示生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"元梯度"},{"Type":"NodeText","Data":"，并通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"注意力机制"},{"Type":"NodeText","Data":"隐式地执行梯度下降。实验也表明，LLM中的某些注意力头能够执行任务无关的原子操作（例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复制和前缀匹配"},{"Type":"NodeText","Data":"），这与ICL能力密切相关。此外，一些研究将ICL抽象为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算法学习过程"},{"Type":"NodeText","Data":"。例如，中的作者发现LLM本质上通过其参数在预训练期间编码了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐式模型"},{"Type":"NodeText","Data":"。通过在ICL中提供的示例，LLM可以实现梯度下降等学习算法，或直接计算闭式解来在前向计算期间更新这些模型。在这个解释框架下，已有研究表明LLM可以有效地学习简单的线性函数，甚至一些复杂的函数，如ICL中的决策树。"}]}]}]},{"ID":"20250922213129-g6g6kfv","Type":"NodeParagraph","Properties":{"id":"20250922213129-g6g6kfv","updated":"20250922213153"},"Children":[{"Type":"NodeText","Data":"正如在最近的一项研究中所讨论的，LLM在ICL中展现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务识别"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务学习"},{"Type":"NodeText","Data":"两种能力，但这两种能力似乎在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同的模型规模"},{"Type":"NodeText","Data":"下具备。正如实验所示，任务识别的能力更容易获得，即使是只有350M参数的小型LM也能展现这种能力，而任务学习只能在至少有66B参数的LLM中涌现。另一项研究也通过专门设计的实验支持了这一发现。他们在实验中设置了带有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"翻转标签"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语义无关标签"},{"Type":"NodeText","Data":"的任务，这些任务在执行ICL时需要任务学习。结果表明，小型LM倾向于忽略标签，主要依赖其先验知识来完成任务，而LLM有能力超越其先验知识，并从演示中获取新知识，从而取得更好的结果。此外，为了提升任务学习能力，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Meta-In-Context Learning"},{"Type":"NodeText","Data":"提议在提示中包含多个相关任务，而不仅仅是一个任务。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Symbol Tuning"},{"Type":"NodeText","Data":"在带有语义无关标签（例如，用foo/bar代替情感分析中的正面/负面）的演示上对LLM进行微调，迫使LLM从演示中学习任务，而不是依赖先验知识。"}]},{"ID":"20250922213129-rvq9fw2","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213129-rvq9fw2","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.3 Chain-of-Thought Prompting (思维链提示)"}]},{"ID":"20250922213129-lc2x929","Type":"NodeParagraph","Properties":{"id":"20250922213129-lc2x929","updated":"20250922213153"},"Children":[{"Type":"NodeText","Data":"思维链（CoT）提示是一种改进的提示策略，旨在提升LLM在复杂推理任务上的性能，例如算术推理、常识推理和符号推理。与ICL那样简单地用输入-输出对构建提示不同，CoT提示进一步并入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"中间推理步骤"},{"Type":"NodeText","Data":"，这些步骤充当了输入和输出之间的桥梁。图14展示了CoT的示意图。在接下来的部分中，我们首先将阐述基本的CoT提示方法及其改进策略，然后讨论CoT提示在何时以及为何有效。"}]},{"ID":"20250922213129-f1fh8rt","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922213129-f1fh8rt","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.3.1 Basic CoT Prompting Approach (基本CoT提示方法)"}]},{"ID":"20250922213129-bdu3rja","Type":"NodeParagraph","Properties":{"id":"20250922213129-bdu3rja","updated":"20250922213153"},"Children":[{"Type":"NodeText","Data":"CoT提示首先被提议作为ICL的扩展，它将每个演示⟨input, output⟩扩充为⟨input, CoT, output⟩。CoT是一系列连接输入和输出的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"中间推理步骤"},{"Type":"NodeText","Data":"。通过这些增强的演示，LLM可以遵循它们为新的输入生成CoT和答案。然而，与ICL中的⟨input, output⟩对不同，CoT很难获得，通常需要人类标注。幸运的是，研究发现，可以通过像“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"让我们一步步思考"},{"Type":"NodeText","Data":"”这样的简单指令来触发LLM生成CoT，使得CoT提示易于使用。还有一些替代的“魔法提示”，可以激发CoT推理的能力并进一步提升LLM的性能，例如，“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深呼吸，然后一步步解决这个问题"},{"Type":"NodeText","Data":"”。"}]},{"ID":"20250922213129-m9qnqqf","Type":"NodeBlockquote","Properties":{"id":"20250922213129-m9qnqqf","updated":"20250922213153"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922213129-3994ubq","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213129-3994ubq","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922213129-7yt4rd1","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213129-7yt4rd1","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL能力的来源：预训练的“遗产”"}]},{"ID":"20250922213129-3642awf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213129-3642awf","updated":"20250922213129"},"Children":[{"ID":"20250922213129-vxmi4cl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-vxmi4cl","updated":"20250922213129"},"Children":[{"ID":"20250922213129-2frseqb","Type":"NodeParagraph","Properties":{"id":"20250922213129-2frseqb","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模是前提"},{"Type":"NodeText","Data":": ICL能力是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现"},{"Type":"NodeText","Data":"的，只有当模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"足够大"},{"Type":"NodeText","Data":"时才会显现。"}]}]},{"ID":"20250922213129-344i859","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-344i859","updated":"20250922213129"},"Children":[{"ID":"20250922213129-ptkjcmk","Type":"NodeParagraph","Properties":{"id":"20250922213129-ptkjcmk","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据是土壤"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213129-de90cus","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213129-de90cus","updated":"20250922213129"},"Children":[{"ID":"20250922213129-fzozrue","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-fzozrue","updated":"20250922213129"},"Children":[{"ID":"20250922213129-3q9lnvb","Type":"NodeParagraph","Properties":{"id":"20250922213129-3q9lnvb","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长程连贯性"},{"Type":"NodeText","Data":": 预训练语料库中包含大量具有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长距离依赖和逻辑连贯性"},{"Type":"NodeText","Data":"的文本（如文章、书籍），这可能是模型学会“联系上下文”的基础。"}]}]},{"ID":"20250922213129-0y8gfrf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-0y8gfrf","updated":"20250922213129"},"Children":[{"ID":"20250922213129-alkq7db","Type":"NodeParagraph","Properties":{"id":"20250922213129-alkq7db","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"组合结构"},{"Type":"NodeText","Data":": 模型在预测下一个词的过程中，被迫学习了语言的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"组合规则"},{"Type":"NodeText","Data":"（词如何组成句子，句子如何组成段落）。ICL可以看作是模型在推理时"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用这些学到的组合规则"},{"Type":"NodeText","Data":"来构建新任务的表示。"}]}]}]}]}]},{"ID":"20250922213129-evjr5p3","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213129-evjr5p3","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL的工作机制：“识别”还是“学习”？"}]},{"ID":"20250922213129-5pba617","Type":"NodeParagraph","Properties":{"id":"20250922213129-5pba617","updated":"20250922213129"},"Children":[{"Type":"NodeText","Data":"这是关于ICL核心机制的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大派理论"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922213129-wzzqytq","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213129-wzzqytq","updated":"20250922213129"},"Children":[{"ID":"20250922213129-hcmbwzd","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213129-hcmbwzd","updated":"20250922213129"},"Children":[{"ID":"20250922213129-kxxnop3","Type":"NodeParagraph","Properties":{"id":"20250922213129-kxxnop3","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务识别 (Task Recognition) - “博学的联想家”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213129-50qkk1i","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213129-50qkk1i","updated":"20250922213129"},"Children":[{"ID":"20250922213129-a21vrhq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-a21vrhq","updated":"20250922213129"},"Children":[{"ID":"20250922213129-virl21t","Type":"NodeParagraph","Properties":{"id":"20250922213129-virl21t","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并没有真正学习新任务"},{"Type":"NodeText","Data":"，它只是从演示中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“识别”"},{"Type":"NodeText","Data":"出这“看起来像”它在预训练中见过的某个任务（例如，情感分类），然后"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"激活并应用"},{"Type":"NodeText","Data":"它早已内化的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"先验知识"},{"Type":"NodeText","Data":"来解决问题。"}]}]},{"ID":"20250922213129-nqlscni","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-nqlscni","updated":"20250922213129"},"Children":[{"ID":"20250922213129-24somk1","Type":"NodeParagraph","Properties":{"id":"20250922213129-24somk1","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"证据"},{"Type":"NodeText","Data":": 即使演示中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标签是随机的"},{"Type":"NodeText","Data":"，LLM的性能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"下降得也不多"},{"Type":"NodeText","Data":"。这说明模型并没有真的“学习”标签的含义，而只是把演示当作一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“任务触发器”"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922213129-6k00q41","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213129-6k00q41","updated":"20250922213129"},"Children":[{"ID":"20250922213129-kzen9n0","Type":"NodeParagraph","Properties":{"id":"20250922213129-kzen9n0","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务学习 (Task Learning) - “聪明的梯度下降器”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213129-krdwciu","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213129-krdwciu","updated":"20250922213129"},"Children":[{"ID":"20250922213129-54v3vdl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-54v3vdl","updated":"20250922213129"},"Children":[{"ID":"20250922213129-yz4d4dk","Type":"NodeParagraph","Properties":{"id":"20250922213129-yz4d4dk","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": LLM在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前向传播"},{"Type":"NodeText","Data":"的过程中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐式地"},{"Type":"NodeText","Data":"进行了一次"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“微调”"},{"Type":"NodeText","Data":"。注意力机制扮演了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“梯度计算器”"},{"Type":"NodeText","Data":"的角色，通过处理演示，它为模型内部的“隐式模型”计算了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“元梯度”"},{"Type":"NodeText","Data":"，并在预测新样本时应用了这个“更新”。"}]}]},{"ID":"20250922213129-rrz53uy","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-rrz53uy","updated":"20250922213129"},"Children":[{"ID":"20250922213129-qeb7ava","Type":"NodeParagraph","Properties":{"id":"20250922213129-qeb7ava","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"证据"},{"Type":"NodeText","Data":": LLM能够学习在预训练中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从未见过"},{"Type":"NodeText","Data":"的、甚至是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与先验知识相悖"},{"Type":"NodeText","Data":"（如翻转标签）的任务，这无法用“任务识别”来解释。"}]}]}]}]}]},{"ID":"20250922213129-3ps4t61","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213129-3ps4t61","updated":"20250922213129"},"Children":[{"ID":"20250922213129-6g91x1a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-6g91x1a","updated":"20250922213129"},"Children":[{"ID":"20250922213129-l3pf23j","Type":"NodeParagraph","Properties":{"id":"20250922213129-l3pf23j","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一理论：规模决定模式"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213129-6d4asr6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213129-6d4asr6","updated":"20250922213129"},"Children":[{"ID":"20250922213129-dep436e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-dep436e","updated":"20250922213129"},"Children":[{"ID":"20250922213129-93ojrsm","Type":"NodeParagraph","Properties":{"id":"20250922213129-93ojrsm","updated":"20250922213129"},"Children":[{"Type":"NodeText","Data":"最新的研究倾向于一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一的观点"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"小模型主要进行“任务识别”，而超大模型才能进行“任务学习”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213129-ayk4qfz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-ayk4qfz","updated":"20250922213129"},"Children":[{"ID":"20250922213129-56oq819","Type":"NodeParagraph","Properties":{"id":"20250922213129-56oq819","updated":"20250922213129"},"Children":[{"Type":"NodeText","Data":"这很好地解释了为什么小模型对随机标签不敏感（因为它主要靠先验知识），而大模型能够学习反直觉的任务（因为它有能力临时构建新的“模型”）。"}]}]}]}]}]},{"ID":"20250922213129-xvbdsys","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213129-xvbdsys","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）提示：从“结果”到“过程”的飞跃"}]},{"ID":"20250922213129-2e7i28w","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213129-2e7i28w","updated":"20250922213129"},"Children":[{"ID":"20250922213129-kw7nzm7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-kw7nzm7","updated":"20250922213129"},"Children":[{"ID":"20250922213129-1o502uz","Type":"NodeParagraph","Properties":{"id":"20250922213129-1o502uz","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": 传统ICL只提供“输入-输出”对，要求模型自己“悟”出解题方法。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT则明确地将“解题过程”（中间推理步骤）也作为演示的一部分"},{"Type":"NodeText","Data":"，手把手地教模型如何思考。"}]}]},{"ID":"20250922213129-s3lvdaa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-s3lvdaa","updated":"20250922213129"},"Children":[{"ID":"20250922213129-fz46fc4","Type":"NodeParagraph","Properties":{"id":"20250922213129-fz46fc4","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“魔法咒语”"},{"Type":"NodeText","Data":": 幸运的是，我们不需要为每个任务都手动编写CoT。像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“Let's think step-by-step.”"},{"Type":"NodeText","Data":"这样的简单指令，就能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“触发”"},{"Type":"NodeText","Data":"LLM自己生成推理过程。这是一个惊人且极其有用的发现，极大地降低了CoT的应用门槛。"}]}]}]}]},{"ID":"20250922213129-dozr9jh","Type":"NodeThematicBreak","Properties":{"id":"20250922213129-dozr9jh","updated":"20250922213153"}},{"ID":"20250922213129-bfoxxl1","Type":"NodeBlockquote","Properties":{"id":"20250922213129-bfoxxl1","updated":"20250922213153"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922213129-v2ypwj5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213129-v2ypwj5","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922213129-w1dgtaa","Type":"NodeParagraph","Properties":{"id":"20250922213129-w1dgtaa","updated":"20250922213129"},"Children":[{"Type":"NodeText","Data":"第四十一部分深入到了LLM两大核心能力——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文学习（ICL）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"——的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“第一性原理”"},{"Type":"NodeText","Data":"。它系统地探讨了这些神奇能力"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从何而来（来源）"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何工作（机制）"},{"Type":"NodeText","Data":"，以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何激发（方法）"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922213129-9adp20u","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213129-9adp20u","updated":"20250922213129"},"Children":[{"ID":"20250922213129-r119a2c","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213129-r119a2c","updated":"20250922213129"},"Children":[{"ID":"20250922213129-3i0rtfy","Type":"NodeParagraph","Properties":{"id":"20250922213129-3i0rtfy","updated":"20250922213129"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL机制的“二元论”与“统一论”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213129-w35zc3l","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213129-w35zc3l","updated":"20250922213129"},"Children":[{"ID":"20250922213129-eo6mz24","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-eo6mz24","updated":"20250922213129"},"Children":[{"ID":"20250922213130-p4n39gl","Type":"NodeParagraph","Properties":{"id":"20250922213130-p4n39gl","updated":"20250922213130"},"Children":[{"Type":"NodeText","Data":"文章清晰地呈现了关于ICL工作机制的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大主流假说"},{"Type":"NodeText","Data":"："}]},{"ID":"20250922213130-8cjv1l3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213130-8cjv1l3","updated":"20250922213130"},"Children":[{"ID":"20250922213129-4uuma3c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-4uuma3c","updated":"20250922213129"},"Children":[{"ID":"20250922213130-i0selbe","Type":"NodeParagraph","Properties":{"id":"20250922213130-i0selbe","updated":"20250922213130"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务识别派"},{"Type":"NodeText","Data":"认为ICL是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“联想”"},{"Type":"NodeText","Data":"，模型只是在庞大的知识库中匹配到了相似的任务模式。"}]}]},{"ID":"20250922213129-yw1umnp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-yw1umnp","updated":"20250922213129"},"Children":[{"ID":"20250922213130-0zxz0dk","Type":"NodeParagraph","Properties":{"id":"20250922213130-0zxz0dk","updated":"20250922213130"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务学习派"},{"Type":"NodeText","Data":"认为ICL是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“学习”"},{"Type":"NodeText","Data":"，模型在推理时进行了一次"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“隐式的梯度下降”"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922213129-ewrkuhr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-ewrkuhr","updated":"20250922213129"},"Children":[{"ID":"20250922213130-2ko1ot1","Type":"NodeParagraph","Properties":{"id":"20250922213130-2ko1ot1","updated":"20250922213130"},"Children":[{"Type":"NodeText","Data":"最终，文章给出了一个更令人信服的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“统一论”：这两种能力都存在，但它们的涌现依赖于不同的模型规模"},{"Type":"NodeText","Data":"。小模型更倾向于“识别”，而只有足够大的模型才能真正“学习”新知识。这一结论深刻地揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模"},{"Type":"NodeText","Data":"在解锁LLM不同层次智能中的关键作用。"}]}]}]}]},{"ID":"20250922213129-su0ip0i","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213129-su0ip0i","updated":"20250922213129"},"Children":[{"ID":"20250922213130-6h9ahex","Type":"NodeParagraph","Properties":{"id":"20250922213130-6h9ahex","updated":"20250922213130"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练的深远影响"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213130-u7hm0l8","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213130-u7hm0l8","updated":"20250922213130"},"Children":[{"ID":"20250922213129-hpegg0s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-hpegg0s","updated":"20250922213129"},"Children":[{"ID":"20250922213130-u03o5bh","Type":"NodeParagraph","Properties":{"id":"20250922213130-u03o5bh","updated":"20250922213130"},"Children":[{"Type":"NodeText","Data":"本部分将ICL能力的来源追溯到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练阶段的数据和任务"},{"Type":"NodeText","Data":"。无论是语料库的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长程连贯性"},{"Type":"NodeText","Data":"还是语言的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"组合结构"},{"Type":"NodeText","Data":"，都表明ICL并非凭空产生，而是模型在海量数据中学习到的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"底层语言规律"},{"Type":"NodeText","Data":"在推理时的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化应用"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922213129-5gdljir","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922213129-5gdljir","updated":"20250922213129"},"Children":[{"ID":"20250922213130-jzi3gdp","Type":"NodeParagraph","Properties":{"id":"20250922213130-jzi3gdp","updated":"20250922213130"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT的本质：让思考过程“显性化”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213130-clfxigw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213130-clfxigw","updated":"20250922213130"},"Children":[{"ID":"20250922213129-xdrec9f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-xdrec9f","updated":"20250922213129"},"Children":[{"ID":"20250922213130-wy3oe46","Type":"NodeParagraph","Properties":{"id":"20250922213130-wy3oe46","updated":"20250922213130"},"Children":[{"Type":"NodeText","Data":"CoT的提出，是提示工程的一次"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重大范式转变"},{"Type":"NodeText","Data":"。它将LLM的“黑箱”推理过程，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"显式地生成中间步骤"},{"Type":"NodeText","Data":"而变得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“透明化”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213129-b7b63rt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-b7b63rt","updated":"20250922213129"},"Children":[{"ID":"20250922213130-5uzmmek","Type":"NodeParagraph","Properties":{"id":"20250922213130-5uzmmek","updated":"20250922213130"},"Children":[{"Type":"NodeText","Data":"这种“让模型自己解释自己”的方式，不仅极大地提升了其在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理任务"},{"Type":"NodeText","Data":"上的性能，也为我们理解和调试模型的思考过程提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"窗口"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213129-8733uve","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213129-8733uve","updated":"20250922213129"},"Children":[{"ID":"20250922213130-6hhe1ik","Type":"NodeParagraph","Properties":{"id":"20250922213130-6hhe1ik","updated":"20250922213130"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“魔法咒语”"},{"Type":"NodeText","Data":"（如“Let's think step-by-step”）的发现，是CoT能够被广泛应用的关键，它将一个复杂的过程简化为了一个简单的指令。"}]}]}]}]}]},{"ID":"20250922213130-x7unec2","Type":"NodeParagraph","Properties":{"id":"20250922213130-x7unec2","updated":"20250922213130"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第四十一部分是关于LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“智能之谜”"},{"Type":"NodeText","Data":"的一次深刻探索。它通过对ICL和CoT底层机制的探讨，试图回答"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“LLM为什么如此聪明？”"},{"Type":"NodeText","Data":"这一根本问题。它告诉我们，LLM的智能，根植于其在海量数据中学到的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言结构和世界知识"},{"Type":"NodeText","Data":"，并通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模的涌现"},{"Type":"NodeText","Data":"，进化出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“识别”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“学习”"},{"Type":"NodeText","Data":"这两种不同的能力模式。而CoT的出现，则为我们提供了一把钥匙，去"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"引导和观察"},{"Type":"NodeText","Data":"这个强大的“思考机器”是如何工作的。"}]}]},{"ID":"20250922213426-tydi8lb","Type":"NodeParagraph","Properties":{"id":"20250922213426-tydi8lb","updated":"20250922213426"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922213426-ggborjl","Type":"NodeThematicBreak","Properties":{"id":"20250922213426-ggborjl","updated":"20250922213426"}},{"ID":"20250922213426-jgkaawh","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213426-jgkaawh","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第四十二部分"}]},{"ID":"20250922213426-9lhxo7c","Type":"NodeParagraph","Properties":{"id":"20250922213426-9lhxo7c","updated":"20250922213459"},"Children":[{"Type":"NodeText","Data":"如图15所示，在基本的CoT提示方法中，CoT的生成过程遵循一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"链式结构"},{"Type":"NodeText","Data":"，其中LLM一步步地生成CoT。通常，CoT采用自然语言文本的格式。然而，文本CoT在需要严谨逻辑进行推理的复杂任务上可能表现不佳。考虑到这一点，一些工作使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码"},{"Type":"NodeText","Data":"，因其结构化和精确的特性。此外，中的作者提议动态地选择文本或代码作为CoT的格式，以结合它们的优点。"}]},{"ID":"20250922213426-7r77eui","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922213426-7r77eui","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.3.2 Improved CoT Prompting Strategies (改进的CoT提示策略)"}]},{"ID":"20250922213426-0t964a7","Type":"NodeParagraph","Properties":{"id":"20250922213426-0t964a7","updated":"20250922213459"},"Children":[{"Type":"NodeText","Data":"尽管在复杂推理任务上性能有所提升，但CoT提示仍然存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不正确的推理"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不稳定性"},{"Type":"NodeText","Data":"等问题。在本部分中，我们首先介绍如何设计更好的CoT提示和增强的CoT生成策略，然后介绍CoT基本链式结构的扩展。图15展示了代表性CoT提示策略的演进。"}]},{"ID":"20250922213426-7xjnmaz","Type":"NodeParagraph","Properties":{"id":"20250922213426-7xjnmaz","updated":"20250922213459"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Better Prompt Design (更好的提示设计)."},{"Type":"NodeText","Data":" 由于CoT提示依赖提示来激发LLM的推理能力，因此提示的设计对其性能至关重要。作为一种直接的方法，已有研究表明，使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样化的CoT"},{"Type":"NodeText","Data":"（即每个问题的多个推理路径）可以有效地提升性能。另一个直观的想法是，带有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更复杂推理路径"},{"Type":"NodeText","Data":"的提示更可能激发LLM的推理能力，这可以导致生成正确答案的更高准确率。然而，所有这些方法都依赖于标注的CoT数据集，这限制了它们在实践中的应用。为了克服这个限制，可以使用像“让我们一步步思考”这样的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"魔法指令"},{"Type":"NodeText","Data":"来通过提示LLM自动构建CoT。"}]},{"ID":"20250922213426-l11pw8q","Type":"NodeParagraph","Properties":{"id":"20250922213426-l11pw8q","updated":"20250922213459"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Enhanced CoT Generation (增强的CoT生成)."},{"Type":"NodeText","Data":" 由于LLM在生成过程中容易产生不正确的推理步骤并表现出不稳定性，因此有一些研究旨在改进CoT的生成。在本部分中，我们将介绍两种增强CoT生成的典型方法："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于采样"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于验证"},{"Type":"NodeText","Data":"的方法。"}]},{"ID":"20250922213426-oc50i4j","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-oc50i4j","updated":"20250922213459"},"Children":[{"ID":"20250922213425-0i0ndtg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-0i0ndtg","updated":"20250922213425"},"Children":[{"ID":"20250922213426-j8uu57w","Type":"NodeParagraph","Properties":{"id":"20250922213426-j8uu57w","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于采样的方法 (Sampling-based methods)."},{"Type":"NodeText","Data":" LLM在推理过程中已知会遭受不稳定性，这可能导致生成的推理步骤不忠实。为了解决这个问题，一些工作提议"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"采样多个推理路径"},{"Type":"NodeText","Data":"，而不是使用贪心解码。作为一个代表性的解决方案，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自洽性（self-consistency）"},{"Type":"NodeText","Data":"首先生成几个推理路径，然后对相应的答案进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"集成"},{"Type":"NodeText","Data":"，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多数投票"},{"Type":"NodeText","Data":"选择最一致的一个。然而，当大多数推理路径都被误导时，这种方法仍可能导致错误的答案。考虑到这一点，中的作者仅对"},{"Type":"NodeTextMark","TextMarkType":"em","TextMarkTextContent":"k"},{"Type":"NodeText","Data":"个最复杂的推理路径进行投票，基于他们的观察，即具有更高复杂性（例如，更多推理步骤）的推理路径通常具有更好的性能。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MCR"},{"Type":"NodeText","Data":"提议在生成下一步时参考其他推理路径的步骤，并跨多个推理路径执行推理以生成最终答案。"}]}]},{"ID":"20250922213425-vd9pivu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-vd9pivu","updated":"20250922213425"},"Children":[{"ID":"20250922213426-qv6fojk","Type":"NodeParagraph","Properties":{"id":"20250922213426-qv6fojk","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于验证的方法 (Verification-based methods)."},{"Type":"NodeText","Data":" CoT中推理步骤的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"顺序性"},{"Type":"NodeText","Data":"可能导致在某些步骤不正确时产生错误的累积。为了缓解这个问题，最近的研究提议用训练好的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"验证器"},{"Type":"NodeText","Data":"或LLM本身来验证生成的推理步骤的正确性。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DIVERSE"},{"Type":"NodeText","Data":"分别训练了解决方案级和步骤级的验证器，以在不同粒度上检验推理步骤。另一种方法利用LLM通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逐步自验证"},{"Type":"NodeText","Data":"来验证推理步骤的正确性，并采用专门设计的推理格式。此外，一些研究提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反向推理"},{"Type":"NodeText","Data":"进行验证：它首先从模型的预测中推导出必要的问题条件或变量，然后将它们与原始的进行比较。"}]}]}]},{"ID":"20250922213426-h0aui1x","Type":"NodeParagraph","Properties":{"id":"20250922213426-h0aui1x","updated":"20250922213459"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Reasoning Structure Extension (推理结构扩展)."},{"Type":"NodeText","Data":" 尽管具有通用性，但基本的CoT提示的链式推理结构限制了其在解决需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前瞻"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"回溯"},{"Type":"NodeText","Data":"等探索性推理的复杂任务中的有效性。因此，许多研究致力于通过设计更复杂的思维过程来扩展推理结构，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"树状"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图状"},{"Type":"NodeText","Data":"推理。"}]},{"ID":"20250922213426-ym7xz1l","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-ym7xz1l","updated":"20250922213459"},"Children":[{"ID":"20250922213425-hgfoaqv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-hgfoaqv","updated":"20250922213425"},"Children":[{"ID":"20250922213426-0qx5jo2","Type":"NodeParagraph","Properties":{"id":"20250922213426-0qx5jo2","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"树状推理 (Tree-structured reasoning)."},{"Type":"NodeText","Data":" 这种方法（以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维树, Tree of Thoughts, ToT"},{"Type":"NodeText","Data":"为例）将推理过程形式化为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"层级树结构"},{"Type":"NodeText","Data":"，其中中间思想是节点。通过这种方式，它使LLM能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并行探索多个推理路径"},{"Type":"NodeText","Data":"，并进一步支持"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前瞻"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"回溯"},{"Type":"NodeText","Data":"操作，以促进更全面的决策。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"TouT"},{"Type":"NodeText","Data":"在基于蒙特卡洛丢弃的思想评估中考虑了中间思想的不确定性。"}]}]},{"ID":"20250922213425-n18ycvn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-n18ycvn","updated":"20250922213425"},"Children":[{"ID":"20250922213426-plvp3ni","Type":"NodeParagraph","Properties":{"id":"20250922213426-plvp3ni","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图状推理 (Graph-structured reasoning)."},{"Type":"NodeText","Data":" 尽管树结构促进了并行推理，但它也对推理过程施加了限制。"}]}]}]},{"ID":"20250922213426-x6kdatj","Type":"NodeParagraph","Properties":{"id":"20250922213426-x6kdatj","updated":"20250922213459"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915180145-z90s57q.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922213426-4axvg4t","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213426-4axvg4t","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 15：CoT提示策略的演进示意图。"}]},{"ID":"20250922213426-0daj7uk","Type":"NodeParagraph","Properties":{"id":"20250922213426-0daj7uk","updated":"20250922213459"},"Children":[{"Type":"NodeText","Data":"它从基本的CoT方法开始，发展到增强的CoT生成技术，包括基于采样和基于验证的方法。最后，它扩展到链式结构的变化，例如树和图。这里，“thought”指的是如中所述的中间推理步骤。"}]},{"ID":"20250922213426-hirupxt","Type":"NodeBlockquote","Properties":{"id":"20250922213426-hirupxt","updated":"20250922213459"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922213426-johpv73","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213426-johpv73","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922213426-pa0ezi8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213426-pa0ezi8","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图15解析：思维链的“进化之路”"}]},{"ID":"20250922213426-i872pwc","Type":"NodeParagraph","Properties":{"id":"20250922213426-i872pwc","updated":"20250922213426"},"Children":[{"Type":"NodeText","Data":"这张图生动地展示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"技术从一个简单的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“线性链条”"},{"Type":"NodeText","Data":"，如何一步步"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“进化”"},{"Type":"NodeText","Data":"成更复杂、更强大的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“思维网络”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922213426-fdl11lu","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-fdl11lu","updated":"20250922213426"},"Children":[{"ID":"20250922213425-p1tdnlv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-p1tdnlv","updated":"20250922213425"},"Children":[{"ID":"20250922213426-nudfwbd","Type":"NodeParagraph","Properties":{"id":"20250922213426-nudfwbd","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT 1.0: 线性链 (Linear Chain)"}]},{"ID":"20250922213426-bo6ekl3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-bo6ekl3","updated":"20250922213426"},"Children":[{"ID":"20250922213425-c3hshoe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-c3hshoe","updated":"20250922213425"},"Children":[{"ID":"20250922213426-xhet906","Type":"NodeParagraph","Properties":{"id":"20250922213426-xhet906","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"形态"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"输入 -\u0026gt; 步骤1 -\u0026gt; 步骤2 -\u0026gt; ... -\u0026gt; 输出"},{"Type":"NodeText","Data":"​。这是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单路径、线性的"},{"Type":"NodeText","Data":"推理过程。"}]}]},{"ID":"20250922213425-3ptj2v8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-3ptj2v8","updated":"20250922213425"},"Children":[{"ID":"20250922213426-q8px8eg","Type":"NodeParagraph","Properties":{"id":"20250922213426-q8px8eg","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“一条路走到黑”"},{"Type":"NodeText","Data":"。一旦中间某一步走错，整个推理链就会崩溃，导致最终结果错误。"}]}]}]}]},{"ID":"20250922213425-0fypof0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-0fypof0","updated":"20250922213425"},"Children":[{"ID":"20250922213426-47nd7x8","Type":"NodeParagraph","Properties":{"id":"20250922213426-47nd7x8","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT 2.0: 并行与验证 (Parallel \u0026amp; Verification)"}]},{"ID":"20250922213426-q03yh4a","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-q03yh4a","updated":"20250922213426"},"Children":[{"ID":"20250922213425-kxuyxf3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-kxuyxf3","updated":"20250922213425"},"Children":[{"ID":"20250922213426-rqt41me","Type":"NodeParagraph","Properties":{"id":"20250922213426-rqt41me","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标"},{"Type":"NodeText","Data":": 解决CoT 1.0的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"脆弱性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不稳定性"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213425-vqelfnh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-vqelfnh","updated":"20250922213425"},"Children":[{"ID":"20250922213426-f3qyl5x","Type":"NodeParagraph","Properties":{"id":"20250922213426-f3qyl5x","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大分支"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-8eumdmi","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213426-8eumdmi","updated":"20250922213426"},"Children":[{"ID":"20250922213425-byqlmr6","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213425-byqlmr6","updated":"20250922213425"},"Children":[{"ID":"20250922213426-pva7tly","Type":"NodeParagraph","Properties":{"id":"20250922213426-pva7tly","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于采样 (Sampling-based CoT)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-07xrg6q","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-07xrg6q","updated":"20250922213426"},"Children":[{"ID":"20250922213425-rt86pz1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-rt86pz1","updated":"20250922213425"},"Children":[{"ID":"20250922213426-2odrbvr","Type":"NodeParagraph","Properties":{"id":"20250922213426-2odrbvr","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"形态"},{"Type":"NodeText","Data":": 从输入出发，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并行地生成多条（Ensemble）"},{"Type":"NodeText","Data":"不同的推理路径，然后通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"投票"},{"Type":"NodeText","Data":"选出最一致的答案。"}]}]},{"ID":"20250922213425-9dvg74t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-9dvg74t","updated":"20250922213425"},"Children":[{"ID":"20250922213426-0ftpsby","Type":"NodeParagraph","Properties":{"id":"20250922213426-0ftpsby","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“广开言路，民主决策”"},{"Type":"NodeText","Data":"。通过群体智慧来弥补单次推理可能出现的随机错误。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Consistency"},{"Type":"NodeText","Data":"是这一思想的代表。"}]}]}]}]},{"ID":"20250922213425-me4fhv4","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213425-me4fhv4","updated":"20250922213425"},"Children":[{"ID":"20250922213426-frqbk9p","Type":"NodeParagraph","Properties":{"id":"20250922213426-frqbk9p","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于验证 (Verification-based CoT)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-8wcsnfn","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-8wcsnfn","updated":"20250922213426"},"Children":[{"ID":"20250922213425-vzttezp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-vzttezp","updated":"20250922213425"},"Children":[{"ID":"20250922213426-kavhgzj","Type":"NodeParagraph","Properties":{"id":"20250922213426-kavhgzj","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"形态"},{"Type":"NodeText","Data":": 在线性推理的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每一步"},{"Type":"NodeText","Data":"都加入一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“验证（Verification）”"},{"Type":"NodeText","Data":"环节。"}]}]},{"ID":"20250922213425-3b0zmm9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-3b0zmm9","updated":"20250922213425"},"Children":[{"ID":"20250922213426-jytzm1a","Type":"NodeParagraph","Properties":{"id":"20250922213426-jytzm1a","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“步步为营，自我纠错”"},{"Type":"NodeText","Data":"。在进入下一步之前，先检查当前步骤是否正确，如果不正确就及时修正或停止。"}]}]}]}]}]}]}]}]},{"ID":"20250922213425-ym7m8gb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-ym7m8gb","updated":"20250922213425"},"Children":[{"ID":"20250922213426-tuu837t","Type":"NodeParagraph","Properties":{"id":"20250922213426-tuu837t","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT 3.0: 结构化推理 (Structured Reasoning)"}]},{"ID":"20250922213426-3gexqob","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-3gexqob","updated":"20250922213426"},"Children":[{"ID":"20250922213425-61p0dqq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-61p0dqq","updated":"20250922213425"},"Children":[{"ID":"20250922213426-n6hntvy","Type":"NodeParagraph","Properties":{"id":"20250922213426-n6hntvy","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标"},{"Type":"NodeText","Data":": 解决线性链无法处理的、需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"探索、前瞻和回溯"},{"Type":"NodeText","Data":"的超复杂问题。"}]}]},{"ID":"20250922213425-b0cliv8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-b0cliv8","updated":"20250922213425"},"Children":[{"ID":"20250922213426-jindqci","Type":"NodeParagraph","Properties":{"id":"20250922213426-jindqci","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大形态"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-28egh0v","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213426-28egh0v","updated":"20250922213426"},"Children":[{"ID":"20250922213425-0yby8m4","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213425-0yby8m4","updated":"20250922213425"},"Children":[{"ID":"20250922213426-dr3ntwi","Type":"NodeParagraph","Properties":{"id":"20250922213426-dr3ntwi","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维树 (Tree of Thoughts, ToT)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-0xprxgx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-0xprxgx","updated":"20250922213426"},"Children":[{"ID":"20250922213425-njsc61n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-njsc61n","updated":"20250922213425"},"Children":[{"ID":"20250922213426-9qlwkyr","Type":"NodeParagraph","Properties":{"id":"20250922213426-9qlwkyr","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"形态"},{"Type":"NodeText","Data":": 推理过程像一棵"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"树"},{"Type":"NodeText","Data":"一样分叉。模型在每个节点都可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"探索多个"},{"Type":"NodeText","Data":"下一步的可能性（Positive thought），并评估每个分支的优劣，甚至可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"回溯（Backtrack）"},{"Type":"NodeText","Data":"到上一个节点，选择另一条路走。"}]}]},{"ID":"20250922213425-jx9zn6o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-jx9zn6o","updated":"20250922213425"},"Children":[{"ID":"20250922213426-icdwjap","Type":"NodeParagraph","Properties":{"id":"20250922213426-icdwjap","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“系统性探索”"},{"Type":"NodeText","Data":"。将简单的线性思考，升级为有组织的、可回溯的树状搜索。"}]}]}]}]},{"ID":"20250922213425-945vajo","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213425-945vajo","updated":"20250922213425"},"Children":[{"ID":"20250922213426-xuut9tg","Type":"NodeParagraph","Properties":{"id":"20250922213426-xuut9tg","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维图 (Graph of Thoughts, GoT)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-09iwhzx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-09iwhzx","updated":"20250922213426"},"Children":[{"ID":"20250922213425-l9zy4lh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-l9zy4lh","updated":"20250922213425"},"Children":[{"ID":"20250922213426-dj237h5","Type":"NodeParagraph","Properties":{"id":"20250922213426-dj237h5","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"形态"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最复杂的形态"},{"Type":"NodeText","Data":"。推理过程是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任意的图"},{"Type":"NodeText","Data":"。不同的推理路径之间可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相互交叉、合并（Aggregate）"},{"Type":"NodeText","Data":"，形成一个复杂的思维网络。"}]}]},{"ID":"20250922213425-ohc1lfd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-ohc1lfd","updated":"20250922213425"},"Children":[{"ID":"20250922213426-ldafjq8","Type":"NodeParagraph","Properties":{"id":"20250922213426-ldafjq8","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“集思广益，融会贯通”"},{"Type":"NodeText","Data":"。允许不同的思考分支相互启发、借鉴，实现更复杂的协同推理。"}]}]}]}]}]}]}]}]}]},{"ID":"20250922213426-94zfzhz","Type":"NodeParagraph","Properties":{"id":"20250922213426-94zfzhz","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张图谱清晰地展示了CoT技术从一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"脆弱的单线程思考"},{"Type":"NodeText","Data":"，进化为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"鲁棒的多线程思考（采样）"},{"Type":"NodeText","Data":"、一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严谨的自纠错思考（验证）"},{"Type":"NodeText","Data":"，最终演化为能够进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度探索和规划的“网络化思考”（树/图）"},{"Type":"NodeText","Data":"的完整路径。"}]}]},{"ID":"20250922213426-4ccqauo","Type":"NodeThematicBreak","Properties":{"id":"20250922213426-4ccqauo","updated":"20250922213459"}},{"ID":"20250922213426-1matchy","Type":"NodeBlockquote","Properties":{"id":"20250922213426-1matchy","updated":"20250922213459"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922213426-bii4h5o","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213426-bii4h5o","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922213426-i7vgjy9","Type":"NodeParagraph","Properties":{"id":"20250922213426-i7vgjy9","updated":"20250922213426"},"Children":[{"Type":"NodeText","Data":"第四十二部分深入探讨了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）提示"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改进策略"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构扩展"},{"Type":"NodeText","Data":"，系统地展示了研究者们是如何将一个最初简单但有效的想法，通过不断地迭代和深化，发展成一个强大而复杂的推理框架的。"}]},{"ID":"20250922213426-nz2j2kd","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213426-nz2j2kd","updated":"20250922213426"},"Children":[{"ID":"20250922213425-qlpugzy","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213425-qlpugzy","updated":"20250922213425"},"Children":[{"ID":"20250922213426-8dxmt7w","Type":"NodeParagraph","Properties":{"id":"20250922213426-8dxmt7w","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“文本”到“代码”的格式演进"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-xe0zj7s","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-xe0zj7s","updated":"20250922213426"},"Children":[{"ID":"20250922213425-bisvgrl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-bisvgrl","updated":"20250922213425"},"Children":[{"ID":"20250922213426-4hvtog1","Type":"NodeParagraph","Properties":{"id":"20250922213426-4hvtog1","updated":"20250922213426"},"Children":[{"Type":"NodeText","Data":"CoT的推理步骤最初是以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然语言"},{"Type":"NodeText","Data":"形式呈现的。但对于需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严谨逻辑"},{"Type":"NodeText","Data":"的数学和符号推理任务，自然语言的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模糊性"},{"Type":"NodeText","Data":"成为一个瓶颈。"}]}]},{"ID":"20250922213425-gwetr83","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-gwetr83","updated":"20250922213425"},"Children":[{"ID":"20250922213426-plp0z11","Type":"NodeParagraph","Properties":{"id":"20250922213426-plp0z11","updated":"20250922213426"},"Children":[{"Type":"NodeText","Data":"将推理步骤用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码"},{"Type":"NodeText","Data":"来表示，是一个重要的进步。因为代码是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确、无歧义且可执行的"},{"Type":"NodeText","Data":"，它能更好地强制模型遵循严密的逻辑。"}]}]}]}]},{"ID":"20250922213425-azdrud2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213425-azdrud2","updated":"20250922213425"},"Children":[{"ID":"20250922213426-tck6f0d","Type":"NodeParagraph","Properties":{"id":"20250922213426-tck6f0d","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"增强CoT生成的“两大流派”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-tiv24cx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-tiv24cx","updated":"20250922213426"},"Children":[{"ID":"20250922213425-1mhly6q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-1mhly6q","updated":"20250922213425"},"Children":[{"ID":"20250922213426-mzse4f7","Type":"NodeParagraph","Properties":{"id":"20250922213426-mzse4f7","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心问题"},{"Type":"NodeText","Data":": 基础的CoT生成过程"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不稳定"},{"Type":"NodeText","Data":"，容易出错。"}]}]},{"ID":"20250922213425-63wbn6j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-63wbn6j","updated":"20250922213425"},"Children":[{"ID":"20250922213426-6iwzls0","Type":"NodeParagraph","Properties":{"id":"20250922213426-6iwzls0","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"采样派（以Self-Consistency为代表）"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-9jwaivw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-9jwaivw","updated":"20250922213426"},"Children":[{"ID":"20250922213425-fy35958","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-fy35958","updated":"20250922213425"},"Children":[{"ID":"20250922213426-wlo9sa7","Type":"NodeParagraph","Properties":{"id":"20250922213426-wlo9sa7","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"哲学"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“三个臭皮匠，顶个诸葛亮”"},{"Type":"NodeText","Data":"。通过生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多条"},{"Type":"NodeText","Data":"推理路径并进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"投票"},{"Type":"NodeText","Data":"，利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“群体智慧”"},{"Type":"NodeText","Data":"来平滑掉单次生成的随机性错误，从而提升结果的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"鲁棒性（Robustness）"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922213425-2vdv7bk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-2vdv7bk","updated":"20250922213425"},"Children":[{"ID":"20250922213426-tg44m6l","Type":"NodeParagraph","Properties":{"id":"20250922213426-tg44m6l","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"验证派（以Self-Verification为代表）"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-qg144sl","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-qg144sl","updated":"20250922213426"},"Children":[{"ID":"20250922213425-48e6iln","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-48e6iln","updated":"20250922213425"},"Children":[{"ID":"20250922213426-tvs527m","Type":"NodeParagraph","Properties":{"id":"20250922213426-tvs527m","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"哲学"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“三省吾身”"},{"Type":"NodeText","Data":"。在推理的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每一步"},{"Type":"NodeText","Data":"都进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自我检查和验证"},{"Type":"NodeText","Data":"，确保当前步骤的正确性，防止"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“一步错，步步错”"},{"Type":"NodeText","Data":"的错误累积。这提升了推理过程的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严谨性（Rigorousness）"},{"Type":"NodeText","Data":"。"}]}]}]}]}]}]},{"ID":"20250922213425-lbkkcr9","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922213425-lbkkcr9","updated":"20250922213425"},"Children":[{"ID":"20250922213426-tiwmu0o","Type":"NodeParagraph","Properties":{"id":"20250922213426-tiwmu0o","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理结构的“维度升级”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-ml1j4nk","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-ml1j4nk","updated":"20250922213426"},"Children":[{"ID":"20250922213425-fhyqlc9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-fhyqlc9","updated":"20250922213425"},"Children":[{"ID":"20250922213426-8ry19ns","Type":"NodeParagraph","Properties":{"id":"20250922213426-8ry19ns","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心动机"},{"Type":"NodeText","Data":": 现实世界中的复杂问题，其解决方案往往不是线性的，需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"探索、试错、回溯和权衡"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213425-sda8knz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-sda8knz","updated":"20250922213425"},"Children":[{"ID":"20250922213426-1tj7uir","Type":"NodeParagraph","Properties":{"id":"20250922213426-1tj7uir","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“链”到“树” (ToT)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-bhpudic","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-bhpudic","updated":"20250922213426"},"Children":[{"ID":"20250922213425-xif4u9q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-xif4u9q","updated":"20250922213425"},"Children":[{"ID":"20250922213426-plvxxmc","Type":"NodeParagraph","Properties":{"id":"20250922213426-plvxxmc","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维树（Tree of Thoughts）"},{"Type":"NodeText","Data":"是CoT的一次"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“维度升级”"},{"Type":"NodeText","Data":"。它将线性的思考过程，扩展为了一个可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"并行探索多个分支"},{"Type":"NodeText","Data":"的树状结构。"}]}]},{"ID":"20250922213425-gnidi40","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-gnidi40","updated":"20250922213425"},"Children":[{"ID":"20250922213426-s2haccl","Type":"NodeParagraph","Properties":{"id":"20250922213426-s2haccl","updated":"20250922213426"},"Children":[{"Type":"NodeText","Data":"它赋予了LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“前瞻”（Lookahead）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“回溯”（Backtracking）"},{"Type":"NodeText","Data":"的能力，使其能够像人类一样，在决策时"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"权衡不同的可能性"},{"Type":"NodeText","Data":"，而不是“一条路走到黑”。"}]}]}]}]},{"ID":"20250922213425-wl4l892","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-wl4l892","updated":"20250922213425"},"Children":[{"ID":"20250922213426-nbzk1d1","Type":"NodeParagraph","Properties":{"id":"20250922213426-nbzk1d1","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“树”到“图” (GoT)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213426-8c6gp6f","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213426-8c6gp6f","updated":"20250922213426"},"Children":[{"ID":"20250922213425-klnayms","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213425-klnayms","updated":"20250922213425"},"Children":[{"ID":"20250922213426-4k8hzip","Type":"NodeParagraph","Properties":{"id":"20250922213426-4k8hzip","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维图（Graph of Thoughts）"},{"Type":"NodeText","Data":"是更进一步的抽象。它允许不同的推理分支"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交叉、合并和循环"},{"Type":"NodeText","Data":"，形成一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任意的图结构"},{"Type":"NodeText","Data":"。这使得模型能够进行更复杂的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“融会贯通”"},{"Type":"NodeText","Data":"式思考。"}]}]}]}]}]}]}]},{"ID":"20250922213426-tu2djst","Type":"NodeParagraph","Properties":{"id":"20250922213426-tu2djst","updated":"20250922213426"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第四十二部分为我们描绘了一幅"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT技术的完整进化图谱"},{"Type":"NodeText","Data":"（如图15所示）。它从解决"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“生成质量”"},{"Type":"NodeText","Data":"问题（采样与验证）出发，最终走向了对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“思考模式”"},{"Type":"NodeText","Data":"本身的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构性重塑"},{"Type":"NodeText","Data":"（树与图）。这一演进路径，清晰地展示了研究者们如何努力地让LLM的“思考”方式，从简单的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"线性推导"},{"Type":"NodeText","Data":"，逐步逼近人类所拥有的那种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂的、探索性的、网络化的"},{"Type":"NodeText","Data":"思维模式。"}]}]},{"ID":"20250922213816-t7hmzx4","Type":"NodeParagraph","Properties":{"id":"20250922213816-t7hmzx4","updated":"20250922213816"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922213816-n3otob3","Type":"NodeThematicBreak","Properties":{"id":"20250922213816-n3otob3","updated":"20250922213816"}},{"ID":"20250922213816-4fgdhbd","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213816-4fgdhbd","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第四十四部分"}]},{"ID":"20250922213816-ebg3o35","Type":"NodeParagraph","Properties":{"id":"20250922213816-ebg3o35","updated":"20250922213840"},"Children":[{"Type":"NodeText","Data":"任务规划器由LLM扮演，旨在生成解决目标任务的整个计划。该计划可以以多种形式呈现，例如，以自然语言形式的动作序列或用编程语言编写的可执行程序。基于LLM的任务规划器可以通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"记忆机制"},{"Type":"NodeText","Data":"来增强，用于计划的存储和检索，这对于长远任务很有帮助。然后，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计划执行器"},{"Type":"NodeText","Data":"负责执行计划中的动作。它可以由像LLM这样的模型来实现文本任务，或由像代码解释器这样的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具"},{"Type":"NodeText","Data":"来实现编码任务。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"环境"},{"Type":"NodeText","Data":"指的是计划执行器执行动作的地方，可以根据特定任务进行不同设置，例如，LLM本身或像Minecraft这样的外部虚拟世界。它向任务规划器提供关于动作执行结果的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反馈"},{"Type":"NodeText","Data":"，可以以自然语言的形式或来自其他多模态信号。"}]},{"ID":"20250922213816-5ageh3v","Type":"NodeParagraph","Properties":{"id":"20250922213816-5ageh3v","updated":"20250922213840"},"Children":[{"Type":"NodeText","Data":"为了解决一个复杂的任务，任务规划器首先需要清晰地理解任务目标，并基于LLM的推理生成一个合理的计划（见6.4.2节）。然后，计划执行器在环境中根据计划行动，环境将为任务规划器产生反馈（见6.4.3节）。任务规划器可以进一步整合从环境中获得的反馈来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提炼"},{"Type":"NodeText","Data":"其初始计划，并迭代地执行上述过程以获得更好的结果作为任务解决方案（见6.4.4节）。"}]},{"ID":"20250922213816-4kwszy3","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922213816-4kwszy3","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.4.2 Plan Generation (计划生成)"}]},{"ID":"20250922213816-xhti4fx","Type":"NodeParagraph","Properties":{"id":"20250922213816-xhti4fx","updated":"20250922213840"},"Children":[{"Type":"NodeText","Data":"计划生成专注于通过提示LLM直接生成动作序列。根据生成的计划的格式，现有的工作可以分为两组："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于文本"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于代码"},{"Type":"NodeText","Data":"的方法。"}]},{"ID":"20250922213816-oc2e6pr","Type":"NodeParagraph","Properties":{"id":"20250922213816-oc2e6pr","updated":"20250922213840"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Text-based Approaches (基于文本的方法)."},{"Type":"NodeText","Data":" LLM以自然语言的形式生成计划是直接的。在这种方法中，LLM被提示生成一个动作序列，供计划执行器执行以解决复杂任务。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Plan-and-Solve"},{"Type":"NodeText","Data":"添加了明确的"}]},{"ID":"20250922213816-9zuowso","Type":"NodeParagraph","Properties":{"id":"20250922213816-9zuowso","updated":"20250922213840"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915181750-f8m4766.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922213816-w3o0cf0","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213816-w3o0cf0","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 16：用于解决复杂任务的基于提示的LLM规划的公式化示意图。"}]},{"ID":"20250922213816-5s1qji5","Type":"NodeBlockquote","Properties":{"id":"20250922213816-5s1qji5","updated":"20250922213840"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922213816-d34lskq","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213816-d34lskq","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922213816-vjcq9a9","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213816-vjcq9a9","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图16解析：LLM智能体的“工作循环”"}]},{"ID":"20250922213816-6ahrkv0","Type":"NodeParagraph","Properties":{"id":"20250922213816-6ahrkv0","updated":"20250922213816"},"Children":[{"Type":"NodeText","Data":"这张图是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM作为自主智能体（Agent）"},{"Type":"NodeText","Data":"核心工作流程的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“蓝图”"},{"Type":"NodeText","Data":"。它展示了一个智能体是如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"感知、思考、行动和学习"},{"Type":"NodeText","Data":"的。"}]},{"ID":"20250922213816-qoqdfph","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-qoqdfph","updated":"20250922213816"},"Children":[{"ID":"20250922213816-wk1xojh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-wk1xojh","updated":"20250922213816"},"Children":[{"ID":"20250922213816-q1xvtma","Type":"NodeParagraph","Properties":{"id":"20250922213816-q1xvtma","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大核心组件"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213816-hd94nnx","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213816-hd94nnx","updated":"20250922213816"},"Children":[{"ID":"20250922213816-mo6fre2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213816-mo6fre2","updated":"20250922213816"},"Children":[{"ID":"20250922213816-2rn2w0w","Type":"NodeParagraph","Properties":{"id":"20250922213816-2rn2w0w","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务规划器 (Task Planner)"},{"Type":"NodeText","Data":": 这是智能体的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“大脑”"},{"Type":"NodeText","Data":"，通常由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM"},{"Type":"NodeText","Data":"本身扮演。"}]},{"ID":"20250922213816-s6jyxsj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-s6jyxsj","updated":"20250922213816"},"Children":[{"ID":"20250922213816-aajz4y8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-aajz4y8","updated":"20250922213816"},"Children":[{"ID":"20250922213816-gk8j7n1","Type":"NodeParagraph","Properties":{"id":"20250922213816-gk8j7n1","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"功能"},{"Type":"NodeText","Data":": 接收"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务（Task）"},{"Type":"NodeText","Data":"，进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思考"},{"Type":"NodeText","Data":"，然后"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成和提炼计划（Plan）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213816-kmh1pf3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-kmh1pf3","updated":"20250922213816"},"Children":[{"ID":"20250922213816-rdrs4vo","Type":"NodeParagraph","Properties":{"id":"20250922213816-rdrs4vo","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辅助工具"},{"Type":"NodeText","Data":": 它拥有一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"记忆（Memory）"},{"Type":"NodeText","Data":"模块，可以存储和检索过去的经验和知识。"}]}]}]}]},{"ID":"20250922213816-28relfb","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213816-28relfb","updated":"20250922213816"},"Children":[{"ID":"20250922213816-lzrr9uz","Type":"NodeParagraph","Properties":{"id":"20250922213816-lzrr9uz","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计划执行器 (Plan Executor)"},{"Type":"NodeText","Data":": 这是智能体的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“手脚”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922213816-i299fer","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-i299fer","updated":"20250922213816"},"Children":[{"ID":"20250922213816-yafgrgr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-yafgrgr","updated":"20250922213816"},"Children":[{"ID":"20250922213816-7ml7g23","Type":"NodeParagraph","Properties":{"id":"20250922213816-7ml7g23","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"功能"},{"Type":"NodeText","Data":": 负责执行“大脑”制定的计划中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"行动（Action）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213816-90awdum","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-90awdum","updated":"20250922213816"},"Children":[{"ID":"20250922213816-3vlqzbs","Type":"NodeParagraph","Properties":{"id":"20250922213816-3vlqzbs","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"执行方式"},{"Type":"NodeText","Data":": 执行器本身可以是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM"},{"Type":"NodeText","Data":"（如生成一段文字），也可以是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部工具（Tool）"},{"Type":"NodeText","Data":"（如代码解释器、搜索引擎API）。"}]}]}]}]},{"ID":"20250922213816-klx9t73","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922213816-klx9t73","updated":"20250922213816"},"Children":[{"ID":"20250922213816-y16is7d","Type":"NodeParagraph","Properties":{"id":"20250922213816-y16is7d","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"环境 (Environment)"},{"Type":"NodeText","Data":": 这是智能体所处的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“世界”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922213816-fdcvhsn","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-fdcvhsn","updated":"20250922213816"},"Children":[{"ID":"20250922213816-uqp7zlf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-uqp7zlf","updated":"20250922213816"},"Children":[{"ID":"20250922213816-75h56b1","Type":"NodeParagraph","Properties":{"id":"20250922213816-75h56b1","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"功能"},{"Type":"NodeText","Data":": 接受智能体的行动，并提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反馈（Feedback）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213816-8hdrtbg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-8hdrtbg","updated":"20250922213816"},"Children":[{"ID":"20250922213816-uazka2v","Type":"NodeParagraph","Properties":{"id":"20250922213816-uazka2v","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类型"},{"Type":"NodeText","Data":": 环境可以是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内部的"},{"Type":"NodeText","Data":"（如LLM自身的知识库），也可以是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部的"},{"Type":"NodeText","Data":"（如互联网、物理世界、模拟器）。外部环境又可以分为与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类（Human）"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"世界（World）"},{"Type":"NodeText","Data":"或其他"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"（Others）"},{"Type":"NodeText","Data":"的交互。"}]}]}]}]}]}]},{"ID":"20250922213816-m85fv2w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-m85fv2w","updated":"20250922213816"},"Children":[{"ID":"20250922213816-42dtsgw","Type":"NodeParagraph","Properties":{"id":"20250922213816-42dtsgw","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心工作循环 (The Loop)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213816-pgz0tdi","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213816-pgz0tdi","updated":"20250922213816"},"Children":[{"ID":"20250922213816-oe5thco","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213816-oe5thco","updated":"20250922213816"},"Children":[{"ID":"20250922213816-nnzfemt","Type":"NodeParagraph","Properties":{"id":"20250922213816-nnzfemt","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规划 (Plan)"},{"Type":"NodeText","Data":": “大脑”（LLM）根据任务，制定一个初步的计划。"}]}]},{"ID":"20250922213816-v2p6bx8","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213816-v2p6bx8","updated":"20250922213816"},"Children":[{"ID":"20250922213816-974icav","Type":"NodeParagraph","Properties":{"id":"20250922213816-974icav","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"行动 (Action)"},{"Type":"NodeText","Data":": “手脚”（执行器）在“世界”（环境）中执行计划的第一步。"}]}]},{"ID":"20250922213816-8dk7hct","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922213816-8dk7hct","updated":"20250922213816"},"Children":[{"ID":"20250922213816-e4ag39s","Type":"NodeParagraph","Properties":{"id":"20250922213816-e4ag39s","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"感知/反馈 (Feedback)"},{"Type":"NodeText","Data":": “世界”（环境）将行动的结果作为“反馈”传回给“大脑”。"}]}]},{"ID":"20250922213816-qhzdn4y","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922213816-qhzdn4y","updated":"20250922213816"},"Children":[{"ID":"20250922213816-977hsav","Type":"NodeParagraph","Properties":{"id":"20250922213816-977hsav","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反思/提炼 (Refine)"},{"Type":"NodeText","Data":": “大脑”（LLM）根据这个反馈，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"修正和提炼"},{"Type":"NodeText","Data":"原来的计划。"}]}]},{"ID":"20250922213816-3vlq5ad","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NS4=","Num":5},"Properties":{"id":"20250922213816-3vlq5ad","updated":"20250922213816"},"Children":[{"ID":"20250922213816-5yczbbb","Type":"NodeParagraph","Properties":{"id":"20250922213816-5yczbbb","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"循环"},{"Type":"NodeText","Data":": 重复步骤2-4，直到最终任务完成，产出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结果（Result）"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922213816-rkvpclb","Type":"NodeParagraph","Properties":{"id":"20250922213816-rkvpclb","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张图揭示了LLM从一个被动的“文本生成器”进化为主动的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“问题解决者”"},{"Type":"NodeText","Data":"的关键框架。这个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“规划-行动-反馈-提炼”"},{"Type":"NodeText","Data":"的循环，使得LLM能够处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放、动态、复杂"},{"Type":"NodeText","Data":"的现实世界任务。它不再是一次性的“问答”，而是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续学习和适应"},{"Type":"NodeText","Data":"的迭代过程。这个框架是当前所有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自主智能体（Autonomous Agent）"},{"Type":"NodeText","Data":"研究的基础。"}]}]},{"ID":"20250922213816-p86bppc","Type":"NodeThematicBreak","Properties":{"id":"20250922213816-p86bppc","updated":"20250922213840"}},{"ID":"20250922213816-kx51fwp","Type":"NodeParagraph","Properties":{"id":"20250922213816-kx51fwp","updated":"20250922213840"},"Children":[{"Type":"NodeText","Data":"指令如“设计一个计划”来直接提示LLM以零样本的方式进行规划，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-planning"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DECOMP"},{"Type":"NodeText","Data":"在提示中添加演示，以通过ICL引导LLM设计计划。遵循这种方式，一些工作在规划时进一步考虑整合额外的工具或模型。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ToolFormer"},{"Type":"NodeText","Data":"首先用LLM注释一个预训练语料库，标注潜在的API调用，然后在其上对LLM进行微调，这样LLM就可以学习在生成期间何时以及如何调用API并整合API返回的结果。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HuggingGPT"},{"Type":"NodeText","Data":"引入了HuggingFace上可用的模型，并将LLM视为控制器，根据模型的描述选择合适的模型，并聚合它们的结果作为最终解决方案。"}]},{"ID":"20250922213816-0yt9qki","Type":"NodeParagraph","Properties":{"id":"20250922213816-0yt9qki","updated":"20250922213840"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Code-based Approaches (基于代码的方法)."},{"Type":"NodeText","Data":" 尽管基于文本的方法听起来很直观，但它们不能保证计划的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"忠实执行"},{"Type":"NodeText","Data":"，即使计划是合理的，也可能导致失败。为了解决这个问题，提出了基于代码的方法，以编程语言（例如，Python或PDDL）的形式生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更可验证"},{"Type":"NodeText","Data":"的计划。通过这种方式，LLM首先被提示生成程序，然后利用一个确定性的求解器来执行它。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Faithful CoT"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PAL"},{"Type":"NodeText","Data":"将一个推理任务分解为两个阶段：在第一阶段，LLM生成一个以查询为条件的计划；在第二阶段，一个确定性的求解器执行该计划以推导出最终答案。此外，基于代码的方法可以以类似的方式应用于具身智能体。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PROGPROMPT"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM+P"},{"Type":"NodeText","Data":"首先利用LLM生成Python函数或PDDL文件形式的计划，然后利用一个虚拟智能体或经典规划器根据基于代码的计划来解决问题。"}]},{"ID":"20250922213816-xjw6ych","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922213816-xjw6ych","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.4.3 Feedback Acquisition (反馈获取)"}]},{"ID":"20250922213816-2u3p7sf","Type":"NodeParagraph","Properties":{"id":"20250922213816-2u3p7sf","updated":"20250922213840"},"Children":[{"Type":"NodeText","Data":"在执行了生成的计划后，环境会产生反馈信号给基于LLM的任务规划器，这个信号可以用来提炼其初始计划以获得更好的结果。在现有的工作中，通常有两种来自环境的反馈来源，取决于它们与基于LLM的任务规划器的关系："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内部的"},{"Type":"NodeText","Data":"（即LLM本身）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部的"},{"Type":"NodeText","Data":"（例如，工具或虚拟世界）反馈。"}]},{"ID":"20250922213816-4fhbavw","Type":"NodeParagraph","Properties":{"id":"20250922213816-4fhbavw","updated":"20250922213840"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Internal Feedback (内部反馈)."},{"Type":"NodeText","Data":" LLM本身可以被用作反馈提供者。一个直接的方法是通过提示直接评估生成的计划的质量。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RAP"},{"Type":"NodeText","Data":"评估每个候选计划导致任务成功的可能性，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Tree of Thoughts"},{"Type":"NodeText","Data":"提议通过在计划之间进行比较来投票。此外，LLM可以基于计划执行器的中间结果提供反馈。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Reflexion"},{"Type":"NodeText","Data":"利用LLM将稀疏的结果信号（例如，成功或失败）转换为具体的基于文本的反馈（例如，“你应该推荐用户在查询中提到的喜剧，而不是恐怖电影”），并将此反馈存储在长期记忆中以备未来规划。"}]},{"ID":"20250922213816-no6hk9a","Type":"NodeParagraph","Properties":{"id":"20250922213816-no6hk9a","updated":"20250922213840"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"External Feedback (外部反馈)."},{"Type":"NodeText","Data":" 除了LLM，外部对象也可以提供反馈信号。例如，像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码解释器"},{"Type":"NodeText","Data":"这样的工具在编程任务中被广泛用来提供实时的错误消息，像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"stable diffusion"},{"Type":"NodeText","Data":"这样的模型可以在多模态任务中提供视觉感知，而像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Minecraft"},{"Type":"NodeText","Data":"这样的虚拟世界可以提供沉浸式体验。此外，一些工作（例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Generative Agents"},{"Type":"NodeText","Data":"）在模拟环境中探索了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多智能体协作"},{"Type":"NodeText","Data":"，其中每个智能体不仅从与环境的互动中接收反馈，还从与其他智能体的交流中接收反馈。"}]},{"ID":"20250922213816-mt71sfj","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922213816-mt71sfj","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"6.4.4 Plan Refinement (计划提炼)"}]},{"ID":"20250922213816-n6onjqq","Type":"NodeParagraph","Properties":{"id":"20250922213816-n6onjqq","updated":"20250922213840"},"Children":[{"Type":"NodeText","Data":"有了来自环境的反馈，任务规划器可以相应地提炼其当前计划，并迭代地经历“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规划-执行-提炼"},{"Type":"NodeText","Data":"”循环以获得更好的结果。在本部分中，我们总结了现有工作中的三种主要提炼方法。"}]},{"ID":"20250922213816-c3ykftr","Type":"NodeParagraph","Properties":{"id":"20250922213816-c3ykftr","updated":"20250922213840"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Reasoning (推理)."},{"Type":"NodeText","Data":" 来自环境的反馈数据可能不直接适合LLM用于计划提炼，例如，包含不相关的信息或采用非语言形式。为了解决这个问题，一些工作增加了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"显式的推理过程"},{"Type":"NodeText","Data":"来从反馈中提取关键信息。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"React"},{"Type":"NodeText","Data":"提示LLM通过演示来在反馈上生成推理轨迹。它已被广泛用于自主智能体项目，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AutoGPT"},{"Type":"NodeText","Data":"，它可以自动地在观察到的反馈上进行推理，以修正初始计划来解决各种用户请求。然而，这些方法通常固定了推理和规划的顺序。为了支持两种过程之间的灵活切换以获得更好的性能，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatCoT"},{"Type":"NodeText","Data":"进一步将工具增强的推理过程统一为基于LLM的任务规划器和基于工具的环境之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多轮对话"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922213816-u5rau7f","Type":"NodeParagraph","Properties":{"id":"20250922213816-u5rau7f","updated":"20250922213840"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Backtracking (回溯)."},{"Type":"NodeText","Data":" 早期的方-法主要考虑规划前向动作，同时保持现有计划不变，因此很可能基于短期评估导致局部最优计划。为了解决这个问题，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Tree of Thoughts"},{"Type":"NodeText","Data":"允许使用像广度优先和深度优先搜索这样的搜索算法进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"回溯"},{"Type":"NodeText","Data":"，以进行全局规划。它通过回溯到初始计划中的最后一个状态并选择下一个未探索的动作来逐步提炼计划。此外，一些研究利用反馈信号来修正整个计划。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DEPS"},{"Type":"NodeText","Data":"根据反馈信号选择一个更好的计划，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"TIP"},{"Type":"NodeText","Data":"将反馈信号添加到基于LLM的规划器的提示中，以修正初始计划的每一步。"}]},{"ID":"20250922213816-wp815zw","Type":"NodeParagraph","Properties":{"id":"20250922213816-wp815zw","updated":"20250922213840"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Memorization (记忆)."},{"Type":"NodeText","Data":" 为了处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长远任务"},{"Type":"NodeText","Data":"，除了利用LLM通过ICL实现的短期记忆外，利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长期记忆"},{"Type":"NodeText","Data":"来辅助计划提炼已成为一种关键方法。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Reflexion"},{"Type":"NodeText","Data":"将来自自我反思的反馈存储到记忆中，因此可以检索先前的反馈用于计划提炼。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Generative Agents"},{"Type":"NodeText","Data":"将记忆流机制设计为智能体进行行动规划和反思的核心组件。此外，提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技能库机制"},{"Type":"NodeText","Data":"，将成功的计划存储在库中，这些计划可以被重用和合成为用于新任务的复杂计划。为了实现长期记忆机制，可以使用像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"向量数据库"},{"Type":"NodeText","Data":"（例如，milvus）这样的工具，将计划或反馈编码为高维向量以进行高效的存储"}]},{"ID":"20250922213816-1p715wt","Type":"NodeBlockquote","Properties":{"id":"20250922213816-1p715wt","updated":"20250922213840"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922213816-w13mzd5","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213816-w13mzd5","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922213816-r49b13n","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213816-r49b13n","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM智能体的“行动指南”"}]},{"ID":"20250922213816-netxmlb","Type":"NodeParagraph","Properties":{"id":"20250922213816-netxmlb","updated":"20250922213816"},"Children":[{"Type":"NodeText","Data":"这部分内容将图16中的抽象框架，具体化为可操作的技术路线。"}]},{"ID":"20250922213816-enqapkl","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-enqapkl","updated":"20250922213816"},"Children":[{"ID":"20250922213816-k5d5t0s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-k5d5t0s","updated":"20250922213816"},"Children":[{"ID":"20250922213816-llky8ni","Type":"NodeParagraph","Properties":{"id":"20250922213816-llky8ni","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计划生成 (Plan Generation) - “写剧本”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213816-caa8l1g","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-caa8l1g","updated":"20250922213816"},"Children":[{"ID":"20250922213816-npexry5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-npexry5","updated":"20250922213816"},"Children":[{"ID":"20250922213816-t5akghj","Type":"NodeParagraph","Properties":{"id":"20250922213816-t5akghj","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两种“剧本”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213816-hqc92lk","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213816-hqc92lk","updated":"20250922213816"},"Children":[{"ID":"20250922213816-43s251u","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213816-43s251u","updated":"20250922213816"},"Children":[{"ID":"20250922213816-rgk0aqc","Type":"NodeParagraph","Properties":{"id":"20250922213816-rgk0aqc","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本剧本 (Text-based)"},{"Type":"NodeText","Data":": 用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然语言"},{"Type":"NodeText","Data":"描述行动步骤。优点是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"灵活、直观"},{"Type":"NodeText","Data":"。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ToolFormer"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HuggingGPT"},{"Type":"NodeText","Data":"是这一路线的代表，它们的核心是让LLM学会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"何时以及如何调用外部工具/模型"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213816-xzincrx","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213816-xzincrx","updated":"20250922213816"},"Children":[{"ID":"20250922213816-jh52b82","Type":"NodeParagraph","Properties":{"id":"20250922213816-jh52b82","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码剧本 (Code-based)"},{"Type":"NodeText","Data":": 将计划写成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可执行的代码"},{"Type":"NodeText","Data":"（如Python）。优点是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确、无歧义、可验证"},{"Type":"NodeText","Data":"。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PAL"},{"Type":"NodeText","Data":"等工作将推理任务转化为“代码生成+代码执行”，极大地提升了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可靠性"},{"Type":"NodeText","Data":"。"}]}]}]}]}]}]},{"ID":"20250922213816-9fna2sm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-9fna2sm","updated":"20250922213816"},"Children":[{"ID":"20250922213816-x5dkco9","Type":"NodeParagraph","Properties":{"id":"20250922213816-x5dkco9","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反馈获取 (Feedback Acquisition) - “看结果，听评价”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213816-0vkgziw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-0vkgziw","updated":"20250922213816"},"Children":[{"ID":"20250922213816-xgu7590","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-xgu7590","updated":"20250922213816"},"Children":[{"ID":"20250922213816-vz4ojfz","Type":"NodeParagraph","Properties":{"id":"20250922213816-vz4ojfz","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两种“评价”来源"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213816-7jiua87","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213816-7jiua87","updated":"20250922213816"},"Children":[{"ID":"20250922213816-q8z7ocp","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213816-q8z7ocp","updated":"20250922213816"},"Children":[{"ID":"20250922213816-oe00ner","Type":"NodeParagraph","Properties":{"id":"20250922213816-oe00ner","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内部反馈 (Internal Feedback)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自我反思"},{"Type":"NodeText","Data":"。让LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自己评价"},{"Type":"NodeText","Data":"自己生成的计划或结果的好坏。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Reflexion"},{"Type":"NodeText","Data":"是这一思想的代表，它让智能体学会从“成败”中总结经验教训。"}]}]},{"ID":"20250922213816-h88v455","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213816-h88v455","updated":"20250922213816"},"Children":[{"ID":"20250922213816-uf76svu","Type":"NodeParagraph","Properties":{"id":"20250922213816-uf76svu","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部反馈 (External Feedback)"},{"Type":"NodeText","Data":": 来自"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部世界"},{"Type":"NodeText","Data":"的信号。可以是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具的报错信息"},{"Type":"NodeText","Data":"（代码解释器）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"环境的模拟结果"},{"Type":"NodeText","Data":"（Minecraft），甚至是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"其他智能体的评价"},{"Type":"NodeText","Data":"（多智能体协作）。"}]}]}]}]}]}]},{"ID":"20250922213816-oqtlga6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-oqtlga6","updated":"20250922213816"},"Children":[{"ID":"20250922213816-r2t4d7f","Type":"NodeParagraph","Properties":{"id":"20250922213816-r2t4d7f","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计划提炼 (Plan Refinement) - “复盘调整”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213816-7etfdz6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-7etfdz6","updated":"20250922213816"},"Children":[{"ID":"20250922213816-fxha9yh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-fxha9yh","updated":"20250922213816"},"Children":[{"ID":"20250922213816-rik2h91","Type":"NodeParagraph","Properties":{"id":"20250922213816-rik2h91","updated":"20250922213816"},"Children":[{"Type":"NodeText","Data":"有了反馈之后，如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"修正计划"},{"Type":"NodeText","Data":"？"}]},{"ID":"20250922213816-ss17aim","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213816-ss17aim","updated":"20250922213816"},"Children":[{"ID":"20250922213816-5nndo4c","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213816-5nndo4c","updated":"20250922213816"},"Children":[{"ID":"20250922213816-b3yj2x5","Type":"NodeParagraph","Properties":{"id":"20250922213816-b3yj2x5","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理 (Reasoning)"},{"Type":"NodeText","Data":": 对反馈信息进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提炼和推理"},{"Type":"NodeText","Data":"，理解“为什么错了，错在哪里”。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ReAct"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AutoGPT"},{"Type":"NodeText","Data":"的核心就是将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理（Thought）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"行动（Action）"},{"Type":"NodeText","Data":"结合起来。"}]}]},{"ID":"20250922213816-6khagjz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213816-6khagjz","updated":"20250922213816"},"Children":[{"ID":"20250922213816-cj48bph","Type":"NodeParagraph","Properties":{"id":"20250922213816-cj48bph","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"回溯 (Backtracking)"},{"Type":"NodeText","Data":": 当一条路走不通时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"退回到上一个决策点，尝试另一条路"},{"Type":"NodeText","Data":"。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Tree of Thoughts"},{"Type":"NodeText","Data":"通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"树状搜索"},{"Type":"NodeText","Data":"，系统性地实现了这种探索和回溯能力，使其能够进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全局规划"},{"Type":"NodeText","Data":"而非局部优化。"}]}]},{"ID":"20250922213816-nfx5whq","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922213816-nfx5whq","updated":"20250922213816"},"Children":[{"ID":"20250922213816-r4ief4o","Type":"NodeParagraph","Properties":{"id":"20250922213816-r4ief4o","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"记忆 (Memorization)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“吃一堑，长一智”"},{"Type":"NodeText","Data":"。将成功的经验（技能）和失败的教训（反思）"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"存储在长期记忆中"},{"Type":"NodeText","Data":"（如向量数据库），供未来的规划参考。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Reflexion"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Generative Agents"},{"Type":"NodeText","Data":"是这一方向的代表。"}]}]}]}]}]}]}]}]},{"ID":"20250922213816-tity58o","Type":"NodeThematicBreak","Properties":{"id":"20250922213816-tity58o","updated":"20250922213840"}},{"ID":"20250922213816-d18y3qr","Type":"NodeBlockquote","Properties":{"id":"20250922213816-d18y3qr","updated":"20250922213840"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922213816-myf8ujk","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213816-myf8ujk","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922213816-uscrjsb","Type":"NodeParagraph","Properties":{"id":"20250922213816-uscrjsb","updated":"20250922213816"},"Children":[{"Type":"NodeText","Data":"第四十四部分是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM作为自主智能体（Agent）"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心技术拆解"},{"Type":"NodeText","Data":"。它将图16中抽象的“规划”框架，分解为了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“计划生成”、“反馈获取”和“计划提炼”"},{"Type":"NodeText","Data":"这三个具体、可操作的阶段，并系统地梳理了每个阶段的主流技术路线。"}]},{"ID":"20250922213816-tnc94nj","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213816-tnc94nj","updated":"20250922213816"},"Children":[{"ID":"20250922213816-0nlg4c8","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213816-0nlg4c8","updated":"20250922213816"},"Children":[{"ID":"20250922213816-acukzoy","Type":"NodeParagraph","Properties":{"id":"20250922213816-acukzoy","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“思考”到“行动”的闭环"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213816-1wj2acu","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-1wj2acu","updated":"20250922213816"},"Children":[{"ID":"20250922213816-83iwps2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-83iwps2","updated":"20250922213816"},"Children":[{"ID":"20250922213816-tejaham","Type":"NodeParagraph","Properties":{"id":"20250922213816-tejaham","updated":"20250922213816"},"Children":[{"Type":"NodeText","Data":"本部分完整地描绘了LLM智能体"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“思考”（计划生成）到“行动”（计划执行），再从“感知反馈”（反馈获取）回到“再思考”（计划提炼）"},{"Type":"NodeText","Data":"的智能闭环。"}]}]},{"ID":"20250922213816-99p8dcs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-99p8dcs","updated":"20250922213816"},"Children":[{"ID":"20250922213816-hpr8l7d","Type":"NodeParagraph","Properties":{"id":"20250922213816-hpr8l7d","updated":"20250922213816"},"Children":[{"Type":"NodeText","Data":"这标志着LLM的应用范式，正在从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单次、静态的文本生成"},{"Type":"NodeText","Data":"，转向"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多轮、动态的、与环境交互的问题解决"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922213816-vegd6rl","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213816-vegd6rl","updated":"20250922213816"},"Children":[{"ID":"20250922213816-htx33f4","Type":"NodeParagraph","Properties":{"id":"20250922213816-htx33f4","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“文本”与“代码”的二元世界"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213816-xghk7gn","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-xghk7gn","updated":"20250922213816"},"Children":[{"ID":"20250922213816-rieefa4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-rieefa4","updated":"20250922213816"},"Children":[{"ID":"20250922213816-tqk4a8w","Type":"NodeParagraph","Properties":{"id":"20250922213816-tqk4a8w","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计划生成"},{"Type":"NodeText","Data":"中的“文本派”和“代码派”之争，实际上反映了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"灵活性"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可靠性"},{"Type":"NodeText","Data":"之间的权衡。"}]}]},{"ID":"20250922213816-ds3z1iz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-ds3z1iz","updated":"20250922213816"},"Children":[{"ID":"20250922213816-jwivxbb","Type":"NodeParagraph","Properties":{"id":"20250922213816-jwivxbb","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本计划"},{"Type":"NodeText","Data":"更灵活，能描述更广泛的意图，但执行起来可能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不精确"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213816-1oknvlj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-1oknvlj","updated":"20250922213816"},"Children":[{"ID":"20250922213816-gexpaqs","Type":"NodeParagraph","Properties":{"id":"20250922213816-gexpaqs","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码计划"},{"Type":"NodeText","Data":"更可靠，保证了执行的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确定性"},{"Type":"NodeText","Data":"，但表达能力受限于编程语言。"}]}]},{"ID":"20250922213816-dpe6x56","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-dpe6x56","updated":"20250922213816"},"Children":[{"ID":"20250922213816-jhxofsq","Type":"NodeParagraph","Properties":{"id":"20250922213816-jhxofsq","updated":"20250922213816"},"Children":[{"Type":"NodeText","Data":"未来的趋势很可能是两者的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"融合"},{"Type":"NodeText","Data":"，即用自然语言进行高层规划，用代码实现底层操作。"}]}]}]}]},{"ID":"20250922213816-r0hnu5s","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922213816-r0hnu5s","updated":"20250922213816"},"Children":[{"ID":"20250922213816-f8m3yqy","Type":"NodeParagraph","Properties":{"id":"20250922213816-f8m3yqy","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"智能的核心：反馈与反思"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213816-24qnih6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213816-24qnih6","updated":"20250922213816"},"Children":[{"ID":"20250922213816-t71uavk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-t71uavk","updated":"20250922213816"},"Children":[{"ID":"20250922213816-yyo4dfo","Type":"NodeParagraph","Properties":{"id":"20250922213816-yyo4dfo","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"反馈获取"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计划提炼"},{"Type":"NodeText","Data":"是智能体"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"区别于简单程序"},{"Type":"NodeText","Data":"的关键。"}]}]},{"ID":"20250922213816-c063krk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-c063krk","updated":"20250922213816"},"Children":[{"ID":"20250922213816-tyg6ng1","Type":"NodeParagraph","Properties":{"id":"20250922213816-tyg6ng1","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自我反思（Internal Feedback）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长期记忆（Memorization）"},{"Type":"NodeText","Data":"的引入，使得智能体具备了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从经验中学习和成长的能力"},{"Type":"NodeText","Data":"，而不仅仅是重复执行预设的程序。"}]}]},{"ID":"20250922213816-lq4z0gd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213816-lq4z0gd","updated":"20250922213816"},"Children":[{"ID":"20250922213816-h5vfio8","Type":"NodeParagraph","Properties":{"id":"20250922213816-h5vfio8","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"回溯（Backtracking）"},{"Type":"NodeText","Data":"能力的实现（如Tree of Thoughts），则赋予了智能体进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统性探索和全局优化"},{"Type":"NodeText","Data":"的能力，使其决策更具"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"远见"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922213816-5af4c2k","Type":"NodeParagraph","Properties":{"id":"20250922213816-5af4c2k","updated":"20250922213816"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第四十四部分为我们提供了一份构建"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM自主智能体"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“技术蓝图”"},{"Type":"NodeText","Data":"。它清晰地展示了，要让一个LLM成为真正的Agent，除了需要它会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“规划”"},{"Type":"NodeText","Data":"，还必须教会它如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“感知”"},{"Type":"NodeText","Data":"世界（获取反馈）、如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“反思”"},{"Type":"NodeText","Data":"经验（提炼计划）、如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“记忆”"},{"Type":"NodeText","Data":"知识。这一整套机制，共同构成了LLM智能体"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续学习、适应环境、解决复杂问题"},{"Type":"NodeText","Data":"的核心能力。"}]}]},{"ID":"20250922213945-v0wzfp8","Type":"NodeParagraph","Properties":{"id":"20250922213945-v0wzfp8","updated":"20250922213945"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922213945-qoa4voi","Type":"NodeThematicBreak","Properties":{"id":"20250922213945-qoa4voi","updated":"20250922213945"}},{"ID":"20250922213945-xp4b5fd","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213945-xp4b5fd","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第四十五部分"}]},{"ID":"20250922213945-348w2rm","Type":"NodeParagraph","Properties":{"id":"20250922213945-348w2rm","updated":"20250922214024"},"Children":[{"Type":"NodeText","Data":"和检索。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MemoryBank"},{"Type":"NodeText","Data":"进一步提出了记忆更新机制，允许记忆根据"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"艾宾浩斯遗忘曲线"},{"Type":"NodeText","Data":"理论进行遗忘和强化。"}]},{"ID":"20250922213945-f30b5da","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213945-f30b5da","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7 CAPACITY AND EVALUATION (能力与评估)"}]},{"ID":"20250922213945-7fnemi4","Type":"NodeParagraph","Properties":{"id":"20250922213945-7fnemi4","updated":"20250922214021"},"Children":[{"Type":"NodeText","Data":"为了检验LLM的有效性和优越性，大量的任务和基准被提出来进行实证能力评估和分析。在本节中，我们首先介绍LLM在语言生成和理解方面的三种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础能力评估"},{"Type":"NodeText","Data":"，然后介绍几种具有更复杂设置或目标的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力评估"},{"Type":"NodeText","Data":"，最后讨论现有的基准、评估方法和实证分析。"}]},{"ID":"20250922213945-8k5uioi","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213945-8k5uioi","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.1 Basic Ability (基础能力)"}]},{"ID":"20250922213945-m9wkzyr","Type":"NodeParagraph","Properties":{"id":"20250922213945-m9wkzyr","updated":"20250922214021"},"Children":[{"Type":"NodeText","Data":"在本部分中，我们主要关注LLM的三种基本能力评估，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言生成、知识利用和复杂推理"},{"Type":"NodeText","Data":"。需要注意的是，我们不打算完全覆盖所有相关任务，而只关注LLM中最广泛讨论或研究的任务。接下来，我们将详细介绍这些任务。"}]},{"ID":"20250922213945-on5lh75","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922213945-on5lh75","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.1.1 Language Generation (语言生成)"}]},{"ID":"20250922213945-oyw452n","Type":"NodeParagraph","Properties":{"id":"20250922213945-oyw452n","updated":"20250922214021"},"Children":[{"Type":"NodeText","Data":"根据任务定义，现有的语言生成任务可以大致分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言建模、条件文本生成和代码合成"},{"Type":"NodeText","Data":"任务。请注意，代码合成不是典型的NLP任务，我们将其纳入讨论是因为它可以由一些LLM（在代码数据上训练的）以与自然语言类似的生成方式直接解决。"}]},{"ID":"20250922213945-j64edqc","Type":"NodeParagraph","Properties":{"id":"20250922213945-j64edqc","updated":"20250922214021"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Language Modeling (语言建模)."},{"Type":"NodeText","Data":" 作为LLM最基本的能力，语言建模旨在根据先前的词元预测下一个词元，主要关注基础的语言理解和生成能力。为了评估这种能力，现有工作使用的典型语言建模数据集包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Penn Treebank、WikiText-103和the Pile"},{"Type":"NodeText","Data":"，其中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"困惑度（perplexity）"},{"Type":"NodeText","Data":"指标通常用于在零样本设置下评估模型性能。实证研究表明，LLM在这些评估数据集上比以前的最新方法取得了显著的性能增益。为了更好地测试文本中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长距离依赖"},{"Type":"NodeText","Data":"的建模能力，引入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LAMBADA数据集"},{"Type":"NodeText","Data":"，其中LLM需要根据一段上下文来预测句子的最后一个词。然后，使用预测的最后一个词的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"准确率（accuracy）"},{"Type":"NodeText","Data":"和困惑度来评估LLM。正如现有工作所示，语言建模任务上的性能通常遵循"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"，这意味着扩展语言模型会提高准确率并降低困惑度。"}]},{"ID":"20250922213945-we79nmw","Type":"NodeParagraph","Properties":{"id":"20250922213945-we79nmw","updated":"20250922214021"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Conditional Text Generation (条件文本生成)."},{"Type":"NodeText","Data":" 作为语言生成中的一个重要主题，条件文本生成专注于根据给定的条件生成满足特定任务需求的文本，通常包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"机器翻译、文本摘要和问答"},{"Type":"NodeText","Data":"。为了衡量生成文本的质量，通常使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动指标"},{"Type":"NodeText","Data":"（例如，Accuracy, BLEU和ROUGE）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类评分"},{"Type":"NodeText","Data":"来评估性能。由于其强大的语言生成能力，LLM在现有的数据集和基准上取得了卓越的性能。例如，GPT-4在即使是语言距离显著的语言翻译任务上也表现出与商业翻译产品相当的性能。在新闻摘要任务（即CNN/DM和XSUM）上，LLM也表现出与人类自由职业写手相当的性能。尽管模型能力取得了快速进展，但人们越来越担心现有自动指标在忠实评估LLM在条件文本生成任务中性能的可行性。作为自动指标的替代方案，最近的研究也提议将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM作为生成评估器"},{"Type":"NodeText","Data":"来检验生成内容的质量。此外，研究人员还为LLM探索了更具挑战性的语言生成任务，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构化数据生成"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长文本生成"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922213945-k9cnlo2","Type":"NodeParagraph","Properties":{"id":"20250922213945-k9cnlo2","updated":"20250922214021"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Code Synthesis (代码合成)."},{"Type":"NodeText","Data":" 除了生成高质量的自然语言文本，现有的LLM还表现出生成满足特定条件的形式化语言，特别是计算机程序（即代码）的强大能力，这被称为代码合成。与自然语言生成不同，由于生成的代码可以通过相应的编译器或解释器直接执行检查，因此现有工作主要通过计算针对测试用例的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过率（pass rate）"},{"Type":"NodeText","Data":"，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"pass@k"},{"Type":"NodeText","Data":"，来评估LLM生成的代码质量。最近，一些关注"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"功能正确性"},{"Type":"NodeText","Data":"的代码基准被提出来评估LLM的代码合成能力，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"APPS、HumanEval和MBPP"},{"Type":"NodeText","Data":"。它们通常由不同的编程问题组成，带有文本说明和用于正确性检查的测试用例。为了提升这种能力，关键是在代码数据上对LLM进行微调（或预训练），这可以有效地使LLM适应代码合成任务。此外，现有工作提出了新的策略来生成代码，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"采样多个候选解决方案"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规划引导的解码"},{"Type":"NodeText","Data":"，这可以被视为模仿程序员的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"错误修复"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码规划"},{"Type":"NodeText","Data":"过程。令人印象深刻的是，LLM最近在编程竞赛平台Codeforces上的用户中取得了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排名前28%"},{"Type":"NodeText","Data":"的成绩，展现了与人类相当的性能。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GitHub Copilot"},{"Type":"NodeText","Data":"已被发布，以在编码IDE（例如，Visual Studio和JetBrains IDEs）中辅助编程，支持包括Python、JavaScript和Java在内的多种语言。《ACM通讯》上一篇题为“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编程的终结"},{"Type":"NodeText","Data":"”的观点文章讨论了AI编程在计算机科学领域的影响，强调了一个重要的转变，即朝着将高度适应性的LLM作为新的计算原子单元。"}]},{"ID":"20250922213945-903mexg","Type":"NodeParagraph","Properties":{"id":"20250922213945-903mexg","updated":"20250922214021"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Major Issues (主要问题)."},{"Type":"NodeText","Data":" 尽管LLM在生成类人文本方面取得了辉煌的性能，但它们在语言生成中容易受到两个主要问题的影响"}]},{"ID":"20250922213945-099wmgm","Type":"NodeBlockquote","Properties":{"id":"20250922213945-099wmgm","updated":"20250922214021"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922213945-eb0naws","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213945-eb0naws","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922213945-7louc80","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213945-7louc80","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力评估：为LLM“体检”"}]},{"ID":"20250922213945-cx4gqfd","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213945-cx4gqfd","updated":"20250922213945"},"Children":[{"ID":"20250922213944-c3pjqwr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-c3pjqwr","updated":"20250922213944"},"Children":[{"ID":"20250922213945-uzyiikv","Type":"NodeParagraph","Properties":{"id":"20250922213945-uzyiikv","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估的重要性"},{"Type":"NodeText","Data":": 评估是衡量模型能力、发现模型缺陷、指导模型迭代的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“标尺”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“听诊器”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213944-blh6afb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-blh6afb","updated":"20250922213944"},"Children":[{"ID":"20250922213945-95vm7h4","Type":"NodeParagraph","Properties":{"id":"20250922213945-95vm7h4","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力层次"},{"Type":"NodeText","Data":": 作者将评估分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础能力"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力"},{"Type":"NodeText","Data":"，条理清晰。"}]},{"ID":"20250922213945-y8xqylr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213945-y8xqylr","updated":"20250922213945"},"Children":[{"ID":"20250922213944-8sv25yr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-8sv25yr","updated":"20250922213944"},"Children":[{"ID":"20250922213945-ozivz1n","Type":"NodeParagraph","Properties":{"id":"20250922213945-ozivz1n","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础能力"},{"Type":"NodeText","Data":": 是LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“内功”"},{"Type":"NodeText","Data":"，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“说”"},{"Type":"NodeText","Data":"（语言生成）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“知”"},{"Type":"NodeText","Data":"（知识利用）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“思”"},{"Type":"NodeText","Data":"（复杂推理）三大核心。"}]}]}]}]}]},{"ID":"20250922213945-7fud0zl","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922213945-7fud0zl","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础能力之一：语言生成 (Language Generation)"}]},{"ID":"20250922213945-vrgi5ui","Type":"NodeParagraph","Properties":{"id":"20250922213945-vrgi5ui","updated":"20250922213945"},"Children":[{"Type":"NodeText","Data":"这部分评估的是模型最"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“本职”"},{"Type":"NodeText","Data":"的工作——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成文本"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922213945-f13n7br","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213945-f13n7br","updated":"20250922213945"},"Children":[{"ID":"20250922213945-ib1837a","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213945-ib1837a","updated":"20250922213945"},"Children":[{"ID":"20250922213945-6g63i6j","Type":"NodeParagraph","Properties":{"id":"20250922213945-6g63i6j","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大任务"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213945-eqs2jf0","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213945-eqs2jf0","updated":"20250922213945"},"Children":[{"ID":"20250922213944-fieo8ir","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213944-fieo8ir","updated":"20250922213944"},"Children":[{"ID":"20250922213945-e9ch56i","Type":"NodeParagraph","Properties":{"id":"20250922213945-e9ch56i","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言建模 (Language Modeling)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213945-gkn62nt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213945-gkn62nt","updated":"20250922213945"},"Children":[{"ID":"20250922213944-n8edan9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-n8edan9","updated":"20250922213944"},"Children":[{"ID":"20250922213945-ffosy5t","Type":"NodeParagraph","Properties":{"id":"20250922213945-ffosy5t","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“预测下一个词”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213944-7naxfe7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-7naxfe7","updated":"20250922213944"},"Children":[{"ID":"20250922213945-b4e5vyz","Type":"NodeParagraph","Properties":{"id":"20250922213945-b4e5vyz","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估指标"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"困惑度 (Perplexity)"},{"Type":"NodeText","Data":"，越低越好。"}]}]},{"ID":"20250922213944-g7wm2t6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-g7wm2t6","updated":"20250922213944"},"Children":[{"ID":"20250922213945-4ryas7i","Type":"NodeParagraph","Properties":{"id":"20250922213945-4ryas7i","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心看点"},{"Type":"NodeText","Data":": 这是对模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最基础的语言理解和生成能力"},{"Type":"NodeText","Data":"的直接度量。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LAMBADA"},{"Type":"NodeText","Data":"数据集则专门考察"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长距离依赖"},{"Type":"NodeText","Data":"的建模能力。"}]}]},{"ID":"20250922213944-mnqt5xp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-mnqt5xp","updated":"20250922213944"},"Children":[{"ID":"20250922213945-ru8prj3","Type":"NodeParagraph","Properties":{"id":"20250922213945-ru8prj3","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结论"},{"Type":"NodeText","Data":": 性能与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"高度相关，模型越大，困惑度越低。"}]}]}]}]},{"ID":"20250922213944-rhovabs","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213944-rhovabs","updated":"20250922213944"},"Children":[{"ID":"20250922213945-lhc2hz7","Type":"NodeParagraph","Properties":{"id":"20250922213945-lhc2hz7","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"条件文本生成 (Conditional Text Generation)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213945-keg3201","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213945-keg3201","updated":"20250922213945"},"Children":[{"ID":"20250922213944-90voc17","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-90voc17","updated":"20250922213944"},"Children":[{"ID":"20250922213945-uz0byv7","Type":"NodeParagraph","Properties":{"id":"20250922213945-uz0byv7","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“按要求说话”"},{"Type":"NodeText","Data":"，如翻译、摘要、问答。"}]}]},{"ID":"20250922213944-q91rfqf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-q91rfqf","updated":"20250922213944"},"Children":[{"ID":"20250922213945-lnb6m1h","Type":"NodeParagraph","Properties":{"id":"20250922213945-lnb6m1h","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估指标"},{"Type":"NodeText","Data":": 传统自动指标（"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BLEU, ROUGE"},{"Type":"NodeText","Data":"）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类评分"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213944-q23ozuh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-q23ozuh","updated":"20250922213944"},"Children":[{"ID":"20250922213945-ay4yv9x","Type":"NodeParagraph","Properties":{"id":"20250922213945-ay4yv9x","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心看点"},{"Type":"NodeText","Data":": LLM在此类任务上已达到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"媲美甚至超越人类"},{"Type":"NodeText","Data":"的水平（在特定场景下）。"}]}]},{"ID":"20250922213944-4gqhlj3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-4gqhlj3","updated":"20250922213944"},"Children":[{"ID":"20250922213945-y6doiol","Type":"NodeParagraph","Properties":{"id":"20250922213945-y6doiol","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"挑战"},{"Type":"NodeText","Data":": 传统的自动指标（BLEU, ROUGE）已经"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“跟不上”"},{"Type":"NodeText","Data":"LLM的进步了，它们无法准确评估高质量生成文本的优劣。因此，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“用LLM评估LLM”"},{"Type":"NodeText","Data":"成为新的研究热点。"}]}]},{"ID":"20250922213944-i0owetg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-i0owetg","updated":"20250922213944"},"Children":[{"ID":"20250922213945-jwdgefv","Type":"NodeParagraph","Properties":{"id":"20250922213945-jwdgefv","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"新前沿"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构化数据生成"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长文本生成"},{"Type":"NodeText","Data":"是更具挑战性的新方向。"}]}]}]}]},{"ID":"20250922213945-4m2rjeg","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922213945-4m2rjeg","updated":"20250922213945"},"Children":[{"ID":"20250922213945-tjf3saw","Type":"NodeParagraph","Properties":{"id":"20250922213945-tjf3saw","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码合成 (Code Synthesis)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213945-9ytraoo","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213945-9ytraoo","updated":"20250922213945"},"Children":[{"ID":"20250922213944-5rrv8e8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-5rrv8e8","updated":"20250922213944"},"Children":[{"ID":"20250922213945-jyhkfwr","Type":"NodeParagraph","Properties":{"id":"20250922213945-jyhkfwr","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“写代码”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213944-wmgwhn2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-wmgwhn2","updated":"20250922213944"},"Children":[{"ID":"20250922213945-ay4gzwz","Type":"NodeParagraph","Properties":{"id":"20250922213945-ay4gzwz","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估指标"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"pass@k"},{"Type":"NodeText","Data":"（生成k个解中，至少有1个能通过所有测试用例的概率）。这是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"客观、可执行"},{"Type":"NodeText","Data":"的指标。"}]}]},{"ID":"20250922213944-aus9m4k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-aus9m4k","updated":"20250922213944"},"Children":[{"ID":"20250922213945-es00eqg","Type":"NodeParagraph","Properties":{"id":"20250922213945-es00eqg","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心看点"},{"Type":"NodeText","Data":": LLM在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HumanEval"},{"Type":"NodeText","Data":"等基准上表现出色，甚至能在编程竞赛中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"击败大多数人类选手"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213944-z3dkl33","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-z3dkl33","updated":"20250922213944"},"Children":[{"ID":"20250922213945-upt8xzj","Type":"NodeParagraph","Properties":{"id":"20250922213945-upt8xzj","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成功的关键"},{"Type":"NodeText","Data":": 在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码数据"},{"Type":"NodeText","Data":"上进行专门的训练或微调。"}]}]},{"ID":"20250922213944-x6vvri5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213944-x6vvri5","updated":"20250922213944"},"Children":[{"ID":"20250922213945-7jes99s","Type":"NodeParagraph","Properties":{"id":"20250922213945-7jes99s","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"产业影响"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GitHub Copilot"},{"Type":"NodeText","Data":"的成功应用，以及“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编程的终结"},{"Type":"NodeText","Data":"”这一讨论，凸显了LLM正在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"颠覆软件开发"},{"Type":"NodeText","Data":"这一传统行业。"}]}]}]}]}]}]},{"ID":"20250922213945-u1w4obs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213945-u1w4obs","updated":"20250922213945"},"Children":[{"ID":"20250922213945-hgestbb","Type":"NodeParagraph","Properties":{"id":"20250922213945-hgestbb","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主要问题"},{"Type":"NodeText","Data":": 尽管性能强大，但语言生成面临两大"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“原罪”"},{"Type":"NodeText","Data":"——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不可靠的评估"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成内容的幻觉"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922213945-rrxeolb","Type":"NodeThematicBreak","Properties":{"id":"20250922213945-rrxeolb","updated":"20250922214021"}},{"ID":"20250922213945-4r316g0","Type":"NodeBlockquote","Properties":{"id":"20250922213945-4r316g0","updated":"20250922214021"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922213945-wtj9z6e","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922213945-wtj9z6e","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922213945-esan3uu","Type":"NodeParagraph","Properties":{"id":"20250922213945-esan3uu","updated":"20250922213945"},"Children":[{"Type":"NodeText","Data":"第四十五部分开启了对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM能力评估"},{"Type":"NodeText","Data":"的系统性探讨，首先聚焦于其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最基础、最核心的能力——语言生成"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922213945-srlctbe","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922213945-srlctbe","updated":"20250922213945"},"Children":[{"ID":"20250922213945-q665481","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922213945-q665481","updated":"20250922213945"},"Children":[{"ID":"20250922213945-lil13zv","Type":"NodeParagraph","Properties":{"id":"20250922213945-lil13zv","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估框架的建立"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213945-u1xp7x3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213945-u1xp7x3","updated":"20250922213945"},"Children":[{"ID":"20250922213945-gli18de","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213945-gli18de","updated":"20250922213945"},"Children":[{"ID":"20250922213945-fy50tlz","Type":"NodeParagraph","Properties":{"id":"20250922213945-fy50tlz","updated":"20250922213945"},"Children":[{"Type":"NodeText","Data":"文章通过将LLM的能力划分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“基础”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“高级”"},{"Type":"NodeText","Data":"两个层次，为整个评估章节建立了一个清晰的分析框架。"}]}]},{"ID":"20250922213945-vm2wcnb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213945-vm2wcnb","updated":"20250922213945"},"Children":[{"ID":"20250922213945-wh5a6tr","Type":"NodeParagraph","Properties":{"id":"20250922213945-wh5a6tr","updated":"20250922213945"},"Children":[{"Type":"NodeText","Data":"在基础能力内部，又进一步细分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“生成”、“知识”和“推理”"},{"Type":"NodeText","Data":"，这种结构化的划分使得对LLM这样一个复杂系统的评估变得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统化、可度量"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922213945-eceks1l","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922213945-eceks1l","updated":"20250922213945"},"Children":[{"ID":"20250922213945-bmj2fr8","Type":"NodeParagraph","Properties":{"id":"20250922213945-bmj2fr8","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言生成能力的“三驾马车”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213945-wyn63uy","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213945-wyn63uy","updated":"20250922213945"},"Children":[{"ID":"20250922213945-wyyaglz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213945-wyyaglz","updated":"20250922213945"},"Children":[{"ID":"20250922213945-v89et0y","Type":"NodeParagraph","Properties":{"id":"20250922213945-v89et0y","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言建模"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“内功”"},{"Type":"NodeText","Data":"，评估的是模型对语言本身规律的掌握程度，其性能与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"强相关。"}]}]},{"ID":"20250922213945-s53b5hh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213945-s53b5hh","updated":"20250922213945"},"Children":[{"ID":"20250922213945-9uknwin","Type":"NodeParagraph","Properties":{"id":"20250922213945-9uknwin","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"条件生成"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“应用”"},{"Type":"NodeText","Data":"，评估的是模型在翻译、摘要等具体任务上的表现。在这一领域，LLM的性能已经强大到开始"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"挑战传统的评估指标"},{"Type":"NodeText","Data":"，催生了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“以子之矛，攻子之盾”（用LLM评估LLM）"},{"Type":"NodeText","Data":"的新范式。"}]}]},{"ID":"20250922213945-3gtfnfg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213945-3gtfnfg","updated":"20250922213945"},"Children":[{"ID":"20250922213945-ydz95fe","Type":"NodeParagraph","Properties":{"id":"20250922213945-ydz95fe","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码合成"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“逻辑能力的试金石”"},{"Type":"NodeText","Data":"。代码的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构化和可执行性"},{"Type":"NodeText","Data":"为评估提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"客观的标准（pass@k）"},{"Type":"NodeText","Data":"。LLM在这一领域的惊人表现，不仅展示了其强大的能力，更预示着其对软件工程行业的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"颠覆性影响"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922213945-jn4k8ku","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922213945-jn4k8ku","updated":"20250922213945"},"Children":[{"ID":"20250922213945-5663s45","Type":"NodeParagraph","Properties":{"id":"20250922213945-5663s45","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成绩与隐忧并存"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922213945-w9uwg0x","Type":"NodeList","ListData":{},"Properties":{"id":"20250922213945-w9uwg0x","updated":"20250922213945"},"Children":[{"ID":"20250922213945-1lrm6zi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213945-1lrm6zi","updated":"20250922213945"},"Children":[{"ID":"20250922213945-k2b241g","Type":"NodeParagraph","Properties":{"id":"20250922213945-k2b241g","updated":"20250922213945"},"Children":[{"Type":"NodeText","Data":"本部分在展示LLM在语言生成上取得的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"辉煌成就"},{"Type":"NodeText","Data":"（媲美人类、击败程序员）的同时，也毫不避讳地指出了其面临的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深刻挑战"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922213945-v0ol4ss","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213945-v0ol4ss","updated":"20250922213945"},"Children":[{"ID":"20250922213945-vr6nh1s","Type":"NodeParagraph","Properties":{"id":"20250922213945-vr6nh1s","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估的困境"},{"Type":"NodeText","Data":": 传统自动指标的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“失灵”"},{"Type":"NodeText","Data":"，意味着我们需要为更强大的AI寻找更可靠的“尺子”。"}]}]},{"ID":"20250922213945-mf5qzti","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922213945-mf5qzti","updated":"20250922213945"},"Children":[{"ID":"20250922213945-0w0by73","Type":"NodeParagraph","Properties":{"id":"20250922213945-0w0by73","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成的幻觉"},{"Type":"NodeText","Data":": 这是LLM在所有生成任务中都面临的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本性问题"},{"Type":"NodeText","Data":"，将在后续章节中详细讨论。"}]}]}]}]}]},{"ID":"20250922213945-z0f0sdn","Type":"NodeParagraph","Properties":{"id":"20250922213945-z0f0sdn","updated":"20250922213945"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第四十五部分为我们提供了一份关于LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言生成能力的全面“体检报告”"},{"Type":"NodeText","Data":"。它系统地梳理了评估这一能力的三大核心任务、对应的基准和指标。报告显示，LLM在这一领域已是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“优等生”"},{"Type":"NodeText","Data":"，成绩斐然，甚至在某些方面超越了人类。但报告也指出了这位“优等生”存在的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“偏科”"},{"Type":"NodeText","Data":"（挑战新评估范式）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“坏习惯”"},{"Type":"NodeText","Data":"（幻觉问题），为后续的讨论和研究指明了方向。"}]}]},{"ID":"20250922214209-zmt0vk4","Type":"NodeParagraph","Properties":{"id":"20250922214209-zmt0vk4","updated":"20250922214209"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922214209-qens12i","Type":"NodeThematicBreak","Properties":{"id":"20250922214209-qens12i","updated":"20250922214209"}},{"ID":"20250922214209-pk820ne","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214209-pk820ne","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第四十六部分"}]},{"ID":"20250922214209-kdtonim","Type":"NodeParagraph","Properties":{"id":"20250922214209-kdtonim","updated":"20250922214221"},"Children":[{"Type":"NodeText","Data":"如下所述。"}]},{"ID":"20250922214209-mmjdpmb","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214209-mmjdpmb","updated":"20250922214221"},"Children":[{"ID":"20250922214209-w9ecx1j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-w9ecx1j","updated":"20250922214209"},"Children":[{"ID":"20250922214209-ks0l5ht","Type":"NodeParagraph","Properties":{"id":"20250922214209-ks0l5ht","updated":"20250922214209"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不可靠的生成评估 (Unreliable generation evaluation)."},{"Type":"NodeText","Data":" 随着LLM语言生成能力的进步，现有研究发现，LLM生成的文本在各种文本生成任务上已经达到了与人类编写的文本相当的质量。然而，由于现有评估基准的内在弱点，人类评估和自动的基于参考的指标之间存在明显的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不一致性"},{"Type":"NodeText","Data":"。例如，在OpenDialKG中，ChatGPT在BLEU和ROUGE-L指标上表现不如一个微调过的GPT-2，但在人类判断中却获得了更多的青睐。此外，现有的工作认为，即使是人类评估也可能不够稳健。在某些情况下，很难在人类标注员之间达成高水平的共识，而且众包工作者和专家的标注质量之间也存在很大差距。因此，如何在LLM时代进行可靠的语言生成任务评估，已成为一个根本性且具有挑战性的研究课题。最近，越来越多的研究工作提议利用LLM来提高生成文本的评估质量。具体来说，LLM可以用来提高现有指标的评估质量。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Para-Ref"},{"Type":"NodeText","Data":"利用LLM将现有参考释义为具有不同表达方式的语义等价参考。此外，LLM被广泛用作文本生成的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无参考评估器"},{"Type":"NodeText","Data":"，包括评估单个预测或比较几个候选者。然而，LLM作为语言生成评估器可能会暴露"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"偏见"},{"Type":"NodeText","Data":"（例如，顺序偏见或偏爱LLM生成的文本而非人类编写的文本），在与人类评估相比时表现出差异。"}]}]},{"ID":"20250922214209-aeqa6mt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-aeqa6mt","updated":"20250922214209"},"Children":[{"ID":"20250922214209-9537067","Type":"NodeParagraph","Properties":{"id":"20250922214209-9537067","updated":"20250922214209"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表现不佳的专业化生成 (Underperforming specialized generation)."},{"Type":"NodeText","Data":" 尽管LLM已经学会了通用的语言模式来生成连贯的文本，但当处理一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业领域或任务"},{"Type":"NodeText","Data":"时，它们的生成熟练度可能会受到限制。例如，一个在通用网络文章上训练的语言模型在生成涉及许多医学术语和方法的医疗报告时可能会面临挑战。直观地说，领域知识对于模型专业化至关重要。然而，将这种专业知识注入LLM并不容易。正如在最近的分析中所讨论的，当LLM被训练来展现某些特定能力，使其在某些领域表现出色时，它们可能会在其他领域挣扎。这样一个问题与训练神经网络中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"灾难性遗忘"},{"Type":"NodeText","Data":"有关，它指的是整合新旧知识时的冲突现象。类似的情况也发生在LLM的人类对齐中，其中为了与人类价值观和需求对齐，必须付出“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐税"},{"Type":"NodeText","Data":"”（例如，上下文学习能力的潜在损失）。此外，由于序列建模架构的限制，LLM在理解和生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构化数据"},{"Type":"NodeText","Data":"方面仍然面临挑战。因此，它们在复杂的结构化数据任务上，如知识库问答和语义分析，通常落后于任务特定的模型。因此，开发能够灵活地将LLM适配到各种任务场景，同时尽可能保留原始能力的有效模型专业化方法非常重要。"}]}]}]},{"ID":"20250922214209-so3ryy3","Type":"NodeTable","TableAligns":[1,1,1,1],"Properties":{"colgroup":"|||","id":"20250922214209-so3ryy3","updated":"20250922214221"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Level"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Ability"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Task"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Dataset"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Basic"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Language Generation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Language Modeling"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Penn Treebank, WikiText-103, the Pile, LAMBADA"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Conditional Text Generation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WMT'14,16,19,20,21,22, Flores-101, DiaBLa, CNN/DailyMail, XSum, WikiLingua, OpenDialKG"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Code Synthesis"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"APPS, HumanEval, MBPP, CodeContest, MTPB, DS-1000, ODEX"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Knowledge Utilization"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Closed-Book QA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Natural Questions, ARC, TruthfulQA, Web Questions, TriviaQA, PIQA, LC-quad2.0, GrailQA, KQApro, CWQ, MKQA, ScienceQA"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Open-Book QA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Natural Questions, OpenBookQA, ARC, TriviaQA, Web Questions, MS MARCO, QASC, SQuAD, WikiMovies"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Knowledge Completion"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WikiFact, FB15k-237, Freebase, WN18RR, WordNet, LAMA, YAGO3-10, YAGO"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Complex Reasoning"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Knowledge Reasoning"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CSQA, StrategyQA, HotpotQA, ARC, BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, COPA, OpenBookQA, ScienceQA, proScript, ProPara, ExplaGraphs, ProofWriter, EntailmentBank, ProOntoQA"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Symbolic Reasoning"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"CoinFlip, ReverseList, LastLetter, Boolean Assignment, Parity, Colored Object, Penguins in a Table, Repeat Copy, Object Counting"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mathematical Reasoning"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MATH, GSM8k, SVAMP, MultiArith, ASDiv, MathQA, AQUA-RAT, MAWPS, DROP, NaturalProofs, PISA, miniF2F, ProofNet"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Advanced"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Human Alignment"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Honestness"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"TruthfulQA, HaluEval"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Helpfulness"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HH-RLHF"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Harmlessness"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HH-RLHF, Crows-Pairs, WinoGender, RealToxicityPrompts"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Interaction with External Environment"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Household"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"VirtualHome, BEHAVIOR, ALFRED, ALFWorld"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Website Environment"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WebShop, Mind2Web"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Open World"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MineRL, MineDojo"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Tool Manipulation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Search Engine"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HotpotQA, TriviaQA, Natural Questions"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Code Executor"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GSM8k, TabMWP, Date Understanding"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Calculator"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GSM8k, MATH, CARP"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Model Interface"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GPT4Tools, Gorilla"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Data Interface"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WebQSP, MetaQA, WTQ, WikiSQL, TabFact, Spider"}]}]}]},{"ID":"20250922214210-nszokkv","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214210-nszokkv","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 14：用于评估的代表性基础和高级能力以及相应的代表性数据集。"}]},{"ID":"20250922214210-o1fds5p","Type":"NodeBlockquote","Properties":{"id":"20250922214210-o1fds5p","updated":"20250922214221"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214210-e24xnmz","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214210-e24xnmz","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922214210-s227f9k","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214210-s227f9k","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表14解析：LLM能力评估的“考纲”与“题库”"}]},{"ID":"20250922214210-ghfqf1m","Type":"NodeParagraph","Properties":{"id":"20250922214210-ghfqf1m","updated":"20250922214210"},"Children":[{"Type":"NodeText","Data":"这张表格是一份极其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM能力评估“考纲”"},{"Type":"NodeText","Data":"，它系统地将模型的能力划分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础（Basic）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级（Advanced）"},{"Type":"NodeText","Data":"两大等级，并为每个能力点列出了具体的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“考试科目”（任务）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“指定教材/题库”（数据集）"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922214210-w5ob68s","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214210-w5ob68s","updated":"20250922214210"},"Children":[{"ID":"20250922214209-5m5ge3v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-5m5ge3v","updated":"20250922214209"},"Children":[{"ID":"20250922214210-x9u7qj0","Type":"NodeParagraph","Properties":{"id":"20250922214210-x9u7qj0","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础能力 (Basic Abilities) - “智商”测试"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214210-1p7mmzs","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214210-1p7mmzs","updated":"20250922214210"},"Children":[{"ID":"20250922214209-5utf7tb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-5utf7tb","updated":"20250922214209"},"Children":[{"ID":"20250922214210-563mr1l","Type":"NodeParagraph","Properties":{"id":"20250922214210-563mr1l","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言生成 (Language Generation)"},{"Type":"NodeText","Data":": 考察"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“说”"},{"Type":"NodeText","Data":"的能力。包括最基础的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言建模"},{"Type":"NodeText","Data":"（遣词造句），到更实用的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"条件生成"},{"Type":"NodeText","Data":"（翻译、摘要），再到逻辑性极强的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码合成"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214209-bobz5aj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-bobz5aj","updated":"20250922214209"},"Children":[{"ID":"20250922214210-gjzsrj1","Type":"NodeParagraph","Properties":{"id":"20250922214210-gjzsrj1","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识利用 (Knowledge Utilization)"},{"Type":"NodeText","Data":": 考察"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“知”"},{"Type":"NodeText","Data":"的能力，即对事实性知识的掌握和运用。"}]},{"ID":"20250922214210-so2mzdh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214210-so2mzdh","updated":"20250922214210"},"Children":[{"ID":"20250922214209-3l7cww1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-3l7cww1","updated":"20250922214209"},"Children":[{"ID":"20250922214210-25f0i2c","Type":"NodeParagraph","Properties":{"id":"20250922214210-25f0i2c","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭卷问答 (Closed-Book QA)"},{"Type":"NodeText","Data":": 完全依赖模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“记忆”"},{"Type":"NodeText","Data":"的内部知识。"}]}]},{"ID":"20250922214209-2mk0n7h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-2mk0n7h","updated":"20250922214209"},"Children":[{"ID":"20250922214210-gb4mfp2","Type":"NodeParagraph","Properties":{"id":"20250922214210-gb4mfp2","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开卷问答 (Open-Book QA)"},{"Type":"NodeText","Data":": 允许模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"查阅外部资料"},{"Type":"NodeText","Data":"（如文档）。"}]}]},{"ID":"20250922214209-se831oi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-se831oi","updated":"20250922214209"},"Children":[{"ID":"20250922214210-cyxiwdw","Type":"NodeParagraph","Properties":{"id":"20250922214210-cyxiwdw","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识补全 (Knowledge Completion)"},{"Type":"NodeText","Data":": 考察对知识图谱中事实三元组的预测能力。"}]}]}]}]},{"ID":"20250922214209-yfsf88d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-yfsf88d","updated":"20250922214209"},"Children":[{"ID":"20250922214210-kp9fcm4","Type":"NodeParagraph","Properties":{"id":"20250922214210-kp9fcm4","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理 (Complex Reasoning)"},{"Type":"NodeText","Data":": 考察"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“思”"},{"Type":"NodeText","Data":"的能力。"}]},{"ID":"20250922214210-h33fo1z","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214210-h33fo1z","updated":"20250922214210"},"Children":[{"ID":"20250922214209-do98eh8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-do98eh8","updated":"20250922214209"},"Children":[{"ID":"20250922214210-rv3w1ik","Type":"NodeParagraph","Properties":{"id":"20250922214210-rv3w1ik","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识推理 (Knowledge Reasoning)"},{"Type":"NodeText","Data":": 基于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域知识"},{"Type":"NodeText","Data":"进行推理。"}]}]},{"ID":"20250922214209-qb5xy9e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-qb5xy9e","updated":"20250922214209"},"Children":[{"ID":"20250922214210-qsv8hpe","Type":"NodeParagraph","Properties":{"id":"20250922214210-qsv8hpe","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符号推理 (Symbolic Reasoning)"},{"Type":"NodeText","Data":": 考察对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"抽象符号和规则"},{"Type":"NodeText","Data":"的操纵能力。"}]}]},{"ID":"20250922214209-dqc2d9x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-dqc2d9x","updated":"20250922214209"},"Children":[{"ID":"20250922214210-0448dws","Type":"NodeParagraph","Properties":{"id":"20250922214210-0448dws","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学推理 (Mathematical Reasoning)"},{"Type":"NodeText","Data":": 考察"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学"},{"Type":"NodeText","Data":"领域的逻辑和计算能力。"}]}]}]}]}]}]},{"ID":"20250922214209-6uvu2zp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-6uvu2zp","updated":"20250922214209"},"Children":[{"ID":"20250922214210-9g63zuj","Type":"NodeParagraph","Properties":{"id":"20250922214210-9g63zuj","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力 (Advanced Abilities) - “情商”与“动手能力”测试"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214210-ld26ki0","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214210-ld26ki0","updated":"20250922214210"},"Children":[{"ID":"20250922214209-2aci9pj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-2aci9pj","updated":"20250922214209"},"Children":[{"ID":"20250922214210-pz8t63t","Type":"NodeParagraph","Properties":{"id":"20250922214210-pz8t63t","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐 (Human Alignment)"},{"Type":"NodeText","Data":": 考察模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“价值观”和“品性”"},{"Type":"NodeText","Data":"，即是否"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"诚实（Honestness）"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有帮助（Helpfulness）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无害（Harmlessness）"},{"Type":"NodeText","Data":"。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“情商”"},{"Type":"NodeText","Data":"测试。"}]}]},{"ID":"20250922214209-hakkkci","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-hakkkci","updated":"20250922214209"},"Children":[{"ID":"20250922214210-57a4pof","Type":"NodeParagraph","Properties":{"id":"20250922214210-57a4pof","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与外部环境交互 (Interaction with External Environment)"},{"Type":"NodeText","Data":": 考察模型在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模拟环境"},{"Type":"NodeText","Data":"（如家庭、网站、游戏世界）中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"感知和行动"},{"Type":"NodeText","Data":"的能力。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“动手能力”"},{"Type":"NodeText","Data":"的雏形。"}]}]},{"ID":"20250922214209-ehjamip","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-ehjamip","updated":"20250922214209"},"Children":[{"ID":"20250922214210-rbbpi5d","Type":"NodeParagraph","Properties":{"id":"20250922214210-rbbpi5d","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具操作 (Tool Manipulation)"},{"Type":"NodeText","Data":": 考察模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"使用外部工具"},{"Type":"NodeText","Data":"（如搜索引擎、计算器、代码执行器、模型API）来增强自身能力。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“动手能力”"},{"Type":"NodeText","Data":"的核心体现。"}]}]}]}]}]},{"ID":"20250922214210-1282ab3","Type":"NodeParagraph","Properties":{"id":"20250922214210-1282ab3","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格为LLM的能力评估提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结构化、多维度"},{"Type":"NodeText","Data":"的框架。它清晰地表明，评估一个现代LLM，早已超越了简单的语言任务。我们需要一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“全方位的素质教育评估体系”"},{"Type":"NodeText","Data":"，既要考察其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“智商”"},{"Type":"NodeText","Data":"（基础能力），也要考察其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“情商”和“动手能力”"},{"Type":"NodeText","Data":"（高级能力），才能全面地了解一个模型的优势和短板。这份“考纲”为后续所有评估工作提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰的指引"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214210-0am8cji","Type":"NodeThematicBreak","Properties":{"id":"20250922214210-0am8cji","updated":"20250922214221"}},{"ID":"20250922214210-imc31uf","Type":"NodeBlockquote","Properties":{"id":"20250922214210-imc31uf","updated":"20250922214221"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214210-sl525gc","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214210-sl525gc","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922214210-i7kzxx2","Type":"NodeParagraph","Properties":{"id":"20250922214210-i7kzxx2","updated":"20250922214210"},"Children":[{"Type":"NodeText","Data":"第四十六部分是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言生成能力评估"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深入反思"},{"Type":"NodeText","Data":"，并提供了一份"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面的LLM能力评估大纲（表14）"},{"Type":"NodeText","Data":"。它揭示了在LLM时代，我们面临的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估困境"},{"Type":"NodeText","Data":"，并为如何系统性地评估一个模型提供了清晰的框架。"}]},{"ID":"20250922214210-wz8v7tx","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214210-wz8v7tx","updated":"20250922214210"},"Children":[{"ID":"20250922214209-75kxs6t","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922214209-75kxs6t","updated":"20250922214209"},"Children":[{"ID":"20250922214210-5ip393c","Type":"NodeParagraph","Properties":{"id":"20250922214210-5ip393c","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估的“危机”与“出路”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214210-vttc06s","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214210-vttc06s","updated":"20250922214210"},"Children":[{"ID":"20250922214209-1ov4qgs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-1ov4qgs","updated":"20250922214209"},"Children":[{"ID":"20250922214210-1ezcj3v","Type":"NodeParagraph","Properties":{"id":"20250922214210-1ezcj3v","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"危机"},{"Type":"NodeText","Data":": 文章尖锐地指出了当前LLM评估面临的两大“危机”："}]},{"ID":"20250922214210-ecezz93","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214210-ecezz93","updated":"20250922214210"},"Children":[{"ID":"20250922214209-suj5wfn","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922214209-suj5wfn","updated":"20250922214209"},"Children":[{"ID":"20250922214210-dp38s30","Type":"NodeParagraph","Properties":{"id":"20250922214210-dp38s30","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估指标的“失灵” (Unreliable Evaluation)"},{"Type":"NodeText","Data":": 传统的自动指标（如BLEU, ROUGE）已经无法准确衡量高质量LLM的生成水平，甚至人类评估本身也存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主观性和不一致性"},{"Type":"NodeText","Data":"。这意味着我们可能正在用一把"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“不准的尺子”"},{"Type":"NodeText","Data":"来度量AI的进步。"}]}]},{"ID":"20250922214209-ztgga9k","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922214209-ztgga9k","updated":"20250922214209"},"Children":[{"ID":"20250922214210-l633dlv","Type":"NodeParagraph","Properties":{"id":"20250922214210-l633dlv","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业能力的“短板” (Underperforming Specialization)"},{"Type":"NodeText","Data":": 通用LLM在面对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业领域"},{"Type":"NodeText","Data":"时，其生成能力会下降。同时，试图注入专业知识的过程，可能会导致"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“灾难性遗忘”"},{"Type":"NodeText","Data":"或付出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“对齐税”"},{"Type":"NodeText","Data":"，损害其通用能力。这是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“既要...又要...”"},{"Type":"NodeText","Data":"的经典困境。"}]}]}]}]},{"ID":"20250922214209-7ts7h7w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-7ts7h7w","updated":"20250922214209"},"Children":[{"ID":"20250922214210-vm39jlc","Type":"NodeParagraph","Properties":{"id":"20250922214210-vm39jlc","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"出路"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214210-z5zdkh3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214210-z5zdkh3","updated":"20250922214210"},"Children":[{"ID":"20250922214209-emy9dx5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-emy9dx5","updated":"20250922214209"},"Children":[{"ID":"20250922214210-4x2mt0j","Type":"NodeParagraph","Properties":{"id":"20250922214210-4x2mt0j","updated":"20250922214210"},"Children":[{"Type":"NodeText","Data":"对于评估危机，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“用LLM评估LLM”"},{"Type":"NodeText","Data":"被认为是一个有前景的方向，但其自身的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"偏见"},{"Type":"NodeText","Data":"问题也亟待解决。"}]}]},{"ID":"20250922214209-5ll3wpj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-5ll3wpj","updated":"20250922214209"},"Children":[{"ID":"20250922214210-of6eov4","Type":"NodeParagraph","Properties":{"id":"20250922214210-of6eov4","updated":"20250922214210"},"Children":[{"Type":"NodeText","Data":"对于专业化困境，开发"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更有效的、能兼顾通用与专业的模型适配方法"},{"Type":"NodeText","Data":"是关键。"}]}]}]}]}]}]},{"ID":"20250922214209-l8yql96","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922214209-l8yql96","updated":"20250922214209"},"Children":[{"ID":"20250922214210-6u9lfr7","Type":"NodeParagraph","Properties":{"id":"20250922214210-6u9lfr7","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力评估的“全景地图” (表14)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214210-bwbpmd1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214210-bwbpmd1","updated":"20250922214210"},"Children":[{"ID":"20250922214209-exubthl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-exubthl","updated":"20250922214209"},"Children":[{"ID":"20250922214210-i3qkoya","Type":"NodeParagraph","Properties":{"id":"20250922214210-i3qkoya","updated":"20250922214210"},"Children":[{"Type":"NodeText","Data":"表14是本部分乃至整个评估章节的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“定海神针”"},{"Type":"NodeText","Data":"。它为评估一个复杂的LLM提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统化、结构化的“全景地图”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214209-72qmmxj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-72qmmxj","updated":"20250922214209"},"Children":[{"ID":"20250922214210-2ny98qi","Type":"NodeParagraph","Properties":{"id":"20250922214210-2ny98qi","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"层次化"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“基础-高级”"},{"Type":"NodeText","Data":"的划分，体现了从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心智能"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用与交互能力"},{"Type":"NodeText","Data":"的评估层次。"}]}]},{"ID":"20250922214209-8nmrgax","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-8nmrgax","updated":"20250922214209"},"Children":[{"ID":"20250922214210-2xlqiap","Type":"NodeParagraph","Properties":{"id":"20250922214210-2xlqiap","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多维度"},{"Type":"NodeText","Data":": 在每个层次下，都细分了多个能力维度（如生成、知识、推理、对齐、交互、工具），确保了评估的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面性"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214209-c7vi5ie","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214209-c7vi5ie","updated":"20250922214209"},"Children":[{"ID":"20250922214210-ytri4yr","Type":"NodeParagraph","Properties":{"id":"20250922214210-ytri4yr","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可操作性"},{"Type":"NodeText","Data":": 为每个能力维度都提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体的任务类型"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代表性的数据集"},{"Type":"NodeText","Data":"，使得这个框架不仅是理论上的，更是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可以直接在实践中操作"},{"Type":"NodeText","Data":"的。"}]}]}]}]}]},{"ID":"20250922214210-4xng2ay","Type":"NodeParagraph","Properties":{"id":"20250922214210-4xng2ay","updated":"20250922214210"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第四十六部分的核心在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“反思”"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“构建”"},{"Type":"NodeText","Data":"。它首先深刻反思了当前LLM在核心生成能力上面临的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估和专业化两大挑战"},{"Type":"NodeText","Data":"，然后通过表14，为应对这些挑战、系统性地理解和衡量LLM，构建了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面而清晰的评估框架"},{"Type":"NodeText","Data":"。这份“能力考纲”不仅是对现有评估工作的总结，更是对未来评估研究方向的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重要指引"},{"Type":"NodeText","Data":"。它告诉我们，要真正理解一个LLM，必须对其进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全方位、多层次的“体检”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214412-dajw8fb","Type":"NodeParagraph","Properties":{"id":"20250922214412-dajw8fb","updated":"20250922214412"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922214412-efaadkp","Type":"NodeThematicBreak","Properties":{"id":"20250922214412-efaadkp","updated":"20250922214412"}},{"ID":"20250922214412-hcwlx1o","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214412-hcwlx1o","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第四十七部分"}]},{"ID":"20250922214412-45le650","Type":"NodeBlockquote","Properties":{"id":"20250922214412-45le650","updated":"20250922214440"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214412-vw5b084","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214412-vw5b084","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不可靠的生成评估"}]},{"ID":"20250922214412-odzrh8o","Type":"NodeParagraph","Properties":{"id":"20250922214412-odzrh8o","updated":"20250922214412"},"Children":[{"Type":"NodeText","Data":"LLM已经能够生成与人类编写的文本质量相当的文本，然而，这可能会被自动的基于参考的指标所低估。作为一种替代的评估方法，LLM可以作为语言生成评估器来评估单个文本、比较多个候选者以及改进现有的指标。然而，这种评估方法仍然需要在真实世界的任务中进行更多的检查和检验。"}]}]},{"ID":"20250922214412-wvb32w8","Type":"NodeBlockquote","Properties":{"id":"20250922214412-wvb32w8","updated":"20250922214440"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214412-56ktebe","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214412-56ktebe","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表现不佳的专业化生成"}]},{"ID":"20250922214412-b7iftf4","Type":"NodeParagraph","Properties":{"id":"20250922214412-b7iftf4","updated":"20250922214412"},"Children":[{"Type":"NodeText","Data":"LLM在掌握需要领域特定知识或生成结构化数据的生成任务方面可能会表现不佳。将专业知识注入LLM，同时尽可能地保持原有能力，并非易事。"}]}]},{"ID":"20250922214412-7v4d7q7","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214412-7v4d7q7","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.1.2 Knowledge Utilization (知识利用)"}]},{"ID":"20250922214412-1ep5449","Type":"NodeParagraph","Properties":{"id":"20250922214412-1ep5449","updated":"20250922214440"},"Children":[{"Type":"NodeText","Data":"知识利用是智能系统完成知识密集型任务（例如，常识问答和事实补全）的一项重要能力，它基于支持性的事实证据。具体来说，它要求LLM适当地利用来自预训练语料库的丰富事实知识，或在必要时检索外部数据。特别地，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问答（QA）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识补全"},{"Type":"NodeText","Data":"是评估该能力的两个常用任务。根据测试任务（问答或知识补全）和评估设置（有或没有外部资源），我们将现有的知识利用任务分为三类，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭卷QA、开卷QA和知识补全"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922214412-s9myran","Type":"NodeParagraph","Properties":{"id":"20250922214412-s9myran","updated":"20250922214440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Closed-Book QA (闭卷问答)."},{"Type":"NodeText","Data":" 闭卷QA任务测试LLM从预训练语料库中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"获取的事实知识"},{"Type":"NodeText","Data":"，其中LLM应仅基于给定的上下文回答问题，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不使用外部资源"},{"Type":"NodeText","Data":"。为了评估该能力，有几个可以利用的数据集，包括Natural Questions、Web Questions和TriviaQA，其中准确率指标被广泛采用。实证结果显示，LLM在该设置下表现良好，甚至能与最先进的开卷QA系统性能相媲美。此外，LLM在闭卷QA任务上的性能在模型大小和数据大小方面都呈现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"的模式：扩展参数和训练词元可以增加LLM的能力，并帮助它们从预训练数据中学习（或记忆）更多知识。此外，在相似的参数规模下，具有更多与评估任务相关的预训练数据的LLM会取得更好的性能。此外，闭卷QA设置为探测LLM编码的事实知识的准确性提供了一个试验平台。然而，正如现有工作所示，LLM在依赖"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"细粒度知识"},{"Type":"NodeText","Data":"的QA任务上可能表现较差，即使它存在于预训练数据中。"}]},{"ID":"20250922214412-hxs31ei","Type":"NodeParagraph","Properties":{"id":"20250922214412-hxs31ei","updated":"20250922214440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Open-Book QA (开卷问答)."},{"Type":"NodeText","Data":" 与闭卷QA不同，在开卷QA任务中，LLM可以从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部知识库或文档集合"},{"Type":"NodeText","Data":"中提取有用的证据，然后基于提取的证据回答问题。典型的开卷QA数据集（例如，Natural Questions、OpenBookQA和SQuAD）与闭卷QA数据集有重叠，但它们整合了外部数据源，例如维基百科。准确率和F1分数是开卷QA任务中广泛用于评估的指标。为了从外部资源中选择相关知识，LLM通常与一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本检索器"},{"Type":"NodeText","Data":"（或甚至是搜索引擎）配对，该检索器可以与LLM独立训练或联合训练。此外，先前的工作已表明，检索器可以帮助LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"验证和纠正推理路径"},{"Type":"NodeText","Data":"。在评估中，现有研究主要关注测试LLM如何利用提取的知识来回答问题，并表明检索到的证据可以极大地提高生成答案的准确率，甚至使一个较小的LLM能够胜过大10倍的模型。此外，开卷QA任务也可以用来评估知识信息的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"时效性"},{"Type":"NodeText","Data":"。在过时的知识资源上进行预训练或检索可能会导致LLM为对时间敏感的问题生成不正确的答案。"}]},{"ID":"20250922214412-c4x2lma","Type":"NodeParagraph","Properties":{"id":"20250922214412-c4x2lma","updated":"20250922214440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Knowledge Completion (知识补全)."},{"Type":"NodeText","Data":" 在知识补全任务中，LLM在某种程度上可以被视为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识库"},{"Type":"NodeText","Data":"，可以用来补全或预测知识单元（例如，知识三元组）的缺失部分。这类任务可以探测和评估LLM从预训练数据中学到了多少以及哪种知识。现有的知识补全任务可以粗略地分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识图谱补全"},{"Type":"NodeText","Data":"任务（例如，FB15k-237和WN18RR）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"事实补全"},{"Type":"NodeText","Data":"任务（例如，WikiFact），它们分别旨在补全来自知识图谱的三元组和关于特定事实的不完整句子。实证研究揭示，现有的LLM在完成与特定关系类型相关的知识补全任务时存在困难。正如在WikiFact上的评估结果所示，LLM在预训练数据中频繁出现的几种关系（例如，"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"currency"},{"Type":"NodeText","Data":"​和"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"author"},{"Type":"NodeText","Data":"​）上表现良好，但在罕见关系（例如，"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"discoverer_or_inventor"},{"Type":"NodeText","Data":"​和"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"place_of_birth"},{"Type":"NodeText","Data":"​）上则表现不佳。有趣的是，在相同的评估设置下（例如，上下文学习），InstructGPT（即"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"text-davinci-002"},{"Type":"NodeText","Data":"​）在WikiFact的所有子集上都优于GPT-3。"}]},{"ID":"20250922214412-h8401ee","Type":"NodeParagraph","Properties":{"id":"20250922214412-h8401ee","updated":"20250922214440"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Major Issues (主要问题)."},{"Type":"NodeText","Data":" 尽管LLM在捕获和利用知识信息方面取得了关键进展，但它们遭受两个主要问题的影响，如下所述。"}]},{"ID":"20250922214412-k7f2b4g","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-k7f2b4g","updated":"20250922214440"},"Children":[{"ID":"20250922214412-avmtjl9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-avmtjl9","updated":"20250922214412"},"Children":[{"ID":"20250922214412-ljea4c1","Type":"NodeParagraph","Properties":{"id":"20250922214412-ljea4c1","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幻觉 (Hallucination)."},{"Type":"NodeText","Data":" 在生成事实性文本时，一个具有挑战性的问题是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幻觉生成"},{"Type":"NodeText","Data":"，即生成的信息要么与现有来源"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冲突（内在幻觉）"},{"Type":"NodeText","Data":"，要么"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无法被可用来源验证（外在幻觉）"},{"Type":"NodeText","Data":"，这通过图17中的两个例子进行了说明。幻觉在现有的LLM中广泛发生，即使是最优越的LLM如GPT-4也是如此。此外，现有的工作表明，LLM在识别文本中的幻觉内容方面存在困难，即使是强大的ChatGPT也是如此。此外，除了语言任务，最近的一项研究表明，大型视觉-语言模型（LVLM）也面临幻觉的挑战，即生成伴随图像中不存在的对象。从本质上讲，LLM似乎在任务解决中“"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无意识地"},{"Type":"NodeText","Data":"”利用知识，仍然缺乏准确控制内部或外部知识使用的能力。幻觉会误导LLM生成不受欢迎的输出，并主要降低性能，在真实世界应用中部署LLM时会导致潜在风险。为了缓解这个问题，对齐微调策略（如5.2节所讨论的）已在现有工作中被广泛使用，它依赖于在高质量数据上对LLM进行微调或使用人类反馈。此外，整合外部工具以提供可信的信息来源可以帮助缓解幻觉问题。另一条研究路线利用LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不确定性估计"},{"Type":"NodeText","Data":"来识别幻觉。例如，考虑到幻觉事实容易在不同的采样输出中表现出不一致性，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SelfCheckGPT"},{"Type":"NodeText","Data":"通过测量采样输出内的信息不一致性来检测幻觉。对于幻觉问题的评估，已经提出了一系列幻觉检测任务，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"TruthfulQA"},{"Type":"NodeText","Data":"用于检测模型模仿的人类谬误。最近，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HaluEval"},{"Type":"NodeText","Data":"创建了一个大规模的、由LLM生成并经人类标注的幻觉样本，以评估语言模型在任务特定和通用场景中识别幻觉的能力。"}]}]}]},{"ID":"20250922214412-lms32kb","Type":"NodeParagraph","Properties":{"id":"20250922214412-lms32kb","updated":"20250922214440"},"Children":[{"Type":"NodeText","Data":"​"},{"Type":"NodeImage","Data":"span","Children":[{"Type":"NodeBang"},{"Type":"NodeOpenBracket"},{"Type":"NodeLinkText","Data":"image"},{"Type":"NodeCloseBracket"},{"Type":"NodeOpenParen"},{"Type":"NodeLinkDest","Data":"assets/image-20250915183856-t6699n9.png"},{"Type":"NodeCloseParen"}]},{"Type":"NodeText","Data":"​"}]},{"ID":"20250922214412-bvaahlx","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214412-bvaahlx","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图 17：一个公共LLM的内在和外在幻觉示例（访问日期：2023年3月19日）。"}]},{"ID":"20250922214412-i7qzxdy","Type":"NodeParagraph","Properties":{"id":"20250922214412-i7qzxdy","updated":"20250922214440"},"Children":[{"Type":"NodeText","Data":"作为内在幻觉的例子，LLM对Cindy和Amy之间的关系给出了一个矛盾的判断，这与输入相矛盾。对于外在幻觉，在这个例子中，LLM似乎对RLHF（从人类反馈中进行强化学习）的含义有不正确的理解，尽管它可以正确理解LLM（大型语言模型）的含义（在这个上下文中）。"}]},{"ID":"20250922214412-8b2najt","Type":"NodeBlockquote","Properties":{"id":"20250922214412-8b2najt","updated":"20250922214440"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214412-frobim4","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214412-frobim4","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922214412-xxps41d","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214412-xxps41d","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图17解析：幻觉的两种“症状”"}]},{"ID":"20250922214412-2nw1pfr","Type":"NodeParagraph","Properties":{"id":"20250922214412-2nw1pfr","updated":"20250922214412"},"Children":[{"Type":"NodeText","Data":"这张图通过两个具体的例子，生动地解释了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幻觉（Hallucination）"},{"Type":"NodeText","Data":"的两种主要类型。"}]},{"ID":"20250922214412-ymu8kts","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-ymu8kts","updated":"20250922214412"},"Children":[{"ID":"20250922214412-1x7ozmb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-1x7ozmb","updated":"20250922214412"},"Children":[{"ID":"20250922214412-ngylaq6","Type":"NodeParagraph","Properties":{"id":"20250922214412-ngylaq6","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(a) 内在幻觉 (Intrinsic Hallucination)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214412-gcy4nmk","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-gcy4nmk","updated":"20250922214412"},"Children":[{"ID":"20250922214412-t2kmhwx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-t2kmhwx","updated":"20250922214412"},"Children":[{"ID":"20250922214412-82a4lo6","Type":"NodeParagraph","Properties":{"id":"20250922214412-82a4lo6","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定义"},{"Type":"NodeText","Data":": 生成的内容与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“对话上下文”或“给定源文本”"},{"Type":"NodeText","Data":"本身"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相矛盾"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214412-mid69n6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-mid69n6","updated":"20250922214412"},"Children":[{"ID":"20250922214412-zdkxdv8","Type":"NodeParagraph","Properties":{"id":"20250922214412-zdkxdv8","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214412-7ucl94h","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-7ucl94h","updated":"20250922214412"},"Children":[{"ID":"20250922214412-wxuuw4t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-wxuuw4t","updated":"20250922214412"},"Children":[{"ID":"20250922214412-5ebc6nw","Type":"NodeParagraph","Properties":{"id":"20250922214412-5ebc6nw","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输入"},{"Type":"NodeText","Data":": Bob的妻子是Amy，女儿是Cindy。"}]}]},{"ID":"20250922214412-7t74ff1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-7t74ff1","updated":"20250922214412"},"Children":[{"ID":"20250922214412-83h77fv","Type":"NodeParagraph","Properties":{"id":"20250922214412-83h77fv","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题"},{"Type":"NodeText","Data":": Cindy是Amy的谁？"}]}]},{"ID":"20250922214412-2fko1tv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-2fko1tv","updated":"20250922214412"},"Children":[{"ID":"20250922214412-udssvdu","Type":"NodeParagraph","Properties":{"id":"20250922214412-udssvdu","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正确答案"},{"Type":"NodeText","Data":": Amy是Cindy的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"母亲"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214412-id7n07c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-id7n07c","updated":"20250922214412"},"Children":[{"ID":"20250922214412-hlmd2c9","Type":"NodeParagraph","Properties":{"id":"20250922214412-hlmd2c9","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型回答"},{"Type":"NodeText","Data":": Cindy是Amy的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"儿媳 (daughter-in-law)"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922214412-7k679vt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-7k679vt","updated":"20250922214412"},"Children":[{"ID":"20250922214412-fgaarun","Type":"NodeParagraph","Properties":{"id":"20250922214412-fgaarun","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分析"},{"Type":"NodeText","Data":": 模型的回答"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"直接违背了"},{"Type":"NodeText","Data":"输入中提供的事实信息。它自己编造了一个完全错误的关系。这是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“睁着眼睛说瞎话”"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922214412-5eken2e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-5eken2e","updated":"20250922214412"},"Children":[{"ID":"20250922214412-ltkuknf","Type":"NodeParagraph","Properties":{"id":"20250922214412-ltkuknf","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"(b) 外在幻觉 (Extrinsic Hallucination)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214412-zkbgq3i","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-zkbgq3i","updated":"20250922214412"},"Children":[{"ID":"20250922214412-r2la6nv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-r2la6nv","updated":"20250922214412"},"Children":[{"ID":"20250922214412-of40aof","Type":"NodeParagraph","Properties":{"id":"20250922214412-of40aof","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定义"},{"Type":"NodeText","Data":": 生成的内容"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无法被外部的、公认的世界知识所证实"},{"Type":"NodeText","Data":"，或者是对事实的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"凭空捏造"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214412-cw71eg2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-cw71eg2","updated":"20250922214412"},"Children":[{"ID":"20250922214412-6dniddu","Type":"NodeParagraph","Properties":{"id":"20250922214412-6dniddu","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"示例"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214412-qfyy2bv","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-qfyy2bv","updated":"20250922214412"},"Children":[{"ID":"20250922214412-8wajzbf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-8wajzbf","updated":"20250922214412"},"Children":[{"ID":"20250922214412-uqfsrlr","Type":"NodeParagraph","Properties":{"id":"20250922214412-uqfsrlr","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题"},{"Type":"NodeText","Data":": 解释一下LLM的RLHF。"}]}]},{"ID":"20250922214412-2228rqk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-2228rqk","updated":"20250922214412"},"Children":[{"ID":"20250922214412-y79oo9y","Type":"NodeParagraph","Properties":{"id":"20250922214412-y79oo9y","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型回答"},{"Type":"NodeText","Data":": RLHF代表\"Rights, Limitations, Harms, and Freedoms\"（权利、限制、危害和自由）..."}]}]}]}]},{"ID":"20250922214412-knl8xdg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-knl8xdg","updated":"20250922214412"},"Children":[{"ID":"20250922214412-1w02mxe","Type":"NodeParagraph","Properties":{"id":"20250922214412-1w02mxe","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分析"},{"Type":"NodeText","Data":": 这是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"彻头彻尾的谎言"},{"Type":"NodeText","Data":"。RLHF的正确全称是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Reinforcement Learning from Human Feedback"},{"Type":"NodeText","Data":"（从人类反馈中进行强化学习）。模型完全"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"捏造"},{"Type":"NodeText","Data":"了一个看似合理但完全错误的解释。这种幻觉更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐蔽、更危险"},{"Type":"NodeText","Data":"，因为它需要用户具备背景知识才能识别。"}]}]}]}]}]},{"ID":"20250922214412-jwkrpgr","Type":"NodeParagraph","Properties":{"id":"20250922214412-jwkrpgr","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张图清晰地区分了两种幻觉。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内在幻觉"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自相矛盾”"},{"Type":"NodeText","Data":"，可以通过与源文本比对来发现。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外在幻觉"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“无中生有”"},{"Type":"NodeText","Data":"，需要用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部世界知识"},{"Type":"NodeText","Data":"来验证。"}]}]},{"ID":"20250922214412-0988ddo","Type":"NodeThematicBreak","Properties":{"id":"20250922214412-0988ddo","updated":"20250922214440"}},{"ID":"20250922214412-e3l8krc","Type":"NodeBlockquote","Properties":{"id":"20250922214412-e3l8krc","updated":"20250922214440"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214412-yttai48","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214412-yttai48","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922214412-132r9tq","Type":"NodeParagraph","Properties":{"id":"20250922214412-132r9tq","updated":"20250922214412"},"Children":[{"Type":"NodeText","Data":"第四十七部分系统地探讨了LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二项基础能力——知识利用"},{"Type":"NodeText","Data":"，并深入剖析了与之相伴而生的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心挑战——幻觉（Hallucination）"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922214412-7n14h58","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214412-7n14h58","updated":"20250922214412"},"Children":[{"ID":"20250922214412-c00ijln","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922214412-c00ijln","updated":"20250922214412"},"Children":[{"ID":"20250922214412-3jebrxn","Type":"NodeParagraph","Properties":{"id":"20250922214412-3jebrxn","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识利用的“三板斧”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214412-1807es5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-1807es5","updated":"20250922214412"},"Children":[{"ID":"20250922214412-ks7ql8i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-ks7ql8i","updated":"20250922214412"},"Children":[{"ID":"20250922214412-o2ebluo","Type":"NodeParagraph","Properties":{"id":"20250922214412-o2ebluo","updated":"20250922214412"},"Children":[{"Type":"NodeText","Data":"文章将知识利用任务清晰地划分为三种模式，这实际上是在考察模型与知识的三种不同关系："}]},{"ID":"20250922214412-2yrekmc","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214412-2yrekmc","updated":"20250922214412"},"Children":[{"ID":"20250922214412-0fczjoo","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922214412-0fczjoo","updated":"20250922214412"},"Children":[{"ID":"20250922214412-urubggi","Type":"NodeParagraph","Properties":{"id":"20250922214412-urubggi","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭卷QA (Closed-Book QA)"},{"Type":"NodeText","Data":": 考察"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“记忆力”"},{"Type":"NodeText","Data":"。模型能从其庞大的参数中“回忆”出多少事实知识。研究发现，这种能力遵循"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则"},{"Type":"NodeText","Data":"——模型越大，记得越多。"}]}]},{"ID":"20250922214412-hscijar","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922214412-hscijar","updated":"20250922214412"},"Children":[{"ID":"20250922214412-l82xvh0","Type":"NodeParagraph","Properties":{"id":"20250922214412-l82xvh0","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开卷QA (Open-Book QA)"},{"Type":"NodeText","Data":": 考察"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“信息检索与整合能力”"},{"Type":"NodeText","Data":"。模型被允许“查资料”（连接外部知识源），然后基于检索到的信息回答问题。这不仅能提升准确率，还能解决知识的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"时效性"},{"Type":"NodeText","Data":"问题。"}]}]},{"ID":"20250922214412-gn9yi4b","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922214412-gn9yi4b","updated":"20250922214412"},"Children":[{"ID":"20250922214412-jd0wwkm","Type":"NodeParagraph","Properties":{"id":"20250922214412-jd0wwkm","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识补全 (Knowledge Completion)"},{"Type":"NodeText","Data":": 考察"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“知识推理与联想能力”"},{"Type":"NodeText","Data":"。将LLM视为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"隐式的知识图谱"},{"Type":"NodeText","Data":"，测试其补全事实三元组的能力。"}]}]}]}]}]}]},{"ID":"20250922214412-5lmpnyn","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922214412-5lmpnyn","updated":"20250922214412"},"Children":[{"ID":"20250922214412-wh024su","Type":"NodeParagraph","Properties":{"id":"20250922214412-wh024su","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幻觉：知识利用的“阿喀琉斯之踵”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214412-pph80lp","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-pph80lp","updated":"20250922214412"},"Children":[{"ID":"20250922214412-pkb231w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-pkb231w","updated":"20250922214412"},"Children":[{"ID":"20250922214412-szx11pm","Type":"NodeParagraph","Properties":{"id":"20250922214412-szx11pm","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心问题"},{"Type":"NodeText","Data":": LLM在利用知识时，并"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不能区分“事实”与“虚构”"},{"Type":"NodeText","Data":"。它只是一个概率模型，会生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“看起来最像真话”"},{"Type":"NodeText","Data":"的文本，而不管其真实性如何。"}]}]},{"ID":"20250922214412-pkbvpnr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-pkbvpnr","updated":"20250922214412"},"Children":[{"ID":"20250922214412-cohhmx4","Type":"NodeParagraph","Properties":{"id":"20250922214412-cohhmx4","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两种幻觉的精准定义"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214412-s5od11q","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-s5od11q","updated":"20250922214412"},"Children":[{"ID":"20250922214412-zud7rmb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-zud7rmb","updated":"20250922214412"},"Children":[{"ID":"20250922214412-y7vu9al","Type":"NodeParagraph","Properties":{"id":"20250922214412-y7vu9al","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内在幻觉"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自相矛盾”"},{"Type":"NodeText","Data":"，与上下文冲突。"}]}]},{"ID":"20250922214412-u2gb22d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-u2gb22d","updated":"20250922214412"},"Children":[{"ID":"20250922214412-aldifcj","Type":"NodeParagraph","Properties":{"id":"20250922214412-aldifcj","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外在幻觉"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“无中生有”"},{"Type":"NodeText","Data":"，与世界知识冲突。"}]}]}]}]},{"ID":"20250922214412-4v3yu8b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-4v3yu8b","updated":"20250922214412"},"Children":[{"ID":"20250922214412-pmq26vf","Type":"NodeParagraph","Properties":{"id":"20250922214412-pmq26vf","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应对幻觉的“组合拳”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214412-0837j0k","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-0837j0k","updated":"20250922214412"},"Children":[{"ID":"20250922214412-e3q3149","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-e3q3149","updated":"20250922214412"},"Children":[{"ID":"20250922214412-srl8tun","Type":"NodeParagraph","Properties":{"id":"20250922214412-srl8tun","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对齐微调"},{"Type":"NodeText","Data":": 通过RLHF等方法，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“教导”"},{"Type":"NodeText","Data":"模型要更诚实。"}]}]},{"ID":"20250922214412-xufh3z8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-xufh3z8","updated":"20250922214412"},"Children":[{"ID":"20250922214412-5g0gmja","Type":"NodeParagraph","Properties":{"id":"20250922214412-5g0gmja","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检索增强 (RAG)"},{"Type":"NodeText","Data":": 为模型提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“事实依据”"},{"Type":"NodeText","Data":"，让其“有据可查”，而不是“凭空想象”。"}]}]},{"ID":"20250922214412-p8h9482","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-p8h9482","updated":"20250922214412"},"Children":[{"ID":"20250922214412-aiy5x1e","Type":"NodeParagraph","Properties":{"id":"20250922214412-aiy5x1e","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不确定性估计"},{"Type":"NodeText","Data":": 让模型学会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“自我怀疑”"},{"Type":"NodeText","Data":"。当模型对某个答案不确定时（如采样结果不一致），就更有可能是幻觉。"}]}]},{"ID":"20250922214412-ttel59s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-ttel59s","updated":"20250922214412"},"Children":[{"ID":"20250922214412-901f3cz","Type":"NodeParagraph","Properties":{"id":"20250922214412-901f3cz","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专用评估基准 (TruthfulQA, HaluEval)"},{"Type":"NodeText","Data":": 设立专门的“测谎”考试，系统性地评估和度量模型的幻觉问题。"}]}]}]}]}]}]},{"ID":"20250922214412-ybus0ts","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922214412-ybus0ts","updated":"20250922214412"},"Children":[{"ID":"20250922214412-720d3aa","Type":"NodeParagraph","Properties":{"id":"20250922214412-720d3aa","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"时效性：知识的“保质期”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214412-os6h96e","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214412-os6h96e","updated":"20250922214412"},"Children":[{"ID":"20250922214412-xvhyt8u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-xvhyt8u","updated":"20250922214412"},"Children":[{"ID":"20250922214412-r946kje","Type":"NodeParagraph","Properties":{"id":"20250922214412-r946kje","updated":"20250922214412"},"Children":[{"Type":"NodeText","Data":"文章还点出了另一个重要问题——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识时效性"},{"Type":"NodeText","Data":"。由于LLM的知识被“冻结”在预训练的那一刻，它们无法回答关于最新事件的问题。"}]}]},{"ID":"20250922214412-mhrh1ib","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214412-mhrh1ib","updated":"20250922214412"},"Children":[{"ID":"20250922214412-1y36kdh","Type":"NodeParagraph","Properties":{"id":"20250922214412-1y36kdh","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开卷问答/检索增强"},{"Type":"NodeText","Data":"是解决这个问题的主流方法，通过实时检索最新信息来弥补模型内部知识的陈旧。"}]}]}]}]}]},{"ID":"20250922214412-1y2juyx","Type":"NodeParagraph","Properties":{"id":"20250922214412-1y2juyx","updated":"20250922214412"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第四十七部分深刻地揭示了LLM在知识利用方面的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“双面性”"},{"Type":"NodeText","Data":"。一方面，它们通过海量数据预训练，内化了惊人的世界知识，在各种问答任务上表现出色。另一方面，它们缺乏真正的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“事实感”"},{"Type":"NodeText","Data":"，导致"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幻觉"},{"Type":"NodeText","Data":"成为其最严重、最根本的缺陷之一。本部分系统地梳理了如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估"},{"Type":"NodeText","Data":"这种能力（三类任务），以及如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应对"},{"Type":"NodeText","Data":"其缺陷（幻觉的检测与缓解），为我们理解和使用LLM的知识能力提供了全面而深入的视角。"}]}]},{"ID":"20250922214645-mwns97n","Type":"NodeParagraph","Properties":{"id":"20250922214645-mwns97n","updated":"20250922214645"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922214645-q7m8l0v","Type":"NodeThematicBreak","Properties":{"id":"20250922214645-q7m8l0v","updated":"20250922214645"}},{"ID":"20250922214645-iui5nxw","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214645-iui5nxw","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第四十八部分"}]},{"ID":"20250922214645-1k8pyxy","Type":"NodeBlockquote","Properties":{"id":"20250922214645-1k8pyxy","updated":"20250922214650"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214645-ka09se7","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214645-ka09se7","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幻觉"}]},{"ID":"20250922214645-d0zs1or","Type":"NodeParagraph","Properties":{"id":"20250922214645-d0zs1or","updated":"20250922214645"},"Children":[{"Type":"NodeText","Data":"LLM容易生成与现有来源冲突或无法被可用来源验证的不真实信息。即使是像ChatGPT这样最强大的LLM，在减轻生成文本的幻觉方面也面临巨大挑战。这个问题可以通过对齐微调和工具利用等特殊方法部分缓解。"}]}]},{"ID":"20250922214645-ldtq27o","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214645-ldtq27o","updated":"20250922214650"},"Children":[{"ID":"20250922214645-7v936d0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-7v936d0","updated":"20250922214645"},"Children":[{"ID":"20250922214645-q9jzrl0","Type":"NodeParagraph","Properties":{"id":"20250922214645-q9jzrl0","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识时效性 (Knowledge recency)."},{"Type":"NodeText","Data":" 另一个主要挑战是，LLM在解决需要超出训练数据的最新知识的任务时会遇到困难。为了解决这个问题，一个直接的方法是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定期用新数据更新LLM"},{"Type":"NodeText","Data":"。然而，微调LLM的成本非常高，并且在增量训练LLM时很可能导致"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"灾难性遗忘"},{"Type":"NodeText","Data":"问题。因此，有必要开发高效且有效的方法，将新知识整合到现有LLM中，使其保持最新状态。现有的研究已经探索了如何利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部知识源"},{"Type":"NodeText","Data":"（例如，搜索引擎）来补充LLM，可以与LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"联合优化"},{"Type":"NodeText","Data":"，或用作"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"即插即用"},{"Type":"NodeText","Data":"的模块。例如，ChatGPT利用一个检索插件来访问最新的信息来源。通过将提取的相关信息并入上下文，LLM可以获取新的事实知识并在相关任务上表现更好。然而，这种方法似乎仍处于一个肤浅的层面。此外，现有的研究也探索了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编辑语言模型的参数"},{"Type":"NodeText","Data":"来更新内在知识。然而，先前的工作表明，几种参数编辑方法在LLM上表现不佳，尽管它们可以提升小型语言模型的性能。因此，直接修改LLM内部的内在知识或注入特定知识仍然是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放的研究问题"},{"Type":"NodeText","Data":"。最近，一个名为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"EasyEdit"},{"Type":"NodeText","Data":"的有用框架已被发布，以促进LLM的知识编辑研究。"}]}]}]},{"ID":"20250922214645-qx4hu58","Type":"NodeBlockquote","Properties":{"id":"20250922214645-qx4hu58","updated":"20250922214650"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214645-l3wk0p0","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214645-l3wk0p0","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识时效性"}]},{"ID":"20250922214645-3xy0hm0","Type":"NodeParagraph","Properties":{"id":"20250922214645-3xy0hm0","updated":"20250922214645"},"Children":[{"Type":"NodeText","Data":"LLM的参数化知识很难及时更新。用外部知识源来增强LLM是解决这个问题的一个实用方法。然而，如何有效地在LLM内部更新知识仍然是一个开放的研究问题。"}]}]},{"ID":"20250922214645-svyc34p","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214645-svyc34p","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.1.3 Complex Reasoning (复杂推理)"}]},{"ID":"20250922214645-9a3jcmf","Type":"NodeParagraph","Properties":{"id":"20250922214645-9a3jcmf","updated":"20250922214650"},"Children":[{"Type":"NodeText","Data":"复杂推理指的是理解和利用支持性证据或逻辑来得出结论或做出决定的能力。根据所涉及的逻辑和证据类型，我们考虑将现有的评估任务分为三个主要类别，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识推理、符号推理和数学推理"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922214645-i6tragc","Type":"NodeParagraph","Properties":{"id":"20250922214645-i6tragc","updated":"20250922214650"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Knowledge Reasoning (知识推理)."},{"Type":"NodeText","Data":" 知识推理任务依赖于关于事实知识的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逻辑关系和证据"},{"Type":"NodeText","Data":"来回答给定的问题。现有的工作主要使用特定的数据集来评估相应类型的知识的推理能力，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CSQA/StrategyQA"},{"Type":"NodeText","Data":"用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识知识推理"},{"Type":"NodeText","Data":"，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ScienceQA"},{"Type":"NodeText","Data":"用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学知识推理"},{"Type":"NodeText","Data":"。除了预测结果的准确性，现有的工作还通过自动指标（例如，BLEU）或人类评估来评估生成的推理过程的质量。通常，这些任务要求LLM基于事实知识进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"逐步推理"},{"Type":"NodeText","Data":"，直到得出给定问题的答案。为了激发逐步推理的能力，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）提示策略"},{"Type":"NodeText","Data":"已被提出来增强LLM的复杂推理能力。正如6.3节所讨论的，CoT将中间推理步骤（可以手动创建或自动生成）并入提示中，以指导LLM执行多步推理。这种方式极大地提升了LLM的推理性能，在几个复杂的知识推理任务上取得了新的最新成果。此外，在将知识推理任务重新形式化为代码生成任务后，研究人员发现LLM的性能可以得到进一步提升，特别是对于在代码上预训练的LLM。然而，由于知识推理任务的复杂性，当前LLM的性能在常识推理等任务上仍然落后于人类。作为一种常见的错误类型，LLM可能会生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不准确的中间步骤"},{"Type":"NodeText","Data":"，导致错误的最终结果。为了解决这个问题，现有的工作提出了特殊的解码或集成策略来提高整个推理链的准确率。"}]},{"ID":"20250922214645-quanr0s","Type":"NodeParagraph","Properties":{"id":"20250922214645-quanr0s","updated":"20250922214650"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Symbolic Reasoning (符号推理)."},{"Type":"NodeText","Data":" 符号推理任务主要关注在形式化规则设置中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"操纵符号"},{"Type":"NodeText","Data":"以实现特定目标，其中操作和规则可能在预训练期间从未被LLM见过。现有的工作通常在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"末尾字母拼接"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"硬币翻转"},{"Type":"NodeText","Data":"任务上评估LLM，其中评估示例要求与上下文中的示例相同的推理步骤（称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域内测试"},{"Type":"NodeText","Data":"）或更多的步骤（称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域外测试"},{"Type":"NodeText","Data":"）。对于领域外测试的例子，LLM可能只在上下文中看到包含两个词的示例，但它需要拼接三个或更多词的末尾字母。通常，采用生成符号的准确率来评估LLM在这些任务上的性能。因此，LLM需要理解符号操作之间的语义关系及其在复杂场景中的组合。然而，在领域外设置下，由于LLM没有见过符号操作和规则的复杂组合（例如，是上下文示例中操作数量的两倍），LLM很难捕捉它们的准确含义。为了解决这个问题，现有的研究整合了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"便笺（scratchpad）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"导师（tutor）"},{"Type":"NodeText","Data":"策略，以帮助LLM更好地操纵符号操作，以生成更长、更复杂的推理过程。另一条研究路线利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"形式化编程语言"},{"Type":"NodeText","Data":"来表示符号操作和规则，这要求LLM生成代码，并通过外部解释器执行推理过程。这种方式可以将复杂的推理过程分解为LLM的代码合成和解释器的程序执行，从而得到一个简化但结果更准确的推理过程。"}]},{"ID":"20250922214645-1kszmb9","Type":"NodeParagraph","Properties":{"id":"20250922214645-1kszmb9","updated":"20250922214650"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Mathematical Reasoning (数学推理).-"},{"Type":"NodeText","Data":" 数学推理任务需要全面利用数学知识、逻辑和计算来解决问题或生成证明陈述。现有的数学推理任务可以主要分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学问题求解"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动定理证明"},{"Type":"NodeText","Data":"。对于数学问题求解任务，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SVAMP、GSM8k和MATH"},{"Type":"NodeText","Data":"数据集通常用于评估，其中LLM需要生成准确的具体数字或方程式来回答数学问题。由于这些任务也需要多步推理，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT提示策略"},{"Type":"NodeText","Data":"已被广泛用于LLM以提升推理性能。作为另一个实用的策略，"}]},{"ID":"20250922214645-ik90kah","Type":"NodeBlockquote","Properties":{"id":"20250922214645-ik90kah","updated":"20250922214650"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214645-hj8tceq","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214645-hj8tceq","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922214645-8lvmlaz","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214645-8lvmlaz","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识时效性：LLM与时间的赛跑"}]},{"ID":"20250922214645-t2znm4i","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214645-t2znm4i","updated":"20250922214645"},"Children":[{"ID":"20250922214645-gq0qypd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-gq0qypd","updated":"20250922214645"},"Children":[{"ID":"20250922214645-8szjqtc","Type":"NodeParagraph","Properties":{"id":"20250922214645-8szjqtc","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心问题"},{"Type":"NodeText","Data":": LLM的知识被"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“冻结”"},{"Type":"NodeText","Data":"在其预训练数据的时间点。它不知道之后发生的新闻、事件和发现。"}]}]},{"ID":"20250922214645-4zy2nk5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-4zy2nk5","updated":"20250922214645"},"Children":[{"ID":"20250922214645-le9sz9a","Type":"NodeParagraph","Properties":{"id":"20250922214645-le9sz9a","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大解决方案与挑战"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214645-qhvel8j","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214645-qhvel8j","updated":"20250922214645"},"Children":[{"ID":"20250922214645-ibjt08z","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922214645-ibjt08z","updated":"20250922214645"},"Children":[{"ID":"20250922214645-jeiexvn","Type":"NodeParagraph","Properties":{"id":"20250922214645-jeiexvn","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内部更新 (Internal Update)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214645-6z3ah5d","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214645-6z3ah5d","updated":"20250922214645"},"Children":[{"ID":"20250922214645-o0zh7qm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-o0zh7qm","updated":"20250922214645"},"Children":[{"ID":"20250922214645-pxe0cof","Type":"NodeParagraph","Properties":{"id":"20250922214645-pxe0cof","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续微调（Continual Fine-tuning）"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数编辑（Parameter Editing）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214645-1jb06zh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-1jb06zh","updated":"20250922214645"},"Children":[{"ID":"20250922214645-en1upnt","Type":"NodeParagraph","Properties":{"id":"20250922214645-en1upnt","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"挑战"},{"Type":"NodeText","Data":": 成本高昂，且容易引发"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“灾难性遗忘”"},{"Type":"NodeText","Data":"——学会了新知识，忘记了旧知识。直接编辑模型参数的技术目前还不成熟。这是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"悬而未决的重大研究课题"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922214645-fkwgpcq","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922214645-fkwgpcq","updated":"20250922214645"},"Children":[{"ID":"20250922214645-eg5hsgv","Type":"NodeParagraph","Properties":{"id":"20250922214645-eg5hsgv","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部增强 (External Augmentation)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214645-tcd8fdt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214645-tcd8fdt","updated":"20250922214645"},"Children":[{"ID":"20250922214645-7ix069z","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-7ix069z","updated":"20250922214645"},"Children":[{"ID":"20250922214645-dkz7bj9","Type":"NodeParagraph","Properties":{"id":"20250922214645-dkz7bj9","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检索增强生成（RAG）"},{"Type":"NodeText","Data":"。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"即插即用"},{"Type":"NodeText","Data":"的搜索引擎等外部工具，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实时检索"},{"Type":"NodeText","Data":"最新信息并提供给LLM作为上下文。"}]}]},{"ID":"20250922214645-7yzcxge","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-7yzcxge","updated":"20250922214645"},"Children":[{"ID":"20250922214645-rn2zb6z","Type":"NodeParagraph","Properties":{"id":"20250922214645-rn2zb6z","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"现状"},{"Type":"NodeText","Data":": 这是当前"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最实用、最主流"},{"Type":"NodeText","Data":"的解决方案。但作者指出，这种方式还比较"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“肤浅”"},{"Type":"NodeText","Data":"，只是简单地将信息拼接，并未真正融入模型的知识体系。"}]}]}]}]}]}]}]},{"ID":"20250922214645-sspyuwk","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214645-sspyuwk","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理：LLM智力的“天花板”"}]},{"ID":"20250922214645-w63gvf0","Type":"NodeParagraph","Properties":{"id":"20250922214645-w63gvf0","updated":"20250922214645"},"Children":[{"Type":"NodeText","Data":"这部分评估的是LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最高级别"},{"Type":"NodeText","Data":"的认知能力。"}]},{"ID":"20250922214645-vgn1kw6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214645-vgn1kw6","updated":"20250922214645"},"Children":[{"ID":"20250922214645-4jnyt30","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-4jnyt30","updated":"20250922214645"},"Children":[{"ID":"20250922214645-klxydi1","Type":"NodeParagraph","Properties":{"id":"20250922214645-klxydi1","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大推理类型"},{"Type":"NodeText","Data":":"}]}]}]}]},{"ID":"20250922214645-pdr98ev","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214645-pdr98ev","updated":"20250922214650"},"Children":[{"ID":"20250922214645-g6q6cfb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-g6q6cfb","updated":"20250922214645"},"Children":[{"ID":"20250922214645-egydvhg","Type":"NodeParagraph","Properties":{"id":"20250922214645-egydvhg","updated":"20250922214645"}}]}]},{"ID":"20250922214645-nhtjjx7","Type":"NodeBlockquote","Properties":{"id":"20250922214645-nhtjjx7","updated":"20250922214650"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214645-vc0g3fk","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214645-vc0g3fk","updated":"20250922214645"},"Children":[{"ID":"20250922214645-2ty9eki","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922214645-2ty9eki","updated":"20250922214645"},"Children":[{"ID":"20250922214646-ircqnuh","Type":"NodeParagraph","Properties":{"id":"20250922214646-ircqnuh","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识推理 (Knowledge Reasoning)"},{"Type":"NodeText","Data":":"}]}]}]},{"ID":"20250922214646-e4l3whw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214646-e4l3whw","updated":"20250922214646"},"Children":[{"ID":"20250922214645-jj93d5x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-jj93d5x","updated":"20250922214645"},"Children":[{"ID":"20250922214646-27gydr0","Type":"NodeParagraph","Properties":{"id":"20250922214646-27gydr0","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本质"},{"Type":"NodeText","Data":": 基于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常识"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"事实知识"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多步逻辑推导"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214645-jbk6ly4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-jbk6ly4","updated":"20250922214645"},"Children":[{"ID":"20250922214646-nxvoe54","Type":"NodeParagraph","Properties":{"id":"20250922214646-nxvoe54","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心技术"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"。CoT是解锁LLM此类能力的关键。"}]}]},{"ID":"20250922214645-f6epsqp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-f6epsqp","updated":"20250922214645"},"Children":[{"ID":"20250922214646-g78pi9j","Type":"NodeParagraph","Properties":{"id":"20250922214646-g78pi9j","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前沿方向"},{"Type":"NodeText","Data":": 将推理问题"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“代码化”"},{"Type":"NodeText","Data":"，利用模型强大的代码生成能力来解决，能进一步提升性能。"}]}]},{"ID":"20250922214645-h46fvho","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-h46fvho","updated":"20250922214645"},"Children":[{"ID":"20250922214646-oj9pk19","Type":"NodeParagraph","Properties":{"id":"20250922214646-oj9pk19","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"瓶颈"},{"Type":"NodeText","Data":": 仍然"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"落后于人类"},{"Type":"NodeText","Data":"，且容易在推理链的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"中间步骤出错"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922214645-heowvr4","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214645-heowvr4","updated":"20250922214645"},"Children":[{"ID":"20250922214645-gki8qqa","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922214645-gki8qqa","updated":"20250922214645"},"Children":[{"ID":"20250922214646-kreinaq","Type":"NodeParagraph","Properties":{"id":"20250922214646-kreinaq","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符号推理 (Symbolic Reasoning)"},{"Type":"NodeText","Data":":"}]}]}]},{"ID":"20250922214646-5p47tml","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214646-5p47tml","updated":"20250922214646"},"Children":[{"ID":"20250922214645-pv2a2lx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-pv2a2lx","updated":"20250922214645"},"Children":[{"ID":"20250922214646-sxliw9p","Type":"NodeParagraph","Properties":{"id":"20250922214646-sxliw9p","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本质"},{"Type":"NodeText","Data":": 在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"抽象规则"},{"Type":"NodeText","Data":"下操纵"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符号"},{"Type":"NodeText","Data":"的能力。这是对模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"抽象推理"},{"Type":"NodeText","Data":"能力的极限测试，因为它需要在训练中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"未见过"},{"Type":"NodeText","Data":"的、更复杂的场景下应用规则。"}]}]},{"ID":"20250922214645-ccpmmhc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-ccpmmhc","updated":"20250922214645"},"Children":[{"ID":"20250922214646-e92nwre","Type":"NodeParagraph","Properties":{"id":"20250922214646-e92nwre","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心技术"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"便笺（Scratchpad）"},{"Type":"NodeText","Data":"——让模型在生成最终答案前，先写出中间的计算或推导步骤。"}]}]},{"ID":"20250922214645-8ojmz8v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-8ojmz8v","updated":"20250922214645"},"Children":[{"ID":"20250922214646-luqorxi","Type":"NodeParagraph","Properties":{"id":"20250922214646-luqorxi","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前沿方向"},{"Type":"NodeText","Data":": 同样是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“代码化”"},{"Type":"NodeText","Data":"，将符号操作翻译成可执行的代码，利用外部解释器保证执行的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确性"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250922214645-abt456c","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214645-abt456c","updated":"20250922214645"},"Children":[{"ID":"20250922214645-dus2h73","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922214645-dus2h73","updated":"20250922214645"},"Children":[{"ID":"20250922214646-kzrhezy","Type":"NodeParagraph","Properties":{"id":"20250922214646-kzrhezy","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学推理 (Mathematical Reasoning)"},{"Type":"NodeText","Data":":"}]}]}]},{"ID":"20250922214646-uxr0pkd","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214646-uxr0pkd","updated":"20250922214646"},"Children":[{"ID":"20250922214645-o7a2lxp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-o7a2lxp","updated":"20250922214645"},"Children":[{"ID":"20250922214646-91kmx0y","Type":"NodeParagraph","Properties":{"id":"20250922214646-91kmx0y","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"本质"},{"Type":"NodeText","Data":": 结合了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识、逻辑和精确计算"},{"Type":"NodeText","Data":"的终极推理挑战。"}]}]},{"ID":"20250922214645-6g8ssqc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-6g8ssqc","updated":"20250922214645"},"Children":[{"ID":"20250922214646-l8vre2n","Type":"NodeParagraph","Properties":{"id":"20250922214646-l8vre2n","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大任务"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题求解"},{"Type":"NodeText","Data":"（如应用题）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定理证明"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214645-7st9hhn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-7st9hhn","updated":"20250922214645"},"Children":[{"ID":"20250922214646-3xf9y3e","Type":"NodeParagraph","Properties":{"id":"20250922214646-3xf9y3e","updated":"20250922214646"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心技术"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维链（CoT）"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922214645-ued4y3q","Type":"NodeThematicBreak","Properties":{"id":"20250922214645-ued4y3q","updated":"20250922214650"}},{"ID":"20250922214645-p1usygs","Type":"NodeBlockquote","Properties":{"id":"20250922214645-p1usygs","updated":"20250922214650"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214645-v3ghv2b","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214645-v3ghv2b","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922214645-5u0a4fi","Type":"NodeParagraph","Properties":{"id":"20250922214645-5u0a4fi","updated":"20250922214645"},"Children":[{"Type":"NodeText","Data":"第四十八部分深入探讨了LLM在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识利用"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理"},{"Type":"NodeText","Data":"这两大核心认知能力上的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成就、局限与前沿探索"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922214645-wp5va4j","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214645-wp5va4j","updated":"20250922214645"},"Children":[{"ID":"20250922214645-5bk2k3x","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922214645-5bk2k3x","updated":"20250922214645"},"Children":[{"ID":"20250922214645-i5qcny3","Type":"NodeParagraph","Properties":{"id":"20250922214645-i5qcny3","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识的“诅咒”：时效性与幻觉"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214645-knt6hkh","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214645-knt6hkh","updated":"20250922214645"},"Children":[{"ID":"20250922214645-9c4xhmj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-9c4xhmj","updated":"20250922214645"},"Children":[{"ID":"20250922214645-1b4hohv","Type":"NodeParagraph","Properties":{"id":"20250922214645-1b4hohv","updated":"20250922214645"},"Children":[{"Type":"NodeText","Data":"本部分再次强调了LLM在知识层面面临的两大根本性挑战："}]},{"ID":"20250922214645-bqo9gp8","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214645-bqo9gp8","updated":"20250922214645"},"Children":[{"ID":"20250922214645-0oiqv3j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-0oiqv3j","updated":"20250922214645"},"Children":[{"ID":"20250922214645-ssmr116","Type":"NodeParagraph","Properties":{"id":"20250922214645-ssmr116","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"时效性"},{"Type":"NodeText","Data":": 模型的知识是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"静态的"},{"Type":"NodeText","Data":"，无法跟上现实世界的变化。"}]}]},{"ID":"20250922214645-2ivzasc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-2ivzasc","updated":"20250922214645"},"Children":[{"ID":"20250922214645-k18u9hy","Type":"NodeParagraph","Properties":{"id":"20250922214645-k18u9hy","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"幻觉"},{"Type":"NodeText","Data":": 模型的知识是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不可靠的"},{"Type":"NodeText","Data":"，它无法区分事实与虚构。"}]}]}]}]},{"ID":"20250922214645-k2j7e6f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-k2j7e6f","updated":"20250922214645"},"Children":[{"ID":"20250922214645-ftxjs1d","Type":"NodeParagraph","Properties":{"id":"20250922214645-ftxjs1d","updated":"20250922214645"},"Children":[{"Type":"NodeText","Data":"文章清晰地指出了当前应对策略的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"权衡"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部检索（RAG）"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实用但肤浅"},{"Type":"NodeText","Data":"的解决方案，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内部编辑"},{"Type":"NodeText","Data":"则是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本但困难"},{"Type":"NodeText","Data":"的开放性问题。这为该领域的研究指明了方向。"}]}]}]}]},{"ID":"20250922214645-vu8cc7o","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922214645-vu8cc7o","updated":"20250922214645"},"Children":[{"ID":"20250922214645-ve83udb","Type":"NodeParagraph","Properties":{"id":"20250922214645-ve83udb","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理：通往更高智能的阶梯"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214645-06lxwrg","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214645-06lxwrg","updated":"20250922214645"},"Children":[{"ID":"20250922214645-ksf4dda","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-ksf4dda","updated":"20250922214645"},"Children":[{"ID":"20250922214645-ahi3a3x","Type":"NodeParagraph","Properties":{"id":"20250922214645-ahi3a3x","updated":"20250922214645"},"Children":[{"Type":"NodeText","Data":"文章将复杂推理分解为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识、符号、数学"},{"Type":"NodeText","Data":"三大领域，这种划分清晰地揭示了推理任务的不同层次和挑战。"}]}]},{"ID":"20250922214645-na8v0om","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-na8v0om","updated":"20250922214645"},"Children":[{"ID":"20250922214645-a99583a","Type":"NodeParagraph","Properties":{"id":"20250922214645-a99583a","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个贯穿始终的核心技术——思维链（CoT）"},{"Type":"NodeText","Data":": CoT被反复提及，证明了它是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解锁LLM所有类型复杂推理能力"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“万能钥匙”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214645-5tzx0ks","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-5tzx0ks","updated":"20250922214645"},"Children":[{"ID":"20250922214645-edjqioo","Type":"NodeParagraph","Properties":{"id":"20250922214645-edjqioo","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个共同的前沿方向——“代码化”"},{"Type":"NodeText","Data":": 无论是知识推理、符号推理还是数学推理，将问题"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重新形式化为代码生成任务"},{"Type":"NodeText","Data":"，都被证明是一条"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极其有效"},{"Type":"NodeText","Data":"的性能提升路径。这深刻地揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码"},{"Type":"NodeText","Data":"作为一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确、结构化的逻辑语言"},{"Type":"NodeText","Data":"，与LLM的推理能力之间存在着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内在的、深刻的联系"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922214645-5pyqacc","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922214645-5pyqacc","updated":"20250922214645"},"Children":[{"ID":"20250922214645-zi5v8sz","Type":"NodeParagraph","Properties":{"id":"20250922214645-zi5v8sz","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“能做”到“做好”的挑战"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214645-f78hslt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214645-f78hslt","updated":"20250922214645"},"Children":[{"ID":"20250922214645-bywhp31","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-bywhp31","updated":"20250922214645"},"Children":[{"ID":"20250922214645-d01j1ra","Type":"NodeParagraph","Properties":{"id":"20250922214645-d01j1ra","updated":"20250922214645"},"Children":[{"Type":"NodeText","Data":"尽管LLM在复杂推理上取得了惊人的进步，但文章也坦诚地指出了其与人类水平的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"差距"},{"Type":"NodeText","Data":"，以及在推理过程中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“中间步骤出错”"},{"Type":"NodeText","Data":"的核心问题。"}]}]},{"ID":"20250922214645-m076aij","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214645-m076aij","updated":"20250922214645"},"Children":[{"ID":"20250922214645-iap6bq8","Type":"NodeParagraph","Properties":{"id":"20250922214645-iap6bq8","updated":"20250922214645"},"Children":[{"Type":"NodeText","Data":"为了解决这个问题，研究者们提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"集成（如Self-Consistency）、验证（如Self-Verification）"},{"Type":"NodeText","Data":"等高级策略。这表明，LLM推理的研究正在从“如何让它思考”，进入到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“如何让它思考得更可靠、更严谨”"},{"Type":"NodeText","Data":"的深水区。"}]}]}]}]}]},{"ID":"20250922214645-b9t0465","Type":"NodeParagraph","Properties":{"id":"20250922214645-b9t0465","updated":"20250922214645"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第四十八部分为我们描绘了一幅LLM在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级认知能力"},{"Type":"NodeText","Data":"上不断探索的画卷。它一方面展示了LLM通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码化"},{"Type":"NodeText","Data":"等技术，在推理方面取得的巨大成就；另一方面，也深刻地揭示了其在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识的可靠性（幻觉与时效性）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理的严谨性"},{"Type":"NodeText","Data":"方面存在的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本性挑战"},{"Type":"NodeText","Data":"。这部分内容清晰地表明，未来的LLM研究，将更加聚焦于如何让模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不仅“会思考”，更能“思考得对、思考得好”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-g3ulmcq","Type":"NodeParagraph","Properties":{"id":"20250922214859-g3ulmcq","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922214859-095q009","Type":"NodeThematicBreak","Properties":{"id":"20250922214859-095q009","updated":"20250922214859"}},{"ID":"20250922214859-90urna2","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214859-90urna2","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第四十九部分"}]},{"ID":"20250922214859-bqemcya","Type":"NodeParagraph","Properties":{"id":"20250922214859-bqemcya","updated":"20250922214917"},"Children":[{"Type":"NodeText","Data":"持续地在大规模数学语料库上对LLM进行预训练可以在很大程度上提升它们在数学推理任务上的性能。此外，由于不同语言的数学问题共享相同的数学逻辑，研究人员还提出了一个多语言数学应用题基准，以评估LLM的多语言数学推理能力。作为另一个具有挑战性的任务，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动定理证明（ATP）"},{"Type":"NodeText","Data":"要求推理模型严格遵循推理逻辑和数学技能。为了评估该任务的性能，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PISA"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"miniF2F"},{"Type":"NodeText","Data":"是两个典型的ATP数据集，以证明成功率作为评估指标。作为一种典型的方法，现有的ATP工作利用LLM来辅助使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交互式定理证明器（ITP）"},{"Type":"NodeText","Data":"（如Lean, Metamath, 和Isabelle）进行证明搜索。ATP研究的一个主要局限是缺乏相关形式化语言的语料库。为了解决这个问题，一些研究利用LLM将非形式化陈述转换为形式化证明以扩充新数据，或生成草稿和证明草图以缩小证明的搜索空间。"}]},{"ID":"20250922214859-j4a2tld","Type":"NodeParagraph","Properties":{"id":"20250922214859-j4a2tld","updated":"20250922214917"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Major Issues (主要问题)."},{"Type":"NodeText","Data":" 尽管取得了进步，LLM在解决复杂的推理任务时仍然存在一些局限性。"}]},{"ID":"20250922214859-660zoth","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-660zoth","updated":"20250922214917"},"Children":[{"ID":"20250922214859-ar9n635","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-ar9n635","updated":"20250922214859"},"Children":[{"ID":"20250922214859-qap8ppi","Type":"NodeParagraph","Properties":{"id":"20250922214859-qap8ppi","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理不一致性 (Reasoning inconsistency)."},{"Type":"NodeText","Data":" 借助改进的推理策略（例如，CoT提示），LLM可以通过基于支持性逻辑和证据进行逐步推理来解决一些复杂的推理任务。尽管有效，但在分解的推理过程中经常出现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理不一致"},{"Type":"NodeText","Data":"的问题。具体来说，LLM可能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"遵循一个无效的推理路径得出正确的答案"},{"Type":"NodeText","Data":"，或者在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"一个正确的推理过程后产生错误的答案"},{"Type":"NodeText","Data":"，导致推导出的答案与推理过程之间不一致。为了缓解这个问题，现有的工作已经提出通过外部工具或模型来引导LLM的整个生成过程，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重新检查"},{"Type":"NodeText","Data":"推理过程和最终答案以纠正潜在的错误，或者用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于过程的反馈"},{"Type":"NodeText","Data":"来微调LLM。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"思维树（ToT）"},{"Type":"NodeText","Data":"通过同时探索和自我评估各种推理路径，赋予LLM参与决策过程的能力。为了提炼推理过程，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Self-Refine"},{"Type":"NodeText","Data":"从LLM对自我生成的解决方案的反馈中引出反馈，从而能够基于反馈对解决方案进行迭代提炼。此外，一些研究通过在训练期间整合"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程监督"},{"Type":"NodeText","Data":"来提高LLM推理链的一致性。作为一个有前景的解决方案，最近的方法将复杂的推理任务重新形式化为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码生成任务"},{"Type":"NodeText","Data":"，其中生成的代码的严格执行确保了推理过程和结果之间的一致性。此外，已经揭示任务之间可能存在与相似输入的不一致性，其中任务描述中的微小变化可能导致模型产生不同的结果。为了缓解这个问题，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自洽性"},{"Type":"NodeText","Data":"采用了多个推理路径的集成来增强LLM的解码过程。"}]}]},{"ID":"20250922214859-k2co6in","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-k2co6in","updated":"20250922214859"},"Children":[{"ID":"20250922214859-0xfj8q3","Type":"NodeParagraph","Properties":{"id":"20250922214859-0xfj8q3","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数值计算 (Numerical computation)."},{"Type":"NodeText","Data":" 对于复杂的推理任务，LLM在涉及的数值计算方面仍然面临困难，特别是对于在预训练期间很少遇到的符号，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大数算术"},{"Type":"NodeText","Data":"。为了解决这个问题，一个直接的方法是在合成的算术问题上对LLM进行微调。此外，大量的研究通过在训练和推理阶段追踪中间计算步骤来提高数值计算性能，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"便笺追踪（scratchpad tracing）"},{"Type":"NodeText","Data":"。此外，现有的工作也整合了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部工具"},{"Type":"NodeText","Data":"（例如，计算器），特别是用于处理算术运算。最近，ChatGPT提供了一个插件机制来使用外部工具。通过这种方式，LLM需要学习如何正确地操纵这些工具。为此，研究人员通过使用工具（甚至是LLM本身）来增强示例以微调LLM，或为上下文学习设计指令和范例。除了外部工具的帮助，最近的研究发现，将数字"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分词为单个数字"},{"Type":"NodeText","Data":"（例如，LLaMA和Galactica分词器）是增强LLM固有算术能力的有用方法。一个可能的解释是，子词分词技术在对数字进行分词时可能导致不一致的序列。例如，使用子词分词器，整数7481可能被分词为 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"7"},{"Type":"NodeText","Data":"​ "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"481"},{"Type":"NodeText","Data":"​，而74815可能被分词为 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"748"},{"Type":"NodeText","Data":"​ "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"15"},{"Type":"NodeText","Data":"​（相同的数字子串具有不同的分割方式）。相比之下，对数字进行基于数字的分词可以避免这种不一致性，从而可能提升数值计算能力。"}]}]}]},{"ID":"20250922214859-7du7tgt","Type":"NodeBlockquote","Properties":{"id":"20250922214859-7du7tgt","updated":"20250922214917"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214859-cp26rqb","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214859-cp26rqb","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理不一致性"}]},{"ID":"20250922214859-cyxrbuc","Type":"NodeParagraph","Properties":{"id":"20250922214859-cyxrbuc","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"LLM可能会遵循一个无效的推理路径得出正确的答案，或者在一个正确的推理过程后产生错误的答案，导致推导出的答案与推理过程之间不一致。这个问题可以通过用过程级反馈微调LLM、使用多样化推理路径的集成以及通过自我反思或外部反馈来提炼推理过程来缓解。"}]}]},{"ID":"20250922214859-0b40bpu","Type":"NodeBlockquote","Properties":{"id":"20250922214859-0b40bpu","updated":"20250922214917"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214859-j3kcf1f","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214859-j3kcf1f","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数值计算"}]},{"ID":"20250922214859-s9ckjaa","Type":"NodeParagraph","Properties":{"id":"20250922214859-s9ckjaa","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"LLM在数值计算方面面临困难，特别是对于在预训练期间很少遇到的符号。除了使用数学工具，将数字分词为单个数字也是一种提高算术能力的有效设计选择。"}]}]},{"ID":"20250922214859-uassfl8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214859-uassfl8","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.2 Advanced Ability (高级能力)"}]},{"ID":"20250922214859-ttt7pkz","Type":"NodeParagraph","Properties":{"id":"20250922214859-ttt7pkz","updated":"20250922214917"},"Children":[{"Type":"NodeText","Data":"除了上述基础评估任务，LLM还展现出一些需要特殊考虑进行评估的卓越能力。在本部分中，我们讨论几种代表性的高级能力及其相应的评估方法，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐、与外部环境的交互和工具操作"},{"Type":"NodeText","Data":"。接下来，我们将详细讨论这些高级能力。"}]},{"ID":"20250922214859-g3c0qpt","Type":"NodeBlockquote","Properties":{"id":"20250922214859-g3c0qpt","updated":"20250922214917"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214859-0a50nuz","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214859-0a50nuz","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922214859-hltfcmr","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214859-hltfcmr","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学推理：LLM的“奥数竞赛”"}]},{"ID":"20250922214859-khg7pom","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-khg7pom","updated":"20250922214859"},"Children":[{"ID":"20250922214859-1tgduzt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-1tgduzt","updated":"20250922214859"},"Children":[{"ID":"20250922214859-c301ig8","Type":"NodeParagraph","Properties":{"id":"20250922214859-c301ig8","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大战场"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题求解"},{"Type":"NodeText","Data":"（应用题）和更抽象的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动定理证明（ATP）"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-4v1ki45","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-4v1ki45","updated":"20250922214859"},"Children":[{"ID":"20250922214859-hrf1rll","Type":"NodeParagraph","Properties":{"id":"20250922214859-hrf1rll","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据是关键"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214859-rbf0l3n","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-rbf0l3n","updated":"20250922214859"},"Children":[{"ID":"20250922214859-abt8p4d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-abt8p4d","updated":"20250922214859"},"Children":[{"ID":"20250922214859-fopl7q5","Type":"NodeParagraph","Properties":{"id":"20250922214859-fopl7q5","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大规模数学语料"},{"Type":"NodeText","Data":"的预训练能显著提升性能。"}]}]},{"ID":"20250922214859-6umqnod","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-6umqnod","updated":"20250922214859"},"Children":[{"ID":"20250922214859-j5i69ep","Type":"NodeParagraph","Properties":{"id":"20250922214859-j5i69ep","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"ATP领域面临"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"形式化语料稀缺"},{"Type":"NodeText","Data":"的瓶颈，利用LLM进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据增强”"},{"Type":"NodeText","Data":"（将非形式化描述转为形式化证明）是一个重要方向。"}]}]}]}]}]},{"ID":"20250922214859-wq9ga78","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214859-wq9ga78","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理的“两大顽疾”"}]},{"ID":"20250922214859-tp1rtlb","Type":"NodeParagraph","Properties":{"id":"20250922214859-tp1rtlb","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"这部分内容深刻地指出了LLM在推理时面临的两个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本性缺陷"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922214859-z1b48gv","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214859-z1b48gv","updated":"20250922214859"},"Children":[{"ID":"20250922214859-obn9ni2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922214859-obn9ni2","updated":"20250922214859"},"Children":[{"ID":"20250922214859-scbew4w","Type":"NodeParagraph","Properties":{"id":"20250922214859-scbew4w","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理不一致性 (Reasoning Inconsistency)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214859-da0wjqt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-da0wjqt","updated":"20250922214859"},"Children":[{"ID":"20250922214859-yfqcwy3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-yfqcwy3","updated":"20250922214859"},"Children":[{"ID":"20250922214859-46cbhig","Type":"NodeParagraph","Properties":{"id":"20250922214859-46cbhig","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"症状"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“歪打正着”"},{"Type":"NodeText","Data":"（过程错，答案对）或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“功亏一篑”"},{"Type":"NodeText","Data":"（过程对，答案错）。"}]}]},{"ID":"20250922214859-6cci6w0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-6cci6w0","updated":"20250922214859"},"Children":[{"ID":"20250922214859-3dh0lws","Type":"NodeParagraph","Properties":{"id":"20250922214859-3dh0lws","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根源"},{"Type":"NodeText","Data":": LLM的推理过程和最终答案的生成，在概率上可能不是强绑定的。它只是在生成一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“看起来最合理的”"},{"Type":"NodeText","Data":"推理链和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“看起来最合理的”"},{"Type":"NodeText","Data":"答案，两者之间缺乏"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"严格的因果约束"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-df10kdp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-df10kdp","updated":"20250922214859"},"Children":[{"ID":"20250922214859-zj4brc0","Type":"NodeParagraph","Properties":{"id":"20250922214859-zj4brc0","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解决方案"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214859-n4xhxvt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-n4xhxvt","updated":"20250922214859"},"Children":[{"ID":"20250922214859-9pwgad3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-9pwgad3","updated":"20250922214859"},"Children":[{"ID":"20250922214859-5vd3o5h","Type":"NodeParagraph","Properties":{"id":"20250922214859-5vd3o5h","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过程监督 (Process Supervision)"},{"Type":"NodeText","Data":": 在训练时，不仅奖励正确的答案，更要奖励"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"正确的推理过程"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-kgboaha","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-kgboaha","updated":"20250922214859"},"Children":[{"ID":"20250922214859-jbqy1i6","Type":"NodeParagraph","Properties":{"id":"20250922214859-jbqy1i6","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自我修正 (Self-Refine / ToT)"},{"Type":"NodeText","Data":": 让模型在推理后进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自我检查和迭代修正"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-h2vvcdc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-h2vvcdc","updated":"20250922214859"},"Children":[{"ID":"20250922214859-vy9v7c9","Type":"NodeParagraph","Properties":{"id":"20250922214859-vy9v7c9","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码化 (Code Generation)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"终极解决方案"},{"Type":"NodeText","Data":"。将推理过程转化为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可执行的代码"},{"Type":"NodeText","Data":"。代码的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"确定性执行"},{"Type":"NodeText","Data":"天然地保证了过程和结果的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"绝对一致"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-14unf0f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-14unf0f","updated":"20250922214859"},"Children":[{"ID":"20250922214859-a6mi4a4","Type":"NodeParagraph","Properties":{"id":"20250922214859-a6mi4a4","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"集成 (Self-Consistency)"},{"Type":"NodeText","Data":": 通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多路径投票"},{"Type":"NodeText","Data":"来平滑掉单次推理的不一致性。"}]}]}]}]}]}]},{"ID":"20250922214859-vyntj4s","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922214859-vyntj4s","updated":"20250922214859"},"Children":[{"ID":"20250922214859-0jzhcsp","Type":"NodeParagraph","Properties":{"id":"20250922214859-0jzhcsp","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数值计算 (Numerical Computation)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214859-srwk1w5","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-srwk1w5","updated":"20250922214859"},"Children":[{"ID":"20250922214859-w5uixzh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-w5uixzh","updated":"20250922214859"},"Children":[{"ID":"20250922214859-t288kst","Type":"NodeParagraph","Properties":{"id":"20250922214859-t288kst","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"症状"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“算不对数”"},{"Type":"NodeText","Data":"，特别是对于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大数"},{"Type":"NodeText","Data":"或不常见的运算。"}]}]},{"ID":"20250922214859-nve0a2c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-nve0a2c","updated":"20250922214859"},"Children":[{"ID":"20250922214859-6fcub6g","Type":"NodeParagraph","Properties":{"id":"20250922214859-6fcub6g","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根源"},{"Type":"NodeText","Data":": LLM本质上是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本模式匹配器"},{"Type":"NodeText","Data":"，而非"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计算器"},{"Type":"NodeText","Data":"。它对数字的理解是基于其在文本中的出现模式，而不是其数学含义。"}]}]},{"ID":"20250922214859-n44ki06","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-n44ki06","updated":"20250922214859"},"Children":[{"ID":"20250922214859-d7xw3jy","Type":"NodeParagraph","Properties":{"id":"20250922214859-d7xw3jy","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解决方案"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214859-1bptxci","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-1bptxci","updated":"20250922214859"},"Children":[{"ID":"20250922214859-5uow1bq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-5uow1bq","updated":"20250922214859"},"Children":[{"ID":"20250922214859-3t4ott8","Type":"NodeParagraph","Properties":{"id":"20250922214859-3t4ott8","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外挂工具 (External Tools)"},{"Type":"NodeText","Data":": 最直接、最可靠的方法。让LLM学会"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"调用计算器"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-0uspngr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-0uspngr","updated":"20250922214859"},"Children":[{"ID":"20250922214859-03dzehg","Type":"NodeParagraph","Properties":{"id":"20250922214859-03dzehg","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"便笺 (Scratchpad)"},{"Type":"NodeText","Data":": 让模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"写出中间计算步骤"},{"Type":"NodeText","Data":"，可以提升其在简单计算上的准确率。"}]}]},{"ID":"20250922214859-aeucc93","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-aeucc93","updated":"20250922214859"},"Children":[{"ID":"20250922214859-1ekb2k6","Type":"NodeParagraph","Properties":{"id":"20250922214859-1ekb2k6","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分词优化 (Digit-based Tokenization)"},{"Type":"NodeText","Data":": 一个非常重要的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"底层优化"},{"Type":"NodeText","Data":"。将"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"7481"},{"Type":"NodeText","Data":"​分词为"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"7"},{"Type":"NodeText","Data":"​ "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"4"},{"Type":"NodeText","Data":"​ "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"8"},{"Type":"NodeText","Data":"​ "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"1"},{"Type":"NodeText","Data":"​，而不是"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"7"},{"Type":"NodeText","Data":"​ "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"481"},{"Type":"NodeText","Data":"​。这使得模型能更好地学习到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数字的位值关系"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"算术规则"},{"Type":"NodeText","Data":"，从而提升其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"固有的（inherent）"},{"Type":"NodeText","Data":"计算能力。"}]}]}]}]}]}]}]},{"ID":"20250922214859-tdz1ypi","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922214859-tdz1ypi","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力：超越文本的交互智能"}]},{"ID":"20250922214859-dtqi7t1","Type":"NodeParagraph","Properties":{"id":"20250922214859-dtqi7t1","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"这部分是对评估框架的进一步拓展，从评估模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“内在智商”"},{"Type":"NodeText","Data":"，转向评估其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与外部世界交互的“综合素质”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922214859-q70x6v9","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-q70x6v9","updated":"20250922214859"},"Children":[{"ID":"20250922214859-qc07lm4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-qc07lm4","updated":"20250922214859"},"Children":[{"ID":"20250922214859-0ogt6gm","Type":"NodeParagraph","Properties":{"id":"20250922214859-0ogt6gm","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐 (Human Alignment)"},{"Type":"NodeText","Data":": 考察模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“价值观”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-kwu9zzc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-kwu9zzc","updated":"20250922214859"},"Children":[{"ID":"20250922214859-1xg082h","Type":"NodeParagraph","Properties":{"id":"20250922214859-1xg082h","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"与外部环境交互 (Interaction with External Environment)"},{"Type":"NodeText","Data":": 考察模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“具身智能”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-gxxcfb1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-gxxcfb1","updated":"20250922214859"},"Children":[{"ID":"20250922214859-s78v36b","Type":"NodeParagraph","Properties":{"id":"20250922214859-s78v36b","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具操作 (Tool Manipulation)"},{"Type":"NodeText","Data":": 考察模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“动手能力”"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922214859-mq57is8","Type":"NodeThematicBreak","Properties":{"id":"20250922214859-mq57is8","updated":"20250922214917"}},{"ID":"20250922214859-0dudpv1","Type":"NodeBlockquote","Properties":{"id":"20250922214859-0dudpv1","updated":"20250922214917"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922214859-7tkvm4p","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922214859-7tkvm4p","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922214859-3xl3g5l","Type":"NodeParagraph","Properties":{"id":"20250922214859-3xl3g5l","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"第四十九部分是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理能力评估"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"收尾"},{"Type":"NodeText","Data":"和对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力评估"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开启"},{"Type":"NodeText","Data":"。它深刻地揭示了LLM在推理能力上的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主要瓶颈"},{"Type":"NodeText","Data":"，并为未来的研究和评估指明了新的方向。"}]},{"ID":"20250922214859-i0untaz","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922214859-i0untaz","updated":"20250922214859"},"Children":[{"ID":"20250922214859-jwz727g","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922214859-jwz727g","updated":"20250922214859"},"Children":[{"ID":"20250922214859-5iiqsvx","Type":"NodeParagraph","Properties":{"id":"20250922214859-5iiqsvx","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理能力的“最后堡垒”——数学"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214859-wx5r4lt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-wx5r4lt","updated":"20250922214859"},"Children":[{"ID":"20250922214859-uqiuaot","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-uqiuaot","updated":"20250922214859"},"Children":[{"ID":"20250922214859-eti5kx4","Type":"NodeParagraph","Properties":{"id":"20250922214859-eti5kx4","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"数学推理被定位为LLM推理能力的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"终极考验"},{"Type":"NodeText","Data":"，因为它要求"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识、逻辑和精确计算"},{"Type":"NodeText","Data":"的完美结合。"}]}]},{"ID":"20250922214859-g2ngfuz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-g2ngfuz","updated":"20250922214859"},"Children":[{"ID":"20250922214859-uzc3sn8","Type":"NodeParagraph","Properties":{"id":"20250922214859-uzc3sn8","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动定理证明（ATP）"},{"Type":"NodeText","Data":"则因其对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"形式化逻辑"},{"Type":"NodeText","Data":"的严格要求，成为这一堡垒中最难攻克的一环。"}]}]}]}]},{"ID":"20250922214859-j8yuihe","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922214859-j8yuihe","updated":"20250922214859"},"Children":[{"ID":"20250922214859-7vgomm5","Type":"NodeParagraph","Properties":{"id":"20250922214859-7vgomm5","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"两大核心缺陷的深刻剖析"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214859-yrpoqkq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-yrpoqkq","updated":"20250922214859"},"Children":[{"ID":"20250922214859-twaouuj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-twaouuj","updated":"20250922214859"},"Children":[{"ID":"20250922214859-vl2msnc","Type":"NodeParagraph","Properties":{"id":"20250922214859-vl2msnc","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理不一致性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数值计算错误"},{"Type":"NodeText","Data":"是本部分最具洞察力的内容。它们揭示了当前LLM推理能力的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根本局限"},{"Type":"NodeText","Data":"："}]},{"ID":"20250922214859-tr46m8m","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-tr46m8m","updated":"20250922214859"},"Children":[{"ID":"20250922214859-pzz4c6q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-pzz4c6q","updated":"20250922214859"},"Children":[{"ID":"20250922214859-zay9v9w","Type":"NodeParagraph","Properties":{"id":"20250922214859-zay9v9w","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"LLM的推理是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“启发式的、概率性的”"},{"Type":"NodeText","Data":"，而非"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“形式化的、确定性的”"},{"Type":"NodeText","Data":"。这导致了过程与结果的脱节。"}]}]},{"ID":"20250922214859-3ljr35i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-3ljr35i","updated":"20250922214859"},"Children":[{"ID":"20250922214859-x2smeyr","Type":"NodeParagraph","Properties":{"id":"20250922214859-x2smeyr","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"LLM的计算是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模式匹配的”"},{"Type":"NodeText","Data":"，而非"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“基于规则的”"},{"Type":"NodeText","Data":"。这导致了其在精确计算上的无力。"}]}]}]}]},{"ID":"20250922214859-0wofdnf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-0wofdnf","updated":"20250922214859"},"Children":[{"ID":"20250922214859-nl83g5u","Type":"NodeParagraph","Properties":{"id":"20250922214859-nl83g5u","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"针对这两个问题提出的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“代码化”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“工具化”"},{"Type":"NodeText","Data":"两大解决方案，清晰地指明了未来提升LLM推理可靠性的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心路径"},{"Type":"NodeText","Data":"："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将LLM不擅长的事情，外包给确定性的程序或工具去完成"},{"Type":"NodeText","Data":"，让LLM专注于其最擅长的高层语义理解和规划。"}]}]}]}]},{"ID":"20250922214859-g826ckm","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922214859-g826ckm","updated":"20250922214859"},"Children":[{"ID":"20250922214859-xlqkp44","Type":"NodeParagraph","Properties":{"id":"20250922214859-xlqkp44","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“静态推理”到“动态交互”的评估升级"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922214859-gxqb3su","Type":"NodeList","ListData":{},"Properties":{"id":"20250922214859-gxqb3su","updated":"20250922214859"},"Children":[{"ID":"20250922214859-suku0zd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-suku0zd","updated":"20250922214859"},"Children":[{"ID":"20250922214859-5wvo2nm","Type":"NodeParagraph","Properties":{"id":"20250922214859-5wvo2nm","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"在系统地评估完LLM的“静态”基础能力（生成、知识、推理）之后，文章自然地将评估的视野拓展到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“动态”的高级能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-1ptl38v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-1ptl38v","updated":"20250922214859"},"Children":[{"ID":"20250922214859-nj3mghh","Type":"NodeParagraph","Properties":{"id":"20250922214859-nj3mghh","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐、环境交互、工具操作"},{"Type":"NodeText","Data":"这三项高级能力，共同指向了一个核心主题："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估LLM作为一个能够在真实世界（或模拟世界）中，与人类、环境和工具进行有效交互的“智能体（Agent）”的能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922214859-qz54zb7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922214859-qz54zb7","updated":"20250922214859"},"Children":[{"ID":"20250922214859-tey4gqd","Type":"NodeParagraph","Properties":{"id":"20250922214859-tey4gqd","updated":"20250922214859"},"Children":[{"Type":"NodeText","Data":"这标志着LLM评估的范式正在从传统的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“题库式”测试"},{"Type":"NodeText","Data":"，向更复杂的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“情境式、交互式”评估"},{"Type":"NodeText","Data":"演进。"}]}]}]}]}]},{"ID":"20250922214859-rcqdlpf","Type":"NodeParagraph","Properties":{"id":"20250922214859-rcqdlpf","updated":"20250922214859"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第四十九部分不仅为复杂推理的评估画上了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深刻的句号"},{"Type":"NodeText","Data":"，指出了其核心挑战和未来方向，更重要的是，它通过引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力"},{"Type":"NodeText","Data":"的概念，为整个评估框架"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"打开了一个新的维度"},{"Type":"NodeText","Data":"。它宣告了对LLM的评估，不能再仅仅局限于其处理文本的“智商”，而必须扩展到其作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"社会化智能体"},{"Type":"NodeText","Data":"的“综合素质”。"}]}]},{"ID":"20250922215126-k8zpy4r","Type":"NodeParagraph","Properties":{"id":"20250922215126-k8zpy4r","updated":"20250922215126"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922215126-3fdhpdh","Type":"NodeThematicBreak","Properties":{"id":"20250922215126-3fdhpdh","updated":"20250922215126"}},{"ID":"20250922215126-wtjk6e8","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215126-wtjk6e8","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第五十部分"}]},{"ID":"20250922215126-jvb6zz9","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215126-jvb6zz9","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.2.1 Human Alignment (人类对齐)"}]},{"ID":"20250922215126-020247l","Type":"NodeParagraph","Properties":{"id":"20250922215126-020247l","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"期望LLM能够很好地符合人类的价值观和需求，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐"},{"Type":"NodeText","Data":"，这是LLM在真实世界应用中广泛使用的关键能力。"}]},{"ID":"20250922215126-36v6m1w","Type":"NodeParagraph","Properties":{"id":"20250922215126-36v6m1w","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"为了评估这种能力，现有的研究考虑了人类对齐的多个标准，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有用性、诚实性和安全性"},{"Type":"NodeText","Data":"。对于有用性和诚实性，可以利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对抗性问答"},{"Type":"NodeText","Data":"任务（例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"TruthfulQA"},{"Type":"NodeText","Data":"）来检验LLM在检测文本中可能存在的谬误方面的能力。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"无害性"},{"Type":"NodeText","Data":"也可以通过几个现有的基准进行评估，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CrowS-Pairs"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Winogender"},{"Type":"NodeText","Data":"。尽管可以使用上述数据集进行自动评估，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类评估"},{"Type":"NodeText","Data":"仍然是有效测试LLM人类对齐能力的更直接方法。OpenAI邀请了与AI风险相关领域的许多专家，在遇到风险内容时评估和改进GPT-4的行为。此外，对于人类对齐的其他方面（例如，真实性），一些研究提出使用特定的指令和设计标注规则来指导标注过程。实证研究表明，这些策略可以极大地提升LLM的人类对齐能力。例如，在通过与专家互动收集的数据上进行对齐微调后，当处理敏感或不允许的提示时，GPT-4的不当行为率可以大大降低。此外，高质量的预训练数据可以减少对齐所需的工作量。例如，由于科学语料库中偏见内容较少，Galactica可能更无害。"}]},{"ID":"20250922215126-uctfxj9","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215126-uctfxj9","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.2.2 Interaction with External Environment (与外部环境的交互)"}]},{"ID":"20250922215126-oyupfd6","Type":"NodeParagraph","Properties":{"id":"20250922215126-oyupfd6","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"除了标准的评估任务，LLM还具有从外部环境接收反馈并根据行为指令执行动作的能力，例如，生成自然语言的行动计划来操纵智能体。这种能力在LLM中也是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现"},{"Type":"NodeText","Data":"的，它们可以生成详细且高度现实的行动计划，而较小的模型（例如，GPT-2）则倾向于生成更短或无意义的计划。"}]},{"ID":"20250922215126-nrjp4f1","Type":"NodeParagraph","Properties":{"id":"20250922215126-nrjp4f1","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"为了测试这种能力，可以使用几个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具身AI环境"},{"Type":"NodeText","Data":"和基准进行评估，描述如下。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"VirtualHome"},{"Type":"NodeText","Data":"构建了一个用于家务任务（如清洁和烹饪）的3D模拟器，其中智能体可以执行由LLM生成的自然语言动作。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ALFRED"},{"Type":"NodeText","Data":"包括更具挑战性的任务，要求LLM完成组合性目标。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BEHAVIOR"},{"Type":"NodeText","Data":"专注于模拟环境中的日常家务，并要求LLM生成复杂的解决方案，例如，改变对象的内部状态。除了像家务任务这样的受限环境，一条研究路线调查了基于LLM的智能体探索"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放世界环境"},{"Type":"NodeText","Data":"（如Minecraft和互联网）的熟练程度。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Voyager"},{"Type":"NodeText","Data":"引入了一个自动课程模块，使LLM能够基于来自环境的反馈不断获取新技能。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GITM"},{"Type":"NodeText","Data":"专注于基于LLM解决Minecraft中的各种挑战，通过任务分解、规划和接口调用。基于生成的行动计划或任务完成情况，现有的工作要么采用基准中的常规指标（例如，生成的行动计划的可执行性和正确性），要么直接进行真实世界的实验并测量"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成功率"},{"Type":"NodeText","Data":"，以评估这种能力。已有研究表明，LLM能够与外部环境互动并生成准确的行动计划。最近，已经提出了几种改进方法来增强LLM的交互能力，例如，设计类似代码的提示和提供真实世界的接地信息。"}]},{"ID":"20250922215126-fhuvj9o","Type":"NodeParagraph","Properties":{"id":"20250922215126-fhuvj9o","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"此外，最近的工作还探索了在模拟环境中基于LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多智能体协作"},{"Type":"NodeText","Data":"。这些研究通过在沙盒环境中实例化多个具有观察、规划和记忆能力的基于LLM的智能体来模拟人类社会行为。在受控评估中，生成式智能体的搜索、规划和思考能力由人类以类似访谈的方式进行评估。此外，他们还在一个模拟环境中对多个智能体进行描述性测量，以检验涌现的社会行为。"}]},{"ID":"20250922215126-kka18lb","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215126-kka18lb","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.2.3 Tool Manipulation (工具操作)"}]},{"ID":"20250922215126-t396org","Type":"NodeParagraph","Properties":{"id":"20250922215126-t396org","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"在解决复杂问题时，如果LLM确定有必要，它可以求助于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"外部工具"},{"Type":"NodeText","Data":"。通过将可用工具封装为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"API调用"},{"Type":"NodeText","Data":"，现有的工作已经涉及了各种外部工具，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"搜索引擎、计算器和编译器"},{"Type":"NodeText","Data":"，以增强LLM在几个特定任务上的性能。最近，OpenAI已经支持在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT中使用插件"},{"Type":"NodeText","Data":"，这可以为LLM配备超越语言建模的更广泛能力。例如，网页浏览器插件使ChatGPT能够访问最新信息。此外，整合第三方插件对于创建一个基于LLM的繁荣应用生态系统尤其关键。"}]},{"ID":"20250922215126-8ko31p2","Type":"NodeParagraph","Properties":{"id":"20250922215126-8ko31p2","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"为了检验工具操作的能力，现有的工作大多采用复杂的推理任务进行评估，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学问题求解"},{"Type":"NodeText","Data":"（如GSM8k和SVAMP）或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识问答"},{"Type":"NodeText","Data":"（如TruthfulQA），在这些任务中，成功利用工具对于增强LLM所不具备的所需技能（例如，数值计算）非常重要。通过这种方式，在这些任务上评估的性能可以反映LLM在工具操作方面的能力。为了教LLM利用工具，现有的研究在上下文中添加"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"使用工具的范例"},{"Type":"NodeText","Data":"来激发LLM，或在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"关于工具利用的模拟数据"},{"Type":"NodeText","Data":"上对LLM进行微调。已有研究发现，借助工具，LLM变得更有能力处理它们不擅长的问题，例如，方程计算和回答及时性问题。然而，随着可用工具数量的增加，LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有限上下文长度"},{"Type":"NodeText","Data":"可能会在描述和演示广泛的工具API时带来挑战。为了解决这个问题，现有的工作检索相关工具的用法，或将工具信息编码为嵌入空间内的词元。"}]},{"ID":"20250922215126-e3vw98t","Type":"NodeParagraph","Properties":{"id":"20250922215126-e3vw98t","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"除了人类开发的现有工具，LLM还拥有为特定任务"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自主制造自己的工具"},{"Type":"NodeText","Data":"的能力。这使得模型能够独立地探索和操纵这些自创的工具，从而扩展它们在解决广泛现实世界任务中自主探索的潜力。"}]},{"ID":"20250922215126-dnjdh2q","Type":"NodeParagraph","Properties":{"id":"20250922215126-dnjdh2q","updated":"20250922215201"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Summary (总结)."},{"Type":"NodeText","Data":" 上述三种能力对于LLM的实际性能具有重要价值："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符合人类价值观和偏好（人类对齐），在真实世界场景中恰当行动（与外部环境交互），以及扩展能力范围（工具操作）"},{"Type":"NodeText","Data":"。除了上述三种高级能力，LLM可能还显示出与某些任务（例如，数据标注）或学习机制（例如，自我改进）特别相关的其他能力。发现、测量和评估这些新涌现的能力，以便更好地利用和改进LLM，将是一个开放的方向。"}]},{"ID":"20250922215126-vj25syg","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215126-vj25syg","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.3 Benchmarks and Evaluation Approaches (基准和评估方法)"}]},{"ID":"20250922215126-bvv0ak5","Type":"NodeParagraph","Properties":{"id":"20250922215126-bvv0ak5","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"在上面，我们讨论了LLM的基础和高级能力。接下来，我们将介绍现有的评估基准和方法。"}]},{"ID":"20250922215126-17azyb9","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922215126-17azyb9","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.3.1 Comprehensive Evaluation Benchmarks (综合评估基准)"}]},{"ID":"20250922215126-hojg35k","Type":"NodeParagraph","Properties":{"id":"20250922215126-hojg35k","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"最近，为评估LLM发布了几个综合性基准。在本部分中，我们介绍几个广泛使用的基准，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MMLU、BIG-bench、HELM"},{"Type":"NodeText","Data":"以及一系列"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类考试基准"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922215126-8dccn7x","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-8dccn7x","updated":"20250922215201"},"Children":[{"ID":"20250922215126-xlvaal4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-xlvaal4","updated":"20250922215126"},"Children":[{"ID":"20250922215126-gs32344","Type":"NodeParagraph","Properties":{"id":"20250922215126-gs32344","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MMLU."},{"Type":"NodeText","Data":" MMLU是一个用于大规模评估"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多任务知识理解"},{"Type":"NodeText","Data":"的通用基准，涵盖了从数学和计算机科学到人文学科和社会科学的广泛知识领域。这些任务的难度从基础到高级不等。正如现有工作所示，LLM在该基准上通常以显著优势胜过小型模型，这显示了模型大小的规模法则。最近，GPT-4在MMLU上取得了卓越的记录（在5样本设置中为86.4%），显著优于之前的最新模型。"}]}]},{"ID":"20250922215126-9qxlz2n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-9qxlz2n","updated":"20250922215126"},"Children":[{"ID":"20250922215126-z902jvs","Type":"NodeParagraph","Properties":{"id":"20250922215126-z902jvs","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BIG-bench."},{"Type":"NodeText","Data":" BIG-bench是一个旨在从各个方面探测现有LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"协作基准"},{"Type":"NodeText","Data":"。它包含204个任务，涵盖了广泛的主题，包括语言学、儿童发展、数学、常识推理、生物学、物理学、社会偏见、软件开发等等。通过扩展模型大小，LLM甚至可以在BIG-bench中65%的任务上，在少样本设置下超越平均人类表现。考虑到整个基准的高昂评估成本，提出了一个轻量级的基准"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BIG-bench-Lite"},{"Type":"NodeText","Data":"，它包含来自BIG-bench的24个小型但多样化且具有挑战性的任务。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BIG-bench hard（BBH）"},{"Type":"NodeText","Data":"基准被提出来，通过选择LLM与人类相比表现较差的挑战性任务，专注于调查LLM当前无法解决的任务。由于BBH变得更加困难，小型模型大多取得接近随机的表现。相比之下，CoT提示可以激发LLM执行逐步推理的能力，以提升性能，甚至在BBH上超越平均人类表现。"}]}]},{"ID":"20250922215126-5n2myne","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-5n2myne","updated":"20250922215126"},"Children":[{"ID":"20250922215126-swm2u3o","Type":"NodeParagraph","Properties":{"id":"20250922215126-swm2u3o","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HELM."},{"Type":"NodeText","Data":" HELM是一个综合性基准，目前实现了一套包含16个场景和7类指标的核心集合。它建立在许多先前研究的基础上，对语言模型进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面的评估"},{"Type":"NodeText","Data":"。正如HELM的实验结果所示，指令微调可以在准确性、鲁棒性和公平性方面持续提升LLM的性能。此外，对于推理任务，在代码语料库上预训练的LLM表现出更优越的性能。"}]}]},{"ID":"20250922215126-aq21em8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-aq21em8","updated":"20250922215126"},"Children":[{"ID":"20250922215126-pabldwc","Type":"NodeParagraph","Properties":{"id":"20250922215126-pabldwc","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类水平测试基准 (Human-level test benchmarks)."},{"Type":"NodeText","Data":" 人类水平测试基准旨在用为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"测试人类而设计的问题"},{"Type":"NodeText","Data":"来评估LLM的综合能力，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AGIEval、MMCU、M3KE、C-Eval和Xiezhi"},{"Type":"NodeText","Data":"。这些基准涵盖了广泛的领域、难度水平和语言，以提供对LLM通用能力的综合评估。与公开可用的模型相比，提供API服务的模型（例如，GPT-4、ChatGPT、Claude）在这些评估基准上表现出优越的性能。作为评估中表现最好的模型，GPT-4在AGIEval上的表现超过了平均人类水平。然而，它在这些具有挑战性的基准上仍然落后于顶尖的人类表现。因此，在LLM的整体能力上，特别是对于公开可用的模型，仍然有充足的提升空间。"}]}]}]},{"ID":"20250922215126-r8xzvmb","Type":"NodeParagraph","Properties":{"id":"20250922215126-r8xzvmb","updated":"20250922215201"},"Children":[{"Type":"NodeText","Data":"上述基准涵盖了各种主流评估任务和真实世界的人类考试问题，用于评估LLM。此外，还有一些专注于评估LLM特定能力的基准，例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"TyDiQA"},{"Type":"NodeText","Data":"用于多语言知识利用，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MGSM"},{"Type":"NodeText","Data":"用于多语言数学推理。为了进行评估，人们可以根据特定目标选择合适的基准。此外，还有几个开源评估框架，供研究人员在现有基准上评估LLM或为定制评估扩展新任务，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Language Model Evaluation Harness"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"OpenAI Evals"},{"Type":"NodeText","Data":"。此外，一些研究人员还通过聚合代表性基准来构建"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"持续更新的排行榜"},{"Type":"NodeText","Data":"，以比较现有LLM的性能，例如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Open LLM Leaderboard"},{"Type":"NodeText","Data":"。上述基准和排行榜为展示LLM的基础和高级能力提供了重要参考。我们将在7.3.2节中对评估方法进行更深入的优缺点讨论。"}]},{"ID":"20250922215126-4hhyvvq","Type":"NodeBlockquote","Properties":{"id":"20250922215126-4hhyvvq","updated":"20250922215201"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922215126-qnlx8lf","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215126-qnlx8lf","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922215126-aajhsqp","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215126-aajhsqp","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力之一：人类对齐"}]},{"ID":"20250922215126-1dybd8a","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-1dybd8a","updated":"20250922215126"},"Children":[{"ID":"20250922215126-24q4la0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-24q4la0","updated":"20250922215126"},"Children":[{"ID":"20250922215126-tpniv0o","Type":"NodeParagraph","Properties":{"id":"20250922215126-tpniv0o","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估核心"},{"Type":"NodeText","Data":": 考察模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“价值观”"},{"Type":"NodeText","Data":"是否符合人类的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“有用、诚实、无害”"},{"Type":"NodeText","Data":"标准。"}]}]},{"ID":"20250922215126-0mu9zhi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-0mu9zhi","updated":"20250922215126"},"Children":[{"ID":"20250922215126-fuvhktu","Type":"NodeParagraph","Properties":{"id":"20250922215126-fuvhktu","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估方法"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215126-ghwd4z3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-ghwd4z3","updated":"20250922215126"},"Children":[{"ID":"20250922215126-6501qwb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-6501qwb","updated":"20250922215126"},"Children":[{"ID":"20250922215126-exolksj","Type":"NodeParagraph","Properties":{"id":"20250922215126-exolksj","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动基准"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"TruthfulQA"},{"Type":"NodeText","Data":"（测谎）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CrowS-Pairs"},{"Type":"NodeText","Data":"（检测偏见）。"}]}]},{"ID":"20250922215126-xk3k300","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-xk3k300","updated":"20250922215126"},"Children":[{"ID":"20250922215126-7wjp82y","Type":"NodeParagraph","Properties":{"id":"20250922215126-7wjp82y","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类评估"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更直接、更可靠"},{"Type":"NodeText","Data":"。通过专家评审来评估模型在处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"风险、敏感"},{"Type":"NodeText","Data":"问题时的行为。"}]}]}]}]}]},{"ID":"20250922215126-swxmnq5","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215126-swxmnq5","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力之二：与环境交互"}]},{"ID":"20250922215126-dbogy4g","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-dbogy4g","updated":"20250922215126"},"Children":[{"ID":"20250922215126-wca8x14","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-wca8x14","updated":"20250922215126"},"Children":[{"ID":"20250922215126-tjgncuu","Type":"NodeParagraph","Properties":{"id":"20250922215126-tjgncuu","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估核心"},{"Type":"NodeText","Data":": 考察模型作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“具身智能体（Embodied Agent）”"},{"Type":"NodeText","Data":"，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模拟或真实环境"},{"Type":"NodeText","Data":"中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"感知和行动"},{"Type":"NodeText","Data":"的能力。"}]}]},{"ID":"20250922215126-t3ibw28","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-t3ibw28","updated":"20250922215126"},"Children":[{"ID":"20250922215126-5phm184","Type":"NodeParagraph","Properties":{"id":"20250922215126-5phm184","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估方法"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215126-6dw5hji","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-6dw5hji","updated":"20250922215126"},"Children":[{"ID":"20250922215126-6azp9rs","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-6azp9rs","updated":"20250922215126"},"Children":[{"ID":"20250922215126-la134bh","Type":"NodeParagraph","Properties":{"id":"20250922215126-la134bh","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模拟环境"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"VirtualHome"},{"Type":"NodeText","Data":"（家务）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ALFRED"},{"Type":"NodeText","Data":"（复杂目标）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Minecraft"},{"Type":"NodeText","Data":"（开放世界）。"}]}]},{"ID":"20250922215126-sfr7637","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-sfr7637","updated":"20250922215126"},"Children":[{"ID":"20250922215126-y0obrd9","Type":"NodeParagraph","Properties":{"id":"20250922215126-y0obrd9","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估指标"},{"Type":"NodeText","Data":": 任务"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成功率"},{"Type":"NodeText","Data":"、生成计划的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可执行性"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215126-cw0qp88","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-cw0qp88","updated":"20250922215126"},"Children":[{"ID":"20250922215126-vcpl8t3","Type":"NodeParagraph","Properties":{"id":"20250922215126-vcpl8t3","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前沿"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多智能体协作"},{"Type":"NodeText","Data":"，在模拟社会中评估"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"涌现的社会行为"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922215126-668zhdn","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215126-668zhdn","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力之三：工具操作"}]},{"ID":"20250922215126-2awj4ur","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-2awj4ur","updated":"20250922215126"},"Children":[{"ID":"20250922215126-7nn7oa3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-7nn7oa3","updated":"20250922215126"},"Children":[{"ID":"20250922215126-rwga83m","Type":"NodeParagraph","Properties":{"id":"20250922215126-rwga83m","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估核心"},{"Type":"NodeText","Data":": 考察模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“使用工具”"},{"Type":"NodeText","Data":"来扩展自身能力边界的能力。"}]}]},{"ID":"20250922215126-ocnx5g3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-ocnx5g3","updated":"20250922215126"},"Children":[{"ID":"20250922215126-qwolrmk","Type":"NodeParagraph","Properties":{"id":"20250922215126-qwolrmk","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估方法"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215126-9yugpcn","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-9yugpcn","updated":"20250922215126"},"Children":[{"ID":"20250922215126-4v5agnh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-4v5agnh","updated":"20250922215126"},"Children":[{"ID":"20250922215126-q2pyxqv","Type":"NodeParagraph","Properties":{"id":"20250922215126-q2pyxqv","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"间接评估"},{"Type":"NodeText","Data":": 在那些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"必须使用工具才能解决"},{"Type":"NodeText","Data":"的复杂任务（如GSM8k数学题）上评估模型的性能。"}]}]},{"ID":"20250922215126-bcr3uto","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-bcr3uto","updated":"20250922215126"},"Children":[{"ID":"20250922215126-7uzpo9l","Type":"NodeParagraph","Properties":{"id":"20250922215126-7uzpo9l","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何教会"},{"Type":"NodeText","Data":": 通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ICL演示"},{"Type":"NodeText","Data":"或"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调"},{"Type":"NodeText","Data":"来教模型如何调用API。"}]}]},{"ID":"20250922215126-80jba2y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-80jba2y","updated":"20250922215126"},"Children":[{"ID":"20250922215126-trve6xm","Type":"NodeParagraph","Properties":{"id":"20250922215126-trve6xm","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前沿"},{"Type":"NodeText","Data":": LLM"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自主创造和使用自己的工具"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922215126-0vqs5vr","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215126-0vqs5vr","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合评估基准：“AI的高考”"}]},{"ID":"20250922215126-1bi97hc","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-1bi97hc","updated":"20250922215126"},"Children":[{"ID":"20250922215126-3fo0r00","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-3fo0r00","updated":"20250922215126"},"Children":[{"ID":"20250922215126-vd7dfz5","Type":"NodeParagraph","Properties":{"id":"20250922215126-vd7dfz5","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心目标"},{"Type":"NodeText","Data":": 提供一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面、标准化、有挑战性"},{"Type":"NodeText","Data":"的“考场”，来系统性地衡量和比较不同LLM的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合能力"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215126-dshauss","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-dshauss","updated":"20250922215126"},"Children":[{"ID":"20250922215126-dnp16zr","Type":"NodeParagraph","Properties":{"id":"20250922215126-dnp16zr","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"四大“考场”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215126-1y1nqhl","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922215126-1y1nqhl","updated":"20250922215126"},"Children":[{"ID":"20250922215126-da13978","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922215126-da13978","updated":"20250922215126"},"Children":[{"ID":"20250922215126-888ao3s","Type":"NodeParagraph","Properties":{"id":"20250922215126-888ao3s","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MMLU"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“文理综合大考”"},{"Type":"NodeText","Data":"。涵盖极广的学科知识，是衡量模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识广度"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度"},{"Type":"NodeText","Data":"的核心基准。"}]}]},{"ID":"20250922215126-pulg0lp","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922215126-pulg0lp","updated":"20250922215126"},"Children":[{"ID":"20250922215126-745dxdb","Type":"NodeParagraph","Properties":{"id":"20250922215126-745dxdb","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BIG-bench"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“创新能力与边界测试”"},{"Type":"NodeText","Data":"。包含了大量"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"非常规、开放性"},{"Type":"NodeText","Data":"的任务，旨在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"探测LLM能力的边界"},{"Type":"NodeText","Data":"。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BBH"},{"Type":"NodeText","Data":"则是其中最难的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“奥赛题”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215126-h54fwrk","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922215126-h54fwrk","updated":"20250922215126"},"Children":[{"ID":"20250922215126-xnm7xpd","Type":"NodeParagraph","Properties":{"id":"20250922215126-xnm7xpd","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HELM"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“全方位素质评估”"},{"Type":"NodeText","Data":"。不仅看准确率，还考察"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"鲁棒性、公平性、效率"},{"Type":"NodeText","Data":"等多个维度的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合素质"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215126-xcjhsdt","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250922215126-xcjhsdt","updated":"20250922215126"},"Children":[{"ID":"20250922215126-wvekl1y","Type":"NodeParagraph","Properties":{"id":"20250922215126-wvekl1y","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类考试基准 (AGIEval, C-Eval等)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“与人同台竞技”"},{"Type":"NodeText","Data":"。直接使用人类的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"真实考试"},{"Type":"NodeText","Data":"（如高考、GRE）来评估LLM，是最直观的与人类能力对比的方式。"}]}]}]}]},{"ID":"20250922215126-3c7b11m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-3c7b11m","updated":"20250922215126"},"Children":[{"ID":"20250922215126-b89gbm6","Type":"NodeParagraph","Properties":{"id":"20250922215126-b89gbm6","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生态工具"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215126-gjl1xay","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-gjl1xay","updated":"20250922215126"},"Children":[{"ID":"20250922215126-4ihqsvx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-4ihqsvx","updated":"20250922215126"},"Children":[{"ID":"20250922215126-ixmuj01","Type":"NodeParagraph","Properties":{"id":"20250922215126-ixmuj01","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估框架 (LM Eval Harness)"},{"Type":"NodeText","Data":": 提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标准化的“考试工具”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215126-zg12djj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-zg12djj","updated":"20250922215126"},"Children":[{"ID":"20250922215126-2o5m7rv","Type":"NodeParagraph","Properties":{"id":"20250922215126-2o5m7rv","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排行榜 (Open LLM Leaderboard)"},{"Type":"NodeText","Data":": 提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实时的“成绩单”"},{"Type":"NodeText","Data":"，促进了社区的良性竞争。"}]}]}]}]}]}]},{"ID":"20250922215126-kb9l4pr","Type":"NodeThematicBreak","Properties":{"id":"20250922215126-kb9l4pr","updated":"20250922215201"}},{"ID":"20250922215126-vrgwaqq","Type":"NodeBlockquote","Properties":{"id":"20250922215126-vrgwaqq","updated":"20250922215201"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922215126-i9c849b","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215126-i9c849b","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922215126-4vlziu7","Type":"NodeParagraph","Properties":{"id":"20250922215126-4vlziu7","updated":"20250922215126"},"Children":[{"Type":"NodeText","Data":"第五十部分系统地梳理了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力评估"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合评估基准"},{"Type":"NodeText","Data":"，标志着对LLM的评估进入了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更成熟、更全面"},{"Type":"NodeText","Data":"的阶段。"}]},{"ID":"20250922215126-b0gfx3z","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922215126-b0gfx3z","updated":"20250922215126"},"Children":[{"ID":"20250922215126-rggn5a7","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922215126-rggn5a7","updated":"20250922215126"},"Children":[{"ID":"20250922215126-hml4z5a","Type":"NodeParagraph","Properties":{"id":"20250922215126-hml4z5a","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“智商”到“情商”与“动手能力”的评估扩展"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215126-n3e7u2g","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-n3e7u2g","updated":"20250922215126"},"Children":[{"ID":"20250922215126-8kzivpt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-8kzivpt","updated":"20250922215126"},"Children":[{"ID":"20250922215126-uotkbjm","Type":"NodeParagraph","Properties":{"id":"20250922215126-uotkbjm","updated":"20250922215126"},"Children":[{"Type":"NodeText","Data":"继基础能力（生成、知识、推理，可类比为“智商”）之后，本部分引入了三大高级能力，可以类比为："}]},{"ID":"20250922215126-2xp4222","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-2xp4222","updated":"20250922215126"},"Children":[{"ID":"20250922215126-mni5xyo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-mni5xyo","updated":"20250922215126"},"Children":[{"ID":"20250922215126-kergkus","Type":"NodeParagraph","Properties":{"id":"20250922215126-kergkus","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“情商”和“德商”"},{"Type":"NodeText","Data":"。考察模型是否可靠、负责。"}]}]},{"ID":"20250922215126-k8s5dxi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-k8s5dxi","updated":"20250922215126"},"Children":[{"ID":"20250922215126-0skri13","Type":"NodeParagraph","Properties":{"id":"20250922215126-0skri13","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"环境交互"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“身体协调能力”"},{"Type":"NodeText","Data":"。考察模型在（模拟）世界中的行动能力。"}]}]},{"ID":"20250922215126-vw3qb4d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-vw3qb4d","updated":"20250922215126"},"Children":[{"ID":"20250922215126-cmrkmp3","Type":"NodeParagraph","Properties":{"id":"20250922215126-cmrkmp3","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具操作"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“动手能力”"},{"Type":"NodeText","Data":"。考察模型使用外部工具解决问题的能力。"}]}]}]}]},{"ID":"20250922215126-zta42u7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-zta42u7","updated":"20250922215126"},"Children":[{"ID":"20250922215126-2gixgtl","Type":"NodeParagraph","Properties":{"id":"20250922215126-2gixgtl","updated":"20250922215126"},"Children":[{"Type":"NodeText","Data":"这一扩展，标志着我们对AI的期望，正在从一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“博学的对话者”"},{"Type":"NodeText","Data":"，演变为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“能干、可靠、能在世界中行动的助手”"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922215126-06ufpbp","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922215126-06ufpbp","updated":"20250922215126"},"Children":[{"ID":"20250922215126-vdi1kyo","Type":"NodeParagraph","Properties":{"id":"20250922215126-vdi1kyo","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“AI高考”体系的建立"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215126-m845u03","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-m845u03","updated":"20250922215126"},"Children":[{"ID":"20250922215126-av92hq1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-av92hq1","updated":"20250922215126"},"Children":[{"ID":"20250922215126-k2pjvzs","Type":"NodeParagraph","Properties":{"id":"20250922215126-k2pjvzs","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MMLU, BIG-bench, HELM"},{"Type":"NodeText","Data":"等综合性基准的出现，如同为AI领域建立了一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"标准化的“高考”体系"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215126-i4rpnmc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-i4rpnmc","updated":"20250922215126"},"Children":[{"ID":"20250922215126-gfh4tk3","Type":"NodeParagraph","Properties":{"id":"20250922215126-gfh4tk3","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MMLU"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“知识大综合”"},{"Type":"NodeText","Data":"，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BIG-bench"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“创新能力附加题”"},{"Type":"NodeText","Data":"，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HELM"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“综合素质面试”"},{"Type":"NodeText","Data":"，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类考试基准"},{"Type":"NodeText","Data":"则是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"直接与人类考生“同场竞技”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215126-g4iaj57","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-g4iaj57","updated":"20250922215126"},"Children":[{"ID":"20250922215126-4dfxlbw","Type":"NodeParagraph","Properties":{"id":"20250922215126-4dfxlbw","updated":"20250922215126"},"Children":[{"Type":"NodeText","Data":"这个体系的建立，使得对不同LLM的比较有了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一的、公认的标尺"},{"Type":"NodeText","Data":"，极大地推动了领域内"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学、量化的进展"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922215126-gea5xam","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922215126-gea5xam","updated":"20250922215126"},"Children":[{"ID":"20250922215126-0rb5je8","Type":"NodeParagraph","Properties":{"id":"20250922215126-0rb5je8","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源生态的推动作用"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215126-w494dse","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215126-w494dse","updated":"20250922215126"},"Children":[{"ID":"20250922215126-bm3exgb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-bm3exgb","updated":"20250922215126"},"Children":[{"ID":"20250922215126-yqcqmaj","Type":"NodeParagraph","Properties":{"id":"20250922215126-yqcqmaj","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源评估框架（如LM Eval Harness）"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"排行榜（如Open LLM Leaderboard）"},{"Type":"NodeText","Data":"的出现，为整个社区提供了一套"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“公开考场”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“实时排名”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215126-vvnonvj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215126-vvnonvj","updated":"20250922215126"},"Children":[{"ID":"20250922215126-rhjnm95","Type":"NodeParagraph","Properties":{"id":"20250922215126-rhjnm95","updated":"20250922215126"},"Children":[{"Type":"NodeText","Data":"这极大地"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"降低了评估的技术门槛"},{"Type":"NodeText","Data":"，并激发了开源社区的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"良性竞争"},{"Type":"NodeText","Data":"，是推动开源LLM能力快速追赶闭源模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"重要催化剂"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922215126-9uixi8o","Type":"NodeParagraph","Properties":{"id":"20250922215126-9uixi8o","updated":"20250922215126"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第五十部分的核心在于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“评估的现代化与体系化”"},{"Type":"NodeText","Data":"。它清晰地表明，对LLM的评估已经超越了零散的任务测试，发展成为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多层次（基础-高级）、多维度、有标准化基准（AI高考）、有开放工具生态"},{"Type":"NodeText","Data":"的成熟领域。这个完善的评估体系，不仅为我们"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"衡量当前AI的能力"},{"Type":"NodeText","Data":"提供了可靠的工具，更为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指引未来AI的发展方向"},{"Type":"NodeText","Data":"提供了宝贵的罗盘。"}]}]},{"ID":"20250922215250-mzfm5wv","Type":"NodeParagraph","Properties":{"id":"20250922215250-mzfm5wv","updated":"20250922215250"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922215250-uvm5gbv","Type":"NodeThematicBreak","Properties":{"id":"20250922215250-uvm5gbv","updated":"20250922215250"}},{"ID":"20250922215250-tapwedh","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215250-tapwedh","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第五十一部分"}]},{"ID":"20250922215250-conw6g3","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922215250-conw6g3","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.3.2 Evaluation Approaches (评估方法)"}]},{"ID":"20250922215250-n4qn3yl","Type":"NodeParagraph","Properties":{"id":"20250922215250-n4qn3yl","updated":"20250922215319"},"Children":[{"Type":"NodeText","Data":"在介绍了现有的基-准之后，在本部分中，我们将回顾现有的评估方法，以评估LLM的性能。为了组织我们的讨论，我们将LLM分为三种不同的类型："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础LLM"},{"Type":"NodeText","Data":"（预训练的模型检查点）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调LLM"},{"Type":"NodeText","Data":"（指令或对齐微调的模型检查点）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业化LLM"},{"Type":"NodeText","Data":"（为某些特定任务或领域适配的模型检查点）。在这里，我们保留了微调LLM和专业化LLM，以区分LLM的不同目的：通用或特定的任务解决器。为了评估这三种类型的LLM，我们可以测试与不同能力相关的LLM的性能（例如，7.1节和7.2节中讨论的基础或高级能力）。总的来说，评估LLM主要有三种方法，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于基准的方法、基于人类的方法和基于模型的方法"},{"Type":"NodeText","Data":"。表15展示了LLM类型、评估方法和测试能力之间关系的示意图。接下来，我们将讨论不同类型LLM的评估方法。"}]},{"ID":"20250922215250-y7qzfr9","Type":"NodeParagraph","Properties":{"id":"20250922215250-y7qzfr9","updated":"20250922215319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Evaluation of Base LLMs (基础LLM的评估)."},{"Type":"NodeText","Data":" 基础LLM指的是在预训练后直接获得的模型检查点。对于基础LLM，我们主要关注检验其基础能力（7.1节），例如复杂推理和知识利用。由于这些基础能力中的大多数都可以用定义明确的任务来评估，因此"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于基准的方法"},{"Type":"NodeText","Data":"已被广泛用于评估基础LLM。接下来，我们将介绍基础LLM的常用评估基准和评估程序。"}]},{"ID":"20250922215250-83jzfsy","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-83jzfsy","updated":"20250922215319"},"Children":[{"ID":"20250922215250-fz1stzt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-fz1stzt","updated":"20250922215250"},"Children":[{"ID":"20250922215250-0sao8gb","Type":"NodeParagraph","Properties":{"id":"20250922215250-0sao8gb","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常用基准 (Common benchmarks)."},{"Type":"NodeText","Data":" 为了评估基础LLM，典型的基准被设计为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭卷问题"},{"Type":"NodeText","Data":"的形式，如多项选择题。这些常用的基准可以主要分为两类："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识导向"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理导向"},{"Type":"NodeText","Data":"的基准。知识导向的基准（例如，MMLU和C-Eval）旨在评估世界知识的能力，而推理导向的基准（例如，GSM8K、BBH和MATH）则专注于评估解决复杂推理任务的能力。此外，一些最近提出的基准（例如，OpenCompass）结合了这两种类型以进行全面的比较。"}]}]},{"ID":"20250922215250-04ocqbq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-04ocqbq","updated":"20250922215250"},"Children":[{"ID":"20250922215250-h4szen8","Type":"NodeParagraph","Properties":{"id":"20250922215250-h4szen8","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于基准的评估程序 (Benchmark based evaluation procedure)."},{"Type":"NodeText","Data":" 为了执行基准评估，每个问题首先将被格式化为一个提示，供LLM生成结果文本。然后，生成的结果文本将通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类编写的规则"},{"Type":"NodeText","Data":"进行解析，以获得预测的答案。最后，LLM的性能可以通过使用标准指标（如准确率）将预测的答案与真实答案进行比较来自动计算。评估方法可以在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本或零样本"},{"Type":"NodeText","Data":"设置下进行，这可能导致不同的评估结果或排名。由于基础LLM没有经过指令微调（任务泛化能力相对较弱），因此"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本设置"},{"Type":"NodeText","Data":"通常更适合评估。对于一些复杂的推理任务，还需要使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT提示"},{"Type":"NodeText","Data":"来在评估期间充分展现其能力。另一个需要注意的是，这种评估方法也可以应用于评估微调LLM的能力。实际上，一些排行榜（例如，Open LLM Leaderboard）是建立在这种方法之上的，评估了基础和微调LLM。"}]}]}]},{"ID":"20250922215250-nzpkll9","Type":"NodeParagraph","Properties":{"id":"20250922215250-nzpkll9","updated":"20250922215319"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Evaluation of Fine-tuned LLMs (微调LLM的评估)."},{"Type":"NodeText","Data":" 本部分中的微调LLM指的是在预训练模型权重的基础上进行指令微调或对齐微调后获得的模型检查点。通常，微调LLM将在各种能力上进行测试（例如，知识利用和人类对齐），因此通常用多种评估方法来评估它们。除了基于基准的评估，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于人类和基于模型的方法"},{"Type":"NodeText","Data":"也已被广泛用于评估"}]},{"ID":"20250922215250-408xj4r","Type":"NodeBlockquote","Properties":{"id":"20250922215250-408xj4r","updated":"20250922215319"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922215250-vybv4vy","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215250-vybv4vy","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922215250-eyktlkk","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215250-eyktlkk","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估方法论的“三驾马车”"}]},{"ID":"20250922215250-6fjpcvw","Type":"NodeParagraph","Properties":{"id":"20250922215250-6fjpcvw","updated":"20250922215250"},"Children":[{"Type":"NodeText","Data":"这部分内容的核心是将LLM的评估方法系统性地划分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“三驾马车”"},{"Type":"NodeText","Data":"，并进一步探讨了如何针对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同类型"},{"Type":"NodeText","Data":"的LLM（基础、微调、专业化）选择合适的评估方法。"}]},{"ID":"20250922215250-it10p7v","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-it10p7v","updated":"20250922215250"},"Children":[{"ID":"20250922215250-dias0ph","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-dias0ph","updated":"20250922215250"},"Children":[{"ID":"20250922215250-qlcr5hz","Type":"NodeParagraph","Properties":{"id":"20250922215250-qlcr5hz","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三种LLM类型"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215250-53qaht6","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922215250-53qaht6","updated":"20250922215250"},"Children":[{"ID":"20250922215250-s3tdlw9","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922215250-s3tdlw9","updated":"20250922215250"},"Children":[{"ID":"20250922215250-kh3lxmh","Type":"NodeParagraph","Properties":{"id":"20250922215250-kh3lxmh","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础LLM (Base LLMs)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“原材料”"},{"Type":"NodeText","Data":"。刚完成预训练，未经任何微调的模型。评估它主要是为了看其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"潜力"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础素质"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215250-xj0z5ij","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922215250-xj0z5ij","updated":"20250922215250"},"Children":[{"ID":"20250922215250-vh65m9i","Type":"NodeParagraph","Properties":{"id":"20250922215250-vh65m9i","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调LLM (Fine-tuned LLMs)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通用产品”"},{"Type":"NodeText","Data":"。经过指令/对齐微调的模型，如ChatGPT。评估它主要是为了看其作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用助手"},{"Type":"NodeText","Data":"的综合能力。"}]}]},{"ID":"20250922215250-y9v7sf3","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922215250-y9v7sf3","updated":"20250922215250"},"Children":[{"ID":"20250922215250-nv34jrx","Type":"NodeParagraph","Properties":{"id":"20250922215250-nv34jrx","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业化LLM (Specialized LLMs)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“定制产品”"},{"Type":"NodeText","Data":"。为特定领域（如医疗）适配的模型。评估它既要看"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业能力"},{"Type":"NodeText","Data":"，也要看是否保留了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用能力"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922215250-afvzta9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-afvzta9","updated":"20250922215250"},"Children":[{"ID":"20250922215250-ujm9w6v","Type":"NodeParagraph","Properties":{"id":"20250922215250-ujm9w6v","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三种评估方法"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215250-68gra04","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922215250-68gra04","updated":"20250922215250"},"Children":[{"ID":"20250922215250-xihm6yn","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922215250-xihm6yn","updated":"20250922215250"},"Children":[{"ID":"20250922215250-4t5ep2u","Type":"NodeParagraph","Properties":{"id":"20250922215250-4t5ep2u","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于基准 (Benchmark-based)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“标准化考试”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922215250-61ppqlx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-61ppqlx","updated":"20250922215250"},"Children":[{"ID":"20250922215250-dmdb318","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-dmdb318","updated":"20250922215250"},"Children":[{"ID":"20250922215250-rcf7ojx","Type":"NodeParagraph","Properties":{"id":"20250922215250-rcf7ojx","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动化、可重复、可扩展"},{"Type":"NodeText","Data":"，适合大规模比较和模型训练过程中的监控。"}]}]},{"ID":"20250922215250-r4ndxkw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-r4ndxkw","updated":"20250922215250"},"Children":[{"ID":"20250922215250-pokb379","Type":"NodeParagraph","Properties":{"id":"20250922215250-pokb379","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":": 可能存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据污染"},{"Type":"NodeText","Data":"，且"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对提示和解析规则敏感"},{"Type":"NodeText","Data":"，固定的题目可能无法全面反映模型的真实能力。"}]}]}]}]},{"ID":"20250922215250-iegp3xq","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922215250-iegp3xq","updated":"20250922215250"},"Children":[{"ID":"20250922215250-1atj0xu","Type":"NodeParagraph","Properties":{"id":"20250922215250-1atj0xu","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于人类 (Human-based)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“专家面试/用户体验测试”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922215250-u0y43z3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-u0y43z3","updated":"20250922215250"},"Children":[{"ID":"20250922215250-bsch5f7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-bsch5f7","updated":"20250922215250"},"Children":[{"ID":"20250922215250-n9zzm3t","Type":"NodeParagraph","Properties":{"id":"20250922215250-n9zzm3t","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最接近真实世界"},{"Type":"NodeText","Data":"，能评估"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放式、主观性强"},{"Type":"NodeText","Data":"的能力（如对话质量、对齐程度），是评估的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“金标准”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215250-40mt2ke","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-40mt2ke","updated":"20250922215250"},"Children":[{"ID":"20250922215250-aywt2f7","Type":"NodeParagraph","Properties":{"id":"20250922215250-aywt2f7","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"昂贵、耗时、主观性强、难以复现"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922215250-u1futsb","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922215250-u1futsb","updated":"20250922215250"},"Children":[{"ID":"20250922215250-9nd013v","Type":"NodeParagraph","Properties":{"id":"20250922215250-9nd013v","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于模型 (Model-based)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“AI当考官”"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922215250-1es7y63","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-1es7y63","updated":"20250922215250"},"Children":[{"ID":"20250922215250-s8sv4t4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-s8sv4t4","updated":"20250922215250"},"Children":[{"ID":"20250922215250-5e1f7w6","Type":"NodeParagraph","Properties":{"id":"20250922215250-5e1f7w6","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优点"},{"Type":"NodeText","Data":": 试图结合前两者的优点，实现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可扩展的、类似人类的"},{"Type":"NodeText","Data":"评估。"}]}]},{"ID":"20250922215250-c7rar6t","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-c7rar6t","updated":"20250922215250"},"Children":[{"ID":"20250922215250-irz9fjj","Type":"NodeParagraph","Properties":{"id":"20250922215250-irz9fjj","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺点"},{"Type":"NodeText","Data":": “考官”模型本身可能存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"偏见"},{"Type":"NodeText","Data":"（如位置偏见、自卖自夸），且在评估超复杂任务时能力有限。"}]}]}]}]}]}]}]},{"ID":"20250922215250-k80a6x3","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215250-k80a6x3","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础LLM的评估策略"}]},{"ID":"20250922215250-xarr3v7","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-xarr3v7","updated":"20250922215250"},"Children":[{"ID":"20250922215250-ogmczyw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-ogmczyw","updated":"20250922215250"},"Children":[{"ID":"20250922215250-a1sezon","Type":"NodeParagraph","Properties":{"id":"20250922215250-a1sezon","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估重点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础能力"},{"Type":"NodeText","Data":"，特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215250-o96cspj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-o96cspj","updated":"20250922215250"},"Children":[{"ID":"20250922215250-y9knzif","Type":"NodeParagraph","Properties":{"id":"20250922215250-y9knzif","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主流方法"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于基准"},{"Type":"NodeText","Data":"的评估。"}]}]},{"ID":"20250922215250-sogubk4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-sogubk4","updated":"20250922215250"},"Children":[{"ID":"20250922215250-o9gtsul","Type":"NodeParagraph","Properties":{"id":"20250922215250-o9gtsul","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"常用基准"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215250-4grmvdj","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-4grmvdj","updated":"20250922215250"},"Children":[{"ID":"20250922215250-ebntsl2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-ebntsl2","updated":"20250922215250"},"Children":[{"ID":"20250922215250-48z4rbf","Type":"NodeParagraph","Properties":{"id":"20250922215250-48z4rbf","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识导向"},{"Type":"NodeText","Data":": MMLU, C-Eval"}]}]},{"ID":"20250922215250-7gde5en","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-7gde5en","updated":"20250922215250"},"Children":[{"ID":"20250922215250-2dxusl7","Type":"NodeParagraph","Properties":{"id":"20250922215250-2dxusl7","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理导向"},{"Type":"NodeText","Data":": GSM8K, BBH"}]}]}]}]},{"ID":"20250922215250-kfmglyk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-kfmglyk","updated":"20250922215250"},"Children":[{"ID":"20250922215250-9o836jz","Type":"NodeParagraph","Properties":{"id":"20250922215250-9o836jz","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估程序要点"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215250-xd1g1kq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-xd1g1kq","updated":"20250922215250"},"Children":[{"ID":"20250922215250-jp97lz0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-jp97lz0","updated":"20250922215250"},"Children":[{"ID":"20250922215250-zuvpr7k","Type":"NodeParagraph","Properties":{"id":"20250922215250-zuvpr7k","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本 (Few-shot) 设置"},{"Type":"NodeText","Data":": 由于基础LLM未经指令微调，直接零样本提问效果可能不佳，提供几个示例能更好地激发其潜力。"}]}]},{"ID":"20250922215250-o4s91pg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-o4s91pg","updated":"20250922215250"},"Children":[{"ID":"20250922215250-16dqegb","Type":"NodeParagraph","Properties":{"id":"20250922215250-16dqegb","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CoT提示"},{"Type":"NodeText","Data":": 对于推理任务，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"必须"},{"Type":"NodeText","Data":"使用CoT提示才能准确评估其推理上限。"}]}]}]}]}]},{"ID":"20250922215250-ehn2i9n","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215250-ehn2i9n","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调LLM的评估策略"}]},{"ID":"20250922215250-plpyntx","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-plpyntx","updated":"20250922215250"},"Children":[{"ID":"20250922215250-fhqvo64","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-fhqvo64","updated":"20250922215250"},"Children":[{"ID":"20250922215250-uy8pkr3","Type":"NodeParagraph","Properties":{"id":"20250922215250-uy8pkr3","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估重点"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合能力"},{"Type":"NodeText","Data":"，特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力"},{"Type":"NodeText","Data":"（如人类对齐）。"}]}]},{"ID":"20250922215250-lq0iw6f","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-lq0iw6f","updated":"20250922215250"},"Children":[{"ID":"20250922215250-z24fz31","Type":"NodeParagraph","Properties":{"id":"20250922215250-z24fz31","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主流方法"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多方法结合"},{"Type":"NodeText","Data":"。除了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于基准"},{"Type":"NodeText","Data":"的测试，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于人类"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于模型"},{"Type":"NodeText","Data":"的评估变得至关重要，因为微调LLM的核心能力（如对话质量）很难用简单的选择题来衡量。"}]}]}]}]},{"ID":"20250922215250-uimijzn","Type":"NodeThematicBreak","Properties":{"id":"20250922215250-uimijzn","updated":"20250922215319"}},{"ID":"20250922215250-k3fivoz","Type":"NodeBlockquote","Properties":{"id":"20250922215250-k3fivoz","updated":"20250922215319"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922215250-st1amyp","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215250-st1amyp","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922215250-2ua7np6","Type":"NodeParagraph","Properties":{"id":"20250922215250-2ua7np6","updated":"20250922215250"},"Children":[{"Type":"NodeText","Data":"第五十一部分的核心是为LLM评估建立了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统性的方法论框架"},{"Type":"NodeText","Data":"。它不再是简单地罗列基准，而是从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“评谁（Who）”"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“怎么评（How）"},{"Type":"NodeText","Data":"”这两个基本问题出发，构建了一个清晰、结构化的评估知识体系。"}]},{"ID":"20250922215250-45z2szh","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922215250-45z2szh","updated":"20250922215250"},"Children":[{"ID":"20250922215250-qgrhtlo","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922215250-qgrhtlo","updated":"20250922215250"},"Children":[{"ID":"20250922215250-8amvv4w","Type":"NodeParagraph","Properties":{"id":"20250922215250-8amvv4w","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“因材施教”的评估哲学"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215250-cgvvikw","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-cgvvikw","updated":"20250922215250"},"Children":[{"ID":"20250922215250-2zran56","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-2zran56","updated":"20250922215250"},"Children":[{"ID":"20250922215250-e20pwcf","Type":"NodeParagraph","Properties":{"id":"20250922215250-e20pwcf","updated":"20250922215250"},"Children":[{"Type":"NodeText","Data":"将LLM划分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础、微调、专业化"},{"Type":"NodeText","Data":"三种类型，是本部分的一个核心洞见。这体现了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“因材施教”"},{"Type":"NodeText","Data":"的评估哲学——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同发展阶段、不同定位的模型，其评估的重点和方法也应有所不同"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215250-zppwboz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-zppwboz","updated":"20250922215250"},"Children":[{"ID":"20250922215250-lck02el","Type":"NodeParagraph","Properties":{"id":"20250922215250-lck02el","updated":"20250922215250"},"Children":[{"Type":"NodeText","Data":"对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础LLM"},{"Type":"NodeText","Data":"，我们更关心其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"潜力（potential）"},{"Type":"NodeText","Data":"，因此采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本+CoT"},{"Type":"NodeText","Data":"的基准测试来探测其能力上限。"}]}]},{"ID":"20250922215250-qm9yowb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-qm9yowb","updated":"20250922215250"},"Children":[{"ID":"20250922215250-hbzdaug","Type":"NodeParagraph","Properties":{"id":"20250922215250-hbzdaug","updated":"20250922215250"},"Children":[{"Type":"NodeText","Data":"对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调LLM"},{"Type":"NodeText","Data":"，我们更关心其作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用产品（product）"},{"Type":"NodeText","Data":"的综合表现，因此需要引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类和模型评估"},{"Type":"NodeText","Data":"来考察其在开放场景下的实际能力。"}]}]}]}]},{"ID":"20250922215250-px1xdx5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922215250-px1xdx5","updated":"20250922215250"},"Children":[{"ID":"20250922215250-d3qeq0c","Type":"NodeParagraph","Properties":{"id":"20250922215250-d3qeq0c","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估方法的“三位一体”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215250-9u4cql3","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-9u4cql3","updated":"20250922215250"},"Children":[{"ID":"20250922215250-zhnl8cf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-zhnl8cf","updated":"20250922215250"},"Children":[{"ID":"20250922215250-m0f5d22","Type":"NodeParagraph","Properties":{"id":"20250922215250-m0f5d22","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基准、人类、模型"},{"Type":"NodeText","Data":"这三种评估方法的划分，高度概括了当前LLM评估的所有主流范式。"}]}]},{"ID":"20250922215250-cw1lsa9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-cw1lsa9","updated":"20250922215250"},"Children":[{"ID":"20250922215250-chf84nz","Type":"NodeParagraph","Properties":{"id":"20250922215250-chf84nz","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基准评估"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“基础”"},{"Type":"NodeText","Data":"，提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可量化、可比较"},{"Type":"NodeText","Data":"的底线。"}]}]},{"ID":"20250922215250-dal8n50","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-dal8n50","updated":"20250922215250"},"Children":[{"ID":"20250922215250-3n3mv4v","Type":"NodeParagraph","Properties":{"id":"20250922215250-3n3mv4v","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类评估"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“金标准”"},{"Type":"NodeText","Data":"，定义了评估的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“天花板”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215250-xmabc4s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-xmabc4s","updated":"20250922215250"},"Children":[{"ID":"20250922215250-5up3tmp","Type":"NodeParagraph","Properties":{"id":"20250922215250-5up3tmp","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型评估"},{"Type":"NodeText","Data":"是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“权衡与未来”"},{"Type":"NodeText","Data":"，它试图在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成本和质量"},{"Type":"NodeText","Data":"之间找到平衡，是评估自动化和规模化的重要发展方向。"}]}]}]}]},{"ID":"20250922215250-wdvi0gl","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922215250-wdvi0gl","updated":"20250922215250"},"Children":[{"ID":"20250922215250-tdptaue","Type":"NodeParagraph","Properties":{"id":"20250922215250-tdptaue","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实践的指导意义"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215250-m8resig","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215250-m8resig","updated":"20250922215250"},"Children":[{"ID":"20250922215250-ofejmsa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-ofejmsa","updated":"20250922215250"},"Children":[{"ID":"20250922215250-2g2ho97","Type":"NodeParagraph","Properties":{"id":"20250922215250-2g2ho97","updated":"20250922215250"},"Children":[{"Type":"NodeText","Data":"本部分的讨论非常具有实践指导意义。例如，它明确指出评估基础LLM时"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应该使用少样本和CoT提示"},{"Type":"NodeText","Data":"，这为研究者提供了清晰的操作指南，避免了因评估设置不当而低估模型能力。"}]}]},{"ID":"20250922215250-5iyk8rh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215250-5iyk8rh","updated":"20250922215250"},"Children":[{"ID":"20250922215250-m5cwblq","Type":"NodeParagraph","Properties":{"id":"20250922215250-m5cwblq","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Open LLM Leaderboard"},{"Type":"NodeText","Data":"等排行榜被提及，也说明了这种基于基准的标准化评估流程，已经成为社区比较和迭代开源模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础设施"},{"Type":"NodeText","Data":"。"}]}]}]}]}]},{"ID":"20250922215250-8yaisw9","Type":"NodeParagraph","Properties":{"id":"20250922215250-8yaisw9","updated":"20250922215250"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第五十一部分为我们提供了一份"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“LLM评估师指南”"},{"Type":"NodeText","Data":"。它系统地回答了“我们应该评估模型的哪些方面？”和“我们应该用什么方法来评估？”这两个核心问题。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模型类型 × 评估方法”"},{"Type":"NodeText","Data":"这个二维矩阵，它为我们构建了一个全面而深刻的评估框架。理解这个框架，对于科学地、公正地、全面地评价一个LLM的能力至关重要。"}]}]},{"ID":"20250922215513-1q8bdae","Type":"NodeParagraph","Properties":{"id":"20250922215513-1q8bdae","updated":"20250922215513"},"Children":[{"Type":"NodeText","Data":"好的，我们继续下一部分。"}]},{"ID":"20250922215513-1ifjrd9","Type":"NodeThematicBreak","Properties":{"id":"20250922215513-1ifjrd9","updated":"20250922215513"}},{"ID":"20250922215513-e0s60kt","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215513-e0s60kt","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第五十二部分"}]},{"ID":"20250922215513-uynyjde","Type":"NodeParagraph","Properties":{"id":"20250922215513-uynyjde","updated":"20250922215526"},"Children":[{"Type":"NodeText","Data":"微调LLM的能力。接下来，我们介绍这两种评估方法。"}]},{"ID":"20250922215513-33r00or","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215513-33r00or","updated":"20250922215526"},"Children":[{"ID":"20250922215513-i1vbdxo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-i1vbdxo","updated":"20250922215513"},"Children":[{"ID":"20250922215514-4kngbdh","Type":"NodeParagraph","Properties":{"id":"20250922215514-4kngbdh","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于人类的评估 (Human-based evaluation)."},{"Type":"NodeText","Data":" 与基础能力的自动评估不同，人类评估通常考虑真实世界使用中的更多因素或能力，例如人类对齐和工具操作。在这种评估方法中，测试任务通常是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开放式问题"},{"Type":"NodeText","Data":"的形式，并邀请人类评估员对LLM生成的答案质量进行判断。通常，人类评估员有两种主要的评分方法："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"成对比较"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单答案评分"},{"Type":"NodeText","Data":"。在成对比较中，给定相同的问题，人类被分配来自不同模型的两个答案以确定哪个更好，而在单答案评分中，他们只需要一次为一个答案评分。例如，HELM雇用人类对摘要和虚假信息任务进行单答案评分，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Chatbot Arena"},{"Type":"NodeText","Data":"构建了一个众包平台，允许用户与两个匿名的聊天LLM进行对话，并报告成对比较结果。"}]}]},{"ID":"20250922215513-wrqmag0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-wrqmag0","updated":"20250922215513"},"Children":[{"ID":"20250922215514-fyyvw8k","Type":"NodeParagraph","Properties":{"id":"20250922215514-fyyvw8k","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于模型的评估 (Model-based evaluation)."},{"Type":"NodeText","Data":" 由于基于人类的评估既昂贵又耗时，一些工作已提议利用强大的闭源LLM，如ChatGPT和GPT-4，作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类评估员的替代品"},{"Type":"NodeText","Data":"。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AlpacaEval"},{"Type":"NodeText","Data":"收集了一组指令，并利用一个有能力的LLM（例如，GPT-4）作为裁判，与参考输出进行成对比较。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MT-bench"},{"Type":"NodeText","Data":"收集了一组多轮问题用于评估，并通过ICL和CoT等方法提高了基于LLM的评估器的可靠性。与人类评估员相比，像ChatGPT和GPT-4这样的LLM可以与人类达成高度一致，无论是在小规模手工制作的评估任务还是大规模众包评估任务中。尽管如此，这些闭源LLM的访问受限，并存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据泄露"},{"Type":"NodeText","Data":"的潜在风险。为了解决这个问题，最近的工作已经探索了将开源LLM（例如，Vicuna）微调为模型评估器，使用来自人类评估员的评分数据，这已经缩小了与强大的闭源LLM（例如，GPT-4）的差距。"}]}]}]},{"ID":"20250922215514-ekgcb9r","Type":"NodeParagraph","Properties":{"id":"20250922215514-ekgcb9r","updated":"20250922215526"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Evaluation of Specialized LLMs (专业化LLM的评估)."},{"Type":"NodeText","Data":" 专业化LLM指的是专门为某些领域或应用（如医疗保健和金融）适配的模型检查点。作为特殊的任务解决器，专业化LLM不仅将在通用能力（例如，像复杂推理这样的基础能力和像人类对齐这样的高级能力）上进行测试，还将在与其指定领域或应用相关的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特定能力"},{"Type":"NodeText","Data":"上进行测试。为此，通常需要构建针对目标领域或应用的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特定基准"},{"Type":"NodeText","Data":"。然后，这些领域特定的基准可以与通用基准相结合，对专业化LLM进行全面而有针对性的评估。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MultiMedQA"},{"Type":"NodeText","Data":"是医疗保健领域的一个特定基准，其中包括医学考试和医疗保健问题。在这项工作中，MultiMedQA已与MMLU相结合，以评估专业化LLM在医疗保健方面的性能，例如Med-PaLM。类似地，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"FLUE"},{"Type":"NodeText","Data":"构建了一个金融领域的基准，涵盖从金融情感分析到问答。它已与BBH协作使用，以评估像BloombergGPT这样的金融LLM。"}]},{"ID":"20250922215514-qkxrnot","Type":"NodeParagraph","Properties":{"id":"20250922215514-qkxrnot","updated":"20250922215526"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pros and Cons of Different Evaluation Approaches (不同评估方法的优缺点)."},{"Type":"NodeText","Data":" 在上面，我们讨论了评估LLM能力的不同评估方法。接下来，我们简单分析每种评估方法的优缺点。"}]},{"ID":"20250922215514-jt6vx56","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-jt6vx56","updated":"20250922215526"},"Children":[{"ID":"20250922215513-gmczhy7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-gmczhy7","updated":"20250922215513"},"Children":[{"ID":"20250922215514-rkw1iod","Type":"NodeParagraph","Properties":{"id":"20250922215514-rkw1iod","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于基准的方法 (Benchmark-based approach)."},{"Type":"NodeText","Data":" 这种评估方法可以利用现有的基准来评估LLM的性能。这些基准中涉及的任务通常包含足够的测试样本来衡量核心能力（例如，推理）。整个评估过程可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"（几乎）自动化"},{"Type":"NodeText","Data":"，并且为各种基础LLM进行测试实验很方便，特别适用于在预训练期间监控模型检查点的性能。然而，LLM通常对评估设置很敏感，包括问题提示、零样本或少样本测试，以及答案解析方法。因此，在进行评估实验时应考虑可能的影-响因素。评估结果应与所采用的评估设置一起注明。另一个问题是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据污染"},{"Type":"NodeText","Data":"，即测试数据本身或相关内容已包含在预训练语料库中。随着为开发LLM收集的开放数据越来越多，这种现象变得越来越严重。"}]}]},{"ID":"20250922215513-ie04qzc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-ie04qzc","updated":"20250922215513"},"Children":[{"ID":"20250922215514-ezo1j3f","Type":"NodeParagraph","Properties":{"id":"20250922215514-ezo1j3f","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于人类的方法 (Human-based approach)."},{"Type":"NodeText","Data":" 在评估LLM解决现实世界任务的能力时，人类评估提供了几个优势。一个关键的好处是它能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"直接反映LLM的实际能力"},{"Type":"NodeText","Data":"。基于真实用户的反馈和经验，人类评估为LLM在真实世界场景中的性能提供了更直接的衡量标准。此外，它可以基于人类评估员进行更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"灵活和多样化"},{"Type":"NodeText","Data":"的评估任务。例如，用户可以提交各种查询，并根据他们自己的任务认知来测试LLM的能力。它允许深入了解LLM在不同类型任务和上下文中的优势和劣势。然而，人类评估也存在固有的局限性，可能影响其准确性和一致性。评估员之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"个性化品味"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同教育水平"},{"Type":"NodeText","Data":"等因素可能会在评估过程中引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"偏见甚至不一致"},{"Type":"NodeText","Data":"。在某些情况下，用户的判断可能是主观的，可能无法反映LLM的真实能力。此外，进行稳健可靠的人类评估通常需要大量的评估员，这可能非常"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"昂贵且耗时"},{"Type":"NodeText","Data":"。此外，人类评估通常是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不可复现的"},{"Type":"NodeText","Data":"，使得扩展现有的评估结果或跟踪LLM的进展变得不可行。"}]}]},{"ID":"20250922215513-edkm7v8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-edkm7v8","updated":"20250922215513"},"Children":[{"ID":"20250922215514-re682sb","Type":"NodeParagraph","Properties":{"id":"20250922215514-re682sb","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于模型的方法 (Model-based approach)."},{"Type":"NodeText","Data":" 作为基于人类的方法的替代品，基于模型的方法旨在减少对人类参与的依赖，并实现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更高效、可扩展"},{"Type":"NodeText","Data":"的评估。此外，LLM可以为分配的评级分数提供有意义的解释，从而增强评估的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可解释性"},{"Type":"NodeText","Data":"。尽管具有可扩展性和可解释性，但基于模型的方法已被发现存在一些问题，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"位置偏见、冗长偏见和自我增强偏见"},{"Type":"NodeText","Data":"。具体来说，位置偏见（即呈现响应的顺序）指的是LLM倾向于为特定位置的答案分配高分，冗长偏见意味着LLM偏爱冗长的答案，即使它们在质量上比更短的答案差，而自我增强偏见表明LLM经常高估自己生成的内-容。此外，由于LLM在解决复杂推理问题方面的能力有限，它们不能作为某些困难任务（例如，数学推理）的合格评估员。这些局限性可以在某种程度上通过特定的提示工程和微调策略来缓解。"}]}]}]},{"ID":"20250922215514-qzjyzh8","Type":"NodeParagraph","Properties":{"id":"20250922215514-qzjyzh8","updated":"20250922215526"},"Children":[{"Type":"NodeText","Data":"总而言之，我们对LLM评估的现有工作（表15）的分类主要基于两个主要维度，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估方法"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型类型"},{"Type":"NodeText","Data":"，并进一步用测试能力进行扩展。有一些最近的工作也讨论了LLM评估现有工作的分类或分类法。"}]},{"ID":"20250922215514-ul2fqg9","Type":"NodeTable","TableAligns":[1,1,1,1,1],"Properties":{"colgroup":"||||","id":"20250922215514-ul2fqg9","updated":"20250922215526"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Method"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Evaluation"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Model Types"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Abilities/Domain"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Data Source"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Benchmark"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MMLU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human exam/practice"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BIG-bench"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human annotation"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HELM"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Benchmark collection"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Open LLM Leaderboard"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Benchmark collection"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AGIEval"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human exam/practice"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MMCU"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human exam/practice"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"M3KE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human exam/practice"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"C-Eval"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human exam/practice"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Xiezhi"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human exam/practice"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"OpenCompass"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Benchmark collection"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Chain-of-Thought Hub"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"General"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Benchmark collection"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"KoLA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Knowledge utilization"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Web"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ARB"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Complex reasoning"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human exam/practice"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"APIBench"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Tool manipulation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Web"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"APIBank"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Tool manipulation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Synthesis"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ToolAlpaca"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Tool manipulation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Synthesis"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"T-Bench"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Tool manipulation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Synthesis"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ToolBench"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Tool manipulation"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Synthesis"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"BOLAA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Environment interaction"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Benchmark collection"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AgentBench"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Environment interaction"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human annotation/Synthesis"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HaluEval"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human alignment"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human annotation/Synthesis"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"PromptBench"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Robustness"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Benchmark collection"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HumanEval"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Code synthesis"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human annotation"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MultiMedQA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Healthcare"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Benchmark collection"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"FLUE"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Finance"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Benchmark collection"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LegalBench"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Legal"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human annotation"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Human"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Chatbot Arena"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned/Specialized"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human Alignment"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human annotation"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SciBench"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Complex reasoning"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human exam/practice"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Model"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"AlpacaEval"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Instruction following"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Synthesis"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MT-bench"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human alignment"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human annotation"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"TrustGPT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Human alignment"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Benchmark collection"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LMExamQA"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Knowledge utilization"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Synthesis"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ChatEval"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Base/Fine-tuned"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Knowledge utilization"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Benchmark collection"}]}]}]},{"ID":"20250922215514-d34ec63","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215514-d34ec63","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 15：现有评估工作的一个类别。"}]},{"ID":"20250922215514-g88x5vk","Type":"NodeParagraph","Properties":{"id":"20250922215514-g88x5vk","updated":"20250922215526"},"Children":[{"Type":"NodeText","Data":"“General”表示评估关注于多种能力的整体性能。评估的能力不限于7.1节和7.2节中提到的代表性基础和高级能力。"}]},{"ID":"20250922215514-x4pep0w","Type":"NodeBlockquote","Properties":{"id":"20250922215514-x4pep0w","updated":"20250922215526"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922215514-cjoeu5e","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215514-cjoeu5e","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922215514-gsi9usn","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215514-gsi9usn","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表15解析：LLM评估工作的“全景地图”"}]},{"ID":"20250922215514-kfe2dvx","Type":"NodeParagraph","Properties":{"id":"20250922215514-kfe2dvx","updated":"20250922215514"},"Children":[{"Type":"NodeText","Data":"这张表格是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"整个评估章节的“索引”和“地图”"},{"Type":"NodeText","Data":"。它通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“方法 × 评估对象 × 评估能力”"},{"Type":"NodeText","Data":"这三个维度，对现有的LLM评估工作进行了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"系统性的、全面的归类"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250922215514-xq96f9n","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-xq96f9n","updated":"20250922215514"},"Children":[{"ID":"20250922215513-i0w5m30","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-i0w5m30","updated":"20250922215513"},"Children":[{"ID":"20250922215514-hephqn1","Type":"NodeParagraph","Properties":{"id":"20250922215514-hephqn1","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三大评估方法 (Method)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215514-9at8jyq","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-9at8jyq","updated":"20250922215514"},"Children":[{"ID":"20250922215513-140xo1x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-140xo1x","updated":"20250922215513"},"Children":[{"ID":"20250922215514-r8iy5ce","Type":"NodeParagraph","Properties":{"id":"20250922215514-r8iy5ce","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基准 (Benchmark)"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数量最多、覆盖最广"},{"Type":"NodeText","Data":"。它既可以评估"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用能力 (General)"},{"Type":"NodeText","Data":"（如MMLU, BIG-bench），也可以评估"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特定能力"},{"Type":"NodeText","Data":"，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具使用 (Tool manipulation)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"环境交互 (Environment interaction)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码 (Code synthesis)"},{"Type":"NodeText","Data":"等。"}]}]},{"ID":"20250922215513-x2vgl2o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-x2vgl2o","updated":"20250922215513"},"Children":[{"ID":"20250922215514-bly5s0y","Type":"NodeParagraph","Properties":{"id":"20250922215514-bly5s0y","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类 (Human)"},{"Type":"NodeText","Data":": 主要用于评估那些"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最主观、最开放"},{"Type":"NodeText","Data":"的能力，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐 (Human Alignment)"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理 (Complex reasoning)"},{"Type":"NodeText","Data":"。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Chatbot Arena"},{"Type":"NodeText","Data":"是其中的典范。"}]}]},{"ID":"20250922215513-8ahd93v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-8ahd93v","updated":"20250922215513"},"Children":[{"ID":"20250922215514-c63ospy","Type":"NodeParagraph","Properties":{"id":"20250922215514-c63ospy","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型 (Model)"},{"Type":"NodeText","Data":": 作为人类评估的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“代理”"},{"Type":"NodeText","Data":"，主要用于评估"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令遵循 (Instruction following)"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐"},{"Type":"NodeText","Data":"等对话能力。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AlpacaEval"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MT-bench"},{"Type":"NodeText","Data":"是代表性工作。"}]}]}]}]},{"ID":"20250922215513-eu50xp0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-eu50xp0","updated":"20250922215513"},"Children":[{"ID":"20250922215514-9b3k6vh","Type":"NodeParagraph","Properties":{"id":"20250922215514-9b3k6vh","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估的模型类型 (Model Types)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215514-qq02o2n","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-qq02o2n","updated":"20250922215514"},"Children":[{"ID":"20250922215513-f6dpt3s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-f6dpt3s","updated":"20250922215513"},"Children":[{"ID":"20250922215514-v3oywdp","Type":"NodeParagraph","Properties":{"id":"20250922215514-v3oywdp","updated":"20250922215514"},"Children":[{"Type":"NodeText","Data":"绝大多数评估工作（特别是通用基准）都适用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"所有类型"},{"Type":"NodeText","Data":"的模型（基础/微调/专业化），以便进行横向比较。"}]}]},{"ID":"20250922215513-8m3uylm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-8m3uylm","updated":"20250922215513"},"Children":[{"ID":"20250922215514-k7ukixa","Type":"NodeParagraph","Properties":{"id":"20250922215514-k7ukixa","updated":"20250922215514"},"Children":[{"Type":"NodeText","Data":"一些专门的基准（如MultiMedQA）则"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只针对专业化 (Specialized)"},{"Type":"NodeText","Data":"模型。"}]}]}]}]},{"ID":"20250922215513-o50icrq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-o50icrq","updated":"20250922215513"},"Children":[{"ID":"20250922215514-sprwuxp","Type":"NodeParagraph","Properties":{"id":"20250922215514-sprwuxp","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估的能力/领域 (Abilities/Domain)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215514-0qg73cm","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-0qg73cm","updated":"20250922215514"},"Children":[{"ID":"20250922215513-gajbmc5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-gajbmc5","updated":"20250922215513"},"Children":[{"ID":"20250922215514-wo4coz2","Type":"NodeParagraph","Properties":{"id":"20250922215514-wo4coz2","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用能力"},{"Type":"NodeText","Data":"是评估的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"主体"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215513-rergknh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-rergknh","updated":"20250922215513"},"Children":[{"ID":"20250922215514-p9af7q7","Type":"NodeParagraph","Properties":{"id":"20250922215514-p9af7q7","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特定能力"},{"Type":"NodeText","Data":"的评估正在兴起，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具、交互、鲁棒性"},{"Type":"NodeText","Data":"，以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"医疗、金融、法律"},{"Type":"NodeText","Data":"等垂直领域。"}]}]}]}]},{"ID":"20250922215513-u60pgym","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-u60pgym","updated":"20250922215513"},"Children":[{"ID":"20250922215514-l04ex4v","Type":"NodeParagraph","Properties":{"id":"20250922215514-l04ex4v","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据来源 (Data Source)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215514-989tpwt","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-989tpwt","updated":"20250922215514"},"Children":[{"ID":"20250922215513-a472r12","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-a472r12","updated":"20250922215513"},"Children":[{"ID":"20250922215514-fml2mm6","Type":"NodeParagraph","Properties":{"id":"20250922215514-fml2mm6","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基准集合 (Benchmark collection)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类考试/实践 (Human exam/practice)"},{"Type":"NodeText","Data":" 是通用能力评估的主要数据来源。"}]}]},{"ID":"20250922215513-epco52u","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-epco52u","updated":"20250922215513"},"Children":[{"ID":"20250922215514-ibdns1k","Type":"NodeParagraph","Properties":{"id":"20250922215514-ibdns1k","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类标注 (Human annotation)"},{"Type":"NodeText","Data":" 是对齐和交互能力评估的核心。"}]}]},{"ID":"20250922215513-86bydn2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-86bydn2","updated":"20250922215513"},"Children":[{"ID":"20250922215514-6oj53js","Type":"NodeParagraph","Properties":{"id":"20250922215514-6oj53js","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"合成 (Synthesis)"},{"Type":"NodeText","Data":" 数据主要用于评估由模型自身生成的能力，如工具使用和指令遵循。"}]}]}]}]}]},{"ID":"20250922215514-uahtd8t","Type":"NodeParagraph","Properties":{"id":"20250922215514-uahtd8t","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张表格为我们提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“按图索骥”"},{"Type":"NodeText","Data":"的指南。如果你想评估一个模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学推理能力"},{"Type":"NodeText","Data":"，你可以找到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ARB"},{"Type":"NodeText","Data":"基准；如果你想评估它的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具使用"},{"Type":"NodeText","Data":"，你可以参考"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ToolBench"},{"Type":"NodeText","Data":"；如果你想评估它的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐"},{"Type":"NodeText","Data":"，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Chatbot Arena"},{"Type":"NodeText","Data":"是一个好去处。它完美地总结了当前LLM评估领域的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"研究现状和可用资源"},{"Type":"NodeText","Data":"，是本章节内容的高度浓缩。"}]}]},{"ID":"20250922215514-9acif4x","Type":"NodeThematicBreak","Properties":{"id":"20250922215514-9acif4x","updated":"20250922215526"}},{"ID":"20250922215514-qini3qd","Type":"NodeBlockquote","Properties":{"id":"20250922215514-qini3qd","updated":"20250922215526"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922215514-1oaomhy","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215514-1oaomhy","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922215514-wsivopd","Type":"NodeParagraph","Properties":{"id":"20250922215514-wsivopd","updated":"20250922215514"},"Children":[{"Type":"NodeText","Data":"第五十二部分是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM评估方法论的深化和总结"},{"Type":"NodeText","Data":"。它不仅详细阐述了针对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同类型LLM"},{"Type":"NodeText","Data":"的评估策略，还对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三种主流评估方法"},{"Type":"NodeText","Data":"进行了深刻的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优缺点（Pros and Cons）"},{"Type":"NodeText","Data":"分析，并最终通过一张"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面的评估工作地图（表15）"},{"Type":"NodeText","Data":"进行了系统性的归纳。"}]},{"ID":"20250922215514-x0f7sn9","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922215514-x0f7sn9","updated":"20250922215514"},"Children":[{"ID":"20250922215513-0oqmsu3","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922215513-0oqmsu3","updated":"20250922215513"},"Children":[{"ID":"20250922215514-e9ezqhh","Type":"NodeParagraph","Properties":{"id":"20250922215514-e9ezqhh","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估的“个性化”与“标准化”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215514-8ekj89c","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-8ekj89c","updated":"20250922215514"},"Children":[{"ID":"20250922215513-ttrgwnl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-ttrgwnl","updated":"20250922215513"},"Children":[{"ID":"20250922215514-35nfnmd","Type":"NodeParagraph","Properties":{"id":"20250922215514-35nfnmd","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专业化LLM的评估"},{"Type":"NodeText","Data":"体现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“个性化”"},{"Type":"NodeText","Data":"。除了通用能力，还必须用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域特定的基准（如MultiMedQA, FLUE）"},{"Type":"NodeText","Data":"来检验其“专业课”成绩。"}]}]},{"ID":"20250922215513-0gtb0fa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-0gtb0fa","updated":"20250922215513"},"Children":[{"ID":"20250922215514-4cedhau","Type":"NodeParagraph","Properties":{"id":"20250922215514-4cedhau","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"微调LLM的评估"},{"Type":"NodeText","Data":"则更侧重于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“标准化”"},{"Type":"NodeText","Data":"。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Chatbot Arena"},{"Type":"NodeText","Data":"这类平台，将不同的模型置于一个统一的、匿名的竞争环境中，让真实用户进行“盲测”，是目前最公认的评估通用对话能力的范式。"}]}]}]}]},{"ID":"20250922215513-y5sgh8d","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922215513-y5sgh8d","updated":"20250922215513"},"Children":[{"ID":"20250922215514-qse7cz8","Type":"NodeParagraph","Properties":{"id":"20250922215514-qse7cz8","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估方法的“三元悖论”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215514-bd2y8wf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-bd2y8wf","updated":"20250922215514"},"Children":[{"ID":"20250922215513-u6b3zit","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-u6b3zit","updated":"20250922215513"},"Children":[{"ID":"20250922215514-vw9xs50","Type":"NodeParagraph","Properties":{"id":"20250922215514-vw9xs50","updated":"20250922215514"},"Children":[{"Type":"NodeText","Data":"对三种评估方法的优缺点分析，揭示了一个类似"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“三元悖论”"},{"Type":"NodeText","Data":"的困境："}]},{"ID":"20250922215514-fn53ki6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-fn53ki6","updated":"20250922215514"},"Children":[{"ID":"20250922215513-jxuzey4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-jxuzey4","updated":"20250922215513"},"Children":[{"ID":"20250922215514-uv512dw","Type":"NodeParagraph","Properties":{"id":"20250922215514-uv512dw","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于基准"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可扩展、自动化"},{"Type":"NodeText","Data":"，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不够灵活"},{"Type":"NodeText","Data":"且可能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"被污染"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215513-3n15gxi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-3n15gxi","updated":"20250922215513"},"Children":[{"ID":"20250922215514-yeg23kp","Type":"NodeParagraph","Properties":{"id":"20250922215514-yeg23kp","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于人类"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最真实、最可靠"},{"Type":"NodeText","Data":"，但"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"昂贵、耗时且不可复现"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215513-j9nysa2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-j9nysa2","updated":"20250922215513"},"Children":[{"ID":"20250922215514-3f6j7lg","Type":"NodeParagraph","Properties":{"id":"20250922215514-3f6j7lg","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于模型"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可扩展、可解释"},{"Type":"NodeText","Data":"，但模型自身存在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"偏见"},{"Type":"NodeText","Data":"且"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力有限"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922215513-ezbvajt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-ezbvajt","updated":"20250922215513"},"Children":[{"ID":"20250922215514-3b2z8xo","Type":"NodeParagraph","Properties":{"id":"20250922215514-3b2z8xo","updated":"20250922215514"},"Children":[{"Type":"NodeText","Data":"这表明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目前不存在任何一种完美的评估方法"},{"Type":"NodeText","Data":"。最佳实践往往是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将这三种方法结合起来"},{"Type":"NodeText","Data":"，互为补充，从不同维度对模型进行全面、立体的考察。"}]}]}]}]}]}]},{"ID":"20250922215514-6gxgxfv","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-6gxgxfv","updated":"20250922215526"},"Children":[{"ID":"20250922215513-q9itinz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-q9itinz","updated":"20250922215513"},"Children":[{"ID":"20250922215513-f2hvwi5","Type":"NodeParagraph","Properties":{"id":"20250922215513-f2hvwi5","updated":"20250922215513"}}]}]},{"ID":"20250922215514-51pbs9x","Type":"NodeBlockquote","Properties":{"id":"20250922215514-51pbs9x","updated":"20250922215526"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922215514-4up00f0","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922215514-4up00f0","updated":"20250922215514"},"Children":[{"ID":"20250922215513-kjpat90","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922215513-kjpat90","updated":"20250922215513"},"Children":[{"ID":"20250922215514-lu9bplu","Type":"NodeParagraph","Properties":{"id":"20250922215514-lu9bplu","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估领域的“全景地图”（表15）"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215514-jvyjc4q","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215514-jvyjc4q","updated":"20250922215514"},"Children":[{"ID":"20250922215513-vwotqll","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-vwotqll","updated":"20250922215513"},"Children":[{"ID":"20250922215514-1qv10ty","Type":"NodeParagraph","Properties":{"id":"20250922215514-1qv10ty","updated":"20250922215514"},"Children":[{"Type":"NodeText","Data":"表15是整个评估章节的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“皇冠上的明珠”"},{"Type":"NodeText","Data":"。它将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"抽象的方法论"},{"Type":"NodeText","Data":"与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"具体的评估工作"},{"Type":"NodeText","Data":"联系起来，为读者提供了一份"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"详尽的、可按需检索的“资源索引”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215513-snc2mg9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215513-snc2mg9","updated":"20250922215513"},"Children":[{"ID":"20250922215514-ss9yfhs","Type":"NodeParagraph","Properties":{"id":"20250922215514-ss9yfhs","updated":"20250922215514"},"Children":[{"Type":"NodeText","Data":"这张表格清晰地展示了当前评估领域的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"研究热点和空白"},{"Type":"NodeText","Data":"。例如，通用能力的评估工作非常丰富，而针对特定高级能力（如环境交互）的基准则相对较少。"}]}]}]}]}]},{"ID":"20250922215514-9z1vkte","Type":"NodeParagraph","Properties":{"id":"20250922215514-9z1vkte","updated":"20250922215514"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第五十二部分为LLM评估这一复杂课题提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"清晰、深刻且极具实践指导意义的框架"},{"Type":"NodeText","Data":"。它不仅教会我们如何"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“因模施评”"},{"Type":"NodeText","Data":"（针对不同模型类型），还让我们深刻理解了不同评估方法的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内在权衡"},{"Type":"NodeText","Data":"。最终，通过表15这张“全景地图”，它为整个LLM评估领域的研究和实践提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"宝贵的导航"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215736-laeoagw","Type":"NodeParagraph","Properties":{"id":"20250922215736-laeoagw","updated":"20250922215736"},"Children":[{"Type":"NodeText","Data":"好的，我们继续输出最后一部分。"}]},{"ID":"20250922215736-huozu1e","Type":"NodeThematicBreak","Properties":{"id":"20250922215736-huozu1e","updated":"20250922215736"}},{"ID":"20250922215736-271eq1l","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215736-271eq1l","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第五十三部分"}]},{"ID":"20250922215736-bu2f1zq","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215736-bu2f1zq","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.4 Empirical Evaluation (实证评估)"}]},{"ID":"20250922215736-f6asid2","Type":"NodeParagraph","Properties":{"id":"20250922215736-f6asid2","updated":"20250922215747"},"Children":[{"Type":"NodeText","Data":"上述评估基准和方法主要用于评估LLM的整体能力。在本部分中，我们对7.1节和7.2节中讨论的能力进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"细粒度的评估"},{"Type":"NodeText","Data":"。对于每种能力，我们选择代表性的任务和数据集进行评估实验，以检验LLM的相应性能。"}]},{"ID":"20250922215736-7kczcsj","Type":"NodeHeading","HeadingLevel":6,"Properties":{"id":"20250922215736-7kczcsj","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"7.4.1 Experimental Settings (实验设置)"}]},{"ID":"20250922215736-3z2706j","Type":"NodeParagraph","Properties":{"id":"20250922215736-3z2706j","updated":"20250922215747"},"Children":[{"Type":"NodeText","Data":"在本部分中，我们介绍评估的实验设置。"}]},{"ID":"20250922215736-eme8ci7","Type":"NodeParagraph","Properties":{"id":"20250922215736-eme8ci7","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Evaluation Models (评估模型)."},{"Type":"NodeText","Data":" 为了进行评估，我们考虑了从开源模型到闭源API访问模型的代表性LLM，如下所示："}]},{"ID":"20250922215736-f0qewcp","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-f0qewcp","updated":"20250922215747"},"Children":[{"ID":"20250922215735-uvrpgp8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-uvrpgp8","updated":"20250922215735"},"Children":[{"ID":"20250922215736-ats2lhp","Type":"NodeParagraph","Properties":{"id":"20250922215736-ats2lhp","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源模型 (Open-source models)."},{"Type":"NodeText","Data":" 现有的开源模型可以分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础模型"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调模型"},{"Type":"NodeText","Data":"。基础模型仅在一个大型通用语料库上用语言建模目标进行预训练，但没有进一步的监督微调。在我们的评估中，我们选择了四个代表性的基础模型，包括LLaMA (7B)、LLaMA 2 (7B)、Pythia (7B and 12B)和Falcon (7B)。指令微调模型是那些使用指令（即任务数据集、日常聊天或合成指令）进行微调的模型。在我们的实验中，我们选择了四个代表性的指令微调模型，包括Vicuna (7B and 13B)、Alpaca (7B)和ChatGLM (6B)。此外，我们还包括了LLaMA 2-Chat (7B)进行比较，它是一个代表性的模型，已通过指令微调和RLHF基于LLaMA 2 (7B)与人类对齐。"}]}]},{"ID":"20250922215735-prg1o0v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-prg1o0v","updated":"20250922215735"},"Children":[{"ID":"20250922215736-zjzv98w","Type":"NodeParagraph","Properties":{"id":"20250922215736-zjzv98w","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭源模型 (Closed-source models)."},{"Type":"NodeText","Data":" 除了开源模型，还有只能通过API访问的闭源模型，这些模型已引起开发者和研究人员的极大关注。在这里，我们选择了四个代表性的闭源模型，包括text-davinci-002/003 (简写为Davinci002/003)、ChatGPT、Claude和Claude 2，其中前三个模型由OpenAI开发，后两个由Anthropic开发。"}]}]}]},{"ID":"20250922215736-da5f7xm","Type":"NodeParagraph","Properties":{"id":"20250922215736-da5f7xm","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Tasks and Datasets (任务与数据集)."},{"Type":"NodeText","Data":" 接下来，我们为7.1节和7.2节中讨论的能力设置评估任务和数据集。我们主要评估LLM在这些数据集上的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本"},{"Type":"NodeText","Data":"性能。对于在零样本方式下难以解决的更复杂的任务（例如，数学推理和工具操作），我们主要报告"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3样本"},{"Type":"NodeText","Data":"性能，考虑到开源模型的上下文长度限制。"}]},{"ID":"20250922215736-917his2","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-917his2","updated":"20250922215747"},"Children":[{"ID":"20250922215735-558jrxo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-558jrxo","updated":"20250922215735"},"Children":[{"ID":"20250922215736-8q0hi3m","Type":"NodeParagraph","Properties":{"id":"20250922215736-8q0hi3m","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语言生成 (Language generation)."},{"Type":"NodeText","Data":" 如前所述，对于语言生成，我们考虑评估三种任务，即语言建模、条件文本生成和代码合成。具体来说，我们选择了四个常用的数据集，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LAMBADA"},{"Type":"NodeText","Data":"（语言建模）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WMT’22"},{"Type":"NodeText","Data":"（机器翻译）、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"XSum"},{"Type":"NodeText","Data":"（文本摘要）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HumanEval"},{"Type":"NodeText","Data":"（代码合成）进行评估。在WMT’22中，我们通过从原始的大规模测试集中为每个语言对选择1000个示例来构建一个新的评估集，以检验LLM在机器翻译中的平均性能。我们评估LLM在这些数据集上的零样本性能，并计算LAMBADA的词语预测准确率，WMT’22的BLEU-4，XSum的ROUGE-L，以及HumanEval的pass@10。"}]}]},{"ID":"20250922215735-g3fgdl9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-g3fgdl9","updated":"20250922215735"},"Children":[{"ID":"20250922215736-eutzb3r","Type":"NodeParagraph","Properties":{"id":"20250922215736-eutzb3r","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识利用 (Knowledge utilization)."},{"Type":"NodeText","Data":" 为了评估知识利用的能力，我们选择了四个问答数据集（即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"TriviaQA, Natural Questions, Web Questions, 和ARC"},{"Type":"NodeText","Data":"）和一个事实抽取数据集"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WikiFact"},{"Type":"NodeText","Data":"。我们也报告LLM在这些数据集上的零样本性能，并计算ARC的准确率和其他数据集的精确匹配率。"}]}]},{"ID":"20250922215735-tqk3f72","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-tqk3f72","updated":"20250922215735"},"Children":[{"ID":"20250922215736-t0q11r1","Type":"NodeParagraph","Properties":{"id":"20250922215736-t0q11r1","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理 (Complex reasoning)."},{"Type":"NodeText","Data":" 对于复杂推理，我们在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"OpenbookQA, HellaSwag, 和SocialIQA"},{"Type":"NodeText","Data":"上评估比较模型进行知识推理；在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Colored Objects和Penguins in the Table"},{"Type":"NodeText","Data":"上进行符号推理；在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GSM8k和MATH"},{"Type":"NodeText","Data":"上进行数学推理。我们计算OpenbookQA, HellaSwag, 和SocialIQA的准确率；Colored Objects和Penguins in the Table的解决率；以及GSM8k和MATH的准确率。对于知识推理任务，我们评估零样本性能，因为它们都是可以在零样本设置下解决的QA任务。对于复杂的符号推理和数学推理任务，我们利用3样本上下文范例来更好地激发LLM完成它们。遵循现有的工作，我们还利用思维链提示策略来更好地解决数学推理任务。"}]}]},{"ID":"20250922215735-jliwsmp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-jliwsmp","updated":"20250922215735"},"Children":[{"ID":"20250922215736-9vaevua","Type":"NodeParagraph","Properties":{"id":"20250922215736-9vaevua","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"人类对齐 (Human alignment)."},{"Type":"NodeText","Data":" 对于人类对齐，我们选择"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"TruthfulQA"},{"Type":"NodeText","Data":"来衡量一个LLM在生成问题答案时是否真实，选择"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CrowS-Pairs"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"WinoGender"},{"Type":"NodeText","Data":"来评估LLM中的刻板印象，选择"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RealToxityPrompts"},{"Type":"NodeText","Data":"来评估LLM生成有毒语言的程度，并选择"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"HaluEval"},{"Type":"NodeText","Data":"来测试LLM识别幻觉的能力。由于Real-Toxicity-Prompts的测试集太大，我们从中随机抽样10000个示例进行评估。我们遵循LLaMA的做法报告零样本性能，并计算识别一个断言为真的准确率（TruthfulQA），识别有偏见句子的准确率（高"}]}]}]},{"ID":"20250922215736-lc2h03p","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1,1,1,1],"Properties":{"colgroup":"|||||||||","id":"20250922215736-lc2h03p","updated":"20250922215747"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Models"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"LBD↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WMT↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"XSum↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HumanEval↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"TriviaQA↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"NaturalQ↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WebQ↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ARC↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WikiFact↑"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"55.81"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"36.44"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"21.71"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"79.88"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"54.54"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"21.52"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"17.77"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"93.69"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.25"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Claude"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64.47"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"31.23"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"18.63"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"51.22"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"40.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"13.77"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.57"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"66.62"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.34"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Claude 2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"45.20"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"12.93"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"19.13"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"78.04"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"54.30"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"21.30"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"21.06"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"79.97"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"35.83"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Davinci003"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"69.98"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"37.46"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"18.19"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"67.07"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"51.51"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"17.76"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"16.68"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"88.47"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"28.29"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Davinci002"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58.85"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"35.11"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"19.15"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"56.70"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"52.11"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"20.47"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"18.45"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"89.23"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.15"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA 2-Chat (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"56.12"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"12.62"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"16.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11.59"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"38.93"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"12.96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"11.32"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"72.35"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"23.37"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna (13B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"62.45"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"20.49"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"17.87"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"20.73"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.04"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.75"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11.52"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"20.69"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"28.76"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"63.90"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"19.95"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"13.59"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"17.07"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"28.58"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"9.17"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"16.96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"26.95"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"63.35"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"21.52"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.74"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"13.41"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"17.14"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"49.75"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"26.05"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGLM (6B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"33.34"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"16.58"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"13.48"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"13.42"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"13.42"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.40"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"9.20"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"55.39"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"16.01"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA 2 (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"66.39"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11.57"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11.57"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"17.07"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"30.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5.15"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.51"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24.16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"28.06"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"67.68"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"13.84"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.77"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"15.24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.62"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11.12"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.88"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"19.78"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Falcon (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"66.89"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.05"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.37"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"28.74"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.78"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.46"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.08"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"23.91"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pythia (12B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"61.19"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5.43"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.87"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.63"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"15.73"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.99"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.72"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11.66"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"20.57"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pythia (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"56.96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.68"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.23"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"9.15"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.77"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.74"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11.03"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"15.75"}]}]}]},{"ID":"20250922215736-zcnfrib","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215736-zcnfrib","updated":"20250922215747"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表 16：LLM在八种能力上的评估，任务经过特别选择。"}]},{"ID":"20250922215736-miqrss5","Type":"NodeParagraph","Properties":{"id":"20250922215736-miqrss5","updated":"20250922215747"},"Children":[{"Type":"NodeText","Data":"橙色和蓝色字体的阴影分别表示闭源和开源模型中结果的性能顺序。此表将通过整合更多模型的结果持续更新。\n（上半部分：语言生成与知识利用）"}]},{"ID":"20250922215736-rsu14y3","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1,1,1,1],"Properties":{"colgroup":"|||||||||","id":"20250922215736-rsu14y3","updated":"20250922215747"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Models"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"OBQA↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HellaSwag↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"SocialIQA↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"C-Objects↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Penguins↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"GSM8k↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"MATH↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"ALFW↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WebShop↑"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"81.20"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"61.43"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"73.23"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"53.20"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"40.27"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"78.47"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"33.78"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58.96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"45.12/15.60"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Claude"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"81.80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"54.95"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"73.23"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"59.95"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"47.65"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70.81"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"20.18"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"76.87"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"47.72/23.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Claude 2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"71.60"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"50.75"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58.34"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"66.76"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"74.50"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"82.87"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32.24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"77.61"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.96/19.20"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Davinci003"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"74.40"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"62.65"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"69.70"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64.60"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"61.07"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"57.16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"17.66"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"65.67"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64.08/32.40"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Davinci002"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"69.80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"47.81"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"57.01"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"62.55"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"67.11"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"49.96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.28"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"76.87"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.66/15.20"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA 2-Chat (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"45.62"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"74.01"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"43.84"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"43.40"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"38.93"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"9.63"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.22"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11.19"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24.51/5.60"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna (13B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"43.65"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"70.51"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"45.97"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"53.55"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"36.91"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"18.50"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.72"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"22.74/5.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"43.84"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"69.25"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"46.27"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"44.25"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"36.24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.03"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.54"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.49"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.90/1.40"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"47.82"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"69.81"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"47.55"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"39.35"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"40.27"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.93"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.48"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00/0.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGLM (6B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"30.42"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.27"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"33.18"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.05"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.09"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.41"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.10"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00/0.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA 2 (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"44.81"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"74.25"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41.72"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"43.95"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"35.75"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.99"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00/0.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"42.42"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"73.91"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41.46"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"39.95"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.90"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.99"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.12"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00/0.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Falcon (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"39.46"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"74.58"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"42.53"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"24.16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.67"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.94"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.46"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00/0.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pythia (12B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"37.02"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"65.45"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41.53"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32.40"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"26.17"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.88"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.96"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5.22"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.68/0.60"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pythia (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.88"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"61.82"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41.01"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"29.05"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"27.52"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.82"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.46"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.46"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.75/1.80"}]}]}]},{"ID":"20250922215736-7hz5qf2","Type":"NodeParagraph","Properties":{"id":"20250922215736-7hz5qf2","updated":"20250922215747"},"Children":[{"Type":"NodeText","Data":"(中半部分：知识推理、符号推理、数学推理、与环境交互)"}]},{"ID":"20250922215736-x5fvgv1","Type":"NodeTable","TableAligns":[1,1,1,1,1,1,1,1,1,1],"Properties":{"colgroup":"|||||||||","id":"20250922215736-x5fvgv1","updated":"20250922215747"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Models"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"TfQA↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"C-Pairs↓"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"WinoGender↓"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"RTP↓"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HaluEval↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"HotpotQA↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Gorilla-TH↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Gorilla-TF↑"}]},{"Type":"NodeTableCell","Data":"th","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"Gorilla-HF↑"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"69.16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"18.60"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"62.50/72.50/79.17"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.07"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"66.64"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"23.80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"67.20"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"44.53"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"19.36"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Claude"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"67.93"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"32.73"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"71.67/55.00/52.50"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.75"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"63.75"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"33.80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"22.04"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.74"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.08"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Claude 2"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"71.11"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"10.67"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"60.00/60.00/55.83"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.20"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"50.63"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"36.40"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"61.29"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"22.19"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"23.67"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Davinci003"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"60.83"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.99"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"67.50/68.33/79.17"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"8.81"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"58.94"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"34.40"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"72.58"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.42"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Davinci002"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"53.73"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"7.56"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"72.50/70.00/64.17"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"10.65"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"59.67"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"26.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"2.69"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.02"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA 2-Chat (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"69.77"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.54"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"47.50/46.67/46.67"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.61"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"43.82"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.40"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.22"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna (13B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"62.30"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"45.95"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"50.83/50.83/52.50"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"49.01"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"11.20"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.44"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.89"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"57.77"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"67.44"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"49.17/49.17/49.17"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.70"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"43.44"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.20"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.33"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Alpaca (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"46.14"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"65.45"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"53.33/51.67/53.33"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.78"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"44.16"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"11.60"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.11"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGLM (6B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"63.53"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"50.53"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"47.50/47.50/46.67"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.89"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"41.82"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"4.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA 2 (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"50.06"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"51.39"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"48.83/48.83/50.83"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.17"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"42.23"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"3.80"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.11"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"47.86"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"67.84"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"54.17/52.50/51.67"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"5.94"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"14.18"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.60"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.11"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Falcon (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"53.24"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"68.04"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"50.00/50.83/50.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.71"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"37.41"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"1.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pythia (12B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"54.47"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"65.78"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"49.17/48.33/49.17"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"6.59"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"27.09"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.40"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Pythia (7B)"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"50.92"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"64.79"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"51.67/49.17/50.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"13.02"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"25.84"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.20"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]},{"Type":"NodeTableCell","Data":"td","TableCellAlign":1,"Children":[{"Type":"NodeText","Data":"0.00"}]}]}]},{"ID":"20250922215736-qdqtz1l","Type":"NodeParagraph","Properties":{"id":"20250922215736-qdqtz1l","updated":"20250922215747"},"Children":[{"Type":"NodeText","Data":"(下半部分：人类对齐与工具操作)"}]},{"ID":"20250922215736-iqkiwhj","Type":"NodeBlockquote","Properties":{"id":"20250922215736-iqkiwhj","updated":"20250922215747"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922215736-u18zx39","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215736-u18zx39","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250922215736-gch1wc1","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250922215736-gch1wc1","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"表16解析：LLM“大比武”成绩单"}]},{"ID":"20250922215736-5fpts2m","Type":"NodeParagraph","Properties":{"id":"20250922215736-5fpts2m","updated":"20250922215736"},"Children":[{"Type":"NodeText","Data":"这张庞大的表格是本文"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实证评估的核心"},{"Type":"NodeText","Data":"，可以看作是一场涵盖了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"14个模型"},{"Type":"NodeText","Data":"、横跨"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"8大能力领域"},{"Type":"NodeText","Data":"、涉及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"27个具体任务"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLM“全能大比武”"},{"Type":"NodeText","Data":"。通过分析这张“成绩单”，我们可以得出几个关键结论。"}]},{"ID":"20250922215736-p5e99zk","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-p5e99zk","updated":"20250922215736"},"Children":[{"ID":"20250922215735-im6wse1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-im6wse1","updated":"20250922215735"},"Children":[{"ID":"20250922215736-i2ixqja","Type":"NodeParagraph","Properties":{"id":"20250922215736-i2ixqja","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭源模型 vs. 开源模型：王者与追赶者"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215736-ty3oo9i","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-ty3oo9i","updated":"20250922215736"},"Children":[{"ID":"20250922215735-8qje29m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-8qje29m","updated":"20250922215735"},"Children":[{"ID":"20250922215736-u78blhk","Type":"NodeParagraph","Properties":{"id":"20250922215736-u78blhk","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭源模型（ChatGPT, Claude, Davinci）"},{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"绝大多数"},{"Type":"NodeText","Data":"任务上，特别是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂推理、环境交互和工具使用"},{"Type":"NodeText","Data":"等高级能力上，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面领先"},{"Type":"NodeText","Data":"于同期的开源模型。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ChatGPT"},{"Type":"NodeText","Data":"更是其中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“全能冠军”"},{"Type":"NodeText","Data":"，在多个项目上夺得头筹。"}]}]},{"ID":"20250922215735-rnfemdp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-rnfemdp","updated":"20250922215735"},"Children":[{"ID":"20250922215736-46iuc8l","Type":"NodeParagraph","Properties":{"id":"20250922215736-46iuc8l","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源模型"},{"Type":"NodeText","Data":"则扮演着"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“追赶者”"},{"Type":"NodeText","Data":"的角色。其中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调模型（LLaMA 2-Chat, Vicuna）"},{"Type":"NodeText","Data":"的性能显著优于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础模型（LLaMA, Falcon, Pythia）"},{"Type":"NodeText","Data":"，这证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调和对齐"},{"Type":"NodeText","Data":"是提升模型能力的关键。"}]}]}]}]},{"ID":"20250922215735-9mwgwf1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-9mwgwf1","updated":"20250922215735"},"Children":[{"ID":"20250922215736-9xg4nxc","Type":"NodeParagraph","Properties":{"id":"20250922215736-9xg4nxc","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力维度的“强项”与“弱项”"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215736-91xauqf","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-91xauqf","updated":"20250922215736"},"Children":[{"ID":"20250922215735-qrznfor","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-qrznfor","updated":"20250922215735"},"Children":[{"ID":"20250922215736-7a5z89l","Type":"NodeParagraph","Properties":{"id":"20250922215736-7a5z89l","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强项"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215736-n2lhxl1","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-n2lhxl1","updated":"20250922215736"},"Children":[{"ID":"20250922215735-8wzgj0w","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-8wzgj0w","updated":"20250922215735"},"Children":[{"ID":"20250922215736-d8uu6y9","Type":"NodeParagraph","Properties":{"id":"20250922215736-d8uu6y9","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭源模型"},{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数学推理 (GSM8k)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代码生成 (HumanEval)"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"环境交互 (WebShop)"},{"Type":"NodeText","Data":" 和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具使用 (Gorilla)"},{"Type":"NodeText","Data":" 上展现出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"压倒性"},{"Type":"NodeText","Data":"的优势。这很可能得益于它们更大规模的预训练、更优质的指令/代码数据以及专门的对齐优化。"}]}]}]}]},{"ID":"20250922215735-0tstrdz","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-0tstrdz","updated":"20250922215735"},"Children":[{"ID":"20250922215736-1sutu55","Type":"NodeParagraph","Properties":{"id":"20250922215736-1sutu55","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"弱项 (共同的挑战)"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215736-egdr5ti","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-egdr5ti","updated":"20250922215736"},"Children":[{"ID":"20250922215735-ziwwtvl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-ziwwtvl","updated":"20250922215735"},"Children":[{"ID":"20250922215736-41r5wd6","Type":"NodeParagraph","Properties":{"id":"20250922215736-41r5wd6","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"所有模型"},{"Type":"NodeText","Data":"，包括最强的ChatGPT，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"极难的数学推理 (MATH)"},{"Type":"NodeText","Data":" 和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多跳问答 (HotpotQA)"},{"Type":"NodeText","Data":" 上都表现平平。这说明这些任务触及了当前LLM能力的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“天花板”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215735-9pcxx3k","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-9pcxx3k","updated":"20250922215735"},"Children":[{"ID":"20250922215736-y8jetv6","Type":"NodeParagraph","Properties":{"id":"20250922215736-y8jetv6","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"开源模型"},{"Type":"NodeText","Data":"在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"环境交互"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"工具使用"},{"Type":"NodeText","Data":"上的得分几乎为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零"},{"Type":"NodeText","Data":"。这清晰地表明，这些高级能力是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“涌现”"},{"Type":"NodeText","Data":"的，并且需要"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专门的训练和对齐"},{"Type":"NodeText","Data":"才能解锁，而不仅仅是靠预训练。"}]}]}]}]}]}]},{"ID":"20250922215735-844ywkx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-844ywkx","updated":"20250922215735"},"Children":[{"ID":"20250922215736-q090raq","Type":"NodeParagraph","Properties":{"id":"20250922215736-q090raq","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调的价值"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215736-unpjjnn","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-unpjjnn","updated":"20250922215736"},"Children":[{"ID":"20250922215735-apxywjn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-apxywjn","updated":"20250922215735"},"Children":[{"ID":"20250922215736-vaeu8zz","Type":"NodeParagraph","Properties":{"id":"20250922215736-vaeu8zz","updated":"20250922215736"},"Children":[{"Type":"NodeText","Data":"比较"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA 2 (基础模型)"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLaMA 2-Chat (微调模型)"},{"Type":"NodeText","Data":"。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识利用"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识推理"},{"Type":"NodeText","Data":"等任务上，LLaMA 2-Chat的性能"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"全面优于"},{"Type":"NodeText","Data":"其基础模型。例如，在HellaSwag上，从74.25提升到74.01（此处原文数据似乎有误，但趋势是提升的）。这直接证明了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调和RLHF"},{"Type":"NodeText","Data":"能有效解锁和提升模型的基础能力。"}]}]}]}]},{"ID":"20250922215735-42b2dqp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-42b2dqp","updated":"20250922215735"},"Children":[{"ID":"20250922215736-4rtrpoi","Type":"NodeParagraph","Properties":{"id":"20250922215736-4rtrpoi","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则的体现"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215736-trkfbhd","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-trkfbhd","updated":"20250922215736"},"Children":[{"ID":"20250922215735-ofv9u19","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-ofv9u19","updated":"20250922215735"},"Children":[{"ID":"20250922215736-6mgy0a5","Type":"NodeParagraph","Properties":{"id":"20250922215736-6mgy0a5","updated":"20250922215736"},"Children":[{"Type":"NodeText","Data":"比较"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna 7B"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vicuna 13B"},{"Type":"NodeText","Data":"。在大多数任务上，13B版本的性能都"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优于"},{"Type":"NodeText","Data":"7B版本，特别是在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"符号推理 (C-Objects)"},{"Type":"NodeText","Data":"等复杂任务上，优势更为明显。这再次验证了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模型越大，能力越强”"},{"Type":"NodeText","Data":"的规模法则。"}]}]}]}]}]},{"ID":"20250922215736-eco25ga","Type":"NodeParagraph","Properties":{"id":"20250922215736-eco25ga","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 这张成绩单为我们提供了一幅"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据驱动的、极其宝贵的LLM能力图谱"},{"Type":"NodeText","Data":"。它不仅"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"量化"},{"Type":"NodeText","Data":"了不同模型之间的差距，更重要的是，它揭示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能力的层次性"},{"Type":"NodeText","Data":"。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础的语言和知识能力"},{"Type":"NodeText","Data":"可以通过大规模预训练和通用指令微调获得，而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级的推理、交互和工具使用能力"},{"Type":"NodeText","Data":"，则似乎是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"顶尖闭源模型"},{"Type":"NodeText","Data":"通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"更庞大的规模、更优质的数据和更精细的对齐"},{"Type":"NodeText","Data":"才得以解锁的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“独门绝技”"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250922215736-t56t9g1","Type":"NodeThematicBreak","Properties":{"id":"20250922215736-t56t9g1","updated":"20250922215747"}},{"ID":"20250922215736-1syj2ip","Type":"NodeBlockquote","Properties":{"id":"20250922215736-1syj2ip","updated":"20250922215747"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250922215736-cnmfuir","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250922215736-cnmfuir","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析"}]},{"ID":"20250922215736-8uh5agy","Type":"NodeParagraph","Properties":{"id":"20250922215736-8uh5agy","updated":"20250922215736"},"Children":[{"Type":"NodeText","Data":"第五十三部分是本综述的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“实证核心”"},{"Type":"NodeText","Data":"，它将前面章节中讨论的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"所有理论和方法，最终落到了可度量、可比较的实验数据上"},{"Type":"NodeText","Data":"。通过这场大规模的“LLM大比武”，文章为我们提供了一幅"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"客观、量化"},{"Type":"NodeText","Data":"的LLM能力全景图。"}]},{"ID":"20250922215736-mvv06ns","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250922215736-mvv06ns","updated":"20250922215736"},"Children":[{"ID":"20250922215736-b0eqb8z","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250922215736-b0eqb8z","updated":"20250922215736"},"Children":[{"ID":"20250922215736-qgwwgmj","Type":"NodeParagraph","Properties":{"id":"20250922215736-qgwwgmj","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“定性”到“定量”的飞跃"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215736-fn4kwp6","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-fn4kwp6","updated":"20250922215736"},"Children":[{"ID":"20250922215735-dmfr90b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215735-dmfr90b","updated":"20250922215735"},"Children":[{"ID":"20250922215736-jlkleay","Type":"NodeParagraph","Properties":{"id":"20250922215736-jlkleay","updated":"20250922215736"},"Children":[{"Type":"NodeText","Data":"前面的章节更多的是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定性的"},{"Type":"NodeText","Data":"介绍和分析，而本部分则是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"定量的"},{"Type":"NodeText","Data":"验证和比较。"}]}]},{"ID":"20250922215736-8anmsoa","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215736-8anmsoa","updated":"20250922215736"},"Children":[{"ID":"20250922215736-ly666h7","Type":"NodeParagraph","Properties":{"id":"20250922215736-ly666h7","updated":"20250922215736"},"Children":[{"Type":"NodeText","Data":"通过在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一的、广泛的"},{"Type":"NodeText","Data":"任务集上进行测试，它将不同模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“宣传”"},{"Type":"NodeText","Data":"转化为了可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"横向比较的“分数”"},{"Type":"NodeText","Data":"，为社区提供了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相对公正的参照系"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922215736-budyagx","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250922215736-budyagx","updated":"20250922215736"},"Children":[{"ID":"20250922215736-cbwol1g","Type":"NodeParagraph","Properties":{"id":"20250922215736-cbwol1g","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实验设计的严谨性与全面性"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215736-0vctzck","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-0vctzck","updated":"20250922215736"},"Children":[{"ID":"20250922215736-zh7fdh7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215736-zh7fdh7","updated":"20250922215736"},"Children":[{"ID":"20250922215736-xm8l3wf","Type":"NodeParagraph","Properties":{"id":"20250922215736-xm8l3wf","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型选择的代表性"},{"Type":"NodeText","Data":": 涵盖了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭源与开源"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础与微调"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同规模"},{"Type":"NodeText","Data":"的多种主流模型，使得比较结果具有广泛的代表性。"}]}]},{"ID":"20250922215736-lgy2l00","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215736-lgy2l00","updated":"20250922215736"},"Children":[{"ID":"20250922215736-3q7zbtn","Type":"NodeParagraph","Properties":{"id":"20250922215736-3q7zbtn","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务选择的全面性"},{"Type":"NodeText","Data":": 评估任务覆盖了从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础（生成、知识、推理）"},{"Type":"NodeText","Data":"到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级（对齐、交互、工具）"},{"Type":"NodeText","Data":"的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"所有核心能力维度"},{"Type":"NodeText","Data":"，能够全面地考察一个模型的综合素质。"}]}]},{"ID":"20250922215736-rcky7az","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215736-rcky7az","updated":"20250922215736"},"Children":[{"ID":"20250922215736-g0f0269","Type":"NodeParagraph","Properties":{"id":"20250922215736-g0f0269","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"评估设置的严谨性"},{"Type":"NodeText","Data":": 明确区分了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本（+CoT）"},{"Type":"NodeText","Data":"的评估设置，并尽可能遵循现有工作的最佳实践，保证了评估结果的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"科学性"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可比性"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250922215736-7glkq43","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250922215736-7glkq43","updated":"20250922215736"},"Children":[{"ID":"20250922215736-kt34ogz","Type":"NodeParagraph","Properties":{"id":"20250922215736-kt34ogz","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据驱动的核心洞见"},{"Type":"NodeText","Data":":"}]},{"ID":"20250922215736-xow8okr","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-xow8okr","updated":"20250922215736"},"Children":[{"ID":"20250922215736-uyeyn5m","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215736-uyeyn5m","updated":"20250922215736"},"Children":[{"ID":"20250922215736-mpmwtik","Type":"NodeParagraph","Properties":{"id":"20250922215736-mpmwtik","updated":"20250922215736"},"Children":[{"Type":"NodeText","Data":"表16的“成绩单”不仅仅是数字的罗列，它雄辩地证明了前面章节的许多论点："}]},{"ID":"20250922215736-3enwi22","Type":"NodeList","ListData":{},"Properties":{"id":"20250922215736-3enwi22","updated":"20250922215736"},"Children":[{"ID":"20250922215736-0cpblez","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215736-0cpblez","updated":"20250922215736"},"Children":[{"ID":"20250922215736-duhzndq","Type":"NodeParagraph","Properties":{"id":"20250922215736-duhzndq","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"闭源SOTA模型的领先地位"},{"Type":"NodeText","Data":": 验证了其在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级能力"},{"Type":"NodeText","Data":"上的巨大优势。"}]}]},{"ID":"20250922215736-9nlb0k1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215736-9nlb0k1","updated":"20250922215736"},"Children":[{"ID":"20250922215736-31j4p8n","Type":"NodeParagraph","Properties":{"id":"20250922215736-31j4p8n","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指令微调和对齐的巨大价值"},{"Type":"NodeText","Data":": 通过对比基础模型和微调模型，量化了其带来的性能提升。"}]}]},{"ID":"20250922215736-jsf4dri","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215736-jsf4dri","updated":"20250922215736"},"Children":[{"ID":"20250922215736-pk19fpu","Type":"NodeParagraph","Properties":{"id":"20250922215736-pk19fpu","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"规模法则的普适性"},{"Type":"NodeText","Data":": 通过对比7B和13B模型，再次证明了规模的重要性。"}]}]},{"ID":"20250922215736-h8hi2bp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250922215736-h8hi2bp","updated":"20250922215736"},"Children":[{"ID":"20250922215736-wevwcfv","Type":"NodeParagraph","Properties":{"id":"20250922215736-wevwcfv","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"当前LLM的能力边界"},{"Type":"NodeText","Data":": 在MATH和HotpotQA等任务上的集体“折戟”，清晰地指出了当前技术的天花板所在。"}]}]}]}]}]}]}]},{"ID":"20250922215736-yvklf3u","Type":"NodeParagraph","Properties":{"id":"20250922215736-yvklf3u","updated":"20250922215736"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结"},{"Type":"NodeText","Data":": 第五十三部分是本综述的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“数据之锚”"},{"Type":"NodeText","Data":"。它用一场"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精心设计、规模宏大"},{"Type":"NodeText","Data":"的实证评估，为所有关于LLM能力的理论讨论提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"坚实的数据支撑"},{"Type":"NodeText","Data":"。它用客观的分数，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"验证了已知，量化了差距，并指明了未知"},{"Type":"NodeText","Data":"。对于任何希望快速了解当前主流LLM真实能力水平和相对排名的读者来说，这一部分（特别是表16）提供了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最直接、最宝贵"},{"Type":"NodeText","Data":"的信息。"}]}]}]}