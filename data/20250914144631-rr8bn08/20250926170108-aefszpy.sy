{"ID":"20250926170108-aefszpy","Spec":"1","Type":"NodeDocument","Properties":{"id":"20250926170108-aefszpy","title":"08 大型视觉模型和视觉提示工程的综述","type":"doc","updated":"20250926171158"},"Children":[{"ID":"20250926170114-pigqk6n","Type":"NodeParagraph","Properties":{"id":"20250926170114-pigqk6n","updated":"20250926170114"},"Children":[{"Type":"NodeText","Data":"好的，我将根据你的要求，对这篇关于大型视觉模型和视觉提示工程的综述文章进行分步翻译和解析。"}]},{"ID":"20250926170114-2v0sza0","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170114-2v0sza0","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"摘要"}]},{"ID":"20250926170114-0dgwx1h","Type":"NodeParagraph","Properties":{"id":"20250926170114-0dgwx1h","updated":"20250926170117"},"Children":[{"Type":"NodeText","Data":"视觉提示工程是视觉和图像"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用人工智能（AGI）"},{"Type":"NodeText","Data":" 领域的一项基本方法论。随着大型视觉模型的发展，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的重要性"},{"Type":"NodeText","Data":"日益凸显。为特定的视觉任务设计合适的提示，已成为一个有意义的研究方向。本综述旨在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总结计算机视觉领域"},{"Type":"NodeText","Data":"中用于大型视觉模型和视觉提示工程的方法，探索视觉提示工程的最新进展。我们介绍了视觉领域中具有影响力的大型模型，以及应用于这些模型的一系列提示工程方法。我们希望这篇综述能对基于大型视觉模型的提示工程方法进行全面而系统的描述，为未来研究人员在这一领域的探索提供有价值的见解。"}]},{"ID":"20250926170114-usuylru","Type":"NodeBlockquote","Properties":{"id":"20250926170114-usuylru","updated":"20250926170117"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170114-bll3bsi","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170114-bll3bsi","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250926170114-43g63fr","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170114-43g63fr","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"摘要解析"}]},{"ID":"20250926170114-uoikssl","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170114-uoikssl","updated":"20250926170114"},"Children":[{"ID":"20250926170114-xuz12ih","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170114-xuz12ih","updated":"20250926170114"},"Children":[{"ID":"20250926170114-64hsjux","Type":"NodeParagraph","Properties":{"id":"20250926170114-64hsjux","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心概念"},{"Type":"NodeText","Data":": 摘要开宗明义，点出了本文的两个核心主题："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型视觉模型 (Large Vision Models)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示工程 (Visual Prompt Engineering)"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250926170114-377bj47","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170114-377bj47","updated":"20250926170114"},"Children":[{"ID":"20250926170114-4fgvfv4","Type":"NodeParagraph","Properties":{"id":"20250926170114-4fgvfv4","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"问题与目标"},{"Type":"NodeText","Data":": 随着模型越来越强大和通用，如何有效地“指挥”它们去完成特定任务成为了一个新问题。视觉提示工程就是解决这个问题的关键方法。"}]}]},{"ID":"20250926170114-v3nqexk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170114-v3nqexk","updated":"20250926170114"},"Children":[{"ID":"20250926170114-ngj5a7v","Type":"NodeParagraph","Properties":{"id":"20250926170114-ngj5a7v","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文章定位"},{"Type":"NodeText","Data":": 这是一篇"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综述性文章 (Review)"},{"Type":"NodeText","Data":"，其目的是系统性地梳理和总结该领域的现有方法、最新进展和代表性模型，并为未来的研究指明方向。"}]}]}]}]},{"ID":"20250926170114-rf0o297","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170114-rf0o297","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1. 引入"}]},{"ID":"20250926170114-pez2qdc","Type":"NodeParagraph","Properties":{"id":"20250926170114-pez2qdc","updated":"20250926170117"},"Children":[{"Type":"NodeText","Data":"自从Vaswani等人提出"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Transformer架构"},{"Type":"NodeText","Data":"以来，深度学习模型在参数规模和复杂性上都取得了显著的进步。随着时间的推移，这些模型的规模呈指数级增长。早期的语言模型例子包括BERT、T5、GPT-1、GPT-2以及各种BERT的变体。此外，还存在大量"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域特定的BERT变体"},{"Type":"NodeText","Data":"，它们被定制用于优化在特定研究领域或行业中的性能。最近，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型语言模型（LLMs）"},{"Type":"NodeText","Data":" 已成为通用人工智能系统的构建模块，并且通常通过自监督学习在海量数据集上进行训练。这种模型规模和复杂性的指数级增长，极大地增强了它们理解自然语言的能力，使其能够适应各种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"下游任务"},{"Type":"NodeText","Data":"。著名的例子包括GPT-3、ChatGPT、GPT-4等，也包括领域特定的大型语言模型。这种无需显式训练就能在多个下游任务上进行泛化的能力，通常被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本泛化 (zero-shot generalization)"},{"Type":"NodeText","Data":"，是该领域的一项突破性进展。"}]},{"ID":"20250926170114-we19awn","Type":"NodeParagraph","Properties":{"id":"20250926170114-we19awn","updated":"20250926170117"},"Children":[{"Type":"NodeText","Data":"受自然语言处理（NLP）领域预训练语言模型成功的启发，研究人员已开始探索计算机视觉领域的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预训练视觉模型"},{"Type":"NodeText","Data":"。这些视觉模型在海量图像数据集上进行预训练，具备理解图像内容和提取丰富语义信息的能力。预训练视觉模型的例子包括ViT、Swin Transformer、VideoMAE V2等。通过从大量数据中学习表示和特征，这些模型使计算机能够更有效地理解和分析图像，以应对各种下游应用。此外，像CLIP和ALIGN这样的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态视觉模型"},{"Type":"NodeText","Data":"，采用对比学习来对齐文本和视觉信息。这种对齐使得预训练模型能有效地将学到的语义信息应用到视觉领域，促进了在下游任务中的高效泛化。然而，尽管取得了显著成就，这些模型在泛化能力方面仍面临限制。人工智能（AI）的飞速发展催生了众多激动人心的技术突破，其中基于基础模型的AI系统的发展已成为一个突出领域。这一概念框架由AI专家提出并统一，代表了该领域一个新兴的范式。这一概念的重要性延伸到了“涌现”这一概念，随着机器学习技术的兴起，涌现现象变得日益明显。涌现体现在诸如自动推理等任务的执行中，以及通过深度学习（如上下文学习）逐步涌现出高级特征和功能。涌现的概念强调了系统行为是内在地被诱导出来的，而不是被明确构建的，这突显了AI领域中基础模型的动态性。"}]},{"ID":"20250926170114-aa4a3sd","Type":"NodeParagraph","Properties":{"id":"20250926170114-aa4a3sd","updated":"20250926170117"},"Children":[{"Type":"NodeText","Data":"最近，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分割一切模型（SAM, Segment Anything Model）"},{"Type":"NodeText","Data":" 在解决下游任务方面带来了新趋势。带有提示工程模块的模型可以通过提示解决广泛的下游任务。这些模型卓越的零样本泛化能力凸显了提示工程在下游任务中的重要性。然而，将大型视觉模型（LVM）应用于特定任务需要一种有效的方法来指导模型的学习和推理过程。这正是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示工程"},{"Type":"NodeText","Data":"发挥作用的地方。它是一种设计和优化视觉提示的方法，用以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"引导大型模型"},{"Type":"NodeText","Data":"生成期望的输出。"}]},{"ID":"20250926170114-wewgxuu","Type":"NodeParagraph","Properties":{"id":"20250926170114-wewgxuu","updated":"20250926170117"},"Children":[{"Type":"NodeText","Data":"基础模型的出现为人工智能系统的进步释放了巨大潜力，尤其是在计算机视觉领域。视觉提示工程作为一个自适应接口和多功能工具包，与大型视觉模型无缝集成。通过将大型视觉模型的能力与视觉提示工程的巧思协同融合，我们能够充分利用基础模型的全部潜力，从而在图像分析和任务解决领域实现前所未有的灵活性和效率。这一开创性的集成为探索人工智能应用的广阔前沿铺平了道路，揭示了众多前景，并带来了前所未有的机遇。"}]},{"ID":"20250926170114-xe40fn8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170114-xe40fn8","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1.1. 综述的范围与焦点"}]},{"ID":"20250926170114-03j6ys1","Type":"NodeParagraph","Properties":{"id":"20250926170114-03j6ys1","updated":"20250926170117"},"Children":[{"Type":"NodeText","Data":"为了更好地探索提示工程如何利用计算机视觉领域的基础模型，我们通过在arXiv上使用关键词“visual prompt”进行爬取，收集了一系列相关文献。如图1所示，随后使用ChatGPT过滤掉了与计算机视觉无关的文章，最终筛选出500篇论文。我们的研究"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以计算机视觉相关的提示工程算法为中心"},{"Type":"NodeText","Data":"，涵盖了从多模态视觉-语言模型到视觉模型和通用人工智能（AGI）模型的广泛范围。我们深入探讨了视觉提示工程如何专门为下游任务定制模型以获得最佳性能。提示的本质是多样的，包括多模态场景中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本提示"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像提示"},{"Type":"NodeText","Data":"以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图文组合提示"},{"Type":"NodeText","Data":"，每种提示都针对不同任务具有独特的特性。本文全面回顾了计算机视觉中的视觉提示工程，提供了跨越多维度（如多模态、图像和图文提示设计）的见解，并根据特定任务需求进行定制。其目标是突出计算机视觉中视觉提示工程的进展和现状，以期激励该领域的持续探索和研究。"}]},{"ID":"20250926170114-at33ix8","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170114-at33ix8","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"1.2. 综述大纲"}]},{"ID":"20250926170114-1r9la89","Type":"NodeParagraph","Properties":{"id":"20250926170114-1r9la89","updated":"20250926170117"},"Children":[{"Type":"NodeText","Data":"本篇综合性综述科学地概述了计算机视觉提示领域的最新进展，并总结了该领域现有的设计方法。综述的结构如下："}]},{"ID":"20250926170114-ohz320c","Type":"NodeParagraph","Properties":{"id":"20250926170114-ohz320c","updated":"20250926170117"},"Children":[{"Type":"NodeText","Data":"在引言部分，我们追溯了基础AI模型从Transformer架构诞生到大型视觉模型发展的演变过程，重点阐述了这些模型在规模和复杂性上的增长如何催生了提示（包括视觉提示）的创新性使用。"}]},{"ID":"20250926170114-uor8dgr","Type":"NodeParagraph","Properties":{"id":"20250926170114-uor8dgr","updated":"20250926170117"},"Children":[{"Type":"NodeText","Data":"第2节概述了对视觉提示和通用人工智能（AGI）发展做出重大贡献的关键模型，包括Transformer、CLIP、视觉提示微调（VPT）和SAM。这些有影响力的模型是理解后续关于提示学习及其在AGI中应用的讨论的基础参考。"}]},{"ID":"20250926170114-r6ni34k","Type":"NodeParagraph","Properties":{"id":"20250926170114-r6ni34k","updated":"20250926170117"},"Children":[{"Type":"NodeText","Data":"\u003cimg src=\"https://storage.googleapis.com/assistly-public/images/2ea24e4d-045a-4b08-963e-63f82a178e2d.png\" alt=\"Meta-Radiology 1 (2023) 100047-2.png\" /\u003e"}]},{"ID":"20250926170114-hdmc324","Type":"NodeParagraph","Properties":{"id":"20250926170114-hdmc324","updated":"20250926170117"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图1. 该图表用于描绘2022年至2023年6月23日期间，计算机视觉领域关于视觉提示工程的研究论文发表数量"},{"Type":"NodeText","Data":"，揭示了该领域随时间发展的趋势和增长情况。该图展示了三个不同的图：月度提交数量、按日期累计的提交数量和年度提交数量。"}]},{"ID":"20250926170114-ncizepf","Type":"NodeBlockquote","Properties":{"id":"20250926170114-ncizepf","updated":"20250926170117"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170114-3vb2cb3","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170114-3vb2cb3","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250926170114-jwqv5wx","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170114-jwqv5wx","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图1：视觉提示工程领域的研究热度"}]},{"ID":"20250926170114-2csv8fk","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170114-2csv8fk","updated":"20250926170114"},"Children":[{"ID":"20250926170114-ram9weq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170114-ram9weq","updated":"20250926170114"},"Children":[{"ID":"20250926170114-85pz35c","Type":"NodeParagraph","Properties":{"id":"20250926170114-85pz35c","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据解读"},{"Type":"NodeText","Data":": 这组图表直观地展示了“视觉提示工程”这一研究方向的热度变化。"}]},{"ID":"20250926170114-16pg4fr","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170114-16pg4fr","updated":"20250926170114"},"Children":[{"ID":"20250926170114-sva5zwk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170114-sva5zwk","updated":"20250926170114"},"Children":[{"ID":"20250926170114-15vtcnx","Type":"NodeParagraph","Properties":{"id":"20250926170114-15vtcnx","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"月度提交量 (左图)"},{"Type":"NodeText","Data":": 2022年提交量相对平稳，但从2023年初开始出现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"爆炸式增长"},{"Type":"NodeText","Data":"，在2023年5月达到顶峰（121篇）。"}]}]},{"ID":"20250926170114-qaghy4e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170114-qaghy4e","updated":"20250926170114"},"Children":[{"ID":"20250926170114-0mhgbnv","Type":"NodeParagraph","Properties":{"id":"20250926170114-0mhgbnv","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"累计提交量 (中图)"},{"Type":"NodeText","Data":": 累计曲线在2023年变得"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"异常陡峭"},{"Type":"NodeText","Data":"，表明论文数量在短期内迅速增加。"}]}]},{"ID":"20250926170114-nztoynf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170114-nztoynf","updated":"20250926170114"},"Children":[{"ID":"20250926170114-qxrbkj2","Type":"NodeParagraph","Properties":{"id":"20250926170114-qxrbkj2","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"年度总提交量 (右图)"},{"Type":"NodeText","Data":": 仅2023年上半年（截至6月）的论文数（391篇）就已经是2022年全年（112篇）的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"三倍多"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250926170114-5keac26","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170114-5keac26","updated":"20250926170114"},"Children":[{"ID":"20250926170114-8mwi3es","Type":"NodeParagraph","Properties":{"id":"20250926170114-8mwi3es","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心结论"},{"Type":"NodeText","Data":": 这些数据强有力地证明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示工程是一个新兴且迅速发展的热点研究领域"},{"Type":"NodeText","Data":"。这不仅验证了作者撰写这篇综述的必要性和及时性，也预示着该领域在未来将有更多的技术突破和应用落地。这种增长趋势很可能与SAM等重量级模型的发布密切相关。"}]}]}]}]},{"ID":"20250926170114-2oa9p9p","Type":"NodeBlockquote","Properties":{"id":"20250926170114-2oa9p9p","updated":"20250926170114"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170114-l2haryn","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170114-l2haryn","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析 (第一部分：引言与背景)"}]},{"ID":"20250926170114-4avt22k","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926170114-4avt22k","updated":"20250926170114"},"Children":[{"ID":"20250926170114-51iu074","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926170114-51iu074","updated":"20250926170114"},"Children":[{"ID":"20250926170114-73vcqi0","Type":"NodeParagraph","Properties":{"id":"20250926170114-73vcqi0","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"技术的演进脉络"},{"Type":"NodeText","Data":": 本部分清晰地勾勒出一条技术发展路线：从奠定基础的 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Transformer 架构"},{"Type":"NodeText","Data":" -\u003e 引发范式革命的 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型语言模型 (LLMs)"},{"Type":"NodeText","Data":" -\u003e 将成功经验迁移至视觉领域的 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"大型视觉模型 (LVMs)"},{"Type":"NodeText","Data":"。这条脉络解释了为什么“提示工程”这一原本在NLP领域兴起的概念，会成为当前计算机视觉领域的研究焦点。"}]}]},{"ID":"20250926170114-9vop5f1","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926170114-9vop5f1","updated":"20250926170114"},"Children":[{"ID":"20250926170114-q4svc6k","Type":"NodeParagraph","Properties":{"id":"20250926170114-q4svc6k","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心概念的引入"},{"Type":"NodeText","Data":": 文章引入并解释了几个关键概念。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本泛化"},{"Type":"NodeText","Data":"指模型无需针对性训练即可完成新任务的能力，这是大型模型的终极目标之一。而"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示工程"},{"Type":"NodeText","Data":"则是实现这一目标的关键“钥匙”，它通过设计巧妙的“提示”（prompts），来引导和控制一个通用的、预训练好的大模型去解决具体问题。"}]}]},{"ID":"20250926170114-5i6ew1l","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926170114-5i6ew1l","updated":"20250926170114"},"Children":[{"ID":"20250926170114-hrft3ym","Type":"NodeParagraph","Properties":{"id":"20250926170114-hrft3ym","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"里程碑模型的提及"},{"Type":"NodeText","Data":": 文章提到了几个关键模型，如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CLIP"},{"Type":"NodeText","Data":"（连接了文本与视觉，是多模态提示的基石）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAM"},{"Type":"NodeText","Data":"（分割一切模型，是提示工程在视觉领域成功应用的典范），这些模型是后文详细论述的基础。"}]}]},{"ID":"20250926170114-wcj2ade","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250926170114-wcj2ade","updated":"20250926170114"},"Children":[{"ID":"20250926170114-hvqhn8j","Type":"NodeParagraph","Properties":{"id":"20250926170114-hvqhn8j","updated":"20250926170114"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"研究的必要性与依据"},{"Type":"NodeText","Data":": 通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图1"},{"Type":"NodeText","Data":"的文献计量分析，作者用数据雄辩地证明了该领域正处于一个“爆发期”，研究热度急剧升温。这不仅为本篇综述的撰写提供了充分的理由，也让读者直观地感受到了这一技术浪潮的迅猛势头。"}]}]}]},{"ID":"20250926170114-8jknlfd","Type":"NodeParagraph","Properties":{"id":"20250926170114-8jknlfd","updated":"20250926170114"},"Children":[{"Type":"NodeText","Data":"总体而言，引言部分成功地为读者构建了该领域的宏观图景，阐明了其历史渊源、核心理念、关键技术和发展趋势，为后续深入技术细节的探讨做好了充分的铺垫。"}]}]},{"ID":"20250926170342-m48aojs","Type":"NodeParagraph","Properties":{"id":"20250926170342-m48aojs","updated":"20250926170342"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。"}]},{"ID":"20250926170342-gfbqoga","Type":"NodeParagraph","Properties":{"id":"20250926170342-gfbqoga","updated":"20250926170342"},"Children":[{"Type":"NodeText","Data":"第2.3节深入探讨"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示学习"},{"Type":"NodeText","Data":"，重点关注多模\n态提示和视觉提示微调。本节探索了专为多模态提示设计的不同模型及其变体，突出了该领域的不同方法和应用。此外，本节还讨论了能够有效微调视觉提示以增强特定任务或领域性能的模型及其变体，强调了为不同应用选择合适提示模态的重要性，例如在医学图像分割中使用边界框提示和在自然图像理解中使用文本提示。"}]},{"ID":"20250926170342-ip0mnde","Type":"NodeParagraph","Properties":{"id":"20250926170342-ip0mnde","updated":"20250926170342"},"Children":[{"Type":"NodeText","Data":"第2.5节关注"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示在通用人工智能（AGI）模型中的应用"},{"Type":"NodeText","Data":"，重点介绍了提示在AGI架构中的集成，并展示了它们对强大泛化性能的贡献。本节介绍了AGI模型视觉提示的最新进展，阐述了恰当的提示设计如何能够在不同领域和任务中提升性能。"}]},{"ID":"20250926170342-pifrznr","Type":"NodeParagraph","Properties":{"id":"20250926170342-pifrznr","updated":"20250926170342"},"Children":[{"Type":"NodeText","Data":"第3节探讨了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示研究的未来方向和影响"},{"Type":"NodeText","Data":"。我们讨论了该领域的潜在发展，考虑了AGI及相关领域的进步。除了进步之外，本节还探讨了与视觉提示技术相关的挑战和机遇，并对其更广泛的影响和潜在冲击提供了见解。"}]},{"ID":"20250926170342-1198v7v","Type":"NodeParagraph","Properties":{"id":"20250926170342-1198v7v","updated":"20250926170342"},"Children":[{"Type":"NodeText","Data":"结论部分对整个综述讨论的要点进行了总结。强调了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示在AGI中的关键作用"},{"Type":"NodeText","Data":"，以及它们在提升性能和泛化能力方面的潜力。重申了提示设计和不同模态对不同应用的重要性，并突出了该领域未来的研究前景。结论部分简明扼要地概括了视觉提示的重要性及其对AGI的影响，作为结束语，让读者对视觉提示的重要性有一个清晰的理解。"}]},{"ID":"20250926170342-46zp3ms","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170342-46zp3ms","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2. 材料与方法"}]},{"ID":"20250926170342-02nmvsc","Type":"NodeParagraph","Properties":{"id":"20250926170342-02nmvsc","updated":"20250926170343"},"Children":[{"Type":"NodeText","Data":"在本节中，我们将介绍一些基本概念，首先阐明"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程"},{"Type":"NodeText","Data":"，然后概述计算机视觉领域的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础模型"},{"Type":"NodeText","Data":"。在这篇综合性综述中，我们的主要焦点将是与大型视觉模型相关的提示工程的关键技术和重要方法。"}]},{"ID":"20250926170342-ohpjdo6","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170342-ohpjdo6","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.1. 自然语言处理中的提示"}]},{"ID":"20250926170342-qhr6b1t","Type":"NodeParagraph","Properties":{"id":"20250926170342-qhr6b1t","updated":"20250926170343"},"Children":[{"Type":"NodeText","Data":"在NLP领域，为了实现对预训练模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效微调"},{"Type":"NodeText","Data":"，研究人员提出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于提示的方法"},{"Type":"NodeText","Data":"，通过在输入中加入额外的上下文来实现。由于基于提示的方法能够弥合预训练和下游任务之间的差距，并释放预训练模型的潜力，它们在各种NLP任务中展现了显著的优势。根据提示在文本中的位置，提示可以分为两种形式。第一种是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"完形填空式提示（cloze prompt）"},{"Type":"NodeText","Data":"，它存在于文本的中间；另一种是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前缀式提示（prefix prompt）"},{"Type":"NodeText","Data":"，通常附加在文本的末尾。大多数早期的工作通过手动定义或自动学习来设计所需的提示。创建提示最简单的方式是根据与下游任务相关的常识"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"手动定义"},{"Type":"NodeText","Data":"。例如，Brown等人为包括机器翻译和问答在内的多个下游NLP任务手动定义了特定的提示。Schick等人利用预定义的提示来促进少样本（few-shot）文本分类和生成任务。尽管手动构建提示简单直观，但它们依赖于针对不同任务的复杂策略，并且需要大量的专业经验，这既昂贵又低效。此外，预先设计的提示通常不是最优的，并且不能很好地自适应地应对许多困难的任务。为了产生更高效的提示模板，许多研究提出通过稀疏监督"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动学习"},{"Type":"NodeText","Data":"最优提示，这可以分为两类："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"离散提示（discrete prompts）"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连续提示（continuous prompts）"},{"Type":"NodeText","Data":"。作为自然的文本上下文，离散提示是在预定义的离散空间中自动搜索与相应短语相关的提示。例如，Jiang等人提出了MINE，一种基于挖掘的方法，通过训练输入和输出来自动寻找提示。Wallace等人设计了一种基于梯度的搜索方法，利用输入词元（token）来寻找与预训练模型相关的短文本，以迭代的方式生成期望的预测。Gao等人将搜索提示视为一个序列到序列（seq2seq）的生成任务，并利用一个seq2seq预训练模型来进行提示搜索过程。与将提示限制在离散空间的自然语言中不同，其他工作旨在在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连续的文本嵌入空间"},{"Type":"NodeText","Data":"中自动构建所需的提示，这放宽了搜索范围，并且可以通过可学习的参数，根据下游数据集进行自适应优化。例如，Li等人将一个连续的任务特定序列前置到输入中，并保持预训练模型冻结。Lester等人用特殊的词元前置输入以构建提示，并显式地调整这些词元的嵌入。"}]},{"ID":"20250926170342-qsepj2w","Type":"NodeParagraph","Properties":{"id":"20250926170342-qsepj2w","updated":"20250926170343"},"Children":[{"Type":"NodeText","Data":"通过提示，可以缩小预训练任务和各种下游任务之间的差距，性能可以得到有效提升，有可能达到完整参数微调的水平。这表明，一个合适的参数初始化对于下游NLP任务可能大有裨益。"}]},{"ID":"20250926170342-1bwv05v","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170342-1bwv05v","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.2. 基础模型"}]},{"ID":"20250926170342-0wcw5bm","Type":"NodeParagraph","Properties":{"id":"20250926170342-0wcw5bm","updated":"20250926170343"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.2.1. Transformer架构"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926170342-v4d3hyy","Type":"NodeParagraph","Properties":{"id":"20250926170342-v4d3hyy","updated":"20250926170343"},"Children":[{"Type":"NodeText","Data":"随着大型模型的逐步发展，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Transformer架构"},{"Type":"NodeText","Data":"已成为一个名副其实的基础模型，预示着该领域一个新时代的到来。Transformer最初是为NLP中的翻译任务提出的，它结合了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多头自注意力机制（Multi-head Self Attention, MSA）"},{"Type":"NodeText","Data":" 和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"前馈网络（Feed-forward Networks, FFN）"},{"Type":"NodeText","Data":"，以提供全局的感知域和多通道的特征提取能力。随后基于Transformer的BERT的发展在NLP中被证明是开创性的，在多种语言相关任务上表现出卓越的性能。利用Transformer巨大的灵活性和可扩展性，研究人员已经开始训练更大的Transformer模型，包括GPT-1、GPT-2、GPT-3、GPT-4、T5、PaLM、LLaMA等。这些模型进一步提升了基于Transformer架构的性能和泛化能力，在某些任务上超越了人类水平，并且在提高训练效率方面仍有进一步发展的潜力。与此同时，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉Transformer（ViT, Vision Transformer）"},{"Type":"NodeText","Data":" 将Transformer架构的应用扩展到了计算机视觉领域，弥合了Transformer模型在文本和图像领域之间的差距，并验证了其作为统一架构的可行性。随后，计算机视觉领域的努力开始改进和扩展ViT模型，例如DeiT、Swin Transformer、TNT、MAE、MoCo-v3、BeiT等。这些工作已成功将ViT应用于各种视觉相关任务，并取得了出色的性能。"}]},{"ID":"20250926170342-kpt610s","Type":"NodeParagraph","Properties":{"id":"20250926170342-kpt610s","updated":"20250926170343"},"Children":[{"Type":"NodeText","Data":"在Transformer架构中，最小的特征单元是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"词元（token）"},{"Type":"NodeText","Data":"。Transformer的这一内在特性使其非常适合处理"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态数据"},{"Type":"NodeText","Data":"，因为嵌入层可以将任何模态转换为词元。因此，多模态领域的众多工作，如ViLT、DALL-E、CLIP、VLMO、ALBEF等，都采用Transformer作为多模态数据交互的主要框架，包括文本到图像和图像到文本的检索、图像描述生成和图像/文本生成等。随着大型模型时代的到来，研究人员已经提出了大型多模态模型，如CoCa、Flamingo、BEiT-v3、PALI、GPT-4，旨在进一步提升在各种下游任务上的性能。总之，作为一种基础模型，Transformer在当今的研究领域中继续占据主导地位。"}]},{"ID":"20250926170342-i6unel8","Type":"NodeBlockquote","Properties":{"id":"20250926170342-i6unel8","updated":"20250926170343"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170342-hcm5kha","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170342-hcm5kha","updated":"20250926170342"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析 (第二部分：核心概念与基础模型)"}]},{"ID":"20250926170342-bxyzt9t","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926170342-bxyzt9t","updated":"20250926170342"},"Children":[{"ID":"20250926170342-wxc0bgw","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926170342-wxc0bgw","updated":"20250926170342"},"Children":[{"ID":"20250926170342-6l7qv1n","Type":"NodeParagraph","Properties":{"id":"20250926170342-6l7qv1n","updated":"20250926170342"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的起源与演进"},{"Type":"NodeText","Data":": 这一部分首先追溯了“提示”这一概念在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然语言处理 (NLP)"},{"Type":"NodeText","Data":" 领域的起源。它清晰地解释了提示从"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"手动设计"},{"Type":"NodeText","Data":"（依赖专家经验、耗时耗力）到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自动学习"},{"Type":"NodeText","Data":"的演进过程。自动学习又进一步细分为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"离散提示"},{"Type":"NodeText","Data":"（在真实词汇中搜索）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连续提示"},{"Type":"NodeText","Data":"（在向量空间中学习“伪词”），后者因其灵活性和优化效率而成为主流。这个演进过程揭示了学术界不断追求更高效、更自适应模型微调方法的趋势。"}]}]},{"ID":"20250926170342-6z2pec2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926170342-6z2pec2","updated":"20250926170342"},"Children":[{"ID":"20250926170342-tin1qbx","Type":"NodeParagraph","Properties":{"id":"20250926170342-tin1qbx","updated":"20250926170342"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心技术：参数高效微调"},{"Type":"NodeText","Data":": 整个2.1节的核心思想是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数高效微调 (Parameter-Efficient Fine-Tuning)"},{"Type":"NodeText","Data":"。与传统的微调需要更新模型所有（数亿甚至数十亿）参数不同，提示工程通过冻结主干网络，仅调整少量（几千到几万）的提示参数，就能使模型适应新任务。这极大地降低了训练成本和存储需求，是大型模型时代能够被广泛应用的关键。"}]}]},{"ID":"20250926170342-lajjoe9","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926170342-lajjoe9","updated":"20250926170342"},"Children":[{"ID":"20250926170342-454m4k9","Type":"NodeParagraph","Properties":{"id":"20250926170342-454m4k9","updated":"20250926170342"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奠基石：Transformer 架构"},{"Type":"NodeText","Data":": 2.2.1节强调了 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Transformer"},{"Type":"NodeText","Data":" 作为这一切的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通用语言”和“基础底座”"},{"Type":"NodeText","Data":" 的核心地位。它不仅统一了NLP（以BERT、GPT系列为代表），也统一了计算机视觉（以ViT为代表）。更重要的是，其基于“词元 (token)”的处理方式，天然地为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态（如CLIP）"},{"Type":"NodeText","Data":" 信息的融合提供了可能。没有Transformer，就没有今天的大模型生态。"}]}]},{"ID":"20250926170342-gb9z1nk","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250926170342-gb9z1nk","updated":"20250926170342"},"Children":[{"ID":"20250926170342-4lxim46","Type":"NodeParagraph","Properties":{"id":"20250926170342-4lxim46","updated":"20250926170342"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型间的传承关系"},{"Type":"NodeText","Data":": 这一部分也隐晦地展示了模型之间的“继承”和“发展”关系。从NLP领域的BERT/GPT -\u003e 视觉领域的ViT -\u003e 多模态领域的CLIP/Flamingo，我们可以看到一个清晰的技术迁移路径。这种跨领域的思想借鉴和模型演进，是推动AI快速发展的强大动力。"}]}]}]},{"ID":"20250926170342-y34ftfm","Type":"NodeParagraph","Properties":{"id":"20250926170342-y34ftfm","updated":"20250926170342"},"Children":[{"Type":"NodeText","Data":"总结来说，这一部分为读者构建了理解后续内容所必需的知识框架。它解释了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“什么是提示”"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“提示如何演变”"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“为什么要用提示”"},{"Type":"NodeText","Data":"，以及支撑这一切的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“底层技术是什么”"},{"Type":"NodeText","Data":"。通过对NLP提示工程和Transformer架构的介绍，为下文深入探讨更复杂的“视觉”提示工程做好了充分的理论铺垫。"}]}]},{"ID":"20250926170449-vxpsbl1","Type":"NodeParagraph","Properties":{"id":"20250926170449-vxpsbl1","updated":"20250926170449"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。"}]},{"ID":"20250926170449-tqtcywz","Type":"NodeParagraph","Properties":{"id":"20250926170449-tqtcywz","updated":"20250926170449"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.2.2. CLIP及其变体"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926170449-qbropyv","Type":"NodeParagraph","Properties":{"id":"20250926170449-qbropyv","updated":"20250926170449"},"Children":[{"Type":"NodeText","Data":"OpenAI发布了一款开创性的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉-语言模型"},{"Type":"NodeText","Data":"，它利用图像和文本之间的关联进行弱监督预训练，通过扩大可用数据显著提升了性能。这项名为CLIP（Contrastive Language-Image Pre-Training）的工作，收集了一个包含"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4亿个图文对"},{"Type":"NodeText","Data":"的海量数据集进行训练。CLIP利用人类设计的固定提示，实现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本预测"},{"Type":"NodeText","Data":"，并展现出超越其他SOTA（state-of-the-art）模型的优越的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本能力"},{"Type":"NodeText","Data":"。CLIP的成功突显了结合视觉和文本信息的力量，并强调了使用大规模数据进行弱监督训练的有效性。CLIP的成就标志着在理解和应用多模态技术方面可能取得的突破，展示了其捕捉丰富特征表示的能力。例如Group ViT、ViLD、Glip、Clipasso、Clip4clip、ActionCLIP等等。它为计算机视觉领域的提示工程进展提供了新的见解，为未来的发展开辟了充满希望的途径。"}]},{"ID":"20250926170449-o48l18j","Type":"NodeParagraph","Properties":{"id":"20250926170449-o48l18j","updated":"20250926170449"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.2.3. 视觉提示微调 (Visual Prompt Tuning)"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926170449-vrwv29w","Type":"NodeParagraph","Properties":{"id":"20250926170449-vrwv29w","updated":"20250926170449"},"Children":[{"Type":"NodeText","Data":"当将大型视觉模型（LVMs）应用于下游任务时，通常首选修改输入而不是改变预训练模型的参数。这种方法涉及在输入空间中引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少量任务特定的可学习参数"},{"Type":"NodeText","Data":"，从而允许学习任务特定的连续向量。这种技术被称为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示微调"},{"Type":"NodeText","Data":"，它能够在不修改预训练模型底层参数的情况下，实现对其进行高效微调。VPT方法是第一个提出并研究视觉提示普适性和可行性的工作。所提出的VPT方法包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深层和浅层"},{"Type":"NodeText","Data":"两个版本，通过学习输入数据的提示和类别头（class head），同时保持预训练Transformer模型的参数固定，取得了令人印象ه 的结果。这项工作主要旨在展示视觉提示的有效性，并提供了一种新颖的提示设计视角。通过证明仅修改输入即可获得满意的结果，VPT展示了提示微调作为下游任务高效策略的潜力，并为提示工程研究开辟了新途径。"}]},{"ID":"20250926170449-sg9ao8v","Type":"NodeParagraph","Properties":{"id":"20250926170449-sg9ao8v","updated":"20250926170449"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.2.4. 分割一切模型 (Segment Anything Model)"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926170449-z688m9d","Type":"NodeParagraph","Properties":{"id":"20250926170449-z688m9d","updated":"20250926170449"},"Children":[{"Type":"NodeText","Data":"2023年，Meta AI发布了一个旨在创建"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通用图像分割模型"},{"Type":"NodeText","Data":"的项目，该模型能够通过提示工程处理广泛的下游分割任务，并适应新数据。为了实现这一目标，他们创建了SAM。SAM利用提示工程来处理通用的下游分割任务，方法是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将提示分割任务作为预训练目标"},{"Type":"NodeText","Data":"。为了增强模型适应提示的灵活性并提高其抗干扰的鲁棒性，SAM被分为三个部分："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像编码器（image encoder）"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示编码器（prompt encoder）"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"掩码解码器（mask decoder）"},{"Type":"NodeText","Data":"。这种划分有效地分配了计算成本，从而产生了一个足够适应性强且功能多样的分割模型。SAM的优势在于其能够高效地泛化到不同的分割任务，这得益于其提示工程方法。这种在提示分割上进行预训练并在特定下游任务上进行微调的方法，帮助SAM利用从提示分割任务中学到的知识，来提升在广泛分割问题上的性能，包括"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"医学图像分析"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视频对象跟踪"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据标注"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3D重建"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"机器人技术"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像编辑"},{"Type":"NodeText","Data":"等等。此外，SAM的模块化设计使其能够灵活地适应不同的提示格式，使其成为适用于各种分割挑战的多功能解决方案。"}]},{"ID":"20250926170449-28bnwgh","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170449-28bnwgh","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.3. 预训练模型中的视觉提示"}]},{"ID":"20250926170449-iovwbvz","Type":"NodeParagraph","Properties":{"id":"20250926170449-iovwbvz","updated":"20250926170451"},"Children":[{"Type":"NodeText","Data":"本章将探讨两个主要领域：基于视觉-语言预训练模型的提示工程方法和基于视觉预训练模型的提示工程方法。"}]},{"ID":"20250926170449-0tfpjhc","Type":"NodeParagraph","Properties":{"id":"20250926170449-0tfpjhc","updated":"20250926170527"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.3.1. 视觉-语言模型中的提示工程"}]},{"ID":"20250926170449-klncyue","Type":"NodeParagraph","Properties":{"id":"20250926170449-klncyue","updated":"20250926170451"},"Children":[{"Type":"NodeText","Data":"通过自然语言监督来学习计算机视觉任务的概念，在近期的研究中获得了极大的关注。在本节中，我们讨论了几项与基于图文的计算机视觉相关的工作。值得注意的是，基于CLIP的视觉-语言模型，它利用大规模数据集上的自然语言监督来训练图像模型，展示了一种引人入胜的方法。该模型在预训练阶段就能熟练执行广泛的任务，这表明了一种可扩展的下游任务处理方法。它不仅在某些情况下实现了零样本结果，还通过提示工程支持特定任务，从而增强了其在目标应用中的适用性。"}]},{"ID":"20250926170449-g2dafjj","Type":"NodeParagraph","Properties":{"id":"20250926170449-g2dafjj","updated":"20250926170451"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.3.1.1. 上下文优化 (Context Optimization, CoOp)"}]},{"ID":"20250926170449-65l38w0","Type":"NodeParagraph","Properties":{"id":"20250926170449-65l38w0","updated":"20250926170451"},"Children":[{"Type":"NodeText","Data":"CoOp发现，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"手动设计的提示"},{"Type":"NodeText","Data":"显著影响CLIP中的预测。为了提升模型在下游任务中的性能，研究者提出了两种方法："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"统一上下文（unified context）"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"类别特定上下文（class-specific context）"},{"Type":"NodeText","Data":"。这两种策略都用一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可学习的文本输入"},{"Type":"NodeText","Data":"替换了原始的、手动设置的文本编码器输入，这个可学习的输入通过使用来自下游任务样本的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少样本学习"},{"Type":"NodeText","Data":"方法进行演化。关键区别在于可学习上下文的适应性：在统一上下文方法中，它在不同类别间保持一致；而在类别特定上下文方法中，每个类别都有其独特的可学习上下文。这些方法的有效性已在多个下游任务中得到验证。"}]},{"ID":"20250926170449-sjgqzvb","Type":"NodeParagraph","Properties":{"id":"20250926170449-sjgqzvb","updated":"20250926170451"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.3.1.2. 条件上下文优化 (Conditional Context Optimization, CoCoOp)"}]},{"ID":"20250926170449-eym1r8b","Type":"NodeParagraph","Properties":{"id":"20250926170449-eym1r8b","updated":"20250926170451"},"Children":[{"Type":"NodeText","Data":"有效地使预训练模型适应下游任务是一个关键挑战。CoOp方法自动化了提示过程，仅用少量标记图像就显示出显著的性能提升。然而，该方法倾向于在训练期间对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基类（base classes）"},{"Type":"NodeText","Data":" 产生"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"过拟合"},{"Type":"NodeText","Data":"。这种过拟合构成了一个严重问题：它损害了模型泛化到同一数据集中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"未见类别（unseen classes）"},{"Type":"NodeText","Data":" 的能力。为了解决这个问题，作者引入了一个轻量级的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"元网络（Meta-Net）"},{"Type":"NodeText","Data":"，它利用图像编码器的输出并将其与可训练的提示相结合。这产生了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动态提示"},{"Type":"NodeText","Data":"，它不仅是一个根据下游任务学习到的自适应连续向量，而且还将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像特征作为条件"},{"Type":"NodeText","Data":"纳入其中。这种动态提示的引入对于实现更好的泛化性能具有重要意义。"}]},{"ID":"20250926170449-u83v9zb","Type":"NodeParagraph","Properties":{"id":"20250926170449-u83v9zb","updated":"20250926170451"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.3.1.3. DenseCLIP框架"}]},{"ID":"20250926170449-q2616aw","Type":"NodeParagraph","Properties":{"id":"20250926170449-q2616aw","updated":"20250926170451"},"Children":[{"Type":"NodeText","Data":"大型预训练模型，特别是那些基于图文对的模型，在各种下游任务中表现出令人印象深刻的适应性。然而，如何有效地将图文先验知识应用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"密集预测任务（dense tasks）"},{"Type":"NodeText","Data":" 仍然是一个具有挑战性的探索领域。DenseCLIP通过将传统的图文匹配问题（如CLIP中所见）转化为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"像素-文本匹配"},{"Type":"NodeText","Data":"的挑战来解决这个问题。其核心创新在于采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉到语言的提示（vision-to-language prompting）"},{"Type":"NodeText","Data":"。这种方法将当前样本的视觉信息引入到一个可学习的上下文中。该方法引导模型通过视觉到语言的交互，更有效地利用预训练知识。实验结果表明，DenseCLIP在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"语义分割"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标检测"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"实例分割"},{"Type":"NodeText","Data":"等任务中取得了领先的性能。"}]},{"ID":"20250926170449-tq112jg","Type":"NodeParagraph","Properties":{"id":"20250926170449-tq112jg","updated":"20250926170451"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.3.1.4. 多模态提示学习 (Multi-modal Prompt Learning, MaPLe)"}]},{"ID":"20250926170449-n7isj9q","Type":"NodeParagraph","Properties":{"id":"20250926170449-n7isj9q","updated":"20250926170451"},"Children":[{"Type":"NodeText","Data":"上述方法都在文本的PROMPT方法上进行了仔细的调整。然而，多模态提示学习（MaPLe）认为，仅使用PROMPT来调整CLIP的单个分支（文本或图像）并不能产生最优结果，因为它无法在下游任务中动态调整两种模态的表示空间。为了解决这个问题，研究者提出了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态提示学习方法"},{"Type":"NodeText","Data":"，它促进了视觉-语言线索的直接、强耦合。该方法通过一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉-语言耦合函数"},{"Type":"NodeText","Data":"，用语言提示来调节视觉提示，从而在两种模态之间引发相互的协同作用。通过在不同的转换阶段明确地用文本提示来调节视觉提示，该方法确保了视觉-语言模态之间的协同作用。它提升了对新类别、跨数据集迁移以及在领域漂移数据集上的性能和泛化能力。"}]},{"ID":"20250926170449-sj2m09t","Type":"NodeBlockquote","Properties":{"id":"20250926170449-sj2m09t","updated":"20250926170451"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170449-0bxhmbl","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170449-0bxhmbl","updated":"20250926170449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析 (第二部分 2.2.2 - 2.3.1.4)"}]},{"ID":"20250926170449-0rr3jv1","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926170449-0rr3jv1","updated":"20250926170449"},"Children":[{"ID":"20250926170449-xtjonmw","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926170449-xtjonmw","updated":"20250926170449"},"Children":[{"ID":"20250926170449-zmn8hlf","Type":"NodeParagraph","Properties":{"id":"20250926170449-zmn8hlf","updated":"20250926170449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"奠基性模型的核心思想"},{"Type":"NodeText","Data":": 这一部分首先介绍了三个里程碑式的模型，它们代表了视觉提示工程发展的不同技术路径。"}]},{"ID":"20250926170449-q5wpaic","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170449-q5wpaic","updated":"20250926170449"},"Children":[{"ID":"20250926170449-cif4fxi","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170449-cif4fxi","updated":"20250926170449"},"Children":[{"ID":"20250926170449-60zrzb7","Type":"NodeParagraph","Properties":{"id":"20250926170449-60zrzb7","updated":"20250926170449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CLIP (多模态的桥梁)"},{"Type":"NodeText","Data":": 它的核心贡献在于通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比学习"},{"Type":"NodeText","Data":"，在一个巨大的图文对数据集上，将图像和文本"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"映射到同一个特征空间"},{"Type":"NodeText","Data":"。这使得我们可以用文本（即“提示”）来理解和检索图像，是所有视觉-语言提示方法的基础。"}]}]},{"ID":"20250926170449-drgsl01","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170449-drgsl01","updated":"20250926170449"},"Children":[{"ID":"20250926170449-9pi27dg","Type":"NodeParagraph","Properties":{"id":"20250926170449-9pi27dg","updated":"20250926170449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"VPT (参数高效的典范)"},{"Type":"NodeText","Data":": VPT的核心思想是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“冻结主干，只调提示”"},{"Type":"NodeText","Data":"。它证明了我们不需要微调整个庞大的视觉模型（如ViT），只需在输入端加入并学习一些微小的、连续的“提示”向量，就能高效地使模型适应新任务。这是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纯视觉提示"},{"Type":"NodeText","Data":"的开山之作。"}]}]},{"ID":"20250926170449-bcpttij","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170449-bcpttij","updated":"20250926170449"},"Children":[{"ID":"20250926170449-cog0znl","Type":"NodeParagraph","Properties":{"id":"20250926170449-cog0znl","updated":"20250926170449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAM (提示工程的集大成者)"},{"Type":"NodeText","Data":": SAM的革命性在于它"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"将“提示”作为模型的核心交互方式"},{"Type":"NodeText","Data":"。它通过一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示编码器"},{"Type":"NodeText","Data":"来理解各种提示（点、框、文本等），并结合强大的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像编码器"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"掩码解码器"},{"Type":"NodeText","Data":"来完成分割任务。它不仅是一个模型，更是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“提示驱动”的视觉交互新范式"},{"Type":"NodeText","Data":"，展示了提示工程在通用模型上的巨大潜力。"}]}]}]}]},{"ID":"20250926170449-77dolzo","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926170449-77dolzo","updated":"20250926170449"},"Children":[{"ID":"20250926170449-a1k21q8","Type":"NodeParagraph","Properties":{"id":"20250926170449-a1k21q8","updated":"20250926170449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉-语言提示的演进"},{"Type":"NodeText","Data":": 2.3.1节详细阐述了基于CLIP的提示工程是如何一步步变得更加智能和强大的。"}]},{"ID":"20250926170449-8nfq9by","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170449-8nfq9by","updated":"20250926170449"},"Children":[{"ID":"20250926170449-zl5r8xh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170449-zl5r8xh","updated":"20250926170449"},"Children":[{"ID":"20250926170449-y0ctmud","Type":"NodeParagraph","Properties":{"id":"20250926170449-y0ctmud","updated":"20250926170449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从手工到自动 (CoOp)"},{"Type":"NodeText","Data":": 最初CLIP使用固定的文本模板（如 \"a photo of a [class]\"）。CoOp则提出，这个模板中的上下文部分（\"a photo of a\"）应该是可以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过学习自动优化"},{"Type":"NodeText","Data":"的，从而更好地适应不同任务。"}]}]},{"ID":"20250926170449-37qpce4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170449-37qpce4","updated":"20250926170449"},"Children":[{"ID":"20250926170449-vci5woj","Type":"NodeParagraph","Properties":{"id":"20250926170449-vci5woj","updated":"20250926170449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从静态到动态 (CoCoOp)"},{"Type":"NodeText","Data":": CoOp学习到的提示对于所有图片都是一样的，这容易导致过拟合。CoCoOp则更进一步，认为提示应该是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“因图而异”"},{"Type":"NodeText","Data":" 的。它引入了一个元网络，使得生成的提示能够"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"根据输入图像的内容动态调整"},{"Type":"NodeText","Data":"，从而提升了模型的泛化能力。"}]}]},{"ID":"20250926170449-jda6sze","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170449-jda6sze","updated":"20250926170449"},"Children":[{"ID":"20250926170449-gwjy6p4","Type":"NodeParagraph","Properties":{"id":"20250926170449-gwjy6p4","updated":"20250926170449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从全局到局部 (DenseCLIP)"},{"Type":"NodeText","Data":": CLIP原本做的是图像级别的分类（整张图匹配一个文本）。DenseCLIP则巧妙地将其思想拓展到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"像素级别"},{"Type":"NodeText","Data":"的密集预测任务（如分割、检测）。它通过“像素-文本”匹配和“视觉到语言”的提示，成功地将CLIP的强大能力应用于更精细的视觉任务。"}]}]},{"ID":"20250926170449-h1oiwi7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170449-h1oiwi7","updated":"20250926170449"},"Children":[{"ID":"20250926170449-gtz5ibr","Type":"NodeParagraph","Properties":{"id":"20250926170449-gtz5ibr","updated":"20250926170449"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从单向到双向 (MaPLe)"},{"Type":"NodeText","Data":": 以往的方法大多只在文本端或图像端进行提示学习。MaPLe指出，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本和图像的提示应该相互影响、协同工作"},{"Type":"NodeText","Data":"。它设计了一种耦合机制，让文本提示能够指导视觉提示的生成，实现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"真正的多模态、交互式提示学习"},{"Type":"NodeText","Data":"，进一步提升了性能。"}]}]}]}]}]},{"ID":"20250926170449-e1iaw0s","Type":"NodeParagraph","Properties":{"id":"20250926170449-e1iaw0s","updated":"20250926170449"},"Children":[{"Type":"NodeText","Data":"总结来说，这一部分从奠基模型讲起，清晰地梳理了视觉提示工程的两大主流方向：纯视觉提示（以VPT为代表）和视觉-语言提示（以CLIP及其变体为代表）。特别是对基于CLIP的提示方法的演进过程（CoOp -\u003e CoCoOp -\u003e DenseCLIP -\u003e MaPLe）的描述，层层递进，揭示了该领域从“静态、手工、全局、单向”向“动态、自动、局部、交互”发展的清晰技术脉络。SAM的介绍则预示着提示工程将成为未来通用AI模型的核心交互方式。"}]}]},{"ID":"20250926170647-ju3lvwc","Type":"NodeParagraph","Properties":{"id":"20250926170647-ju3lvwc","updated":"20250926170647"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。"}]},{"ID":"20250926170647-3wvcmvb","Type":"NodeParagraph","Properties":{"id":"20250926170647-3wvcmvb","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.3.1.5. 生成对抗CLIP (Generative Adversarial CLIPs, GALIP)"}]},{"ID":"20250926170647-a23gsr9","Type":"NodeParagraph","Properties":{"id":"20250926170647-a23gsr9","updated":"20250926170647"},"Children":[{"Type":"NodeText","Data":"为了从文本中实现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高保真度的复杂图像合成"},{"Type":"NodeText","Data":"，研究人员提出了生成对抗CLIP（GALIP），以实现高质量、高效、快速且可控的文本到图像合成。具体来说，研究者提出了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于CLIP的判别器"},{"Type":"NodeText","Data":"。CLIP复杂的场景理解能力使判别器能够准确评估图像质量。同时，他们还设计了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"由CLIP赋能的生成器"},{"Type":"NodeText","Data":"，通过桥接特征（bridge features）和提示（cues）从CLIP中引入视觉概念。其中涉及的多模态提示工程思想是，文本和图像数据之间存在巨大差距。为了缓解从文本特征转换桥接特征的困难，研究者设计了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示预测器（cue predictor）"},{"Type":"NodeText","Data":"，通过一个全连接层（FC layer）来预测基于句子和噪声向量的提示。也就是说，预测出的文本条件提示被附加到CLIP-ViT模块中的视觉块嵌入（visual patch embeddings）上。这项工作在一些数据集上取得了显著成果，表明理解模型和生成模型之间可能存在一些共性，这可能为构建通用的大型模型提供启示。"}]},{"ID":"20250926170647-qtk2ei9","Type":"NodeParagraph","Properties":{"id":"20250926170647-qtk2ei9","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.3.1.6. 位置引导的文本提示 (Position-guided Text Prompting, PTP)"}]},{"ID":"20250926170647-10s97uj","Type":"NodeParagraph","Properties":{"id":"20250926170647-10s97uj","updated":"20250926170647"},"Children":[{"Type":"NodeText","Data":"尽管视觉语言训练有潜力在各种跨模态学习任务中表现出色，但人们发现视觉语言处理（VLP）模型缺乏"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉定位/位置感知能力"},{"Type":"NodeText","Data":"，而这对于许多下游任务（如视觉推理）至关重要。因此，研究者提出了位置引导的文本提示（PTP）范式，其目标是在这些端到端模型中缓解位置信息的缺失，同时保持其为下游任务快速推理的能力。其核心思想是，通过向图像和文本中添加"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于位置的共指标记（co-reference markers）"},{"Type":"NodeText","Data":"，视觉基础可以被重新表述为一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"填空问题"},{"Type":"NodeText","Data":"，从而最大限度地减少对物体信息的学习。PTP通过语言表达的两个组成部分构建到图像中："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"区块标记生成（block marker generation）"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本提示生成（text cue generation）"},{"Type":"NodeText","Data":"，这将位置信息引入到预训练中，从而赋予VLP模型强大的视觉基础能力。"}]},{"ID":"20250926170647-1uz0zkd","Type":"NodeParagraph","Properties":{"id":"20250926170647-1uz0zkd","updated":"20250926170647"},"Children":[{"Type":"NodeText","Data":"实验表明，该方法在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"物体位置引导的视觉推理"},{"Type":"NodeText","Data":"以及其他常见的VLP任务（如视觉问答和图像描述）中能取得强大的性能。"}]},{"ID":"20250926170647-8hm9fqw","Type":"NodeParagraph","Properties":{"id":"20250926170647-8hm9fqw","updated":"20250926170647"},"Children":[{"Type":"NodeText","Data":"在本节中，我们讨论了基于视觉语言预训练模型的相关提示工程的建设性方法和思想，从分支提示到个体模态间的交互，不同的方法在各自的领域展示了其优势。其中，CoOp和CoCoOp通过将手动提示调整为自动提示，改进了原始CLIP的文本提示，并在数据集的未见类别上做出了有效的增强。DenseCLIP通过将视觉特征引入上下文提示，为处理密集任务（如语义分割、目标检测和实例分割）提供了新的见解，通过视觉-语言交互实现了性能提升。此外，MaPLe通过动态交互，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"同时对文本和图像两种模态进行提示工程"},{"Type":"NodeText","Data":"，以调整下游任务的两个表示空间，从而实现更有效的泛化性能。与此同时，提示工程也可以作为模型结构的一小部分，以协助模型实现相应的需求，例如在GALIP中引入文本条件提示来补偿文本和图像特征之间的差异。如图2所示，多模态模型的提示设计高度多样化，涵盖了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"手动或自动的文本提示"},{"Type":"NodeText","Data":"、在图像中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"整合可学习的词元"},{"Type":"NodeText","Data":"、引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像特征以补充文本特征"},{"Type":"NodeText","Data":"，以及涉及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本和图像的交互式提示"},{"Type":"NodeText","Data":"。这些方法在通过利用文本和图像的互补性来增强多模态模型的性能方面起着至关重要的作用。提示构建方法的选择应由具体的任务需求来指导，确保模型能有效地从两种模态中捕捉协同信息。随着研究的进展，我们可以期待新的、创新的提示构建方法的出现，为处理多模态任务带来更大的可能性和挑战。"}]},{"ID":"20250926170647-2evrdm9","Type":"NodeParagraph","Properties":{"id":"20250926170647-2evrdm9","updated":"20250926170647"},"Children":[{"Type":"NodeText","Data":"\u003cimg src=\"https-i-imgur-com-j7tfl3y-png\" alt=\"Meta-Radiology 1 (2023) 100047-5.png\" /\u003e"}]},{"ID":"20250926170647-8dm314o","Type":"NodeParagraph","Properties":{"id":"20250926170647-8dm314o","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图2. 该图展示了一个基于CLIP的多模态提示工程框架。"},{"Type":"NodeText","Data":" 该框架的核心思想是将各种形式的提示整合到模型中，这些提示可以是纯文本形式，也可以是可学习的参数。这些提示引导模型生成与给定输入图像和文本相匹配的输出。"}]},{"ID":"20250926170647-i1b0scc","Type":"NodeBlockquote","Properties":{"id":"20250926170647-i1b0scc","updated":"20250926170647"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170647-rh23jyd","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170647-rh23jyd","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250926170647-kvxhxav","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170647-kvxhxav","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图2：多模态提示工程框架示意图"}]},{"ID":"20250926170647-s9fd1xy","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170647-s9fd1xy","updated":"20250926170647"},"Children":[{"ID":"20250926170647-6qt65t7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170647-6qt65t7","updated":"20250926170647"},"Children":[{"ID":"20250926170647-997ghz7","Type":"NodeParagraph","Properties":{"id":"20250926170647-997ghz7","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解分析"},{"Type":"NodeText","Data":": 这张图以CLIP模型为基础，形象地展示了多模态提示工程的几种核心思路。"}]},{"ID":"20250926170647-xqts6g8","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926170647-xqts6g8","updated":"20250926170647"},"Children":[{"ID":"20250926170647-v7bhb4l","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926170647-v7bhb4l","updated":"20250926170647"},"Children":[{"ID":"20250926170647-t41xhj5","Type":"NodeParagraph","Properties":{"id":"20250926170647-t41xhj5","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本侧提示 (上部分)"},{"Type":"NodeText","Data":": 传统的提示工程发生在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本编码器 (Text encoder)"},{"Type":"NodeText","Data":" 的输入端。输入的文本（如 \"A photo of [ ]\"）与可学习的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示 (Prompts)"},{"Type":"NodeText","Data":" 向量结合，送入编码器，最终得到文本特征向量 (y1, y2, ...)。"}]}]},{"ID":"20250926170647-82cqfke","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926170647-82cqfke","updated":"20250926170647"},"Children":[{"ID":"20250926170647-hhfml9w","Type":"NodeParagraph","Properties":{"id":"20250926170647-hhfml9w","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉侧提示 (下部分)"},{"Type":"NodeText","Data":": 与之对应，视觉提示工程发生在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像编码器 (Image encoder)"},{"Type":"NodeText","Data":" 的输入端。输入的图像被切分成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"块嵌入 (Patch embedding)"},{"Type":"NodeText","Data":"，然后与可学习的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示 (Prompts)"},{"Type":"NodeText","Data":" 向量结合，送入编码器，得到图像特征向量 (x1, x2, ...)。"}]}]},{"ID":"20250926170647-ci5swnz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926170647-ci5swnz","updated":"20250926170647"},"Children":[{"ID":"20250926170647-egn1qw1","Type":"NodeParagraph","Properties":{"id":"20250926170647-egn1qw1","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态交互 (中间部分)"},{"Type":"NodeText","Data":": 更高级的提示工程（如MaPLe）不仅在各自的编码器内操作，还在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不同层级 (Layer 1...Layer K) 之间建立了交互"},{"Type":"NodeText","Data":"。图中的箭头示意了文本侧的信息可以影响视觉侧的提示，反之亦然。"}]}]},{"ID":"20250926170647-hd2q1t4","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250926170647-hd2q1t4","updated":"20250926170647"},"Children":[{"ID":"20250926170647-7u9byf5","Type":"NodeParagraph","Properties":{"id":"20250926170647-7u9byf5","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最终目标 (右侧矩阵)"},{"Type":"NodeText","Data":": 无论提示如何设计，最终目标都是让匹配的图文对（如 x1 和 y1）在特征空间中的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相似度最高"},{"Type":"NodeText","Data":"，而与不匹配的图文对（如 x1 和 y2）的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"相似度最低"},{"Type":"NodeText","Data":"。这个矩阵代表了CLIP的核心机制——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"对比学习"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250926170647-j2hlh1j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170647-j2hlh1j","updated":"20250926170647"},"Children":[{"ID":"20250926170647-dyuw956","Type":"NodeParagraph","Properties":{"id":"20250926170647-dyuw956","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心结论"},{"Type":"NodeText","Data":": 这张图高度概括了多模态提示工程的本质："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过在模型的不同位置（文本输入、图像输入、甚至模型中间层）插入可学习的参数（即“提示”），来灵活、高效地引导模型学习特定任务，并最终优化图文特征的对齐效果。"}]}]}]}]},{"ID":"20250926170647-7ta5icp","Type":"NodeBlockquote","Properties":{"id":"20250926170647-7ta5icp","updated":"20250926170647"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170647-te2ljk3","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170647-te2ljk3","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析 (第二部分 2.3.1.5 - 2.3.1.6 及图2)"}]},{"ID":"20250926170647-ns668j7","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926170647-ns668j7","updated":"20250926170647"},"Children":[{"ID":"20250926170647-8f4vy03","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926170647-8f4vy03","updated":"20250926170647"},"Children":[{"ID":"20250926170647-pvd5osk","Type":"NodeParagraph","Properties":{"id":"20250926170647-pvd5osk","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的多样化应用"},{"Type":"NodeText","Data":": 这一部分通过两个具体的案例 (GALIP 和 PTP) 展示了提示工程应用的广度和深度，已经超越了简单的分类任务。"}]},{"ID":"20250926170647-hw531yr","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170647-hw531yr","updated":"20250926170647"},"Children":[{"ID":"20250926170647-xj7hv8y","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170647-xj7hv8y","updated":"20250926170647"},"Children":[{"ID":"20250926170647-vcgyqir","Type":"NodeParagraph","Properties":{"id":"20250926170647-vcgyqir","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GALIP (用于生成任务)"},{"Type":"NodeText","Data":": 传统上，提示工程主要用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理解"},{"Type":"NodeText","Data":"任务（如分类、分割）。GALIP则创新性地将其用于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成"},{"Type":"NodeText","Data":"任务（文本到图像）。它通过设计一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示预测器"},{"Type":"NodeText","Data":"，将文本和噪声映射为一个“提示”，这个提示被注入到生成器的不同层级中，从而更好地控制生成图像的内容和风格。这表明提示工程可以作为一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精细化的条件控制机制"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250926170647-cie6ssp","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170647-cie6ssp","updated":"20250926170647"},"Children":[{"ID":"20250926170647-f15fnur","Type":"NodeParagraph","Properties":{"id":"20250926170647-f15fnur","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"PTP (用于提升定位能力)"},{"Type":"NodeText","Data":": PTP则关注于解决现有视觉-语言模型的一个核心痛点——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺乏空间和位置感知能力"},{"Type":"NodeText","Data":"。它通过在文本和图像中巧妙地加入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"位置标记"},{"Type":"NodeText","Data":"，将复杂的视觉定位问题转化为一个模型更擅长的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“填空”"},{"Type":"NodeText","Data":"问题。这展示了提示工程可以被用来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"弥补模型的内在能力缺陷"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250926170647-43kj26o","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926170647-43kj26o","updated":"20250926170647"},"Children":[{"ID":"20250926170647-mpvycs3","Type":"NodeParagraph","Properties":{"id":"20250926170647-mpvycs3","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程的设计原则总结"},{"Type":"NodeText","Data":": 在介绍完一系列具体方法后，本部分做了一个非常精彩的总结，并由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图2"},{"Type":"NodeText","Data":"进行了可视化呈现。它将复杂多样的提示工程方法归纳为几个核心类别："}]},{"ID":"20250926170647-jk6omx0","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170647-jk6omx0","updated":"20250926170647"},"Children":[{"ID":"20250926170647-yhm3xm2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170647-yhm3xm2","updated":"20250926170647"},"Children":[{"ID":"20250926170647-udnmg39","Type":"NodeParagraph","Properties":{"id":"20250926170647-udnmg39","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本侧提示"},{"Type":"NodeText","Data":": 修改或学习文本输入。"}]}]},{"ID":"20250926170647-dcoyc2o","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170647-dcoyc2o","updated":"20250926170647"},"Children":[{"ID":"20250926170647-rt5kid7","Type":"NodeParagraph","Properties":{"id":"20250926170647-rt5kid7","updated":"20250926170647"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉侧提示"},{"Type":"NodeText","Data":": 在图像输入中加入可学习的参数。"}]}]},{"ID":"20250926170647-04x875j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170647-04x875j","updated":"20250926170647"},"Children":[{"ID":"20250926170648-k3viz49","Type":"NodeParagraph","Properties":{"id":"20250926170648-k3viz49","updated":"20250926170648"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特征融合提示"},{"Type":"NodeText","Data":": 将一种模态的特征作为另一种模态的提示。"}]}]},{"ID":"20250926170647-jv8084j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170647-jv8084j","updated":"20250926170647"},"Children":[{"ID":"20250926170648-ddjwy8l","Type":"NodeParagraph","Properties":{"id":"20250926170648-ddjwy8l","updated":"20250926170648"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交互式提示"},{"Type":"NodeText","Data":": 在模型的中间层级让两种模态的提示相互影响。"}]}]}]},{"ID":"20250926170648-y397ryi","Type":"NodeParagraph","Properties":{"id":"20250926170648-y397ryi","updated":"20250926170648"},"Children":[{"Type":"NodeText","Data":"这个总结为读者构建了一个清晰的知识框架，帮助理解各种看似不同的提示方法背后的共通原理。"}]}]},{"ID":"20250926170647-czcfnhv","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926170647-czcfnhv","updated":"20250926170647"},"Children":[{"ID":"20250926170648-0pamgcy","Type":"NodeParagraph","Properties":{"id":"20250926170648-0pamgcy","updated":"20250926170648"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图2的指导意义"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图2"},{"Type":"NodeText","Data":"不仅是对现有方法的可视化，更是一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指导性的设计框架"},{"Type":"NodeText","Data":"。它告诉研究者们，当面对一个新的多模态任务时，可以从哪些“位置”和“层面”去设计和插入“提示”，为未来的研究提供了清晰的路线图。"}]}]}]},{"ID":"20250926170648-a2mg463","Type":"NodeParagraph","Properties":{"id":"20250926170648-a2mg463","updated":"20250926170648"},"Children":[{"Type":"NodeText","Data":"总结而言，这一部分内容展示了视觉-语言提示工程领域的高度创新性和多样性。它不仅能提升传统任务的性能（如CoOp, MaPLe），还能被应用于全新的领域（如GALIP），甚至用来弥补模型的根本性缺陷（如PTP）。通过最后的总结和图2的可视化，文章成功地将这些多样化的方法统一到了一个连贯的框架之下。"}]}]},{"ID":"20250926170803-mmqsjrq","Type":"NodeParagraph","Properties":{"id":"20250926170803-mmqsjrq","updated":"20250926170803"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。"}]},{"ID":"20250926170803-wpz7fgg","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170803-wpz7fgg","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.4. 视觉模型中的提示工程"}]},{"ID":"20250926170803-1fob1la","Type":"NodeParagraph","Properties":{"id":"20250926170803-1fob1la","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"最近，受NLP领域提示工程成功的启发，计算机视觉领域见证了在使用提示方面的一系列进展。研究人员已经开始探索将提示表述为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"针对特定视觉任务量身定制的连续向量"},{"Type":"NodeText","Data":"的想法。这涉及到将提示设计为视觉模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"指导信号"},{"Type":"NodeText","Data":"，帮助它们更有效地生成或分析视觉内容。通过使用任务特定的提示对模型进行微调，在包括图像分类、目标检测和图像生成在内的各种视觉任务中取得了显著的改进。"}]},{"ID":"20250926170803-54nurwx","Type":"NodeParagraph","Properties":{"id":"20250926170803-54nurwx","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.4.1. 视觉提示微调 (Visual Prompt Tuning, VPT)"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926170803-xcrycya","Type":"NodeParagraph","Properties":{"id":"20250926170803-xcrycya","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"除了不同模态中的各种提示技术外，在计算机视觉领域的视觉图像提示方面也出现了戏剧性的创新发展。VPT从大型NLP模型中汲取灵感，并采用提示工程来指导一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结的预训练骨干模型"},{"Type":"NodeText","Data":"的微调过程。它通过在输入空间中引入"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"少量可训练参数作为提示"},{"Type":"NodeText","Data":"来实现这一点。通过优化这些提示，VPT在推理过程中增强了模型针对特定视觉模式和任务需求的性能，正如论文中所描绘的那样。VPT"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效、适应性强，并适用于广泛的视觉任务"},{"Type":"NodeText","Data":"。通过利用精心设计的提示，研究人员可以引导模型在特定视觉任务上表现得更好。"}]},{"ID":"20250926170803-vxvf2sr","Type":"NodeParagraph","Properties":{"id":"20250926170803-vxvf2sr","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.4.2. AdaptFormer模型"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926170803-ckyuog3","Type":"NodeParagraph","Properties":{"id":"20250926170803-ckyuog3","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"类似地，AdaptFormer是一个现有的基于ViT的模型，它通过将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"轻量级模块"},{"Type":"NodeText","Data":"集成到其架构中，被优化以提高其在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"动作识别"},{"Type":"NodeText","Data":"基准测试上的效率。AdaptFormer背后的设计理念是利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"为任务特定约束量身定制的可训练模块"},{"Type":"NodeText","Data":"，并将其置于预训练的ViT模型中。实验结果表明，AdaptFormer在动作识别任务上的性能优于完全微调的模型。"}]},{"ID":"20250926170803-n6tyxlt","Type":"NodeParagraph","Properties":{"id":"20250926170803-n6tyxlt","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.4.3. Convpass方法"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926170803-9zr25g8","Type":"NodeParagraph","Properties":{"id":"20250926170803-9zr25g8","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"Convpass是一种旨在通过实现"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"卷积旁路（convolutional bypasses）"},{"Type":"NodeText","Data":" 来快速定制预训练ViT的方法。Convpass的主要目标是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"减少与微调相关的计算开销"},{"Type":"NodeText","Data":"，同时增加预训练模型对特定计算机视觉任务的适应性。集成在Convpass中的卷积旁路，允许在不牺牲性能的情况下加速模型的训练和推理。该技术旨在简化学习过程，并最大限度地提高利用预训练ViT进行目标计算机视觉应用的效率。"}]},{"ID":"20250926170803-jzca7en","Type":"NodeParagraph","Properties":{"id":"20250926170803-jzca7en","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.4.4. ViPT方法"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926170803-wl4uipi","Type":"NodeParagraph","Properties":{"id":"20250926170803-wl4uipi","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"ViPT提出了一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示微调方法"},{"Type":"NodeText","Data":"，以解决下游"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态跟踪任务"},{"Type":"NodeText","Data":"中大规模数据有限的挑战。该技术允许直接利用现有基础知识来提取RGB模态跟踪任务中的RGB模态特征。提示微调方法涉及微调基础模型的参数，同时保留预训练阶段的知识。提示模块允许根据任务特定数据进行灵活调整。ViPT通过采用提示微调方法解决了多模态跟踪任务中数据不足的问题。这种方法利用嵌入在预训练模型中的先验知识来促进RGB模态特征的提取。通过在保留其现有知识的同时微调基础模型，提示模块能够根据手头任务的具体数据需求进行高效调整。ViPT的提示微tuning技术是克服多模态跟踪任务中数据稀缺问题的有效解决方案，它优化了基础模型的参数，保留了来自预训练的宝贵知识，并为任务特定数据提供了适应性。这种方法确保了RGB模态特征的逻辑和流畅集成，从而在RGB+辅助模态跟踪任务中最大化性能。"}]},{"ID":"20250926170803-hjkl8qu","Type":"NodeParagraph","Properties":{"id":"20250926170803-hjkl8qu","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.4.5. 多样性感知元视觉提示 (Diversity-Aware Meta Visual Prompting)"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926170803-i9p4p5m","Type":"NodeParagraph","Properties":{"id":"20250926170803-i9p4p5m","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"为了解决在使用单个特定于数据集的提示时，处理来自原始预训练数据分布的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"复杂分布偏移"},{"Type":"NodeText","Data":"的挑战，多样性感知元视觉提示（DAM-VP）引入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性感知元视觉提示"},{"Type":"NodeText","Data":"的概念。该方法采用一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样性自适应机制"},{"Type":"NodeText","Data":"，将下游数据集聚类成更小的、同质的子集，每个子集都有其自己独立优化的提示。其目的是解决因在不同数据分布之间转移知识而产生的困难。研究表明，利用从先前数据集中学到的提示知识可以加速新数据集上的收敛并提高性能。在DAM-VP中集成多样性感知元视觉提示，使模型能够自适应地利用下游数据集内的多样性，从而促进更有效的迁移学习和改进的泛化能力。"}]},{"ID":"20250926170803-u0k7amt","Type":"NodeParagraph","Properties":{"id":"20250926170803-u0k7amt","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"在本节中，我们介绍了基于视觉模型的提示构建方法。VPT通过在输入空间中引入可训练的提示来增强模型性能，利用提示工程为特定视觉模式微调模型。AdaptFormer专注于动作识别，将轻量级模块集成到ViT模型中以进行任务特定优化。与此同时，Convpass在预训练的ViT模型中使用卷积旁路来降低计算成本并增加各种视觉任务的适应性。ViPT解决了多模-模态跟踪任务中数据有限的挑战，采用提示微调来优化RGB模态特征提取。最后，DAM-VP引入了多样性感知元视觉提示，以管理数据集中的复杂分布偏移，使用多样性自适应机制实现更有效的知识转移和泛化。这些方法中的每一种都为提升计算机视觉应用中预训练模型的效率、适应性和任务特定性能做出了独特的贡献。"}]},{"ID":"20250926170803-hjexvg6","Type":"NodeParagraph","Properties":{"id":"20250926170803-hjexvg6","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"如图3所示，视觉模型的提示大多以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"网络架构内的可训练词元（trainable tokens）"},{"Type":"NodeText","Data":" 的形式存在。在模型的不同阶段，对这些可训练词元采用了各种设计方法。这些词元被策略性地设计为特殊标记，允许将信息集成到模型中并增强其在各种任务上的性能。通过将这些可学习的词元整合到模型中，它增强了模型在给定任务中表现出色的能力。这种方法使视觉模型能够适应并响应特定的视觉模式，使其更善于处理复杂的视觉任务。"}]},{"ID":"20250926170803-w7w0l01","Type":"NodeParagraph","Properties":{"id":"20250926170803-w7w0l01","updated":"20250926170805"},"Children":[{"Type":"NodeText","Data":"\u003cimg src=\"https://i.imgur.com/GzB9k2l.png\" alt=\"Meta-Radiology 1 (2023) 100047-7.png\" /\u003e"}]},{"ID":"20250926170803-3yefz3k","Type":"NodeParagraph","Properties":{"id":"20250926170803-3yefz3k","updated":"20250926170805"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图3. 该图展示了用于视觉提示的不同类型的提示构建方法。"},{"Type":"NodeText","Data":" VPT的策略是在一个固定的预训练模型上，通过优化输入空间内少量可训练参数（称为提示）来指导微调过程。AdaptFormer是一个基于ViT的模型，它通过将轻量级模块集成到其架构中，来提升其在动作识别基准测试上的效率。Convpass方法通过实现卷积旁路来快速调整预训练的ViT。图中描绘的“提示”代表了被插入到模型中以提高其对特定任务的适应性和性能的可训练参数或模块。"}]},{"ID":"20250926170803-9b4qz58","Type":"NodeBlockquote","Properties":{"id":"20250926170803-9b4qz58","updated":"20250926170805"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170803-dun6hbd","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170803-dun6hbd","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250926170803-k1vhmxb","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170803-k1vhmxb","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图3：纯视觉模型提示工程方法的可视化"}]},{"ID":"20250926170803-f0l523t","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170803-f0l523t","updated":"20250926170803"},"Children":[{"ID":"20250926170803-u727wcb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170803-u727wcb","updated":"20250926170803"},"Children":[{"ID":"20250926170803-i2oawji","Type":"NodeParagraph","Properties":{"id":"20250926170803-i2oawji","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解分析"},{"Type":"NodeText","Data":": 这张图非常直观地展示了第2.4节中讨论的几种主流"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纯视觉提示工程"},{"Type":"NodeText","Data":"方法是如何在Transformer（特指ViT）架构中实现的。"}]},{"ID":"20250926170803-hennoii","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926170803-hennoii","updated":"20250926170803"},"Children":[{"ID":"20250926170803-kfz8wei","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926170803-kfz8wei","updated":"20250926170803"},"Children":[{"ID":"20250926170803-ndd3543","Type":"NodeParagraph","Properties":{"id":"20250926170803-ndd3543","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"VPT (输入端提示)"},{"Type":"NodeText","Data":": 图中最左侧的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"橙色“Prompts”"},{"Type":"NodeText","Data":" 框代表了VPT的方法。它将可学习的提示向量与图像的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"块嵌入 (Patch embedding)"},{"Type":"NodeText","Data":" 在送入Transformer编码器之前进行拼接或相加。这是最直接、最简单的一种提示方式。"}]}]},{"ID":"20250926170803-e8oatdg","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926170803-e8oatdg","updated":"20250926170803"},"Children":[{"ID":"20250926170803-cynljcl","Type":"NodeParagraph","Properties":{"id":"20250926170803-cynljcl","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AdaptFormer (层间适配器)"},{"Type":"NodeText","Data":": 图中最右侧的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AdaptMLP"},{"Type":"NodeText","Data":"模块代表了AdaptFormer的思想。它不是在输入端，而是在Transformer的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"编码器层 (Encoder Layer) 之间"},{"Type":"NodeText","Data":"插入一个轻量级的、可训练的模块（通常是一个小型的多层感知机MLP）。这种“适配器 (Adapter)”结构可以在不改变主干网络的情况下，为模型注入任务特定的知识。"}]}]},{"ID":"20250926170803-8l8pmda","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926170803-8l8pmda","updated":"20250926170803"},"Children":[{"ID":"20250926170803-3nxgw7j","Type":"NodeParagraph","Properties":{"id":"20250926170803-3nxgw7j","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Convpass (并行旁路)"},{"Type":"NodeText","Data":": 图中并未直接画出Convpass，但可以理解为在Transformer Encoder的旁边并行地增加一个卷积分支，并将两者的输出融合。"}]}]},{"ID":"20250926170803-xgvpb86","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250926170803-xgvpb86","updated":"20250926170803"},"Children":[{"ID":"20250926170803-754lpbw","Type":"NodeParagraph","Properties":{"id":"20250926170803-754lpbw","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深层提示 (Deep Prompting)"},{"Type":"NodeText","Data":": 图中在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Encoder Layer 1"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Encoder Layer K"},{"Type":"NodeText","Data":" 之间也画了“Prompts”，这代表了更复杂的“深层提示”思想，即提示不仅可以加在输入层，也可以被插入到模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"每一个或多个中间层"},{"Type":"NodeText","Data":"，从而对模型的特征提取过程进行更精细的调控。"}]}]}]}]},{"ID":"20250926170803-c1zkdam","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170803-c1zkdam","updated":"20250926170803"},"Children":[{"ID":"20250926170803-ccfeylu","Type":"NodeParagraph","Properties":{"id":"20250926170803-ccfeylu","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心结论"},{"Type":"NodeText","Data":": 这张图揭示了纯视觉提示工程的核心思想："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过在ViT模型的不同“战略位置”——无论是输入端、层与层之间，还是并行分支——插入小型的、可训练的参数或模块（即“提示”），来实现对整个庞大模型的参数高效微调。"},{"Type":"NodeText","Data":" 这张图清晰地对比了不同方法的实现路径，帮助读者理解它们各自的特点和差异。"}]}]}]}]},{"ID":"20250926170803-6kesrj6","Type":"NodeBlockquote","Properties":{"id":"20250926170803-6kesrj6","updated":"20250926170805"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170803-al653a8","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170803-al653a8","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析 (第二部分 2.4 及图3)"}]},{"ID":"20250926170803-5j2w6gi","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926170803-5j2w6gi","updated":"20250926170803"},"Children":[{"ID":"20250926170803-kwzmihz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926170803-kwzmihz","updated":"20250926170803"},"Children":[{"ID":"20250926170803-fxc3f2m","Type":"NodeParagraph","Properties":{"id":"20250926170803-fxc3f2m","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心思想的统一"},{"Type":"NodeText","Data":": 这一部分聚焦于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"纯视觉模型"},{"Type":"NodeText","Data":"（以ViT为代表）的提示工程，其核心思想与NLP领域的提示工程一脉相承，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“参数高效微调”"},{"Type":"NodeText","Data":"。所有方法（VPT, AdaptFormer, Convpass等）的共同目标都是：在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"冻结"},{"Type":"NodeText","Data":"庞大的预训练模型主干网络的前提下，通过引入并"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"只训练"},{"Type":"NodeText","Data":"一小部分额外的参数（即“提示”），来使模型快速、低成本地适应新的视觉任务。"}]}]},{"ID":"20250926170803-kx9uvyi","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926170803-kx9uvyi","updated":"20250926170803"},"Children":[{"ID":"20250926170803-8zq3xo0","Type":"NodeParagraph","Properties":{"id":"20250926170803-8zq3xo0","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"方法论的多样化"},{"Type":"NodeText","Data":": 尽管核心思想统一，但实现路径却呈现出多样性，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图3"},{"Type":"NodeText","Data":" 对此进行了完美的总结。"}]},{"ID":"20250926170803-0ih4uam","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170803-0ih4uam","updated":"20250926170803"},"Children":[{"ID":"20250926170803-gak2015","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170803-gak2015","updated":"20250926170803"},"Children":[{"ID":"20250926170803-ampc1vn","Type":"NodeParagraph","Properties":{"id":"20250926170803-ampc1vn","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"VPT"},{"Type":"NodeText","Data":": 是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“前置式”"},{"Type":"NodeText","Data":" 的方法，在数据进入模型的最开始就进行干预，简单直接。"}]}]},{"ID":"20250926170803-4gqu4f9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170803-4gqu4f9","updated":"20250926170803"},"Children":[{"ID":"20250926170803-xdurir2","Type":"NodeParagraph","Properties":{"id":"20250926170803-xdurir2","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AdaptFormer"},{"Type":"NodeText","Data":": 是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“插入式”"},{"Type":"NodeText","Data":" 的方法，在模型处理流程的中间环节进行干预，像是在高速公路上增加一个个智能收费站，对信息流进行微调。"}]}]},{"ID":"20250926170803-mrd6062","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170803-mrd6062","updated":"20250926170803"},"Children":[{"ID":"20250926170803-ovxz9c7","Type":"NodeParagraph","Properties":{"id":"20250926170803-ovxz9c7","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Convpass"},{"Type":"NodeText","Data":": 是一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“并行式”"},{"Type":"NodeText","Data":" 的方法，它不直接干预Transformer的主干道，而是在旁边修了一条“辅路”（卷积旁路），让信息可以走不同的路径，最后再汇合，结合了卷积的局部归纳偏置和Transformer的全局建模能力。"}]}]}]}]},{"ID":"20250926170803-nyun9dn","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926170803-nyun9dn","updated":"20250926170803"},"Children":[{"ID":"20250926170803-s9rwo7a","Type":"NodeParagraph","Properties":{"id":"20250926170803-s9rwo7a","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"针对特定挑战的演进"},{"Type":"NodeText","Data":": 方法的演进往往是为了解决特定的问题。"}]},{"ID":"20250926170803-xca7ajf","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170803-xca7ajf","updated":"20250926170803"},"Children":[{"ID":"20250926170803-i6leywu","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170803-i6leywu","updated":"20250926170803"},"Children":[{"ID":"20250926170803-uwfh3hr","Type":"NodeParagraph","Properties":{"id":"20250926170803-uwfh3hr","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ViPT"},{"Type":"NodeText","Data":": 针对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模-模态跟踪"},{"Type":"NodeText","Data":"中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"数据稀缺"},{"Type":"NodeText","Data":"的问题，展示了提示工程在小样本场景下的巨大价值。"}]}]},{"ID":"20250926170803-h24j421","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170803-h24j421","updated":"20250926170803"},"Children":[{"ID":"20250926170803-zcmn1fw","Type":"NodeParagraph","Properties":{"id":"20250926170803-zcmn1fw","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DAM-VP"},{"Type":"NodeText","Data":": 针对更复杂的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"分布偏移"},{"Type":"NodeText","Data":"问题，即模型在训练数据和测试数据分布不一致时性能下降。它创新地引入了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“元学习” (Meta Learning)"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“聚类”"},{"Type":"NodeText","Data":" 的思想，为不同的数据子集学习不同的“专家提示”，使得模型能够动态地适应数据内部的多样性。这代表了提示工程从“静态”向“动态自适应”的更高层次演进。"}]}]}]}]},{"ID":"20250926170803-gfzlui3","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250926170803-gfzlui3","updated":"20250926170803"},"Children":[{"ID":"20250926170803-nivyqlq","Type":"NodeParagraph","Properties":{"id":"20250926170803-nivyqlq","updated":"20250926170803"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“提示”到“模块”"},{"Type":"NodeText","Data":": 在这一部分，我们能观察到“提示”的概念正在泛化。它不再仅仅指输入端的一些可学习向量（如VPT），而是可以指代任何被插入到大模型中用于高效微调的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"轻量级可训练模块"},{"Type":"NodeText","Data":"（如AdaptFormer中的MLP）。这个概念的扩展极大地丰富了参数高效微调的技术库。"}]}]}]},{"ID":"20250926170803-3avj4zt","Type":"NodeParagraph","Properties":{"id":"20250926170803-3avj4zt","updated":"20250926170803"},"Children":[{"Type":"NodeText","Data":"总结而言，第2.4节系统地介绍了纯视觉模型提示工程的主流方法。通过对VPT、AdaptFormer等不同技术路径的分析，并结合图3的可视化，本节清晰地阐述了如何在ViT这类模型上实现参数高效微调。同时，通过ViPT和DAM-VP等更前沿方法的介绍，展示了该领域为解决具体应用挑战（如数据稀缺、分布偏移）而进行的持续创新。"}]}]},{"ID":"20250926170914-q1c2g7b","Type":"NodeParagraph","Properties":{"id":"20250926170914-q1c2g7b","updated":"20250926170914"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。"}]},{"ID":"20250926170914-2qurtvz","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170914-2qurtvz","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.5. AGI中的提示工程"}]},{"ID":"20250926170914-tba38dt","Type":"NodeParagraph","Properties":{"id":"20250926170914-tba38dt","updated":"20250926170916"},"Children":[{"Type":"NodeText","Data":"随着通用模型在各个领域展示出令人印象ه 的泛化能力，大型视觉模型（LVMs）也取得了显著进展。通过在多样化数据集上训练基础模型，这些模型能够通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示学习"},{"Type":"NodeText","Data":"适应下游任务。这种方法不仅减轻了训练需求并优化了资源利用，还为计算机视觉的发展引入了新途径。例如，创新的“分割一切模型”通过采用适当的提示，实现了对下游任务强大的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本迁移能力"},{"Type":"NodeText","Data":"，因此其在各个领域都有广泛的应用。这种通用AI模型可以学习一般概念，并因其可迁移性而在未知数据上展现出零样本迁移能力，展示了AGI的巨大潜力。然而，提示工程对于将模型泛化到新任务仍然至关重要，不能被其他因素所压倒。提示工程指的是设计提示的过程，使模型能够适应和泛化到不同的任务。这个问题至关重要，因为一个精心设计的提示可以引导有效的表示学习，从而增强其在各种任务上的性能。应强调提示作为引导模型理解和适应已见或未见任务的上下文和需求的关键。许多其他模型也已出现，包括著名的模型如OneFormer、SegGPT、SEEM和Uni-Perceiver v2，它们在AGI中展示了强大的能力，并为应对各种任务提供了新的可能性。这些模型采用零样本迁移方法，使得提示学习成为模型泛化的一个关键体现。"}]},{"ID":"20250926170914-vtsspmo","Type":"NodeParagraph","Properties":{"id":"20250926170914-vtsspmo","updated":"20250926170916"},"Children":[{"Type":"NodeText","Data":"在本节中，我们将深入详细地解释基于"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"即时交互模型（promptly, interactive models）"},{"Type":"NodeText","Data":" 的提示构建方法，涵盖诸如目标检测、多模态融合以及各种模型的组合等关键元素。这些方法为利用大型模型的泛化能力提供了强大的工具，从而为实现下游任务提供了可行的解决方案。"}]},{"ID":"20250926170914-72w8v84","Type":"NodeParagraph","Properties":{"id":"20250926170914-72w8v84","updated":"20250926170916"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.5.1. 目标检测"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926170914-ihd8six","Type":"NodeParagraph","Properties":{"id":"20250926170914-ihd8six","updated":"20250926170916"},"Children":[{"Type":"NodeText","Data":"在目标检测任务中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于提示的方法"},{"Type":"NodeText","Data":"在实现泛化能力方面对达成AGI至关重要。这些方法被认为是实现这种泛化的基础。然而，尽管SAM声称能够分割任何物体，但其实际应用受到了质疑。特别地，人们对SAM在诸如医学图像分割、伪装目标检测、镜面和透明物体检测以及其他类似场景中的应用效果提出了担忧。因此，近期的研究集中于评估SAM在各种设置下的性能。如图4所示，这些研究已经证明，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"点或框提示"},{"Type":"NodeText","Data":"在各种实际场景中非常有效。SAM在自然图像、遥感和医学成像领域取得了稳健的零样本性能。然而，其在复杂应用场景中的泛化能力，特别是在语义信息模糊或环境对比度低的情况下，可能无法满足任务要求。因此，需要进行额外研究以增强SAM在复杂环境中的性能。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"陨石坑检测"},{"Type":"NodeText","Data":"领域，SAM被用于自动化图像分割。随后，对每个分割出的掩码的形状进行评估，并执行额外的处理步骤，如过滤和边界提取。"}]},{"ID":"20250926170914-muid100","Type":"NodeParagraph","Properties":{"id":"20250926170914-muid100","updated":"20250926170916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.5.1.1. 目标计数 (Object Counting)"}]},{"ID":"20250926170914-izzqvqr","Type":"NodeParagraph","Properties":{"id":"20250926170914-izzqvqr","updated":"20250926170916"},"Children":[{"Type":"NodeText","Data":"在目标计数领域，研究人员采用SAM，利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"边界框作为提示"},{"Type":"NodeText","Data":"来生成分割掩码。从图像编码器获得的密集图像特征与一个参考物体的特征向量进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"乘法和平均"},{"Type":"NodeText","Data":"。随后，一个每边包含32个点的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"点网格"},{"Type":"NodeText","Data":"被用作分割的提示。通过将得到的掩码特征向量与密集特征相乘并平均，得到最终的掩码特征。最终，为了确定总数，计算预测掩码与参考掩码之间的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"余弦相似度"},{"Type":"NodeText","Data":"。"}]},{"ID":"20250926170914-w7gmcpi","Type":"NodeParagraph","Properties":{"id":"20250926170914-w7gmcpi","updated":"20250926170916"},"Children":[{"Type":"NodeText","Data":"\u003cimg src=\"https://i.imgur.com/gK9qQ7E.png\" alt=\"Meta-Radiology 1 (2023) 100047-7 (1).png\" /\u003e"}]},{"ID":"20250926170914-qicmtsr","Type":"NodeParagraph","Properties":{"id":"20250926170914-qicmtsr","updated":"20250926170916"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图4. 该图描绘了基于SAM的AGI内目标检测的提示工程方法。"},{"Type":"NodeText","Data":" 在图中，“提示”代表了框架内各种目标检测方法的位置。通过将提示工程与自适应模块化架构相结合，根据不同的任务和环境选择最合适的目标检测方法，从而实现更智能、更灵活的目标检测能力。"}]},{"ID":"20250926170914-xxsnmsz","Type":"NodeBlockquote","Properties":{"id":"20250926170914-xxsnmsz","updated":"20250926170916"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170914-vih709e","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170914-vih709e","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250926170914-9ihfiiu","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926170914-9ihfiiu","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图4：基于SAM的目标检测流程示意图"}]},{"ID":"20250926170914-z8vqvr0","Type":"NodeList","ListData":{},"Properties":{"id":"20250926170914-z8vqvr0","updated":"20250926170914"},"Children":[{"ID":"20250926170914-dtmlc19","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170914-dtmlc19","updated":"20250926170914"},"Children":[{"ID":"20250926170914-x80iave","Type":"NodeParagraph","Properties":{"id":"20250926170914-x80iave","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解分析"},{"Type":"NodeText","Data":": 这张图简明扼要地展示了如何利用SAM进行目标检测（或更准确地说，是“提示驱动的实例分割”）。"}]},{"ID":"20250926170914-yjaxheb","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926170914-yjaxheb","updated":"20250926170914"},"Children":[{"ID":"20250926170914-dxtwx83","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926170914-dxtwx83","updated":"20250926170914"},"Children":[{"ID":"20250926170914-8k1fmul","Type":"NodeParagraph","Properties":{"id":"20250926170914-8k1fmul","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"输入与编码"},{"Type":"NodeText","Data":": 首先，输入一张"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像 (Image)"},{"Type":"NodeText","Data":"，通过一个强大的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像编码器 (Image encoder)"},{"Type":"NodeText","Data":"（通常是一个大型ViT）将其转换为深层的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像嵌入 (Image embedding)"},{"Type":"NodeText","Data":"。这个嵌入包含了图像中所有物体的丰富视觉信息。"}]}]},{"ID":"20250926170914-putch4d","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926170914-putch4d","updated":"20250926170914"},"Children":[{"ID":"20250926170914-bwanju8","Type":"NodeParagraph","Properties":{"id":"20250926170914-bwanju8","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示的编码与注入"},{"Type":"NodeText","Data":": 其次，用户提供"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示 (Prompts)"},{"Type":"NodeText","Data":"，例如一个点、一个边界框或一段文本。这些提示被送入一个专门的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示编码器 (Prompt encoder)"},{"Type":"NodeText","Data":"，将其转换为提示嵌入。"}]}]},{"ID":"20250926170914-f6ou217","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926170914-f6ou217","updated":"20250926170914"},"Children":[{"ID":"20250926170914-jotzuns","Type":"NodeParagraph","Properties":{"id":"20250926170914-jotzuns","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"解码与输出"},{"Type":"NodeText","Data":": 图像嵌入和提示嵌入被共同送入一个轻量级的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"掩码解码器 (Mask decoder)"},{"Type":"NodeText","Data":"。解码器“理解”提示的意图（即用户想要分割哪个物体），并在图像嵌入中找到相应区域，最终输出该物体的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"掩码 (Mask)"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250926170914-ecf5kug","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250926170914-ecf5kug","updated":"20250926170914"},"Children":[{"ID":"20250926170914-fnj1qty","Type":"NodeParagraph","Properties":{"id":"20250926170914-fnj1qty","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"架构的通用性"},{"Type":"NodeText","Data":": 图中的卷积层（Conv）和整体流程代表了一种通用的范式。通过改变提示编码器和解码器的设计，或者在流程中加入其他模块，这个框架可以适应各种不同的检测/分割任务。"}]}]}]}]},{"ID":"20250926170914-jvt83m9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926170914-jvt83m9","updated":"20250926170914"},"Children":[{"ID":"20250926170914-d05scag","Type":"NodeParagraph","Properties":{"id":"20250926170914-d05scag","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心结论"},{"Type":"NodeText","Data":": 这张图的核心在于展示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“提示”是如何作为“查询”来引导分割过程的"},{"Type":"NodeText","Data":"。SAM的强大之处在于其图像编码器提供了一个高质量的“视觉数据库”（图像嵌入），而用户可以通过灵活的提示来精确地“检索”出自己感兴趣的任何物体。这种交互式的、提示驱动的范式是迈向更通用、更智能视觉系统（AGI）的关键一步。"}]}]}]}]},{"ID":"20250926170914-m3s8w99","Type":"NodeBlockquote","Properties":{"id":"20250926170914-m3s8w99","updated":"20250926170916"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926170914-2m4t6ti","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926170914-2m4t6ti","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析 (第二部分 2.5 及图4)"}]},{"ID":"20250926170914-h6pd57g","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926170914-h6pd57g","updated":"20250926170914"},"Children":[{"ID":"20250926170914-e4r0ggz","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926170914-e4r0ggz","updated":"20250926170914"},"Children":[{"ID":"20250926170914-q9a9xp6","Type":"NodeParagraph","Properties":{"id":"20250926170914-q9a9xp6","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AGI与提示工程的共生关系"},{"Type":"NodeText","Data":": 这一部分的核心论点是，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程是实现通用人工智能（AGI）的关键路径和核心体现"},{"Type":"NodeText","Data":"。大型模型（LVMs）的强大"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化能力"},{"Type":"NodeText","Data":"（潜力）需要通过灵活的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程"},{"Type":"NodeText","Data":"（钥匙）来解锁和引导，以适应无穷无尽的下游任务。像SAM这样的模型，其革命性不在于分割做得多好，而在于它建立了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"以提示为中心的交互范式"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250926170914-af7osvi","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926170914-af7osvi","updated":"20250926170914"},"Children":[{"ID":"20250926170914-qctgebp","Type":"NodeParagraph","Properties":{"id":"20250926170914-qctgebp","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“模型为中心”到“任务为中心”的转变"},{"Type":"NodeText","Data":": 传统的AI开发是“模型为中心”的，即为每个任务训练一个专门的模型。而基于提示的AGI范式则是“任务为中心”的：我们有一个（或少数几个）强大的通用基础模型，当面临新任务时，我们不再训练新模型，而是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"设计新的提示"},{"Type":"NodeText","Data":"。这种转变极大地提高了AI系统开发的效率和灵活性。"}]}]},{"ID":"20250926170914-qo0a8wh","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926170914-qo0a8wh","updated":"20250926170914"},"Children":[{"ID":"20250926170914-kk12ke2","Type":"NodeParagraph","Properties":{"id":"20250926170914-kk12ke2","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAM的现实应用与局限性"},{"Type":"NodeText","Data":": 文章客观地指出了SAM的“双面性”。一方面，它在通用场景（自然图像、遥感等）下表现出惊人的零样本分割能力，验证了提示驱动范式的成功。另一方面，文章也坦诚地指出了其"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"局限性"},{"Type":"NodeText","Data":"，即在一些专业或边缘场景（如医学影像中的模糊边界、伪装/透明物体等低对比度或语义模糊环境）中，其性能可能不尽如人意。这为未来的研究指明了方向："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"如何将领域知识更有效地融入提示，以提升模型在专业领域的性能"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250926170914-et2alub","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250926170914-et2alub","updated":"20250926170914"},"Children":[{"ID":"20250926170914-2azijg8","Type":"NodeParagraph","Properties":{"id":"20250926170914-2azijg8","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示工程在具体任务中的应用 (目标计数)"},{"Type":"NodeText","Data":": 通过目标计数的例子，文章具体展示了提示工程如何被创造性地应用。研究者将SAM作为强大的“实例分割器”，通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"边界框提示"},{"Type":"NodeText","Data":"分割出所有物体，然后通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特征相似度比较"},{"Type":"NodeText","Data":"来判断哪些是被计数的类别。这体现了提示工程的灵活性——它不仅能直接完成任务，还能作为一个强大的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"中间工具"},{"Type":"NodeText","Data":"，被嵌入到更复杂的算法流程中。"}]}]},{"ID":"20250926170914-ra9ozu2","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NS4=","Num":5},"Properties":{"id":"20250926170914-ra9ozu2","updated":"20250926170914"},"Children":[{"ID":"20250926170914-kbloxgn","Type":"NodeParagraph","Properties":{"id":"20250926170914-kbloxgn","updated":"20250926170914"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图4的范式总结"},{"Type":"NodeText","Data":": "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图4"},{"Type":"NodeText","Data":" 不仅是SAM工作原理的示意图，更是对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“提示驱动的视觉感知”这一AGI新范式"},{"Type":"NodeText","Data":"的总结。它展示了一个“编码-提示-解码”的清晰流程，其中“提示”是连接通用视觉理解（编码器）和具体任务执行（解码器）的桥梁。这个框架具有高度的可扩展性，预示着未来AI系统将越来越依赖于与用户的交互和提示。"}]}]}]},{"ID":"20250926170914-s6lgq5p","Type":"NodeParagraph","Properties":{"id":"20250926170914-s6lgq5p","updated":"20250926170914"},"Children":[{"Type":"NodeText","Data":"总结而言，这一部分将讨论从具体的技术方法提升到了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"AGI的哲学高度"},{"Type":"NodeText","Data":"。它不仅介绍了提示工程在目标检测等任务中的应用，更重要的是，它将提示工程定位为通往AGI的关键方法论，并探讨了这一新范式的巨大潜力和当前面临的挑战，为读者描绘了计算机视觉未来的发展蓝图。"}]}]},{"ID":"20250926171003-n1u0j56","Type":"NodeParagraph","Properties":{"id":"20250926171003-n1u0j56","updated":"20250926171003"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。"}]},{"ID":"20250926171003-9ur0uzk","Type":"NodeParagraph","Properties":{"id":"20250926171003-9ur0uzk","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.5.1.2. 遥感SAM (Remote Sensing SAM)"}]},{"ID":"20250926171003-a72v0d3","Type":"NodeParagraph","Properties":{"id":"20250926171003-a72v0d3","updated":"20250926171003"},"Children":[{"Type":"NodeText","Data":"在遥感图像分割领域，由于遥感图像的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"俯视视角"},{"Type":"NodeText","Data":"，场景中的物体可能具有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任意方向"},{"Type":"NodeText","Data":"。因此，有人提出一种技术，使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"旋转边界框（R-Box）"},{"Type":"NodeText","Data":" 的最小外接水平矩形作为SAM分割的引导提示。对于掩码提示，它被定义为边界框所包围的相应区域。先前的研究也已经证明了边界框在为高效标注目的设计提示时的适用性和有效性。"}]},{"ID":"20250926171003-3b7u15b","Type":"NodeParagraph","Properties":{"id":"20250926171003-3b7u15b","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.5.1.3. SAM-Adapter"}]},{"ID":"20250926171003-07nigb3","Type":"NodeParagraph","Properties":{"id":"20250926171003-07nigb3","updated":"20250926171003"},"Children":[{"Type":"NodeText","Data":"SAM-Adapter被开发用于将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"专门的领域知识"},{"Type":"NodeText","Data":"注入到原始SAM模型中，从而增强其在各种下游任务中的泛化能力。这种集成已经取得了有希望的结果。Adapter被设计用于获取相关知识并在初步阶段生成"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"任务特定的提示"},{"Type":"NodeText","Data":"。值得注意的是，提示可以在每个Transformer层输出。通过采用这种方法，分割网络中包含的提示显著提升了SAM在挑战性任务中的性能。该方法在诸如伪彩色物体检测、阴影检测和医学图像分割等不同领域取得了令人印象深刻的结果。"}]},{"ID":"20250926171003-o9racir","Type":"NodeParagraph","Properties":{"id":"20250926171003-o9racir","updated":"20250926171003"},"Children":[{"Type":"NodeText","Data":"在本节中，我们介绍了视觉目标识别和分割领域，其中已经开发了各种创新方法，每种方法都有其独特之处，但共享着提升准确性和适应性的共同目标。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"目标计数"},{"Type":"NodeText","Data":"中，研究人员利用带有边界框提示的SAM来生成分割掩码，利用图像编码器和余弦相似度进行准确的目标识别和计数。在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"遥感"},{"Type":"NodeText","Data":"背景下，SAM被调整以处理由俯视视角和物体任意方向带来的独特挑战，采用旋转边界框（R-Boxes）作为分割提示。该方法展示了边界框在复杂场景中进行高效标注的有效性。最后，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAM-Adapter"},{"Type":"NodeText","Data":"将专门的领域知识注入到SAM模型中，以增强其在各种任务中的泛化能力，利用任务特定的提示在每个Transformer层提升性能，应用于伪彩色物体检测、阴影检测和医学图像分割等多种应用。虽然每种方法都针对其各自领域的特定挑战量身定制，但它们都共享利用复杂的基于提示的技术来提高SAM在复杂视觉识别和分割任务中的精度和适用性的目标。"}]},{"ID":"20250926171003-c43srwp","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926171003-c43srwp","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.6. 多模态融合"}]},{"ID":"20250926171003-tkb7xui","Type":"NodeParagraph","Properties":{"id":"20250926171003-tkb7xui","updated":"20250926171006"},"Children":[{"Type":"NodeText","Data":"在近期的研究中，将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本信息"},{"Type":"NodeText","Data":"引入到视觉模型中，例如图像、绘画、帧和视频，已经显著地多样化并提高了任务的保真度。受生成模型概念的启发，将文本提示整合到CLIP中已成为一种有效的方法。"}]},{"ID":"20250926171003-3totusp","Type":"NodeParagraph","Properties":{"id":"20250926171003-3totusp","updated":"20250926171006"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.6.1. Text2Seg模型"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926171003-2irnuun","Type":"NodeParagraph","Properties":{"id":"20250926171003-2irnuun","updated":"20250926171006"},"Children":[{"Type":"NodeText","Data":"Text2Seg引入了一个依赖"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本提示作为输入"},{"Type":"NodeText","Data":"的视觉-语言模型。该模型的工作流程如下：首先，文本提示作为输入，生成边界框。这些边界框引导SAM生成分割掩码。在此之后，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CLIP Surgery"},{"Type":"NodeText","Data":"过程使用文本提示生成热力图，从这些热力图中派生出的点提示被送入SAM。最后，应用一个相似性算法来获得最终的分割图。"}]},{"ID":"20250926171003-kfagkqb","Type":"NodeParagraph","Properties":{"id":"20250926171003-kfagkqb","updated":"20250926171006"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.6.2. SAMText模型"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926171003-3j79r0c","Type":"NodeParagraph","Properties":{"id":"20250926171003-3j79r0c","updated":"20250926171006"},"Children":[{"Type":"NodeText","Data":"SAMText引入了一种通用的方法，用于生成旨在处理图像或视频帧中"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"场景文本"},{"Type":"NodeText","Data":"的分割掩码。该过程一旦提供了输入，便通过从一个场景文本检测模型中提取边界框坐标来启动，使用现有的标注。这些提取的边界框坐标作为SAM的提示，从而促进后续的掩码生成。如果边界框带有方向，SAMText会计算它们的最小外接矩形以获得水平边界框，这反过来又作为SAM生成掩码的提示。"}]},{"ID":"20250926171003-liysmlx","Type":"NodeParagraph","Properties":{"id":"20250926171003-liysmlx","updated":"20250926171006"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.6.3. Caption Anything (任意描述)"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926171003-bwnghz6","Type":"NodeParagraph","Properties":{"id":"20250926171003-bwnghz6","updated":"20250926171006"},"Children":[{"Type":"NodeText","Data":"Caption Anything引入了一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基础模型增强的图像描述框架"},{"Type":"NodeText","Data":"，该框架促进了包含视觉和语言方面的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态控制"},{"Type":"NodeText","Data":"。该框架无缝集成了SAM和ChatGPT，融合了视觉和语言模态，使用户可以与框架进行"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交互式建模"},{"Type":"NodeText","Data":"。在使用过程中，用户最初利用各种提示，特别是点或边界框，来灵活地控制输入图像，从而实现交互式的用户操作。该框架进一步使用大型语言模型来优化输出指令，确保与用户预期含义的有效对齐，并实现与用户意图的显著一致性。"}]},{"ID":"20250926171003-1upsoq9","Type":"NodeParagraph","Properties":{"id":"20250926171003-1upsoq9","updated":"20250926171006"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.6.4. Segment Any Anomaly + (分割任何异常+)"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926171003-hljtqwc","Type":"NodeParagraph","Properties":{"id":"20250926171003-hljtqwc","updated":"20250926171006"},"Children":[{"Type":"NodeText","Data":"Segment Any Anomaly + (SAA+) 引入了一种新颖的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"零样本异常分割"},{"Type":"NodeText","Data":"技术，该技术利用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混合提示正则化"},{"Type":"NodeText","Data":"来增强现有基础模型的适应性。所提出的正则化提示融合了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域特定的专业知识"},{"Type":"NodeText","Data":"和来自目标图像的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"上下文信息"},{"Type":"NodeText","Data":"，从而加强了更鲁棒的提示，并促进了对异常区域更准确的识别。此外，许多工作也同样得出结论，将领域专家知识作为先验支持纳入，可能为复杂场景中的分割问题提供一个潜在的解决方案。"}]},{"ID":"20250926171003-m3sqf84","Type":"NodeParagraph","Properties":{"id":"20250926171003-m3sqf84","updated":"20250926171006"},"Children":[{"Type":"NodeText","Data":"总之，这些方法例证了文本提示和视觉模型的创新融合，每种方法都针对特定应用量身定制，例如边界框生成、场景文本分割、交互式图像描述和异常检测。它们共同依赖于文本提示和SAM，以及它们在分割和图像理解方面的独特方法，突显了在先进的计算机视觉任务中结合语言和视觉数据的多样化潜力。"}]},{"ID":"20250926171003-4cpwi6v","Type":"NodeBlockquote","Properties":{"id":"20250926171003-4cpwi6v","updated":"20250926171006"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926171003-nc56yt8","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926171003-nc56yt8","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析 (第二部分 2.5.1.2 - 2.6.4)"}]},{"ID":"20250926171003-rqa6kcr","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926171003-rqa6kcr","updated":"20250926171003"},"Children":[{"ID":"20250926171003-vhlufmi","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926171003-vhlufmi","updated":"20250926171003"},"Children":[{"ID":"20250926171003-qsvq1jk","Type":"NodeParagraph","Properties":{"id":"20250926171003-qsvq1jk","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域适应性：提示工程的核心挑战与解决方案"},{"Type":"NodeText","Data":": 这一部分的核心议题是如何让通用的基础模型（如SAM）在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"特定领域（遥感、医学、场景文本等）"},{"Type":"NodeText","Data":" 中表现得更好。文章提出了两条主要路径："}]},{"ID":"20250926171003-vn6n59x","Type":"NodeList","ListData":{},"Properties":{"id":"20250926171003-vn6n59x","updated":"20250926171003"},"Children":[{"ID":"20250926171003-8dq6a20","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171003-8dq6a20","updated":"20250926171003"},"Children":[{"ID":"20250926171003-6ghztpo","Type":"NodeParagraph","Properties":{"id":"20250926171003-6ghztpo","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"调整提示 (Prompt Adaptation)"},{"Type":"NodeText","Data":": 以"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"遥感SAM"},{"Type":"NodeText","Data":"为例，核心问题是遥感图像中的物体有任意旋转角度，而标准的边界框是水平的。解决方案非常巧妙：不改变模型，而是改变提供给模型的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示"},{"Type":"NodeText","Data":"——使用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"旋转框 (R-Box)"},{"Type":"NodeText","Data":" 来更精确地指示物体，从而引导SAM进行更准确的分割。这体现了提示工程的灵活性。"}]}]},{"ID":"20250926171003-h275k21","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171003-h275k21","updated":"20250926171003"},"Children":[{"ID":"20250926171003-tgfmq86","Type":"NodeParagraph","Properties":{"id":"20250926171003-tgfmq86","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"调整模型 (Model Adaptation)"},{"Type":"NodeText","Data":": 以 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAM-Adapter"},{"Type":"NodeText","Data":" 为例，它代表了更深入的适应方式。它通过在SAM的骨干网络中插入轻量级的、可训练的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"适配器 (Adapter) 模块"},{"Type":"NodeText","Data":"，将领域知识直接"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"注入"},{"Type":"NodeText","Data":"到模型内部。这些适配器可以学习生成任务特定的“内部提示”，在模型的每一层对特征进行微调。这是一种更强大但也更复杂的领域适应方法。"}]}]}]}]},{"ID":"20250926171003-zzxm0mq","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926171003-zzxm0mq","updated":"20250926171003"},"Children":[{"ID":"20250926171003-5suixpb","Type":"NodeParagraph","Properties":{"id":"20250926171003-5suixpb","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态融合：1+1 \u0026gt; 2 的力量"},{"Type":"NodeText","Data":": 2.6节展示了将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本（语言模态）"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉模型（SAM）"},{"Type":"NodeText","Data":" 结合所产生的巨大威力。这不再是简单的视觉提示（点、框），而是利用了语言丰富的语义信息。"}]},{"ID":"20250926171003-6t3bvr2","Type":"NodeList","ListData":{},"Properties":{"id":"20250926171003-6t3bvr2","updated":"20250926171003"},"Children":[{"ID":"20250926171003-jm8xnn8","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171003-jm8xnn8","updated":"20250926171003"},"Children":[{"ID":"20250926171003-3vq6dru","Type":"NodeParagraph","Properties":{"id":"20250926171003-3vq6dru","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Text2Seg / SAMText"},{"Type":"NodeText","Data":": 这两者展示了如何用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本"},{"Type":"NodeText","Data":"来驱动分割。例如，输入文本“天空”，模型就能自动定位并分割出天空区域。这背后通常是一个“文本-\u003e定位-\u003e分割”的级联过程：首先一个模型（如CLIP）根据文本生成粗略的位置信息（热力图或边界框），然后这个位置信息再作为提示送给SAM进行精细分割。"}]}]},{"ID":"20250926171003-hese0e1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171003-hese0e1","updated":"20250926171003"},"Children":[{"ID":"20250926171003-e08lgvc","Type":"NodeParagraph","Properties":{"id":"20250926171003-e08lgvc","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Caption Anything"},{"Type":"NodeText","Data":": 这个项目将交互提升到了一个新的高度。它构建了一个由 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAM + 大语言模型 (LLM, 如ChatGPT)"},{"Type":"NodeText","Data":" 组成的强大系统。用户可以通过视觉提示（点、框）在SAM中选中任意区域，然后LLM会根据这个区域生成详细的文字描述。这真正实现了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“指哪打哪，说哪是哪”"},{"Type":"NodeText","Data":"的智能交互，是通往多模-模态AGI的重要一步。"}]}]},{"ID":"20250926171003-6eveqxw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171003-6eveqxw","updated":"20250926171003"},"Children":[{"ID":"20250926171003-dlpk9zg","Type":"NodeParagraph","Properties":{"id":"20250926171003-dlpk9zg","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Segment Any Anomaly+"},{"Type":"NodeText","Data":": 这个例子展示了如何利用提示来解决一个非常规但重要的任务——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"异常检测"},{"Type":"NodeText","Data":"。它通过设计一种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“混合提示”"},{"Type":"NodeText","Data":"，将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域知识"},{"Type":"NodeText","Data":"（例如，什么是“正常”的纹理）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像上下文"},{"Type":"NodeText","Data":"结合起来，引导模型去发现那些“不正常”的区域。"}]}]}]}]},{"ID":"20250926171003-iilk9s5","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926171003-iilk9s5","updated":"20250926171003"},"Children":[{"ID":"20250926171003-af8gd3w","Type":"NodeParagraph","Properties":{"id":"20250926171003-af8gd3w","updated":"20250926171003"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从“工具”到“生态”"},{"Type":"NodeText","Data":": 综合来看，本部分的内容揭示了一个重要的趋势：像SAM这样的基础模型，正在从一个独立的“工具”演变为一个可以被集成、被扩展的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“生态平台”"},{"Type":"NodeText","Data":"。研究者们不再满足于单独使用它，而是像搭积木一样，将它与适配器、CLIP、LLM等其他模块组合起来，创造出功能更强大、应用更多样化的复合系统。这种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“组合式创新” (Compositional Innovation)"},{"Type":"NodeText","Data":" 是当前AI领域发展的一个核心驱动力。"}]}]}]},{"ID":"20250926171003-rfd43y1","Type":"NodeParagraph","Properties":{"id":"20250926171003-rfd43y1","updated":"20250926171003"},"Children":[{"Type":"NodeText","Data":"总结而言，这一部分内容从领域适应和多模态融合两个维度，深入探讨了如何扩展和增强基础视觉模型（特别是SAM）的能力。它不仅展示了多种创新的技术方法，更重要的是，它揭示了未来AI发展的两大趋势："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过提示工程实现高效的领域适应"},{"Type":"NodeText","Data":"，以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"通过组合不同模态的基础模型来构建更强大的通用人工智能系统"},{"Type":"NodeText","Data":"。"}]}]},{"ID":"20250926171101-ed7hoer","Type":"NodeParagraph","Properties":{"id":"20250926171101-ed7hoer","updated":"20250926171101"},"Children":[{"Type":"NodeText","Data":"好的，我们继续。"}]},{"ID":"20250926171101-v7dyise","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926171101-v7dyise","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.7. 各种模型的组合"}]},{"ID":"20250926171101-4eimclz","Type":"NodeParagraph","Properties":{"id":"20250926171101-4eimclz","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"在复杂场景中，SAM的性能通常缺乏鲁棒性，因此需要一种结合了交互式方法和高效工具的新解决方案。如图5所示，这些功能的组合为广泛的领域带来了多种潜力，并在各种任务中展现出卓越的性能。"}]},{"ID":"20250926171101-nrghwxo","Type":"NodeParagraph","Properties":{"id":"20250926171101-nrghwxo","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.7.1. Inpaint Anything (任意修复)"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926171101-gdgv4yz","Type":"NodeParagraph","Properties":{"id":"20250926171101-gdgv4yz","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"图像修复是一个病态的逆问题，涉及到用视觉上合理的结构和纹理来恢复图像中缺失或损坏的部分，在计算机视觉领域已被广泛研究。Inpaint Anything提出了一个基于各种基础模型组合的概念性流程。通过利用这些模型的优势，IA（Inpaint Anything）在图像修复中引入了三个关键功能："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"移除任何东西（Remove Anything）"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"填充任何东西（Fill Anything）"},{"Type":"NodeText","Data":" 和 "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"替换任何东西（Replace Anything）"},{"Type":"NodeText","Data":"。该流程遵循一个精确的序列，如图所示。最初，使用一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"点击提示"},{"Type":"NodeText","Data":"来自动分割指定区域，创建掩码。接下来，利用最先进的修复模型，如LaMa和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"稳定扩散（Stable Diffusion, SD）"},{"Type":"NodeText","Data":" 来填充这些掩码，有效地完成移除任务。在这一步之后，像SD这样强大的AI模型利用一个精心设计的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本提示"},{"Type":"NodeText","Data":"来生成填充或替换空缺所需的特定内容，从而成功地完成整个操作。"}]},{"ID":"20250926171101-jz130oa","Type":"NodeParagraph","Properties":{"id":"20250926171101-jz130oa","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"\u003cimg src=\"https://i.imgur.com/7123jYV.png\" alt=\"Meta-Radiology 1 (2023) 100047-9.png\" /\u003e"}]},{"ID":"20250926171101-vfchdbe","Type":"NodeParagraph","Properties":{"id":"20250926171101-vfchdbe","updated":"20250926171104"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图5. 该图展示了一个基于AGI的多模态融合提示工程框架。"},{"Type":"NodeText","Data":" “提示”一词指代了不同设计模式的位置。通过结合多模态融合和提示工程，该框架允许AGI系统利用跨多种模态的信息，从而达到更高水平的智能和适应性。"}]},{"ID":"20250926171101-d7t24ar","Type":"NodeBlockquote","Properties":{"id":"20250926171101-d7t24ar","updated":"20250926171104"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926171101-1oy1mvx","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926171101-1oy1mvx","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容解析"}]},{"ID":"20250926171101-wonqi93","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926171101-wonqi93","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图5：基于多模型融合的AGI交互框架"}]},{"ID":"20250926171101-szylxla","Type":"NodeList","ListData":{},"Properties":{"id":"20250926171101-szylxla","updated":"20250926171101"},"Children":[{"ID":"20250926171101-gyclsjq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-gyclsjq","updated":"20250926171101"},"Children":[{"ID":"20250926171101-otxzh8i","Type":"NodeParagraph","Properties":{"id":"20250926171101-otxzh8i","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图解分析"},{"Type":"NodeText","Data":": 这张图生动地展示了2.7节讨论的“模型组合”思想，以一个典型的图像编辑任务为例。"}]},{"ID":"20250926171101-pua1cl9","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926171101-pua1cl9","updated":"20250926171101"},"Children":[{"ID":"20250926171101-o3ptv4r","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926171101-o3ptv4r","updated":"20250926171101"},"Children":[{"ID":"20250926171101-3gefuzk","Type":"NodeParagraph","Properties":{"id":"20250926171101-3gefuzk","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第一阶段：交互式分割 (SAM)"}]},{"ID":"20250926171101-uhytrer","Type":"NodeList","ListData":{},"Properties":{"id":"20250926171101-uhytrer","updated":"20250926171101"},"Children":[{"ID":"20250926171101-vxj5y8j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-vxj5y8j","updated":"20250926171101"},"Children":[{"ID":"20250926171101-h8qe1ka","Type":"NodeParagraph","Properties":{"id":"20250926171101-h8qe1ka","updated":"20250926171101"},"Children":[{"Type":"NodeText","Data":"用户在原始"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像 (Image)"},{"Type":"NodeText","Data":" 上提供一个简单的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示 (Prompts)"},{"Type":"NodeText","Data":"，比如点击一下想要移除的物体。"}]}]},{"ID":"20250926171101-2eyckxo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-2eyckxo","updated":"20250926171101"},"Children":[{"ID":"20250926171101-3yg0dru","Type":"NodeParagraph","Properties":{"id":"20250926171101-3yg0dru","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAM"},{"Type":"NodeText","Data":" 模型接收到图像和提示，精确地分割出该物体，生成一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"有效掩码 (Valid mask)"},{"Type":"NodeText","Data":"。这一步的核心是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确的交互式定位"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250926171101-any5may","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926171101-any5may","updated":"20250926171101"},"Children":[{"ID":"20250926171101-6z5i0b7","Type":"NodeParagraph","Properties":{"id":"20250926171101-6z5i0b7","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"第二阶段：智能生成与修复 (LaMa, SD, CLIP, ChatGPT)"}]},{"ID":"20250926171101-by3ubag","Type":"NodeList","ListData":{},"Properties":{"id":"20250926171101-by3ubag","updated":"20250926171101"},"Children":[{"ID":"20250926171101-uz4os9v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-uz4os9v","updated":"20250926171101"},"Children":[{"ID":"20250926171101-mlnseyy","Type":"NodeParagraph","Properties":{"id":"20250926171101-mlnseyy","updated":"20250926171101"},"Children":[{"Type":"NodeText","Data":"这个掩码区域现在需要被处理（例如，移除并填充背景，或者替换成新物体）。"}]}]},{"ID":"20250926171101-ljd8iy7","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-ljd8iy7","updated":"20250926171101"},"Children":[{"ID":"20250926171101-smxi7xf","Type":"NodeParagraph","Properties":{"id":"20250926171101-smxi7xf","updated":"20250926171101"},"Children":[{"Type":"NodeText","Data":"这里引入了一个强大的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成模型“全家桶”"},{"Type":"NodeText","Data":"："}]},{"ID":"20250926171101-k4jc9ar","Type":"NodeList","ListData":{},"Properties":{"id":"20250926171101-k4jc9ar","updated":"20250926171101"},"Children":[{"ID":"20250926171101-v2m1k2n","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-v2m1k2n","updated":"20250926171101"},"Children":[{"ID":"20250926171101-68367g8","Type":"NodeParagraph","Properties":{"id":"20250926171101-68367g8","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LaMa / Stable Diffusion (SD)"},{"Type":"NodeText","Data":": 负责底层的图像生成和修复，确保填充或替换的内容在纹理、光照上与周围环境无缝衔接。"}]}]},{"ID":"20250926171101-9pxkm9l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-9pxkm9l","updated":"20250926171101"},"Children":[{"ID":"20250926171101-gov549g","Type":"NodeParagraph","Properties":{"id":"20250926171101-gov549g","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CLIP / ChatGPT"},{"Type":"NodeText","Data":": 负责"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"理解用户的意图"},{"Type":"NodeText","Data":"。用户会提供第二个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示 (Prompts)"},{"Type":"NodeText","Data":"，这次是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本提示"},{"Type":"NodeText","Data":"，比如“a blue sky”或者“a cute cat”。CLIP帮助SD理解文本与图像内容的关系，而ChatGPT可以用来生成更丰富、更自然的文本提示。"}]}]}]}]},{"ID":"20250926171101-k473luk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-k473luk","updated":"20250926171101"},"Children":[{"ID":"20250926171101-yf5y3in","Type":"NodeParagraph","Properties":{"id":"20250926171101-yf5y3in","updated":"20250926171101"},"Children":[{"Type":"NodeText","Data":"这些模型协同工作，根据文本提示在掩码区域生成新的内容，完成最终的编辑。"}]}]}]}]}]}]},{"ID":"20250926171101-mrniyk9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-mrniyk9","updated":"20250926171101"},"Children":[{"ID":"20250926171101-78c335b","Type":"NodeParagraph","Properties":{"id":"20250926171101-78c335b","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心结论"},{"Type":"NodeText","Data":": 这张图完美诠释了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“各司其职，强强联合”"},{"Type":"NodeText","Data":"的思想。SAM负责"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“看”和“定位”"},{"Type":"NodeText","Data":"（视觉感知与交互），而SD、CLIP、LLM等模型负责"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“想”和“画”"},{"Type":"NodeText","Data":"（语义理解与内容生成）。通过"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示 (Prompts)"},{"Type":"NodeText","Data":" 这个统一的接口，将不同能力的模型串联起来，形成一个功能远超任何单个模型的强大AIGC（AI Generated Content）系统。这代表了未来AGI系统的主流构建范式——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"基于基础模型的组合式创新"},{"Type":"NodeText","Data":"。"}]}]}]}]},{"ID":"20250926171101-d8ph9yh","Type":"NodeParagraph","Properties":{"id":"20250926171101-d8ph9yh","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.7.2. Edit Everything (任意编辑)"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926171101-brrpxjd","Type":"NodeParagraph","Properties":{"id":"20250926171101-brrpxjd","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"Edit Everything引入了一个结合了SAM、CLIP和SD的生成系统，用于在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像和文本输入的双重引导下"},{"Type":"NodeText","Data":"编辑图像。原始图像首先使用SAM被分割成多个片段。然后，图像编辑过程由"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"文本提示"},{"Type":"NodeText","Data":"引导，使得源图像能够转换为目标图像，与提供的源和目标提示对齐。"}]},{"ID":"20250926171101-r2g3rtm","Type":"NodeParagraph","Properties":{"id":"20250926171101-r2g3rtm","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.7.3. SAM-Track"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926171101-idg78q2","Type":"NodeParagraph","Properties":{"id":"20250926171101-idg78q2","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"SAM-Track提出了一个视频分割框架，它结合了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Grounding-DINO"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DeAOT"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAM"},{"Type":"NodeText","Data":"，以实现跨多种模态的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交互式和自动化的目标跟踪与分割"},{"Type":"NodeText","Data":"。该框架在视频的第一帧中集成了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"点击提示、框提示和文本提示"},{"Type":"NodeText","Data":"等交互式提示，以引导SAM的分割过程。随后，在接下来的帧中利用文本提示进行进一步的结果优化。这个多功能的框架在广泛的领域中都有应用，包括无人机技术、自动驾驶、医学成像、增强现实和生物分析。"}]},{"ID":"20250926171101-1vo2lgy","Type":"NodeParagraph","Properties":{"id":"20250926171101-1vo2lgy","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"***** "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"2.7.4. Explain Any Concept (解释任何概念)"},{"Type":"NodeText","Data":" *****"}]},{"ID":"20250926171101-njmwvfv","Type":"NodeParagraph","Properties":{"id":"20250926171101-njmwvfv","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"Explain Any Concept提出了一个基于三个流程来解释概念的新方法。虽然SAM在实例分割方面表现出色，但将其集成到"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可解释性AI（Explainable AI, XAI）"},{"Type":"NodeText","Data":" 中会带来过度复杂的计算挑战。Explain Any Concept通过使用SAM进行初始分割，并引入一个"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"代理模型（surrogate model）"},{"Type":"NodeText","Data":" 来进行高效解释，从而解决了这个问题。该过程的第一阶段使用SAM进行实例分割，然后利用一个代理模型来近似目标深度神经网络。在最后阶段，训练好的网络被应用于第一阶段获得的结果，从而促进对模型预测的有效解释。"}]},{"ID":"20250926171101-q8xg68s","Type":"NodeParagraph","Properties":{"id":"20250926171101-q8xg68s","updated":"20250926171104"},"Children":[{"Type":"NodeText","Data":"在计算机视觉和AGI这个不断发展的领域，像Inpaint Anything、Edit Everything、SAM-Track和Explain Any Concept这样的方法，展示了基础模型集成和基于提示的交互性的和谐融合，每种方法都为独特的挑战量身定制，但都遵循着共同的原则。这些方法共同展示了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"组合各种AI模型（如SAM、CLIP和稳定扩散）的力量"},{"Type":"NodeText","Data":"，利用它们的优势来创建多功能和适应性强的系统。例如，Inpaint Anything擅长图像修复，具有移除、填充和替换图像部分的功能，而Edit Everything通过合并图像和文本输入来引导转换，从而改变了图像编辑的领域。另一方面，SAM-Track为视频分割和目标跟踪带来了创新，适用于从自动驾驶到医学成像的各种领域，展示了跨视频帧动态使用交互式提示。同样，Explain Any Concept涉足可解释性AI领域，使用SAM进行分割和一个代理模型来揭开AI决策的神秘面纱。这些方法不仅突显了AGI在各种背景下不断扩展的能力，而且强调了向更"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"用户引导、交互式系统"},{"Type":"NodeText","Data":"的转变，这些系统能够适应广泛的应用，从增强视觉内容到为AGI的工作提供更深的见解。"}]},{"ID":"20250926171101-yqp5ml1","Type":"NodeBlockquote","Properties":{"id":"20250926171101-yqp5ml1","updated":"20250926171104"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926171101-pd19u52","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926171101-pd19u52","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析 (第二部分 2.7 及图5)"}]},{"ID":"20250926171101-pk6gi29","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926171101-pk6gi29","updated":"20250926171101"},"Children":[{"ID":"20250926171101-o7riqlq","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926171101-o7riqlq","updated":"20250926171101"},"Children":[{"ID":"20250926171101-ltdb925","Type":"NodeParagraph","Properties":{"id":"20250926171101-ltdb925","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心范式：组合式创新 (Compositional Innovation)"},{"Type":"NodeText","Data":": 这一部分是全篇综述的高潮，它揭示了当前AGI发展的最前沿范式——"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"不再依赖单个“万能”模型，而是像搭乐高一样，将多个具有不同专长的基础模型（Foundation Models）组合起来，形成一个功能远超各部分之和的强大系统"},{"Type":"NodeText","Data":"。"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图5"},{"Type":"NodeText","Data":" 便是这一思想的完美图解。"}]}]},{"ID":"20250926171101-nzd86wj","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926171101-nzd86wj","updated":"20250926171101"},"Children":[{"ID":"20250926171101-yhwmdnn","Type":"NodeParagraph","Properties":{"id":"20250926171101-yhwmdnn","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“明星组合”与各自的角色"},{"Type":"NodeText","Data":": 文章介绍的几个项目（Inpaint Anything, Edit Everything, SAM-Track）反复出现了一个“明星组合”："}]},{"ID":"20250926171101-411hik7","Type":"NodeList","ListData":{},"Properties":{"id":"20250926171101-411hik7","updated":"20250926171101"},"Children":[{"ID":"20250926171101-alidk3s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-alidk3s","updated":"20250926171101"},"Children":[{"ID":"20250926171101-3cj9cfe","Type":"NodeParagraph","Properties":{"id":"20250926171101-3cj9cfe","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SAM"},{"Type":"NodeText","Data":": 扮演"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“眼睛”和“手指”"},{"Type":"NodeText","Data":"的角色，负责"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉感知"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"交互式定位"},{"Type":"NodeText","Data":"。它能精确地理解用户的意图（通过点、框等提示）并分割出任意物体。"}]}]},{"ID":"20250926171101-awvd1so","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-awvd1so","updated":"20250926171101"},"Children":[{"ID":"20250926171101-puk4v0f","Type":"NodeParagraph","Properties":{"id":"20250926171101-puk4v0f","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CLIP"},{"Type":"NodeText","Data":": 扮演"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“翻译官”"},{"Type":"NodeText","Data":"的角色，负责"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"连接文本和视觉"},{"Type":"NodeText","Data":"。它能理解文本提示（如“一只猫”）与图像内容的对应关系，是多模态理解的桥梁。"}]}]},{"ID":"20250926171101-pbp4fw0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-pbp4fw0","updated":"20250926171101"},"Children":[{"ID":"20250926171101-zdc3btr","Type":"NodeParagraph","Properties":{"id":"20250926171101-zdc3btr","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Stable Diffusion (SD)"},{"Type":"NodeText","Data":": 扮演"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“画笔”"},{"Type":"NodeText","Data":"的角色，是强大的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"内容生成器"},{"Type":"NodeText","Data":"。它能根据文本提示（通过CLIP的引导）在指定区域（通过SAM的定位）绘制出逼真的图像内容。"}]}]},{"ID":"20250926171101-3uhr3p1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-3uhr3p1","updated":"20250926171101"},"Children":[{"ID":"20250926171101-drd4yqy","Type":"NodeParagraph","Properties":{"id":"20250926171101-drd4yqy","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"LLMs (如ChatGPT)"},{"Type":"NodeText","Data":": 扮演"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“大脑”"},{"Type":"NodeText","Data":"的角色，负责"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高级语义理解和规划"},{"Type":"NodeText","Data":"。它可以与用户进行更复杂的对话，生成更丰富、更有创意的文本提示，甚至规划整个编辑流程。"}]}]}]}]},{"ID":"20250926171101-bk6hmul","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926171101-bk6hmul","updated":"20250926171101"},"Children":[{"ID":"20250926171101-f9mue91","Type":"NodeParagraph","Properties":{"id":"20250926171101-f9mue91","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“提示”作为通用语言"},{"Type":"NodeText","Data":": 在这种组合式系统中，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“提示 (Prompt)”"},{"Type":"NodeText","Data":" 成为了不同模型之间沟通的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“通用语言”和“标准接口”"},{"Type":"NodeText","Data":"。用户通过视觉提示与SAM交互，通过文本提示与CLIP/SD/LLM交互。一个复杂的任务被分解为一系列通过提示串联起来的子任务，每个子任务由最擅长的模型来完成。"}]}]},{"ID":"20250926171101-4fcqgrj","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250926171101-4fcqgrj","updated":"20250926171101"},"Children":[{"ID":"20250926171101-ylq02is","Type":"NodeParagraph","Properties":{"id":"20250926171101-ylq02is","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"应用的广度与深度"},{"Type":"NodeText","Data":": 这种组合范式极大地拓展了AI的应用边界。"}]},{"ID":"20250926171101-6sh0bsv","Type":"NodeList","ListData":{},"Properties":{"id":"20250926171101-6sh0bsv","updated":"20250926171101"},"Children":[{"ID":"20250926171101-tazfm0v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-tazfm0v","updated":"20250926171101"},"Children":[{"ID":"20250926171101-e3k4m6q","Type":"NodeParagraph","Properties":{"id":"20250926171101-e3k4m6q","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"广度"},{"Type":"NodeText","Data":": 从静态的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像编辑"},{"Type":"NodeText","Data":" (Inpaint/Edit Anything) 拓展到了动态的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视频处理"},{"Type":"NodeText","Data":" (SAM-Track)。"}]}]},{"ID":"20250926171101-9sv795h","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171101-9sv795h","updated":"20250926171101"},"Children":[{"ID":"20250926171101-2k6qcwq","Type":"NodeParagraph","Properties":{"id":"20250926171101-2k6qcwq","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度"},{"Type":"NodeText","Data":": 从“做什么”（编辑、跟踪）深入到了“为什么这么做”，即"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可解释性AI"},{"Type":"NodeText","Data":" (Explain Any Concept)。后者通过引入代理模型来解释SAM这类复杂模型的决策过程，这对于AI在关键领域的安全应用至关重要。"}]}]}]}]},{"ID":"20250926171101-ivmqcde","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NS4=","Num":5},"Properties":{"id":"20250926171101-ivmqcde","updated":"20250926171101"},"Children":[{"ID":"20250926171101-tiz56la","Type":"NodeParagraph","Properties":{"id":"20250926171101-tiz56la","updated":"20250926171101"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"迈向真正的AGI"},{"Type":"NodeText","Data":": 这种"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“用户引导、多模态交互、模型协同”"},{"Type":"NodeText","Data":"的范式，被认为是通往更通用人工智能（AGI）的坚实一步。它使得AI系统不再是一个被动执行指令的黑箱，而是一个可以与用户进行灵活、深入交互的创意伙伴和问题解决者。"}]}]}]},{"ID":"20250926171101-g5i0bkw","Type":"NodeParagraph","Properties":{"id":"20250926171101-g5i0bkw","updated":"20250926171101"},"Children":[{"Type":"NodeText","Data":"总结而言，2.7节所描述的“模型组合”是提示工程发展的必然结果和更高阶的体现。它不仅展示了令人惊叹的应用效果，更重要的是，它为构建下一代通用、智能、可交互的AI系统提供了一个清晰、可行的蓝图。"}]}]},{"ID":"20250926171158-iqfknja","Type":"NodeParagraph","Properties":{"id":"20250926171158-iqfknja","updated":"20250926171158"},"Children":[{"Type":"NodeText","Data":"好的，我们继续最后一部分的翻译和解析。"}]},{"ID":"20250926171158-4jixbi9","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926171158-4jixbi9","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3. 结果与讨论"}]},{"ID":"20250926171158-vc9i3dr","Type":"NodeParagraph","Properties":{"id":"20250926171158-vc9i3dr","updated":"20250926171200"},"Children":[{"Type":"NodeText","Data":"随着强大的大型视觉模型（LVMs）的持续进步，提示在这些模型中的重要性变得更加突出。设计精心制作的提示以有效引导下游任务，已成为解决此问题的一个新兴途径。然而，通用人工智能（AGI）的性能仍然受到其对"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"领域特定知识"},{"Type":"NodeText","Data":"依赖的限制。为了克服这一限制，未来的努力应侧重于通过整合"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多样化和全面的数据集"},{"Type":"NodeText","Data":"、采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"跨学科方法"},{"Type":"NodeText","Data":"以及促进来自不同领域专家之间的富有成效的合作来"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩展知识的广度"},{"Type":"NodeText","Data":"。这些努力将有助于增强AI系统的能力，并以更全面的方式解决与利用提示相关的挑战。"}]},{"ID":"20250926171158-s8e79is","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926171158-s8e79is","updated":"20250926171200"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.1. 大型视觉模型的适配"}]},{"ID":"20250926171158-5tx7y7t","Type":"NodeParagraph","Properties":{"id":"20250926171158-5tx7y7t","updated":"20250926171200"},"Children":[{"Type":"NodeText","Data":"大型视觉模型（LVMs）已成为人工智能领域的一个突出趋势，这促使我们需要解决如何有效使这些模型适应下游任务的挑战。几种关键技术为此提供了潜在的解决方案。"}]},{"ID":"20250926171158-0sxh6ap","Type":"NodeParagraph","Properties":{"id":"20250926171158-0sxh6ap","updated":"20250926171200"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示微调"},{"Type":"NodeText","Data":"是AGI中的一个基本工具，在使模型能更好地应用于下游任务方面起着至关重要的作用。通过设计合适的提示示例和预定义输入，可以引导模型更好地与目标任务对齐，从而通过微调增强性能，以完成改进的下游任务。"}]},{"ID":"20250926171158-m8jqn95","Type":"NodeParagraph","Properties":{"id":"20250926171158-m8jqn95","updated":"20250926171200"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习"},{"Type":"NodeText","Data":"使模型能够通过利用从实验和错误中获得的反馈信号来持续学习和调整其参数，从而最大化其性能。当与提示微调相结合时，强化学习在优化自适应模型性能方面表现出卓越的有效性。"}]},{"ID":"20250926171158-m225a75","Type":"NodeParagraph","Properties":{"id":"20250926171158-m225a75","updated":"20250926171200"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"适配器模块"},{"Type":"NodeText","Data":"通过引入小型的功能性模块，使得在大型模型中能够对特定任务进行高效调整。这种方法选择性地只修改模型结构的某些部分，而无需对整体架构进行重大更改。在提示工程中整合适配器模块，不仅保持了较大型模型的完整性，而且引入了任务特定的功能结构，从而实现了更有针对性的提示构建。"}]},{"ID":"20250926171158-75zibik","Type":"NodeParagraph","Properties":{"id":"20250926171158-75zibik","updated":"20250926171200"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识蒸馏"},{"Type":"NodeText","Data":"是一种将知识从一个大型模型转移到一个较小模型的技术。关键在于紧凑地表示来自较大模型的知识并将其应用于新任务，同时保留基本的性能和泛化能力，从而促进在新的环境中的自然部署。虽然提示微-调是大型模型的自然选择，但提示工程在较小模型中的有效性仍然是一个悬而未决的问题。知识蒸馏可以通过转移大型模型的基础知识和泛化能力来帮助将提示应用于小型模型，从而实现小型模型的本地部署。"}]},{"ID":"20250926171158-j8bqx3k","Type":"NodeParagraph","Properties":{"id":"20250926171158-j8bqx3k","updated":"20250926171200"},"Children":[{"Type":"NodeText","Data":"研究人员已经设计出一系列模型适配方法，这些方法在不同领域已被证明是有效的。这些方法包括诸如迁移学习、领域自适应和微调等技术。虽然这些方法各有其优点，但它们可能无法完全解决不同领域所带来的独特挑战。随着对有效模型适配的追求不断继续，未来有望在跨不同领域将模型应用于特定任务方面取得更大成就。"}]},{"ID":"20250926171158-ac3kri7","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926171158-ac3kri7","updated":"20250926171200"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.2. 视觉AGI的挑战与思考"}]},{"ID":"20250926171158-k145rip","Type":"NodeParagraph","Properties":{"id":"20250926171158-k145rip","updated":"20250926171200"},"Children":[{"Type":"NodeText","Data":"在NLP领域进步的引领下，为大型模型开发一个统一的框架，有望成为未来视觉模型的关键任务。然而，与NLP取得的进展形成鲜明对比的是，大型模型在计算机视觉领域面临的挑战更为严峻。"}]},{"ID":"20250926171158-0vn49e8","Type":"NodeParagraph","Properties":{"id":"20250926171158-0vn49e8","updated":"20250926171200"},"Children":[{"Type":"NodeText","Data":"首先，实现AGI的一个关键方面在于与"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"环境的互动参与"},{"Type":"NodeText","Data":"和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"最大化奖励"},{"Type":"NodeText","Data":"。虽然NLP受益于明确定义的学习环境，能够通过多轮对话进行文本交流和任务完成，但计算机视觉领域"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺乏一条清晰的路径和互动环境"},{"Type":"NodeText","Data":"。为计算机视觉构建一个现实的环境被证明是极其困难的，因为这与人机交互相关的成本和风险很高。另一方面，构建一个虚拟环境在将训练好的智能体转移到现实世界场景时也带来了挑战。"}]},{"ID":"20250926171158-qttp3ff","Type":"NodeParagraph","Properties":{"id":"20250926171158-qttp3ff","updated":"20250926171200"},"Children":[{"Type":"NodeText","Data":"此外，与文本空间相比，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像空间表现出更强的语义稀疏性、领域变异性和无限的粒度"},{"Type":"NodeText","Data":"。在NLP的巨大成功基础上，为实现计算机视觉统一范式的基础已经建立。未来的研究工作可以从大型NLP模型的发展中汲取灵感，采用"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成式预训练"},{"Type":"NodeText","Data":"技术结合通过指令进行微调，以实现计算机视觉的统一方法。此外，整合NLP的能力，并将多模态技术应用于LVMs，可以实现语言和图像的融合，作为一种用于生成式预训练的交互模式。这反过来又为作为一种新颖的预训练交互模式的人机交互开辟了新途径。"}]},{"ID":"20250926171158-uzduwzd","Type":"NodeHeading","HeadingLevel":5,"Properties":{"id":"20250926171158-uzduwzd","updated":"20250926171200"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"3.3. 跨多个领域的应用"}]},{"ID":"20250926171158-larzzoo","Type":"NodeParagraph","Properties":{"id":"20250926171158-larzzoo","updated":"20250926171200"},"Children":[{"Type":"NodeText","Data":"视觉提示和大型视觉模型已经在视觉理解和分析至关重要的领域取得了显著进展。例如，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示驱动的SAM"},{"Type":"NodeText","Data":"已经在诸如"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"医学成像、农业、图像编辑、目标检测、视听定位"},{"Type":"NodeText","Data":"等领域开启了新的机遇。在医学领域，诸如分割掩码、边界框和关键点等视觉提示被用来帮助检测疾病、量化病变严重程度以及分析医学扫描。例如，在放射肿瘤学的典型治疗部位，Zhang等人比较了临床手动勾画和使用带框提示的SAM进行自动分割的Dice和Jaccard结果，并证明了SAM在放射治疗自动分割方面具有强大的泛-化能力。在农业领域，视觉提示可用于监测作物生长、检测杂草或害虫以及估计作物产量。Yang等人评估了SAM在代表性鸡分割任务上的零样本分割性能，并证明基于SAM的目标跟踪可以为肉鸡的行为和运动模式提供有价值的数据。"}]},{"ID":"20250926171158-vztvvjn","Type":"NodeParagraph","Properties":{"id":"20250926171158-vztvvjn","updated":"20250926171200"},"Children":[{"Type":"NodeText","Data":"通过利用LVM提示的进步，众多领域将从其整合中受益。对齐语言和视觉数据的能力为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"改进医疗诊断"},{"Type":"NodeText","Data":"打开了大门，使医疗保健提供者能够从基于图像的信息中获得有价值的见解。此外，LVM提示的灵活性在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自然图像领域"},{"Type":"NodeText","Data":"实现了变革性的应用，促进了创造性的图像处理，并赋予用户强大的编辑能力。此外，在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视频跟踪"},{"Type":"NodeText","Data":"中利用提示为无缝的人机交互引入了新的可能性，实现了增强的目标检测和精确的视听定位。"}]},{"ID":"20250926171158-j8ywnbs","Type":"NodeParagraph","Properties":{"id":"20250926171158-j8ywnbs","updated":"20250926171200"},"Children":[{"Type":"NodeText","Data":"随着该领域研究的进展，预计LVM提示的日益普及将"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"彻底改变各个行业和领域"},{"Type":"NodeText","Data":"。由提示促进的语言和视觉模型之间的协同作用，为跨多个领域的新颖解决方案、提高效率和增强用户体验铺平了道路。总而言之，视觉提示为跨领域的视觉理解提供了标注数据。它们提供上下文和指导，增强了机器解释视觉数据的能力。随着机器学习使用的增加，视觉提示已成为优化视觉识别系统的重要工具。"}]},{"ID":"20250926171158-at3ktcy","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926171158-at3ktcy","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"4. 结论"}]},{"ID":"20250926171158-p8ny1hw","Type":"NodeParagraph","Properties":{"id":"20250926171158-p8ny1hw","updated":"20250926171159"},"Children":[{"Type":"NodeText","Data":"本综述文章对计算机视觉领域内视觉提示工程取得的重大进展进行了富有洞察力和彻底的审视。它深入探讨了视觉提示，特别是那些与基于视觉模型的提示工程方法相关的提示，以及它们与AGI模型的集成，展示了这些进步如何正在彻底改变该领域。该研究从多个角度审视了提示对下游任务的变革性影响，突出了它们解锁和增强大型模型新兴能力的能力。此外，文章深入讨论了视觉提示工程在计算机视觉内各种场景和领域中的关键作用和功效。它强调了这种方法的巨大潜力和变革力量，将其确立为该学科未来突破的基础。最后，文章揭示了视觉提示工程的激动人心的前景。它将此方法确定为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"从根本上改变计算机视觉、增强现有模型和催生创新应用"},{"Type":"NodeText","Data":"的关键。视觉提示工程重新定义计算机视觉领域的潜力被强调，为研究和发展指明了新的方向。鉴于视觉提示在各种计算机视觉应用中的重要性日益增加，本研究的见解和发现具有特别的现实意义和及时性，代表了对该领域的重大贡献。"}]},{"ID":"20250926171158-6kmo642","Type":"NodeParagraph","Properties":{"id":"20250926171158-6kmo642","updated":"20250926171159"},"Children":[{"Type":"NodeText","Data":"在现有研究的基础上，很明显，提示工程尽管在某些领域取得了实质性进展，但在其应用于基础建模方面仍遇到一些挑战。一个突出的挑战是"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"视觉提示工程有限的泛化能力"},{"Type":"NodeText","Data":"。虽然它在特定领域表现出色，但其在现实世界应用中新颖和不熟悉场景下的有效性尚未完全实现。这一限制凸显了需要进一步探索模型如何能更有效地适应处理新的和意想不到的情况。此外，"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"提示的设计和可解释性"},{"Type":"NodeText","Data":"，特别是自动化提示，构成了另一个重大挑战。当前模型可以响应复杂的提示，但理解这些响应的潜在机制以及优化提示以获得更精确和可靠的结果，仍然是一个很大程度上未被探索的领域。这一差距突显了需要继续进行研究，使提示工程更加透明和可解释。尽管存在这些挑战，提示工程为计算机视觉领域引入了创新的视角和方法。它强调了模型交互的重要性，并为未来的探索开辟了大量的可能性。展望未来研究的轨迹，人们强烈期望这些挑战不仅会得到解决，而且进一步的调查还将揭示提示工程更大的潜力。这些进步对于利用基础模型的全部能力至关重要，从而推动计算机视觉领域的重大进展。"}]},{"ID":"20250926171158-xldp21u","Type":"NodeBlockquote","Properties":{"id":"20250926171158-xldp21u","updated":"20250926171159"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e"},{"ID":"20250926171158-qqta46n","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250926171158-qqta46n","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"综合性解析 (第三、四部分：讨论与结论)"}]},{"ID":"20250926171158-juqzwf1","Type":"NodeList","ListData":{"Typ":1},"Properties":{"id":"20250926171158-juqzwf1","updated":"20250926171158"},"Children":[{"ID":"20250926171158-s9c00z3","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"MS4=","Num":1},"Properties":{"id":"20250926171158-s9c00z3","updated":"20250926171158"},"Children":[{"ID":"20250926171158-yjgpjxe","Type":"NodeParagraph","Properties":{"id":"20250926171158-yjgpjxe","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"核心议题：模型适配 (Model Adaptation)"},{"Type":"NodeText","Data":": 3.1节是全篇技术部分的总结和升华。它将前面提到的各种具体方法（提示微调、适配器等）归纳为更宏观的"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“模型适配”"},{"Type":"NodeText","Data":"策略。文章还前瞻性地指出了"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"强化学习"},{"Type":"NodeText","Data":"（通过与环境交互试错来优化提示）和"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"知识蒸馏"},{"Type":"NodeText","Data":"（将大模型的提示能力迁移到小模型以实现本地化部署）等更前沿的方向。这表明，如何让庞大的基础模型"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"高效、低成本、智能化"},{"Type":"NodeText","Data":"地服务于千行百业的特定需求，是该领域的核心议题。"}]}]},{"ID":"20250926171158-b4y3c2u","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"Mi4=","Num":2},"Properties":{"id":"20250926171158-b4y3c2u","updated":"20250926171158"},"Children":[{"ID":"20250926171158-wqk08lr","Type":"NodeParagraph","Properties":{"id":"20250926171158-wqk08lr","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深刻的挑战反思"},{"Type":"NodeText","Data":": 3.2节展现了作者对该领域的深刻洞察和批判性思考。它指出了视觉AGI面临的两个根本性挑战："}]},{"ID":"20250926171158-3292cib","Type":"NodeList","ListData":{},"Properties":{"id":"20250926171158-3292cib","updated":"20250926171158"},"Children":[{"ID":"20250926171158-469bm9d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171158-469bm9d","updated":"20250926171158"},"Children":[{"ID":"20250926171158-in8l903","Type":"NodeParagraph","Properties":{"id":"20250926171158-in8l903","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"缺乏交互环境"},{"Type":"NodeText","Data":": 与NLP可以在虚拟的文本世界中通过对话进行学习不同，视觉AI需要与物理世界交互，这带来了巨大的成本和安全风险。这是从“虚拟”走向“现实”的鸿沟。"}]}]},{"ID":"20250926171158-u9di2hr","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171158-u9di2hr","updated":"20250926171158"},"Children":[{"ID":"20250926171158-zng1p8z","Type":"NodeParagraph","Properties":{"id":"20250926171158-zng1p8z","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图像空间的复杂性"},{"Type":"NodeText","Data":": 相比于离散的文本符号，连续的图像空间具有"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“语义稀疏性、领域变异性和无限粒度”"},{"Type":"NodeText","Data":"，这意味着视觉理解本质上比语言理解更困难、更模糊。"}]}]}]},{"ID":"20250926171158-i1r6hzu","Type":"NodeParagraph","Properties":{"id":"20250926171158-i1r6hzu","updated":"20250926171158"},"Children":[{"Type":"NodeText","Data":"这些反思指出了视觉AGI发展的根本瓶颈，并提出了从NLP成功经验中借鉴（如生成式预训练+指令微调）的可能路径。"}]}]},{"ID":"20250926171158-hhhmmcs","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"My4=","Num":3},"Properties":{"id":"20250926171158-hhhmmcs","updated":"20250926171158"},"Children":[{"ID":"20250926171158-td1cqv8","Type":"NodeParagraph","Properties":{"id":"20250926171158-td1cqv8","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"广阔的应用蓝图"},{"Type":"NodeText","Data":": 3.3节通过在"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"医学、农业、视频跟踪"},{"Type":"NodeText","Data":"等领域的具体应用案例，为读者描绘了一幅激动人心的应用蓝图。它清晰地表明，视觉提示工程不是空中楼阁，而是已经开始在各个关键领域创造实际价值的实用技术。这不仅展示了其巨大的商业潜力，也增强了读者对该技术前景的信心。"}]}]},{"ID":"20250926171158-8x0a54a","Type":"NodeListItem","ListData":{"Typ":1,"Delimiter":46,"Marker":"NC4=","Num":4},"Properties":{"id":"20250926171158-8x0a54a","updated":"20250926171158"},"Children":[{"ID":"20250926171158-n5mxcgh","Type":"NodeParagraph","Properties":{"id":"20250926171158-n5mxcgh","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"结论的总结与展望"},{"Type":"NodeText","Data":": 第4节对全文进行了高度凝练的总结，并对未来进行了展望。它再次强调了提示工程作为"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"“变革性力量”"},{"Type":"NodeText","Data":"的核心地位，同时也坦诚地指出了当前面临的两大主要障碍："}]},{"ID":"20250926171158-bikxzxb","Type":"NodeList","ListData":{},"Properties":{"id":"20250926171158-bikxzxb","updated":"20250926171158"},"Children":[{"ID":"20250926171158-n6xmi2b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171158-n6xmi2b","updated":"20250926171158"},"Children":[{"ID":"20250926171158-85wexlg","Type":"NodeParagraph","Properties":{"id":"20250926171158-85wexlg","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"泛化能力有限"},{"Type":"NodeText","Data":": 在特定领域效果好，但在开放、未知的现实世界中表现仍有待提升。"}]}]},{"ID":"20250926171158-kgpf8pg","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250926171158-kgpf8pg","updated":"20250926171158"},"Children":[{"ID":"20250926171158-tgerf9a","Type":"NodeParagraph","Properties":{"id":"20250926171158-tgerf9a","updated":"20250926171158"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"可解释性差"},{"Type":"NodeText","Data":": 我们知道提示“有效”，但往往不完全清楚“为什么有效”，这使得提示的设计和优化仍带有一定的“炼金术”色彩。"}]}]}]},{"ID":"20250926171158-vqz92mh","Type":"NodeParagraph","Properties":{"id":"20250926171158-vqz92mh","updated":"20250926171158"},"Children":[{"Type":"NodeText","Data":"这个结论部分做到了既肯定成就，又正视问题，为该领域的未来研究设定了清晰的目标："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"追求更强的泛化能力和更好的可解释性"},{"Type":"NodeText","Data":"。"}]}]}]},{"ID":"20250926171158-5hf7kk6","Type":"NodeParagraph","Properties":{"id":"20250926171158-5hf7kk6","updated":"20250926171158"},"Children":[{"Type":"NodeText","Data":"总结而言，这最后一部分内容成功地将文章从具体的技术细节拉回到了宏观的战略层面。它系统地总结了模型适配的方法论，深刻地反思了视觉AGI面临的根本性挑战，生动地描绘了其广阔的应用前景，并以一个客观、前瞻性的结论收尾。这使得整篇综述不仅有技术深度，更有思想高度，为读者提供了对该领域过去、现在和未来的全面理解。"}]}]}]}